{"config":{"lang":["de"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ThemisDB Dokumentation","text":"<p>Willkommen bei ThemisDB. Diese Dokumentation beschreibt Architektur, Datenmodell, Storage &amp; MVCC, Query/AQL, Indexe, Content-Pipeline, Vektor-/Zeitreihenfunktionen, Sicherheit/Governance, APIs, Admin-Tools sowie Betrieb &amp; Performance.</p>"},{"location":"#fur-wen-ist-das-gedacht","title":"F\u00fcr wen ist das gedacht?","text":"<ul> <li>Benutzerinnen/Benutzer: Wie verwende ich AQL und die Server-APIs?</li> <li>Operator/DevOps: Deployment, Betrieb, Observability, Backup/Restore</li> <li>Entwicklerinnen/Entwickler: Architektur, interne Module, Erweiterungspunkte</li> </ul>"},{"location":"#schnellstart","title":"Schnellstart","text":"<ul> <li>Architektur\u00fcberblick: siehe \u201eArchitektur\u201c</li> <li>AQL Einstieg: siehe \u201eQuery &amp; AQL \u2192 AQL Syntax\u201c</li> <li>REST-APIs: siehe \u201eAPIs \u2192 OpenAPI &amp; Endpunkte\u201c</li> </ul>"},{"location":"#aktuelle-schwerpunkte","title":"Aktuelle Schwerpunkte","text":"<ul> <li>TSStore und Aggregationen (Stabilisierung)</li> <li>Tracing/Observability</li> <li>API-Hardening (Keys, Classification, Reports)</li> </ul>"},{"location":"#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ul> <li>OpenAPI um Keys/Classification/Reports aktualisieren</li> <li>Konsolidierung Storage &amp; MVCC-Dokumente</li> <li>Styleguide &amp; Glossar finalisieren</li> </ul>"},{"location":"EXTENDED_COMPLIANCE_FEATURES/","title":"Erweiterte Compliance-Features - Implementierungsroadmap","text":""},{"location":"EXTENDED_COMPLIANCE_FEATURES/#status-code-bereit-integration-ausstehend","title":"Status: Code bereit, Integration ausstehend","text":"<p>Alle erweiterten Compliance-Features aus den Strategiedokumenten sind implementiert, aber noch nicht in CMake/Build integriert (Breaking Changes vermeiden).</p>"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#implementierte-features","title":"\u2705 Implementierte Features","text":""},{"location":"EXTENDED_COMPLIANCE_FEATURES/#1-saga-log-pki-signierung-manipulationsschutz","title":"1. SAGA-Log PKI-Signierung (Manipulationsschutz)","text":"<p>Dateien: - <code>include/utils/saga_logger.h</code> - <code>src/utils/saga_logger.cpp</code></p> <p>Features: - Batch-Collection: 1000 SAGA-Steps oder 5-Minuten-Intervalle - Encrypt-then-Sign: AES-256-GCM + RSA-SHA256 PKI-Signatur - Ciphertext-Hashing: Manipulationsschutz durch Hash-\u00fcber-Ciphertext - Verification: <code>verifyBatch()</code> pr\u00fcft Integrit\u00e4t + Signatur - Decryption: <code>loadBatch()</code> l\u00e4dt und entschl\u00fcsselt nur bei g\u00fcltiger Signatur</p> <p>Workflow:</p> <pre><code>// Setup\nSAGALoggerConfig cfg;\ncfg.batch_size = 1000;\ncfg.batch_interval = std::chrono::minutes(5);\ncfg.encrypt_then_sign = true;\ncfg.key_id = \"saga_lek\"; // Log Encryption Key\n\nSAGALogger logger(field_enc, pki_client, cfg);\n\n// Log SAGA steps\nSAGAStep step;\nstep.saga_id = \"tx_001\";\nstep.step_name = \"create_user\";\nstep.action = \"forward\";\nstep.payload = {{\"email\", \"user@example.com\"}};\nlogger.logStep(step);\n\n// Verify integrity\nbool valid = logger.verifyBatch(\"saga_batch_12345\");\nif (valid) {\n    auto steps = logger.loadBatch(\"saga_batch_12345\");\n}\n</code></pre> <p>Compliance: - \u2705 eIDAS-konforme Langzeitarchivierung - \u2705 Manipulationssichere Audit-Logs - \u2705 DSGVO Art. 30 Verarbeitungsverzeichnis</p>"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#2-lek-log-encryption-key-manager","title":"2. LEK (Log Encryption Key) Manager","text":"<p>Dateien: - <code>include/utils/lek_manager.h</code> - <code>src/utils/lek_manager.cpp</code></p> <p>Features: - T\u00e4gliche Rotation: Neuer 256-bit AES-Key pro Tag - KEK-Ableitung: HKDF-SHA256 aus PKI-Zertifikat - Verschl\u00fcsselte Speicherung: LEK mit KEK verschl\u00fcsselt in RocksDB - Historischer Zugriff: <code>getLEKForDate(\"2025-11-01\")</code> f\u00fcr alte Logs</p> <p>Workflow:</p> <pre><code>LEKManager lek_mgr(db, pki_client, key_provider);\n\n// Get current LEK (creates if not exists)\nstd::string lek_id = lek_mgr.getCurrentLEK(); // \"lek_2025-11-01\"\n\n// Use for encryption\nauto encrypted = field_enc-&gt;encrypt(plaintext, lek_id);\n\n// Decrypt historical logs\nstd::string old_lek = lek_mgr.getLEKForDate(\"2025-10-15\");\nauto decrypted = field_enc-&gt;decrypt(old_blob, old_lek);\n\n// Force rotation\nlek_mgr.rotate(); // Generates new LEK for today\n</code></pre> <p>Key-Hierarchie:</p> <pre><code>PKI-Zertifikat\n  \u2514\u2500&gt; KEK (HKDF-SHA256, deterministisch)\n       \u2514\u2500&gt; LEK(date) verschl\u00fcsselt mit KEK\n            \u2514\u2500&gt; Log-Eintr\u00e4ge verschl\u00fcsselt mit LEK\n</code></pre>"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#3-pkikeyprovider-production-key-hierarchie","title":"3. PKIKeyProvider (Production Key-Hierarchie)","text":"<p>Dateien: - <code>include/security/pki_key_provider.h</code> - <code>src/security/pki_key_provider.cpp</code></p> <p>Features: - 3-Tier Hierarchy: KEK \u2192 DEK \u2192 Field-Keys - KEK aus PKI: Abgeleitet von VCC-PKI Service-Zertifikat - DEK-Rotation: Ohne Daten-Re-Encryption m\u00f6glich - Field-Key-Derivation: HKDF per-field, ephemeral</p> <p>Workflow:</p> <pre><code>// Initialize\nauto pki_kp = std::make_shared&lt;PKIKeyProvider&gt;(\n    pki_client,\n    db,\n    \"themis-service\"\n);\n\n// Use as KeyProvider\nFieldEncryption enc(pki_kp);\n\n// Field keys automatically derived from DEK\nauto encrypted = enc.encrypt(data, \"users.email\");\n\n// Rotate DEK (e.g., every 90 days)\nuint32_t new_version = pki_kp-&gt;rotateDEK();\n</code></pre> <p>Vorteile: - \ud83d\udd10 Hardware-backed KEK (via PKI) - \ud83d\udd04 Key-Rotation ohne Downtime - \ud83c\udfaf Per-field Isolation - \ud83d\udce6 Kein manuelles Key-Management</p>"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#4-jwtvalidator-user-context-verschlusselung","title":"4. JWTValidator + User-Context-Verschl\u00fcsselung","text":"<p>Dateien: - <code>include/auth/jwt_validator.h</code> - <code>src/auth/jwt_validator.cpp</code></p> <p>Features: - Keycloak-Integration: OIDC JWT-Token Parsing - Signature-Verification: JWKS-basiert (RS256/ES256) - User-Key-Derivation: HKDF(DEK, salt=user_id, info=field) - Group-Access: Encryption-Context f\u00fcr Gruppenschl\u00fcssel</p> <p>Workflow:</p> <pre><code>JWTValidator validator(\"https://keycloak.vcc.local/.../certs\");\n\n// Parse token from HTTP header\nstd::string token = request.headers[\"Authorization\"];\nauto claims = validator.parseAndValidate(token);\n\n// Derive user-specific key\nauto dek = key_provider-&gt;getKey(\"dek\", 1);\nauto user_key = JWTValidator::deriveUserKey(\n    dek,\n    claims,\n    \"content.blob:abc123\"\n);\n\n// Encrypt with user context\nFieldEncryption enc(key_provider);\nauto encrypted = enc.encryptWithKey(data, user_key);\n\n// Access control\nif (!JWTValidator::hasAccess(claims, encryption_context)) {\n    throw UnauthorizedException();\n}\n</code></pre> <p>Use-Cases: - \ud83d\udc64 Per-User Verschl\u00fcsselung (HR-Daten) - \ud83d\udc65 Group-Shared Keys (Projektteams) - \ud83d\udd12 Zero-Knowledge f\u00fcr andere User</p>"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#5-pii-pseudonymisierung-dsgvo-art-17","title":"5. PII-Pseudonymisierung (DSGVO Art. 17)","text":"<p>Dateien: - <code>include/utils/pii_pseudonymizer.h</code> - <code>src/utils/pii_pseudonymizer.cpp</code></p> <p>Features: - UUID-Replacement: PII \u2192 <code>pii_&lt;uuid&gt;</code> in Entities - Encrypted Mapping: Original verschl\u00fcsselt in separater CF - revealPII(): Audit-geloggter Zugriff auf Original - erasePII(): Mapping l\u00f6schen \u2192 Original unwiederbringlich</p> <p>Workflow:</p> <pre><code>PIIPseudonymizer pseudo(db, field_enc, pii_detector);\n\n// Import mit Auto-Pseudonymisierung\nnlohmann::json data = {\n    {\"name\", \"Max Mustermann\"},\n    {\"email\", \"max@example.com\"},\n    {\"ssn\", \"123-45-6789\"}\n};\n\nauto [pseudonymized, uuids] = pseudo.pseudonymize(data);\n// pseudonymized:\n// {\n//   \"name\": \"pii_7a3f2e1b-...\",\n//   \"email\": \"pii_9b4e3f2c-...\",\n//   \"ssn\": \"pii_1c5d4e3f-...\"\n// }\n\n// Reveal (authorized user only)\nauto original_email = pseudo.revealPII(\"pii_9b4e3f2c-...\", \"admin_user\");\n// \u2192 \"max@example.com\"\n\n// DSGVO Art. 17: Recht auf Vergessenwerden\npseudo.eraseAllPIIForEntity(\"entity_123\");\n// \u2192 UUIDs bleiben, aber Original-Werte gel\u00f6scht\n</code></pre> <p>Compliance: - \u2705 DSGVO Art. 17 (Recht auf Vergessenwerden) - \u2705 DSGVO Art. 25 (Privacy by Design) - \u2705 Audit-Trail f\u00fcr PII-Zugriffe</p>"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#integration-schritte-future-work","title":"\ud83d\udccb Integration-Schritte (Future Work)","text":""},{"location":"EXTENDED_COMPLIANCE_FEATURES/#phase-1-minimal-integration-wochen","title":"Phase 1: Minimal-Integration (Wochen)","text":"<ol> <li>SAGA-Logger aktivieren:    ```cpp    // In main_server.cpp    auto saga_logger = std::make_shared(enc, pki_client, saga_cfg); <p>// Bei Transaction-Commit    SAGAStep step;    step.saga_id = transaction_id;    step.step_name = \"commit\";    saga_logger-&gt;logStep(step);    ```</p> <ol> <li>LEK-Manager f\u00fcr Audit-Logs:    ```cpp    auto lek_mgr = std::make_shared(db, pki_client, key_provider); <p>AuditLoggerConfig audit_cfg;    audit_cfg.key_id = lek_mgr-&gt;getCurrentLEK();    audit_cfg.encrypt_then_sign = true;    ```</p> <ol> <li>Tests anpassen:</li> <li>Namespace-Fixes (<code>storage::RocksDBWrapper</code>)</li> <li>OpenSSL 3.0 HKDF-API (statt veraltete Funktionen)</li> <li>KeyProvider API-Erweiterungen</li> </ol>"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#phase-2-full-integration-monate","title":"Phase 2: Full-Integration (Monate)","text":"<ol> <li>PKIKeyProvider in Produktion:</li> <li>MockKeyProvider \u2192 PKIKeyProvider in Release-Builds</li> <li>VCC-PKI Zertifikat-Bereitstellung</li> <li> <p>DEK-Rotation Background-Worker</p> </li> <li> <p>JWT-basierte Verschl\u00fcsselung:</p> </li> <li>HTTP-Handler mit JWT-Parsing</li> <li>Per-User Field-Keys</li> <li> <p>Access-Control f\u00fcr verschl\u00fcsselte Felder</p> </li> <li> <p>PII-Pseudonymisierung:</p> </li> <li>Import-Pipeline mit Auto-Detection</li> <li>Admin-UI f\u00fcr <code>revealPII()</code> / <code>erasePII()</code></li> <li>DSGVO-Compliance-Reports</li> </ol>"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#test-status","title":"\ud83e\uddea Test-Status","text":"Feature Unit-Tests Integration Status SAGA-Logger \u2705 Geschrieben \u274c Nicht gebaut Code bereit LEK-Manager \u274c TODO \u274c Nicht gebaut Code bereit PKIKeyProvider \u274c TODO \u274c Nicht gebaut Code bereit JWTValidator \u274c TODO \u274c Nicht gebaut Code bereit PII-Pseudo \u274c TODO \u274c Nicht gebaut Code bereit"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#known-issues-todos","title":"\ud83d\udd27 Known Issues &amp; TODOs","text":""},{"location":"EXTENDED_COMPLIANCE_FEATURES/#build-errors-zu-beheben-vor-integration","title":"Build-Errors (zu beheben vor Integration)","text":"<ol> <li>Namespace-Fehler:    ```cpp    // Aktuell:    std::shared_ptr db_ <p>// Sollte sein:    std::shared_ptr db_    ``` <ol> <li>OpenSSL 3.0 HKDF-API:    ```cpp    // Veraltet (OpenSSL 1.1):    EVP_PKEY_CTX_set_hkdf_md(...)</li> </ol> <p>// Neu (OpenSSL 3.0):    EVP_PKEY_CTX_set1_hkdf_md(...)    // oder EVP_KDF API nutzen    ```</p> <ol> <li> <p>KeyProvider API-Mismatch:    <code>cpp    // Fehlt in key_provider.h:    virtual void createKeyFromBytes(const std::string&amp; key_id,                                     const std::vector&lt;uint8_t&gt;&amp; bytes) = 0;    virtual bool hasKey(const std::string&amp; key_id) const = 0;    virtual void deleteKey(const std::string&amp; key_id) = 0;</code></p> </li> <li> <p>FieldEncryption API-Erweiterung:    <code>cpp    // Fehlt:    std::string decrypt(const EncryptedBlob&amp; blob);    std::shared_ptr&lt;KeyProvider&gt; getKeyProvider() const;</code></p> </li> <li> <p>PIIDetector::detectInJson() Return-Type:    ```cpp    // Aktuell:    std::unordered_map&gt; <p>// Sollte f\u00fcr Iterator sein:    std::vector    ```"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#architektur-todos","title":"Architektur-TODOs","text":"<ul> <li>[ ] RocksDB Column Family f\u00fcr PII-Mapping</li> <li>[ ] SAGA-Log Background-Worker in main_server.cpp</li> <li>[ ] VCC-PKI Service-Zertifikat Provisioning</li> <li>[ ] Keycloak JWKS-Caching + HTTP-Client</li> <li>[ ] Prometheus-Metriken f\u00fcr alle Features</li> </ul>"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#vergleich-basis-vs-erweitert","title":"\ud83d\udcca Vergleich: Basis vs. Erweitert","text":"Feature Basis (JETZT) Erweitert (IMPLEMENTIERT) Audit-Logs Plaintext JSONL \u2705 Encrypt-then-Sign PKI SAGA-Logs Keine Signierung \u2705 Batch-PKI-Signierung Key-Management MockKeyProvider \u2705 PKI-basierte Hierarchie Log-Encryption Statischer Key \u2705 T\u00e4gliche LEK-Rotation User-Context Global Keys \u2705 Per-User/Group Keys PII-Handling Detection only \u2705 UUID-Pseudonymisierung + Erasure DSGVO Art. 17 Manuell \u2705 Automatisiert (erasePII) Compliance Basis \u2705 Enterprise-Grade"},{"location":"EXTENDED_COMPLIANCE_FEATURES/#empfehlung","title":"\ud83c\udfaf Empfehlung","text":"<p>Basis-Features (JETZT) sind produktionsreif f\u00fcr: - \u2705 Standard-Compliance (DSGVO/eIDAS/HGB) - \u2705 Interne Deployments - \u2705 Mittelst\u00e4ndische Unternehmen</p> <p>Erweiterte Features (IMPLEMENTIERT) sind erforderlich f\u00fcr: - \ud83c\udfe6 Finanzsektor (strenge Audit-Anforderungen) - \ud83c\udfe5 Gesundheitswesen (HIPAA + DSGVO) - \ud83c\udfdb\ufe0f Beh\u00f6rden (eIDAS-konforme Langzeitarchivierung) - \ud83c\udf10 Multi-Tenancy mit User-Isolation</p> <p>N\u00e4chster Schritt: Integration als separate CMake-Option:</p> <pre><code>option(THEMIS_EXTENDED_COMPLIANCE \"Enable extended compliance features\" OFF)\n\nif(THEMIS_EXTENDED_COMPLIANCE)\n    target_sources(themis_core PRIVATE\n        src/utils/saga_logger.cpp\n        src/utils/lek_manager.cpp\n        # ...\n    )\nendif()\n</code></pre> <p>Version: 0.2.0-alpha Datum: 1. November 2025 Maintainer: Themis Extended Compliance Team</p>"},{"location":"_inventory/","title":"Doku-Inventar (Stand: 2025-11-02)","text":"<p>Dieser \u00dcberblick listet vorhandene Inhalte, offene Dubletten/Kollisionen und Quick-Wins zur Konsolidierung.</p>"},{"location":"_inventory/#wurzel-docs","title":"Wurzel (docs/)","text":"<ul> <li>Architektur &amp; Modell: <code>architecture.md</code>, <code>base_entity.md</code>, <code>property_graph_model.md</code>, <code>path_constraints.md</code></li> <li>Query/AQL: <code>aql_syntax.md</code>, <code>aql_explain_profile.md</code>, <code>cursor_pagination.md</code>, <code>recursive_path_queries.md</code>, <code>temporal_graphs.md</code>, <code>temporal_time_range_queries.md</code>, <code>semantic_cache.md</code></li> <li>Storage &amp; MVCC: <code>time_series.md</code>, <code>mvcc_design.md</code>, <code>transactions.md</code>, <code>memory_tuning.md</code>, <code>compression_benchmarks.md</code>, <code>compression_strategy.md</code>, <code>chain_of_thought_storage.md</code></li> <li>Indexe &amp; Stats: <code>indexes.md</code>, <code>index_stats_maintenance.md</code></li> <li>Content: <code>content_architecture.md</code></li> <li>Sicherheit &amp; Compliance: <code>encryption_strategy.md</code>, <code>encryption_deployment.md</code>, <code>column_encryption.md</code>, <code>pii_detection_engines.md</code>, <code>pii_engine_signing.md</code>, <code>security_hardening_guide.md</code>, <code>security_audit_checklist.md</code>, <code>compliance_audit.md</code>, <code>compliance_governance_strategy.md</code>, <code>compliance_integration.md</code>, <code>governance_usage.md</code>, <code>EXTENDED_COMPLIANCE_FEATURES.md</code></li> <li>Deployment &amp; Ops: <code>deployment.md</code>, <code>tracing.md</code></li> <li>Admin-Tools: <code>admin_tools_*.md</code></li> <li>Sonstiges: <code>sprint_a_plan.md</code>, <code>vector_ops.md</code>, <code>gnn_embeddings.md</code>, <code>openapi.yaml</code></li> </ul>"},{"location":"_inventory/#unterordner","title":"Unterordner","text":"<ul> <li><code>content/</code>: <code>ingestion.md</code>, <code>geo_processor_design.md</code>, <code>image_processor_design.md</code></li> <li><code>ingestion/</code>: <code>json_ingestion_spec.md</code></li> <li><code>search/</code>: <code>hybrid_search_design.md</code>, <code>pagination_benchmarks.md</code></li> <li><code>storage/</code>: <code>geo_relational_schema.md</code></li> <li><code>security/</code>: (leer)</li> </ul>"},{"location":"_inventory/#mogliche-dublettenkollisionen","title":"M\u00f6gliche Dubletten/Kollisionen","text":"<ul> <li>Change Data Capture: <code>cdc.md</code> vs. <code>change_data_capture.md</code> \u2192 zusammenf\u00fchren (eine Datei, Kurzform alias im Navi)</li> <li>Compliance/ Governance: <code>compliance_audit.md</code>, <code>compliance_governance_strategy.md</code>, <code>compliance_integration.md</code>, <code>EXTENDED_COMPLIANCE_FEATURES.md</code>, <code>governance_usage.md</code> \u2192 b\u00fcndeln in Kapitel mit Unterseiten; Duplizite Abschnitte pr\u00fcfen</li> <li>Encryption: <code>encryption_strategy.md</code> vs. <code>encryption_deployment.md</code> vs. <code>column_encryption.md</code> \u2192 klare Abgrenzung (Strategie vs. Deployment vs. Feature)</li> <li>Time-Series: <code>time_series.md</code> referenziert alten API-Stand? \u2192 mit TSStore/API aktualisieren</li> </ul>"},{"location":"_inventory/#quick-wins-empfohlen-zuerst","title":"Quick-Wins (empfohlen zuerst)","text":"<p>1) <code>cdc.md</code> und <code>change_data_capture.md</code> konsolidieren \u2192 <code>change_data_capture.md</code> behalten, altes umleiten/verlinken 2) <code>time_series.md</code> um TSStore API, Aggregationen und Limitierungen erg\u00e4nzen 3) <code>openapi.yaml</code> um Keys/Classification/Reports erweitern (siehe <code>docs/apis/openapi.md</code>) 4) <code>security/</code>-Ordner mit passenden Inhalten f\u00fcllen oder entfernen (derzeit leer) 5) Admin-Tools: <code>admin_tools_*</code> um Screens/Flows aktualisieren</p>"},{"location":"_inventory/#hinweise-zur-navigation-mkdocsyml","title":"Hinweise zur Navigation (mkdocs.yml)","text":"<ul> <li>Navi ist erstellt; nach Konsolidierung Dateipfade ggf. anpassen</li> <li>F\u00fcr OpenAPI-Render (Swagger/Redoc) sp\u00e4ter Plugin erg\u00e4nzen</li> </ul>"},{"location":"admin_tools_admin_guide/","title":"Themis Admin Tools \u2013 Admin-Guide","text":"<p>Dieser Guide richtet sich an Administratoren und beschreibt Bereitstellung, Konfiguration, Betrieb und Troubleshooting der Themis Admin-Tools (Audit, SAGA, Keys, Classification, Reports, Retention, PII).</p>"},{"location":"admin_tools_admin_guide/#architektur-uberblick","title":"Architektur-\u00dcberblick","text":"<ul> <li>Frontend: WPF-Tools mit einheitlichem Themis-Layout</li> <li>Backend: Themis-Server (Boost.Beast HTTP), Standard-Port: 8765</li> <li>Kommunikation: REST-APIs gem\u00e4\u00df <code>docs/openapi.yaml</code> und erg\u00e4nzende SSE-Streams</li> </ul>"},{"location":"admin_tools_admin_guide/#build-deployment","title":"Build &amp; Deployment","text":""},{"location":"admin_tools_admin_guide/#self-contained-publish-win-x64","title":"Self-contained Publish (Win-x64)","text":"<ul> <li>Skript: <code>publish-all.ps1</code></li> <li>Ausgabe: <code>dist/&lt;ProjektName&gt;/</code></li> <li>Beispiel:</li> <li>Release-Build aller Tools ver\u00f6ffentlichen</li> <li>Artefakte in gemeinsamen <code>dist</code>-Ordner ablegen</li> </ul>"},{"location":"admin_tools_admin_guide/#verteilung","title":"Verteilung","text":"<ul> <li>Kopieren Sie die jeweiligen Tool-Ordner aus <code>dist/&lt;ProjektName&gt;/</code> auf Zielsysteme</li> <li>Optional: Code Signing der EXEs (Empfehlung f\u00fcr produktive Nutzung)</li> </ul>"},{"location":"admin_tools_admin_guide/#update-prozess","title":"Update-Prozess","text":"<ul> <li>Erneut <code>publish-all.ps1</code> ausf\u00fchren (Release)</li> <li>Verteilte Ordner ersetzen (Downtime beachten, wenn Tools ge\u00f6ffnet sind)</li> </ul>"},{"location":"admin_tools_admin_guide/#konfiguration","title":"Konfiguration","text":"<ul> <li>Standard-Server-URL: <code>http://localhost:8765</code></li> <li>WICHTIG: Aktuell erwarten die Admin-Tools-HTTP-Clients teils einen <code>/api</code>-Prefix (z. B. <code>/api/keys</code>). Der Themis-Server stellt die Endpunkte ohne Prefix bereit (z. B. <code>/keys</code>). Empfohlene Optionen:</li> <li>Reverse-Proxy (empfohlen): Leiten Sie <code>/api/*</code> auf den Server-Root <code>/</code> um (Rewrite). Beispiel: Nginx <code>location /api/ { proxy_pass http://localhost:8765/; rewrite ^/api/(.*)$ /$1 break; }</code></li> <li>Alternativ (Folgearbeit): Die Tools auf prefix-freie Routen umstellen.</li> <li>Netzwerk: Firewalls/Proxies so konfigurieren, dass der Server erreichbar ist</li> <li>Konfigurationsdatei: Basis-URL der Tools zentral konfigurierbar halten (BaseUrl, Timeout)</li> </ul>"},{"location":"admin_tools_admin_guide/#relevante-admin-apis-fur-keysclassificationreports","title":"Relevante Admin-APIs (f\u00fcr Keys/Classification/Reports)","text":"<ul> <li>Keys Management</li> <li>GET <code>/keys</code> \u2192 Liste gemanagter Schl\u00fcssel</li> <li>POST <code>/keys/rotate</code> \u2192 Rotation eines Schl\u00fcssels; Parameter <code>key_id</code> im Body (JSON) oder als Query (<code>?key_id=...</code>)</li> <li>Classification</li> <li>GET <code>/classification/rules</code> \u2192 Liste aktiver Klassifizierungsregeln</li> <li>POST <code>/classification/test</code> \u2192 Testen mit Body <code>{ \"text\": \"...\", \"metadata\": { ... } }</code></li> <li>Compliance Reports</li> <li>GET <code>/reports/compliance?type=overview|dsgvo|sox|hipaa|iso27001|pci</code></li> </ul> <p>Hinweis: Die genauen Schemas und Fehlercodes sind in <code>docs/openapi.yaml</code> beschrieben. Der SSE-Changefeed ist separat dokumentiert (<code>docs/apis/openapi.md#sse-streaming-changefeed</code>).</p>"},{"location":"admin_tools_admin_guide/#betrieb-monitoring","title":"Betrieb &amp; Monitoring","text":"<ul> <li>Server-Logs pr\u00fcfen (<code>server.err</code>)</li> <li>Health-Check: <code>GET /health</code> \u2192 200 OK bei funktionsf\u00e4higem Server</li> <li>Metriken: <code>GET /metrics</code> (Prometheus-Format)</li> <li>Tool-Start per Doppelklick aus <code>dist/...</code></li> <li>Performance: Self-contained reduziert Abh\u00e4ngigkeiten; ggf. R2R/Trim anpassen</li> </ul>"},{"location":"admin_tools_admin_guide/#sicherheit-kurzuberblick","title":"Sicherheit (Kurz\u00fcberblick)","text":"<ul> <li>Code-Signierung der Binaries</li> <li>Least-Privilege f\u00fcr Service-Accounts</li> <li>TLS-Termination/Reverse-Proxy vor Themis-Server</li> <li>Regelm\u00e4\u00dfige Dependency-Scans (Server/Clients)</li> <li>Schl\u00fcsselverwaltung: Nur autorisierte Nutzer d\u00fcrfen <code>/keys/rotate</code> verwenden (Absicherung via Reverse-Proxy/Firewall/RBAC)</li> </ul>"},{"location":"admin_tools_admin_guide/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Tools zeigen keine Daten</li> <li>L\u00e4uft der Server? H\u00f6rt er auf Port 8765?</li> <li>API-Routen mit Browser/HTTP-Client testen</li> <li>Stimmt das Routing <code>/api/*</code> \u2192 <code>/</code> (Reverse-Proxy)?</li> <li>Filter zur\u00fccksetzen, Logs pr\u00fcfen</li> <li>Export schl\u00e4gt fehl</li> <li>Schreibrechte im Zielverzeichnis</li> <li>Ggf. Admin-Konsole verwenden</li> <li>UI wirkt \u201eleer\u201c</li> <li>Server offline / Endpoints liefern 204/404</li> <li>Pr\u00fcfen, ob Demo-Daten-Backend aktiv ist</li> </ul>"},{"location":"admin_tools_admin_guide/#anhang","title":"Anhang","text":"<ul> <li>OpenAPI: <code>docs/openapi.yaml</code></li> <li>Architekturdokumentation: <code>docs/architecture.md</code>, <code>docs/content_architecture.md</code></li> <li>Admin-Tools Benutzerhandbuch: <code>docs/admin_tools_user_guide.md</code></li> </ul>"},{"location":"admin_tools_demo_script/","title":"ThemisDB Admin Tools - Demo Script","text":""},{"location":"admin_tools_demo_script/#demo-1-audit-log-viewer-such-und-filterfunktionen-5-minuten","title":"Demo 1: Audit Log Viewer - Such- und Filterfunktionen (5 Minuten)","text":""},{"location":"admin_tools_demo_script/#setup-30-sekunden","title":"Setup (30 Sekunden)","text":"<pre><code>1. themis_server starten (Port 8765)\n2. AuditLogViewer.exe \u00f6ffnen\n3. Zeige UI-Overview:\n   - Header \"ThemisDB Audit Log Viewer\"\n   - Filter-Bereich (Datum, User, Action, Entity)\n   - DataGrid (leer)\n   - Status-Leiste \"Bereit\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-1-basis-filter-1-minute","title":"Szenario 1: Basis-Filter (1 Minute)","text":"<pre><code>AKTION: Datum-Filter setzen\n- Von: Letzte 7 Tage (bereits gesetzt)\n- Bis: Heute\n- Klick \"Laden\"\n\nERWARTUNG:\n\u2713 Loading-Indicator erscheint\n\u2713 DataGrid f\u00fcllt sich mit Audit-Logs\n\u2713 Status: \"X Eintr\u00e4ge geladen (Gesamt: Y)\"\n\nDEMO-PUNKT:\n\u2192 \"Standard-Filter l\u00e4dt Audit-Logs der letzten Woche\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-2-echtzeit-suche-1-minute","title":"Szenario 2: Echtzeit-Suche (1 Minute)","text":"<pre><code>AKTION: Globale Suche verwenden\n- Suchfeld: \"admin\"\n- KEINE Taste dr\u00fccken (auto-update)\n\nERWARTUNG:\n\u2713 DataGrid filtert sofort\n\u2713 Nur Zeilen mit \"admin\" (in User, Action, etc.)\n\u2713 Status: \"5 von 100 Eintr\u00e4gen angezeigt\"\n\nDEMO-PUNKT:\n\u2192 \"Echtzeit-Suche durchsucht alle Spalten gleichzeitig\"\n\u2192 \"UpdateSourceTrigger=PropertyChanged = Instant Feedback\"\n\nAKTION: Suche \u00e4ndern\n- Suchfeld: \"create\" (\u00fcberschreibe \"admin\")\n\nERWARTUNG:\n\u2713 DataGrid aktualisiert sofort\n\u2713 Nur Zeilen mit \"create\"\n\u2713 Status: \"12 von 100 Eintr\u00e4gen angezeigt\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-3-multi-column-sorting-1-minute","title":"Szenario 3: Multi-Column Sorting (1 Minute)","text":"<pre><code>AKTION: Nach Zeitstempel sortieren\n- Klick auf \"Zeitstempel\" Spalten\u00fcberschrift\n\nERWARTUNG:\n\u2713 Sortier-Pfeil erscheint (\u2191 aufsteigend)\n\u2713 Eintr\u00e4ge chronologisch sortiert\n\nAKTION: Sortierung umkehren\n- Nochmal Klick auf \"Zeitstempel\"\n\nERWARTUNG:\n\u2713 Sortier-Pfeil dreht (\u2193 absteigend)\n\u2713 Neueste Eintr\u00e4ge zuerst\n\nDEMO-PUNKT:\n\u2192 \"Toggle Sort Direction mit einem Klick\"\n\nAKTION: Nach anderem Feld sortieren\n- Klick auf \"Benutzer\" Spalte\n\nERWARTUNG:\n\u2713 Sortierung wechselt zu \"Benutzer\" (alphabetisch)\n\u2713 Alter Sortier-Pfeil verschwindet\n\u2713 Neuer Sortier-Pfeil bei \"Benutzer\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-4-kombinierte-filter-1-minute","title":"Szenario 4: Kombinierte Filter (1 Minute)","text":"<pre><code>AKTION: Filter kombinieren\n- Suchfeld: \"error\"\n- Checkbox: \"Nur erfolgreiche Aktionen\" DEAKTIVIEREN\n- Benutzer-Filter: \"system\"\n- Klick \"Laden\"\n\nERWARTUNG:\n\u2713 Server-Request mit Filtern\n\u2713 DataGrid zeigt nur:\n  - Eintr\u00e4ge mit \"error\" im Text\n  - Von Benutzer \"system\"\n  - Inkl. Fehler (Success=false)\n\u2713 Status: \"3 von 8 Eintr\u00e4gen angezeigt (Gesamt im System: 1234)\"\n\nDEMO-PUNKT:\n\u2192 \"Server-Filter (User, Datum) + Client-Suche (Suchfeld)\"\n\u2192 \"AND-Verkn\u00fcpfung aller Filter\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-5-export-30-sekunden","title":"Szenario 5: Export (30 Sekunden)","text":"<pre><code>AKTION: CSV Export\n- Klick \"CSV Export\"\n- Save-Dialog: \"audit_log_20251101_143022.csv\"\n- Klick \"Speichern\"\n\nERWARTUNG:\n\u2713 Loading-Indicator\n\u2713 Success-Dialog: \"Daten erfolgreich exportiert\"\n\u2713 CSV-Datei mit gefilterten Daten\n\nDEMO-PUNKT:\n\u2192 \"Export ber\u00fccksichtigt aktuelle Filter\"\n\u2192 \"Automatischer Dateiname mit Timestamp\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-6-filter-zurucksetzen-30-sekunden","title":"Szenario 6: Filter zur\u00fccksetzen (30 Sekunden)","text":"<pre><code>AKTION: Filter l\u00f6schen\n- Klick \"Filter l\u00f6schen\"\n\nERWARTUNG:\n\u2713 Datum: Zur\u00fcck zu \"Letzte 7 Tage\"\n\u2713 Suchfeld: Leer\n\u2713 Benutzer/Action/Entity: Leer\n\u2713 SuccessOnly: Deaktiviert\n\u2713 DataGrid: Zeigt wieder alle Eintr\u00e4ge\n\nDEMO-PUNKT:\n\u2192 \"Ein Klick zur\u00fcck zu Standard-Filtern\"\n</code></pre>"},{"location":"admin_tools_demo_script/#demo-2-saga-verifier-batch-suche-und-verifizierung-5-minuten","title":"Demo 2: SAGA Verifier - Batch-Suche und Verifizierung (5 Minuten)","text":""},{"location":"admin_tools_demo_script/#setup-30-sekunden_1","title":"Setup (30 Sekunden)","text":"<pre><code>1. themis_server l\u00e4uft (Port 8765)\n2. SAGAVerifier.exe \u00f6ffnen\n3. Zeige UI-Overview:\n   - Header \"SAGA Batch Verifier\"\n   - Toolbar (Refresh, Verify, Flush, Export)\n   - Split-View: Batch-Liste | Detail-Ansicht\n   - Status-Leiste\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-1-auto-load-batch-liste-1-minute","title":"Szenario 1: Auto-Load &amp; Batch-Liste (1 Minute)","text":"<pre><code>BEIM START:\n\u2713 Auto-Load l\u00e4dt Batches\n\u2713 Batch-Liste zeigt:\n  - Batch ID (kurz)\n  - Timestamp (formatiert)\n  - Entries (Anzahl)\n\u2713 Status: \"Loaded 5 batch(es)\"\n\nDEMO-PUNKT:\n\u2192 \"Automatisches Laden beim Start\"\n\u2192 \"Window.Loaded Event \u2192 LoadBatchesCommand\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-2-batch-suche-1-minute","title":"Szenario 2: Batch-Suche (1 Minute)","text":"<pre><code>AKTION: Batch suchen\n- Batch-Suchfeld: \"abc\" (Teil der Batch-ID)\n\nERWARTUNG:\n\u2713 Batch-Liste filtert sofort\n\u2713 Nur Batches mit \"abc\" in ID, Hash, Signatur, Timestamp\n\u2713 Status: \"2 of 5 batches shown\"\n\nDEMO-PUNKT:\n\u2192 \"Echtzeit-Suche in Batch-Liste\"\n\u2192 \"Durchsucht BatchId, Hash, Signature, Timestamp\"\n\nAKTION: Batch-ID sortieren\n- Klick auf \"Batch ID\" Spalte\n\nERWARTUNG:\n\u2713 Batches alphabetisch sortiert\n\u2713 Sortier-Pfeil erscheint\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-3-batch-detail-auto-load-1-minute","title":"Szenario 3: Batch-Detail Auto-Load (1 Minute)","text":"<pre><code>AKTION: Batch ausw\u00e4hlen\n- Klick auf ersten Batch in Liste\n\nERWARTUNG:\n\u2713 Loading-Indicator\n\u2713 Detail-Bereich f\u00fcllt sich:\n  - Batch ID (vollst\u00e4ndig)\n  - Hash (SHA-256, Monospace-Font)\n  - Signature (Kryptographisch, Monospace-Font)\n  - Verification: (leer, noch nicht verifiziert)\n\u2713 SAGA-Steps DataGrid:\n  - Time, SAGA ID, Step, Status, Correlation ID\n  - X Schritte geladen\n\u2713 Status: \"Loaded 15 SAGA step(s)\"\n\nDEMO-PUNKT:\n\u2192 \"Auto-Load Detail bei Batch-Auswahl\"\n\u2192 \"OnSelectedBatchChanged \u2192 LoadBatchDetailAsync\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-4-saga-steps-suche-1-minute","title":"Szenario 4: SAGA-Steps Suche (1 Minute)","text":"<pre><code>AKTION: Steps durchsuchen\n- Step-Suchfeld: \"compensation\"\n\nERWARTUNG:\n\u2713 Steps-DataGrid filtert\n\u2713 Nur Steps mit \"compensation\" in:\n  - SagaId, StepName, Status, CorrelationId, Metadata\n\u2713 Status: \"3 of 15 steps shown\"\n\nDEMO-PUNKT:\n\u2192 \"Separate Suche f\u00fcr Batches und Steps\"\n\u2192 \"ICollectionView f\u00fcr beide unabh\u00e4ngig\"\n\nAKTION: Nach Status sortieren\n- Klick auf \"Status\" Spalte\n\nERWARTUNG:\n\u2713 Steps nach Status sortiert\n\u2713 z.B. \"completed\" \u2192 \"pending\" \u2192 \"failed\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-5-signatur-verifizierung-1-minute","title":"Szenario 5: Signatur-Verifizierung (1 Minute)","text":"<pre><code>AKTION: Batch verifizieren\n- Button \"Verify Selected\" klicken\n\nERWARTUNG:\n\u2713 Loading-Indicator\n\u2713 REST API Call: POST /api/saga/batch/{id}/verify\n\u2713 MessageBox erscheint:\n  - Bei Erfolg: \"\u2713 Batch verified successfully\"\n  - Bei Fehler: \"\u2717 Verification failed: ...\"\n\u2713 Detail-Bereich aktualisiert:\n  - Verification: \"\u2713 Verified\" (gr\u00fcn) / \"\u2717 Failed\" (rot)\n\u2713 Status: \"\u2713 Batch verified successfully\"\n\nDEMO-PUNKT:\n\u2192 \"Kryptographische Signatur-Pr\u00fcfung\"\n\u2192 \"SHA-256 Hash + HMAC-Verification\"\n\u2192 \"Visual Feedback (\u2713/\u2717, Farben)\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-6-export-saga-steps-30-sekunden","title":"Szenario 6: Export SAGA-Steps (30 Sekunden)","text":"<pre><code>AKTION: Steps exportieren\n- Button \"Export Steps\" klicken\n- Save-Dialog: \"saga_steps_abc123_20251101_143530.csv\"\n- Klick \"Speichern\"\n\nERWARTUNG:\n\u2713 CSV-Datei mit allen (gefilterten) Steps\n\u2713 Success-Dialog\n\u2713 Status: \"Exported 15 steps\"\n\nDEMO-PUNKT:\n\u2192 \"Export ber\u00fccksichtigt aktuelle Step-Suche\"\n\u2192 \"Batch-ID im Dateinamen\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-7-batch-flush-30-sekunden","title":"Szenario 7: Batch Flush (30 Sekunden)","text":"<pre><code>AKTION: Aktuellen Batch flushen\n- Button \"Flush Current\" klicken\n\nERWARTUNG:\n\u2713 Confirmation-Dialog (optional)\n\u2713 REST API Call: POST /api/saga/flush\n\u2713 MessageBox: \"Current SAGA batch flushed successfully\"\n\u2713 Batch-Liste aktualisiert (neuer Batch erscheint)\n\u2713 Status: \"Batch flushed successfully\"\n\nDEMO-PUNKT:\n\u2192 \"Manuelles Flushen erzwingt Batch-Abschluss\"\n\u2192 \"N\u00fctzlich f\u00fcr Testing oder Notfall-Situationen\"\n</code></pre>"},{"location":"admin_tools_demo_script/#demo-3-key-rotation-schlussel-anzeigen-und-rotieren-3-minuten","title":"Demo 3: Key Rotation \u2013 Schl\u00fcssel anzeigen und rotieren (3 Minuten)","text":""},{"location":"admin_tools_demo_script/#setup-30-sekunden_2","title":"Setup (30 Sekunden)","text":"<pre><code>1. themis_server l\u00e4uft (Port 8765)\n2. KeyRotation.exe \u00f6ffnen\n3. UI-\u00dcberblick: Schl\u00fcssel-Liste, Filter (Typ/abgelaufen), Buttons (Aktualisieren, Rotieren)\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-1-schlussel-laden-1-minute","title":"Szenario 1: Schl\u00fcssel laden (1 Minute)","text":"<pre><code>AKTION: Klick \u201eAktualisieren\u201c\n\nERWARTUNG:\n\u2713 GET /keys \u2192 Liste mit LEK/KEK/DEK\n\u2713 Spalten: KeyId, Version, Status, ExpiresAt\n\u2713 Status: \"3 Schl\u00fcssel geladen\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-2-rotation-auslosen-15-minuten","title":"Szenario 2: Rotation ausl\u00f6sen (1,5 Minuten)","text":"<pre><code>AKTION: Schl\u00fcssel \u201eDEK\u201c ausw\u00e4hlen \u2192 \u201eRotieren\u201c klicken\n\nERWARTUNG:\n\u2713 POST /keys/rotate mit Body { key_id: \"DEK\" }\n\u2713 Success-Dialog: \"DEK erfolgreich rotiert (neue Version: X)\"\n\u2713 Liste aktualisiert \u2192 neue Version sichtbar\n\nEDGE CASES:\n\u2022 400 Missing key_id \u2192 Hinweis im UI\n\u2022 503 Keys API not available \u2192 Admin-Guide verlinken\n</code></pre>"},{"location":"admin_tools_demo_script/#demo-4-classification-regeln-laden-und-test-classification-3-minuten","title":"Demo 4: Classification \u2013 Regeln laden und Test-Classification (3 Minuten)","text":""},{"location":"admin_tools_demo_script/#setup-30-sekunden_3","title":"Setup (30 Sekunden)","text":"<pre><code>1. themis_server l\u00e4uft (Port 8765)\n2. ClassificationDashboard.exe \u00f6ffnen\n3. UI-\u00dcberblick: Regeln-Panel, Testeingabe, Ergebnisse/Export\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-1-regeln-laden-45-sekunden","title":"Szenario 1: Regeln laden (45 Sekunden)","text":"<pre><code>AKTION: Klick \u201eAktualisieren\u201c\n\nERWARTUNG:\n\u2713 GET /classification/rules\n\u2713 Anzeige: Name, Muster, Gewichtung\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-2-klassifikation-testen-15-minuten","title":"Szenario 2: Klassifikation testen (1,5 Minuten)","text":"<pre><code>AKTION: Beispieltext eingeben \u2192 \u201eTesten\u201c\n\nERWARTUNG:\n\u2713 POST /classification/test mit { text, metadata }\n\u2713 Ergebnis: classification=CONFIDENTIAL, confidence ~0.9, detected_entities\n\u2713 Export-Button aktiv\n\nEDGE CASES:\n\u2022 400 Missing JSON body \u2192 Validierungs-Hinweis\n\u2022 503 Classification API not available \u2192 Admin-Guide verlinken\n</code></pre>"},{"location":"admin_tools_demo_script/#demo-5-compliance-reports-ubersicht-abrufen-2-minuten","title":"Demo 5: Compliance Reports \u2013 \u00dcbersicht abrufen (2 Minuten)","text":""},{"location":"admin_tools_demo_script/#setup-15-sekunden","title":"Setup (15 Sekunden)","text":"<pre><code>Tool \"ComplianceReports.exe\" \u00f6ffnen\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-overview-report-15-minuten","title":"Szenario: Overview-Report (1,5 Minuten)","text":"<pre><code>AKTION: Typ \u201eoverview\u201c ausw\u00e4hlen \u2192 \u201eGenerieren\u201c\n\nERWARTUNG:\n\u2713 GET /reports/compliance?type=overview\n\u2713 Anzeige zentraler Metriken (verschl\u00fcsselte Entit\u00e4ten, PII-Funde, etc.)\n\u2713 Export als CSV/PDF/Excel\n\nEDGE CASES:\n\u2022 503 Reports API not available \u2192 Hinweis/Retry Option\n</code></pre>"},{"location":"admin_tools_demo_script/#demo-6-performance-benutzerfreundlichkeit-3-minuten","title":"Demo 6: Performance &amp; Benutzerfreundlichkeit (3 Minuten)","text":""},{"location":"admin_tools_demo_script/#feature-1-echtzeit-feedback-30-sekunden","title":"Feature 1: Echtzeit-Feedback (30 Sekunden)","text":"<pre><code>DEMO:\n1. Suchfeld langsam tippen: \"a\" \u2192 \"ad\" \u2192 \"adm\" \u2192 \"admin\"\n2. Zeige: Filter aktualisiert bei JEDEM Buchstaben\n3. Status-Leiste zeigt sofort gefilterte Anzahl\n\nERKL\u00c4RUNG:\n\u2192 \"UpdateSourceTrigger=PropertyChanged\"\n\u2192 \"Kein Button-Klick n\u00f6tig\"\n\u2192 \"Instant Visual Feedback\"\n</code></pre>"},{"location":"admin_tools_demo_script/#feature-2-icollectionview-performance-1-minute","title":"Feature 2: ICollectionView Performance (1 Minute)","text":"<pre><code>DEMO:\n1. Lade 100 Audit-Logs\n2. Suche \"test\" \u2192 Filter in &lt;50ms\n3. Wechsle zu \"admin\" \u2192 Filter in &lt;50ms\n4. Sortiere nach Zeitstempel \u2192 Instant\n\nERKL\u00c4RUNG:\n\u2192 \"ICollectionView \u00e4ndert nur Ansicht\"\n\u2192 \"Quell-Collection bleibt unver\u00e4ndert\"\n\u2192 \"Keine Netzwerk-Requests\"\n\u2192 \"Nur bereits geladene Daten betroffen\"\n</code></pre>"},{"location":"admin_tools_demo_script/#feature-3-kombinierte-filter-1-minute","title":"Feature 3: Kombinierte Filter (1 Minute)","text":"<pre><code>DEMO:\n1. Server-Filter: User=\"admin\", Datum=Letzte Woche\n2. Klick \"Laden\" \u2192 50 Eintr\u00e4ge vom Server\n3. Client-Suche: \"create\" \u2192 12 von 50 angezeigt\n4. Status: \"12 von 50 Eintr\u00e4gen angezeigt (Gesamt im System: 1234)\"\n\nERKL\u00c4RUNG:\n\u2192 \"Server-Filter reduzieren Netzwerk-Traffic\"\n\u2192 \"Client-Suche f\u00fcr Feinabstimmung\"\n\u2192 \"AND-Verkn\u00fcpfung aller Filter\"\n\u2192 \"Status zeigt 3 Ebenen: Gefiltert / Geladen / Gesamt\"\n</code></pre>"},{"location":"admin_tools_demo_script/#feature-4-platzhalter-tooltips-30-sekunden","title":"Feature 4: Platzhalter &amp; Tooltips (30 Sekunden)","text":"<pre><code>DEMO:\n1. Zeige leeres Suchfeld: \"\ud83d\udd0d Search...\"\n2. Hover \u00fcber Suchfeld: Tooltip \"Durchsucht alle Spalten...\"\n3. Hover \u00fcber Buttons: Tooltips erkl\u00e4ren Funktion\n\nERKL\u00c4RUNG:\n\u2192 \"VisualBrush f\u00fcr Platzhalter-Text\"\n\u2192 \"Tooltips f\u00fcr Benutzerfreundlichkeit\"\n\u2192 \"Keine zus\u00e4tzlichen Labels n\u00f6tig\"\n</code></pre>"},{"location":"admin_tools_demo_script/#demo-7-error-handling-edge-cases-2-minuten","title":"Demo 7: Error Handling &amp; Edge Cases (2 Minuten)","text":""},{"location":"admin_tools_demo_script/#szenario-1-server-nicht-erreichbar-30-sekunden","title":"Szenario 1: Server nicht erreichbar (30 Sekunden)","text":"<pre><code>SETUP: themis_server beenden\n\nAKTION:\n- AuditLogViewer \u00f6ffnen\n- Klick \"Laden\"\n\nERWARTUNG:\n\u2713 Loading-Indicator erscheint\n\u2713 Nach Timeout: MessageBox \"Fehler beim Laden der Audit-Logs: ...\"\n\u2713 Status: \"Fehler: Connection refused\"\n\u2713 DataGrid bleibt leer\n\nDEMO-PUNKT:\n\u2192 \"Graceful Error Handling\"\n\u2192 \"Benutzer-freundliche Fehlermeldungen\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-2-keine-ergebnisse-30-sekunden","title":"Szenario 2: Keine Ergebnisse (30 Sekunden)","text":"<pre><code>AKTION:\n- Suchfeld: \"XYZABCNOTFOUND\"\n\nERWARTUNG:\n\u2713 DataGrid leer\n\u2713 Status: \"0 von 100 Eintr\u00e4gen angezeigt (Gesamt: 100)\"\n\u2713 KEINE Fehlermeldung (= valider Zustand)\n\nDEMO-PUNKT:\n\u2192 \"Leere Ergebnisse \u2260 Fehler\"\n\u2192 \"Status zeigt deutlich: 0 Treffer\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-3-verify-ohne-auswahl-30-sekunden","title":"Szenario 3: Verify ohne Auswahl (30 Sekunden)","text":"<pre><code>AKTION:\n- SAGAVerifier \u00f6ffnen\n- Klick \"Verify Selected\" (ohne Batch-Auswahl)\n\nERWARTUNG:\n\u2713 Button ist DISABLED\n\u2713 Grau ausgegraut\n\u2713 Kein API-Call m\u00f6glich\n\nDEMO-PUNKT:\n\u2192 \"IsEnabled Binding verhindert ung\u00fcltige Aktionen\"\n\u2192 \"Converter: NullToBoolConverter\"\n</code></pre>"},{"location":"admin_tools_demo_script/#szenario-4-export-ohne-daten-30-sekunden","title":"Szenario 4: Export ohne Daten (30 Sekunden)","text":"<pre><code>AKTION:\n- SAGAVerifier \u00f6ffnen (keine Steps geladen)\n- Klick \"Export Steps\"\n\nERWARTUNG:\n\u2713 Button ist DISABLED (wegen CountToBoolConverter)\n\u2713 Oder: MessageBox \"No SAGA steps to export\"\n\nDEMO-PUNKT:\n\u2192 \"Validation vor Export\"\n\u2192 \"Verhindert leere Dateien\"\n</code></pre>"},{"location":"admin_tools_demo_script/#technische-highlights-fur-entwickler-prasentation","title":"Technische Highlights (f\u00fcr Entwickler-Pr\u00e4sentation)","text":""},{"location":"admin_tools_demo_script/#highlight-1-mvvm-pattern","title":"Highlight 1: MVVM Pattern","text":"<pre><code>// ViewModel (MainViewModel.cs)\n[ObservableProperty]\nprivate string _searchText = string.Empty;\n\npartial void OnSearchTextChanged(string value)\n{\n    _logsView?.Refresh();  // Aktualisiert UI automatisch\n    UpdateStatusMessage();\n}\n\n// View (MainWindow.xaml)\n&lt;TextBox Text=\"{Binding SearchText, UpdateSourceTrigger=PropertyChanged}\"/&gt;\n</code></pre>"},{"location":"admin_tools_demo_script/#highlight-2-icollectionview-filter","title":"Highlight 2: ICollectionView Filter","text":"<pre><code>// Setup\n_logsView = CollectionViewSource.GetDefaultView(AuditLogs);\n_logsView.Filter = FilterLogs;\n\n// Filter-Logik\nprivate bool FilterLogs(object obj)\n{\n    if (obj is not AuditLogEntry log)\n        return false;\n\n    if (!string.IsNullOrWhiteSpace(SearchText))\n    {\n        var search = SearchText.ToLowerInvariant();\n        return log.User?.ToLowerInvariant().Contains(search) == true ||\n               log.Action?.ToLowerInvariant().Contains(search) == true;\n    }\n\n    return true;\n}\n</code></pre>"},{"location":"admin_tools_demo_script/#highlight-3-dependency-injection","title":"Highlight 3: Dependency Injection","text":"<pre><code>// App.xaml.cs\nprotected override void OnStartup(StartupEventArgs e)\n{\n    var services = new ServiceCollection();\n\n    services.AddSingleton(serverConfig);\n    services.AddTransient&lt;ThemisApiClient&gt;(sp =&gt; {\n        var config = sp.GetRequiredService&lt;ThemisServerConfig&gt;();\n        var httpClient = new HttpClient {\n            BaseAddress = new Uri(config.BaseUrl),\n            Timeout = TimeSpan.FromSeconds(config.Timeout)\n        };\n        return new ThemisApiClient(httpClient, config);\n    });\n    services.AddTransient&lt;MainViewModel&gt;();\n    services.AddTransient&lt;MainWindow&gt;();\n\n    _serviceProvider = services.BuildServiceProvider();\n    _serviceProvider.GetRequiredService&lt;MainWindow&gt;().Show();\n}\n</code></pre>"},{"location":"admin_tools_demo_script/#highlight-4-async-commands","title":"Highlight 4: Async Commands","text":"<pre><code>// CommunityToolkit.Mvvm\n[RelayCommand]\nprivate async Task LoadBatchesAsync()\n{\n    IsLoading = true;\n    StatusMessage = \"Loading SAGA batches...\";\n\n    var response = await _apiClient.GetSAGABatchesAsync();\n\n    if (response.Success &amp;&amp; response.Data != null)\n    {\n        Batches = new ObservableCollection&lt;SAGABatchInfo&gt;(response.Data.Batches);\n        StatusMessage = $\"Loaded {Batches.Count} batch(es)\";\n    }\n\n    IsLoading = false;\n}\n</code></pre>"},{"location":"admin_tools_demo_script/#zusammenfassung-fur-prasentation","title":"Zusammenfassung f\u00fcr Pr\u00e4sentation","text":""},{"location":"admin_tools_demo_script/#key-messages","title":"Key Messages:","text":"<ol> <li>Echtzeit-Suche: Sofortiges Feedback, keine Button-Klicks</li> <li>Multi-Column Sort: Toggle Direction, visueller Feedback</li> <li>Kombinierte Filter: Server + Client, AND-Logik</li> <li>Performance: ICollectionView, keine Collection-Manipulation</li> <li>Benutzerfreundlichkeit: Tooltips, Platzhalter, Status-Updates</li> <li>Fehlerbehandlung: Graceful Degradation, klare Meldungen</li> <li>MVVM: Clean Architecture, Testbar, Wartbar</li> <li>DI: Loose Coupling, konfigurierbar</li> </ol>"},{"location":"admin_tools_demo_script/#demo-reihenfolge-10-minuten","title":"Demo-Reihenfolge (10 Minuten):","text":"<ol> <li>AuditLogViewer - Basis-Funktionen (2 Min)</li> <li>AuditLogViewer - Such &amp; Filter (2 Min)</li> <li>SAGAVerifier - Batch-Suche (2 Min)</li> <li>SAGAVerifier - Verifizierung (2 Min)</li> <li>Performance &amp; UX Highlights (1 Min)</li> <li>Error Handling (1 Min)</li> </ol>"},{"location":"admin_tools_feature_matrix/","title":"ThemisDB Admin Tools - Feature Matrix","text":""},{"location":"admin_tools_feature_matrix/#ubersicht-der-implementierten-features","title":"\u00dcbersicht der implementierten Features","text":""},{"location":"admin_tools_feature_matrix/#key-rotation-dashboard","title":"\u2705 Key Rotation Dashboard","text":"Feature Status Beschreibung Schl\u00fcssel-\u00dcbersicht \u2705 Anzeige LEK/KEK/DEK inkl. Version/Status Manuelle Rotation \u2705 POST <code>/keys/rotate</code> mit <code>key_id</code> (Body/Query) Filter \u2705 Nach Typ (LEK/KEK/DEK), \u201enur abgelaufene\u201c Status-Updates \u2705 Z\u00e4hler gesamt/abgelaufen Fehlerbehandlung \u2705 400/503 verst\u00e4ndlich anzeigen"},{"location":"admin_tools_feature_matrix/#classification-dashboard","title":"\u2705 Classification Dashboard","text":"Feature Status Beschreibung Regeln laden \u2705 GET <code>/classification/rules</code> Test-Classification \u2705 POST <code>/classification/test</code> mit <code>{ text, metadata }</code> Export \u2705 CSV-Export der Ergebnisse Filter \u2705 Level, Verschl\u00fcsselung, Compliance-Status Live-Statistik \u2705 Counts in Sidebar"},{"location":"admin_tools_feature_matrix/#compliance-reports","title":"\u2705 Compliance Reports","text":"Feature Status Beschreibung Report-Generierung \u2705 GET <code>/reports/compliance?type=...</code> Formate \u2705 JSON (Server), Export in den Tools (CSV/PDF/Excel) Vorlagen \u2705 Standard/Detailliert (Tool-seitig) Zeitraum \u2705 Parametrierbar (Tool-seitig) Fehlerbehandlung \u2705 503 \u201eReports API not available\u201c verst\u00e4ndlich"},{"location":"admin_tools_feature_matrix/#audit-log-viewer","title":"\u2705 Audit Log Viewer","text":"Feature Status Beschreibung Datumsfilter \u2705 Von/Bis-Datum mit DatePicker Benutzerfilter \u2705 Filter nach Username Aktionsfilter \u2705 Filter nach Action-Typ Entit\u00e4tsfilter \u2705 Filter nach EntityType Erfolgsfilter \u2705 \"Nur erfolgreiche Aktionen\" Checkbox Globale Suche \u2705 Durchsucht alle 9 Spalten gleichzeitig Multi-Column Sort \u2705 Sortierung nach ID, Timestamp, User, Action, etc. Toggle Sort \u2705 Klick wechselt aufsteigend/absteigend Paginierung \u2705 Vor/Zur\u00fcck Buttons, 100 Eintr\u00e4ge/Seite CSV Export \u2705 Export gefilterte Daten Status-Updates \u2705 Zeigt gefilterte/gesamt Anzahl Filter l\u00f6schen \u2705 Reset aller Filter auf Default ICollectionView \u2705 Performante Client-Filter MVVM Pattern \u2705 Clean Architecture Dependency Injection \u2705 Microsoft.Extensions.DI <p>Durchsuchbare Felder: - User (Benutzername) - Action (Aktion) - EntityType (Entit\u00e4tstyp) - EntityId (Entit\u00e4ts-ID) - OldValue (Alter Wert) - NewValue (Neuer Wert) - IpAddress (IP-Adresse) - SessionId (Sitzungs-ID) - ErrorMessage (Fehlermeldung)</p>"},{"location":"admin_tools_feature_matrix/#saga-verifier","title":"\u2705 SAGA Verifier","text":"Feature Status Beschreibung Batch-Liste \u2705 \u00dcbersicht aller SAGA-Batches Batch-Suche \u2705 Suche nach ID, Hash, Signatur, Timestamp Batch-Detail \u2705 Vollst\u00e4ndige Batch-Informationen SAGA-Steps \u2705 Liste aller Schritte im Batch Step-Suche \u2705 Suche nach SAGA ID, Step Name, Status, etc. Multi-Column Sort \u2705 Sortierung f\u00fcr Batches &amp; Steps Signatur-Verifizierung \u2705 Kryptographische Pr\u00fcfung Batch Flush \u2705 Manuelles Flushen des aktuellen Batches CSV Export \u2705 Export SAGA-Steps Auto-Load Detail \u2705 Automatisches Laden bei Batch-Auswahl Status-Updates \u2705 Zeigt gefilterte/gesamt Anzahl Split-View \u2705 Batch-Liste Visual Feedback \u2705 \u2713/\u2717 f\u00fcr Verifikations-Status ICollectionView \u2705 Separate Filter f\u00fcr Batches &amp; Steps MVVM Pattern \u2705 CommunityToolkit.Mvvm <p>Batch-Suchfelder: - BatchId (Batch-ID) - Hash (SHA-256 Hash) - Signature (Kryptographische Signatur) - Timestamp (Zeitstempel)</p> <p>Step-Suchfelder: - SagaId (SAGA-ID) - StepName (Schrittname) - Status (Status) - CorrelationId (Korrelations-ID) - Metadata (Metadaten JSON)</p>"},{"location":"admin_tools_feature_matrix/#gemeinsame-features","title":"Gemeinsame Features","text":""},{"location":"admin_tools_feature_matrix/#technologie-stack","title":"Technologie-Stack","text":"Komponente Technologie Version Framework .NET 8.0 UI WPF Windows Presentation Foundation MVVM CommunityToolkit.Mvvm 8.x DI Microsoft.Extensions.DI 8.x HTTP HttpClient .NET 8 Config Microsoft.Extensions.Configuration.Json 8.x Backend C++ themis_server REST API"},{"location":"admin_tools_feature_matrix/#architektur-pattern","title":"Architektur-Pattern","text":"<p>\u2705 MVVM (Model-View-ViewModel) - Klare Trennung UI \u2194 Logik - Data Binding - Command Pattern - ObservableObject/ObservableProperty</p> <p>\u2705 Dependency Injection - Service Container (App.xaml.cs) - Singleton ThemisServerConfig - Transient ViewModels &amp; Windows - Factory Pattern f\u00fcr HttpClient</p> <p>\u2705 ICollectionView Pattern - Client-seitige Filterung - Keine \u00c4nderung der Source-Collection - Performance-Optimierung - Kombinierbar mit Sorting</p> <p>\u2705 Repository Pattern - ThemisApiClient als Repository - ApiResponse Wrapper - Error Handling - Asynchrone Operationen"},{"location":"admin_tools_feature_matrix/#benutzerfreundlichkeit","title":"Benutzerfreundlichkeit","text":"<p>\u2705 Echtzeit-Suche - UpdateSourceTrigger=PropertyChanged - Instant Feedback - Keine Server-Anfragen bei Texteingabe</p> <p>\u2705 Visuelle Indikatoren - Loading Spinner/Progress Bar - Status-Leiste mit Meldungen - Sortier-Pfeile in Spalten\u00fcberschriften - Platzhalter-Text in Suchfeldern (\"\ud83d\udd0d Search...\")</p> <p>\u2705 Tastatur-Support - Tab-Navigation - Enter in Suchfeldern - ESC f\u00fcr Abbrechen</p> <p>\u2705 Responsive Design - GridSplitter f\u00fcr variable Layouts - Auto-Sizing Columns - ScrollViewer f\u00fcr gro\u00dfe Daten - AlternatingRowBackground f\u00fcr Lesbarkeit</p>"},{"location":"admin_tools_feature_matrix/#performance","title":"Performance","text":"<p>\u2705 Optimierungen - Server-seitige Paginierung (100/Seite) - Client-seitige Filterung nur auf geladene Daten - ICollectionView statt Collection-Manipulation - Async/Await f\u00fcr non-blocking UI - Background-Threads f\u00fcr I/O</p> <p>\u2705 Memory Management - ObservableCollection statt List (f\u00fcr Binding) - Dispose Pattern in App.OnExit - ServiceProvider Lifecycle Management</p>"},{"location":"admin_tools_feature_matrix/#fehlerbehandlung","title":"Fehlerbehandlung","text":"<p>\u2705 Exception Handling - Try-Catch in allen Commands - MessageBox f\u00fcr Benutzer-Feedback - ErrorMessage Property f\u00fcr UI - StatusMessage f\u00fcr Kontext</p> <p>\u2705 Validation - Null-Checks vor API-Calls - Config-Validation beim Startup - Filter-Validation (optional vs. required)</p>"},{"location":"admin_tools_feature_matrix/#rest-api-endpoints","title":"REST API Endpoints","text":""},{"location":"admin_tools_feature_matrix/#admin-apis-keys-classification-reports","title":"Admin APIs (Keys | Classification | Reports)","text":"Endpoint Method Beschreibung <code>/keys</code> GET Liste aller gemanagten Schl\u00fcssel <code>/keys/rotate</code> POST Rotation; <code>key_id</code> im Body <code>{ key_id: \"DEK\" }</code> oder Query <code>?key_id=DEK</code> <code>/classification/rules</code> GET Liste der Klassifizierungsregeln <code>/classification/test</code> POST Test-Classification <code>{ text, metadata }</code> <code>/reports/compliance</code> GET Compliance-Report <code>?type=overview|dsgvo|sox|hipaa|iso27001|pci</code> <p>Hinweis: Einige Tool-Clients verwenden einen <code>/api</code>-Prefix (z. B. <code>/api/keys</code>). Siehe Admin-Guide f\u00fcr Reverse-Proxy-Rewrite auf prefix-freie Server-Endpunkte.</p>"},{"location":"admin_tools_feature_matrix/#audit-api","title":"Audit API","text":"Endpoint Method Beschreibung <code>/api/audit</code> GET Liste Audit-Logs mit Filtern <code>/api/audit/export/csv</code> GET Export als CSV <p>Query-Parameter: - <code>start_date</code> (DateTime) - <code>end_date</code> (DateTime) - <code>user</code> (string) - <code>action</code> (string) - <code>entity_type</code> (string) - <code>success_only</code> (bool) - <code>page</code> (int) - <code>page_size</code> (int)</p>"},{"location":"admin_tools_feature_matrix/#saga-api","title":"SAGA API","text":"Endpoint Method Beschreibung <code>/api/saga/batches</code> GET Liste aller SAGA-Batches <code>/api/saga/batch/{id}</code> GET Batch-Detail mit Steps <code>/api/saga/batch/{id}/verify</code> POST Verifiziere Signatur <code>/api/saga/flush</code> POST Flush aktuellen Batch"},{"location":"admin_tools_feature_matrix/#geplante-features-roadmap","title":"Geplante Features (Roadmap)","text":""},{"location":"admin_tools_feature_matrix/#kurzfristig-nachste-2-wochen","title":"Kurzfristig (n\u00e4chste 2 Wochen)","text":"<ul> <li>[ ] PII-Manager Tool</li> <li>UUID \u2194 Pseudonym Mapping</li> <li>DSGVO Art. 17 L\u00f6schung</li> <li>Export-Funktionen</li> </ul>"},{"location":"admin_tools_feature_matrix/#mittelfristig-nachste-4-wochen","title":"Mittelfristig (n\u00e4chste 4 Wochen)","text":"<ul> <li>[ ] Retention-Manager</li> <li>Policy-Konfiguration</li> <li>\u00dcberwachung</li> <li>Manuelle Bereinigung</li> </ul>"},{"location":"admin_tools_feature_matrix/#langfristig-2-3-monate","title":"Langfristig (2-3 Monate)","text":"<ul> <li>[ ] Erweiterte Admin-Features</li> <li>Saved Filter Profiles</li> <li>Team-Filter Templates</li> <li>Regex-Support in Suche</li> <li>Advanced Filter Builder (AND/OR)</li> <li>Visualisierung (Charts)</li> </ul>"},{"location":"admin_tools_feature_matrix/#deployment","title":"Deployment","text":""},{"location":"admin_tools_feature_matrix/#aktueller-status","title":"Aktueller Status","text":"<p>\u2705 Development Build - Debug-Build funktionsf\u00e4hig - Local Testing erfolgreich - themis_server Integration getestet</p>"},{"location":"admin_tools_feature_matrix/#geplant","title":"Geplant","text":"<ul> <li>[ ] Release Build</li> <li>Optimierte Binaries</li> <li>Code-Signierung</li> <li> <p>Installer (MSI/ClickOnce)</p> </li> <li> <p>[ ] Auto-Update</p> </li> <li>ClickOnce Deployment</li> <li>Version-Check</li> <li> <p>Automatische Updates</p> </li> <li> <p>[ ] Documentation</p> </li> <li>Benutzerhandb\u00fccher</li> <li>Admin-Guide</li> <li>API-Dokumentation</li> <li>Video-Tutorials</li> </ul>"},{"location":"admin_tools_feature_matrix/#zusammenfassung","title":"Zusammenfassung","text":"<p>Aktuelle Features: - \u2705 Admin-Tools: AuditLogViewer, SAGAVerifier, KeyRotation, Classification, Compliance Reports - \u2705 Vollst\u00e4ndige Such-, Sortier- und Filterlogik - \u2705 REST API Integration (inkl. Keys, Classification, Reports) - \u2705 MVVM + DI Architecture - \u2705 ICollectionView Performance-Optimierung - \u2705 CSV Export - \u2705 Echtzeit-Suche - \u2705 Multi-Column Sorting - \u2705 Responsive UI</p> <p>N\u00e4chste Schritte: 1. PII-Manager Tool entwickeln 2. Retention-Manager erstellen 3. Deployment vorbereiten 4. Dokumentation vervollst\u00e4ndigen</p> <p>Code-Qualit\u00e4t: - \u2705 MVVM Pattern konsequent - \u2705 Dependency Injection - \u2705 Error Handling - \u2705 Performance-optimiert - \u2705 Wartbar &amp; erweiterbar</p>"},{"location":"admin_tools_search_sort_filter/","title":"Admin Tools - Such-, Sortier- und Filterlogik","text":""},{"location":"admin_tools_search_sort_filter/#ubersicht","title":"\u00dcbersicht","text":"<p>Alle ThemisDB Admin Tools verf\u00fcgen \u00fcber eine vollst\u00e4ndige Such-, Sortier- und Filterlogik, um gro\u00dfe Datenmengen effizient zu durchsuchen und zu analysieren.</p>"},{"location":"admin_tools_search_sort_filter/#implementierte-features","title":"Implementierte Features","text":""},{"location":"admin_tools_search_sort_filter/#1-echtzeit-suche-real-time-search","title":"1. Echtzeit-Suche (Real-time Search)","text":"<p>AuditLogViewer: - Suchfeld: Durchsucht alle Spalten gleichzeitig - Durchsuchte Felder:   - User (Benutzername)   - Action (Aktion)   - EntityType (Entit\u00e4tstyp)   - EntityId (Entit\u00e4ts-ID)   - OldValue (Alter Wert)   - NewValue (Neuer Wert)   - IpAddress (IP-Adresse)   - SessionId (Sitzungs-ID)   - ErrorMessage (Fehlermeldung) - UpdateSourceTrigger=PropertyChanged: Suche erfolgt automatisch bei jeder Texteingabe - Case-insensitive: Gro\u00df-/Kleinschreibung wird ignoriert</p> <p>SAGAVerifier: - Batch-Suche: Durchsucht Batch-Liste   - BatchId (Batch-ID)   - Hash (SHA-256 Hash)   - Signature (Kryptographische Signatur)   - Timestamp (Zeitstempel formatiert) - Step-Suche: Durchsucht SAGA-Schritte   - SagaId (SAGA-ID)   - StepName (Schrittname)   - Status (Status)   - CorrelationId (Korrelations-ID)   - Metadata (Metadaten) - Separate Suchfelder f\u00fcr Batches und Steps - Platzhalter-Text mit \ud83d\udd0d Icon</p>"},{"location":"admin_tools_search_sort_filter/#2-multi-column-sorting","title":"2. Multi-Column Sorting","text":"<p>Implementierung: - Click-to-Sort: Klick auf Spalten\u00fcberschrift sortiert - Toggle Sort Direction: Erneuter Klick kehrt Sortierung um - Visual Feedback: WPF DataGrid zeigt Sortier-Pfeile - SortMemberPath: Definiert Sortier-Eigenschaft pro Spalte</p> <p>AuditLogViewer Sortierbare Spalten: - Id (Audit-Log ID) - Timestamp (Zeitstempel) - User (Benutzer) - Action (Aktion) - EntityType (Entit\u00e4tstyp) - EntityId (Entit\u00e4ts-ID) - OldValue (Alter Wert) - NewValue (Neuer Wert) - Success (Erfolgsstatus)</p> <p>SAGAVerifier Sortierbare Spalten:</p> <p>Batches: - BatchId (Batch-ID) - Timestamp (Zeitstempel) - EntryCount (Anzahl Eintr\u00e4ge)</p> <p>Steps: - Timestamp (Zeitstempel) - SagaId (SAGA-ID) - StepName (Schrittname) - Status (Status) - CorrelationId (Korrelations-ID)</p>"},{"location":"admin_tools_search_sort_filter/#3-erweiterte-filter","title":"3. Erweiterte Filter","text":"<p>AuditLogViewer: - Datum-Filter:   - Von-Datum (StartDate)   - Bis-Datum (EndDate)   - Default: Letzte 7 Tage - Text-Filter:   - Benutzer (UserFilter)   - Aktion (ActionFilter)   - Entit\u00e4tstyp (EntityTypeFilter) - Boolean-Filter:   - \"Nur erfolgreiche Aktionen\" (SuccessOnly) - Globale Suche:   - Durchsucht alle Spalten gleichzeitig   - Kombinierbar mit anderen Filtern</p> <p>Filter werden kombiniert: - Server-seitige Filter: Datum, User, Action, EntityType, SuccessOnly - Client-seitige Suche: SearchText (nach Laden der Daten)</p>"},{"location":"admin_tools_search_sort_filter/#4-icollectionview-integration","title":"4. ICollectionView Integration","text":"<p>Technische Implementierung:</p> <pre><code>// ViewModel Setup\n_logsView = CollectionViewSource.GetDefaultView(AuditLogs);\n_logsView.Filter = FilterLogs;\n\n// Filter-Methode\nprivate bool FilterLogs(object obj)\n{\n    if (obj is not AuditLogEntry log)\n        return false;\n\n    if (!string.IsNullOrWhiteSpace(SearchText))\n    {\n        var search = SearchText.ToLowerInvariant();\n        var matches = log.User?.ToLowerInvariant().Contains(search) == true ||\n                     log.Action?.ToLowerInvariant().Contains(search) == true ||\n                     // ... weitere Felder\n\n        if (!matches)\n            return false;\n    }\n\n    return true;\n}\n\n// Refresh bei \u00c4nderung\npartial void OnSearchTextChanged(string value)\n{\n    _logsView?.Refresh();\n    UpdateStatusMessage();\n}\n</code></pre> <p>Vorteile: - \u2705 Keine \u00c4nderung der Quell-Collection n\u00f6tig - \u2705 Performance: Nur Ansicht wird aktualisiert - \u2705 Observable Pattern: Automatische UI-Updates - \u2705 Kombinierbar mit Sorting</p>"},{"location":"admin_tools_search_sort_filter/#5-status-updates","title":"5. Status-Updates","text":"<p>Intelligente Statusmeldungen:</p> <pre><code>private void UpdateStatusMessage()\n{\n    var filtered = AuditLogs.Count(log =&gt; _logsView?.Filter == null || _logsView.Filter(log));\n    var total = AuditLogs.Count;\n\n    if (filtered != total)\n    {\n        StatusMessage = $\"{filtered} von {total} Eintr\u00e4gen angezeigt (Gesamt im System: {TotalCount})\";\n    }\n    else\n    {\n        StatusMessage = $\"{total} Eintr\u00e4ge geladen (Gesamt: {TotalCount})\";\n    }\n}\n</code></pre> <p>Angezeigte Informationen: - Gefilterte Anzahl (wenn Filter aktiv) - Geladene Anzahl (aktuelle Seite) - Gesamt-Anzahl im System (alle Seiten)</p>"},{"location":"admin_tools_search_sort_filter/#6-performance-optimierungen","title":"6. Performance-Optimierungen","text":"<p>Client-seitige Filterung: - Filter wird nur auf geladene Daten angewendet (max. 100 Eintr\u00e4ge pro Seite) - Keine Server-Anfrage bei jeder Texteingabe - Instant Feedback f\u00fcr Benutzer</p> <p>Paginierung: - Server-seitige Paginierung (100 Eintr\u00e4ge pro Seite) - Reduziert Netzwerk-Traffic - Schnelle Ladezeiten</p> <p>UpdateSourceTrigger: - PropertyChanged: Sofortige Suche bei Texteingabe - Balance zwischen Responsiveness und Performance</p>"},{"location":"admin_tools_search_sort_filter/#benutzer-workflows","title":"Benutzer-Workflows","text":""},{"location":"admin_tools_search_sort_filter/#workflow-1-schnellsuche-nach-benutzeraktionen","title":"Workflow 1: Schnellsuche nach Benutzeraktionen","text":"<pre><code>1. Tool \u00f6ffnen \u2192 AuditLogViewer\n2. Standard-Filter \u2192 Letzte 7 Tage\n3. \"Laden\" klicken \u2192 Daten werden geladen\n4. Suchfeld eingeben \u2192 \"admin\" (durchsucht alle Spalten)\n5. Ergebnis \u2192 Nur Eintr\u00e4ge mit \"admin\" in irgendeinem Feld\n6. Spalte klicken \u2192 Nach Zeitstempel sortieren\n7. Export \u2192 Gefilterte Daten als CSV exportieren\n</code></pre>"},{"location":"admin_tools_search_sort_filter/#workflow-2-saga-batch-verifizierung-finden","title":"Workflow 2: SAGA-Batch Verifizierung finden","text":"<pre><code>1. Tool \u00f6ffnen \u2192 SAGAVerifier\n2. Auto-Load \u2192 Batches werden geladen\n3. Batch-Suche \u2192 \"abc123\" (Batch-ID Teilstring)\n4. Batch ausw\u00e4hlen \u2192 Details werden geladen\n5. Step-Suche \u2192 \"compensation\" (findet Kompensationsschritte)\n6. Step-Spalte sortieren \u2192 Nach Status sortieren\n7. Verify \u2192 Signatur pr\u00fcfen\n8. Export \u2192 Schritte als CSV exportieren\n</code></pre>"},{"location":"admin_tools_search_sort_filter/#workflow-3-fehleranalyse","title":"Workflow 3: Fehleranalyse","text":"<pre><code>1. AuditLogViewer \u00f6ffnen\n2. Datum setzen \u2192 Gestern bis Heute\n3. Filter: SuccessOnly \u2192 DEAKTIVIEREN\n4. Laden \u2192 Alle Eintr\u00e4ge (inkl. Fehler)\n5. Suche \u2192 \"error\" oder \"exception\"\n6. Spalte \"Success\" \u2192 Sortieren (Fehler zuerst)\n7. Spalte \"Timestamp\" \u2192 Sekund\u00e4re Sortierung\n8. Analyse \u2192 Fehler-Pattern erkennen\n</code></pre>"},{"location":"admin_tools_search_sort_filter/#code-beispiele","title":"Code-Beispiele","text":""},{"location":"admin_tools_search_sort_filter/#beispiel-1-filter-logik-erweitern","title":"Beispiel 1: Filter-Logik erweitern","text":"<pre><code>// Neue Filter-Eigenschaft hinzuf\u00fcgen\n[ObservableProperty]\nprivate string _customFilter = string.Empty;\n\n// In FilterLogs-Methode erweitern\nprivate bool FilterLogs(object obj)\n{\n    if (obj is not AuditLogEntry log)\n        return false;\n\n    // Bestehende Suche...\n    if (!string.IsNullOrWhiteSpace(SearchText))\n    {\n        // ...\n    }\n\n    // NEUE Filter-Logik\n    if (!string.IsNullOrWhiteSpace(CustomFilter))\n    {\n        if (!log.SomeField?.Contains(CustomFilter) == true)\n            return false;\n    }\n\n    return true;\n}\n</code></pre>"},{"location":"admin_tools_search_sort_filter/#beispiel-2-benutzerdefinierte-sortierung","title":"Beispiel 2: Benutzerdefinierte Sortierung","text":"<pre><code>[RelayCommand]\nprivate void CustomSort()\n{\n    _logsView?.SortDescriptions.Clear();\n\n    // Multi-Level Sorting\n    _logsView?.SortDescriptions.Add(\n        new SortDescription(\"Success\", ListSortDirection.Ascending));\n    _logsView?.SortDescriptions.Add(\n        new SortDescription(\"Timestamp\", ListSortDirection.Descending));\n\n    UpdateStatusMessage();\n}\n</code></pre>"},{"location":"admin_tools_search_sort_filter/#beispiel-3-filter-kombinieren","title":"Beispiel 3: Filter kombinieren","text":"<pre><code>private bool FilterLogs(object obj)\n{\n    if (obj is not AuditLogEntry log)\n        return false;\n\n    // AND-Verkn\u00fcpfung: Alle Bedingungen m\u00fcssen erf\u00fcllt sein\n\n    // 1. Suchtext-Filter\n    if (!string.IsNullOrWhiteSpace(SearchText))\n    {\n        var search = SearchText.ToLowerInvariant();\n        var matches = log.User?.ToLowerInvariant().Contains(search) == true ||\n                     log.Action?.ToLowerInvariant().Contains(search) == true;\n\n        if (!matches)\n            return false; // Nicht gefunden \u2192 raus\n    }\n\n    // 2. Erfolgs-Filter\n    if (SuccessOnlyFilter &amp;&amp; !log.Success)\n        return false; // Fehler, aber nur Erfolge gew\u00fcnscht \u2192 raus\n\n    // 3. Benutzer-Filter\n    if (!string.IsNullOrWhiteSpace(UserFilter))\n    {\n        if (!log.User?.Contains(UserFilter, StringComparison.OrdinalIgnoreCase) == true)\n            return false; // Benutzer passt nicht \u2192 raus\n    }\n\n    return true; // Alle Filter bestanden \u2192 anzeigen\n}\n</code></pre>"},{"location":"admin_tools_search_sort_filter/#best-practices","title":"Best Practices","text":""},{"location":"admin_tools_search_sort_filter/#1-performance","title":"1. Performance","text":"<p>\u2705 DO: - Client-seitige Filterung f\u00fcr geladene Daten verwenden - UpdateSourceTrigger=PropertyChanged f\u00fcr Echtzeit-Suche - ICollectionView f\u00fcr effiziente Filterung - Paginierung f\u00fcr gro\u00dfe Datenmengen</p> <p>\u274c DON'T: - Nicht bei jeder Texteingabe Server-Request - Nicht gesamte Datenbank in Memory laden - Nicht ohne Paginierung arbeiten bei &gt;1000 Eintr\u00e4gen</p>"},{"location":"admin_tools_search_sort_filter/#2-benutzerfreundlichkeit","title":"2. Benutzerfreundlichkeit","text":"<p>\u2705 DO: - Platzhalter-Text in Suchfeldern (\"\ud83d\udd0d Search...\") - Tooltips f\u00fcr Suchfunktion - Status-Updates (gefilterte/gesamte Anzahl) - Klare visuelle Trennung von Filtern</p> <p>\u274c DON'T: - Nicht ohne Feedback filtern - Nicht Filter ohne \"L\u00f6schen\"-Button - Nicht ohne Sortier-Indikatoren</p>"},{"location":"admin_tools_search_sort_filter/#3-code-qualitat","title":"3. Code-Qualit\u00e4t","text":"<p>\u2705 DO: - MVVM Pattern verwenden - ICollectionView f\u00fcr Filterung - ObservableCollection f\u00fcr Data Binding - Partial Methods f\u00fcr Property-Change-Events</p> <p>\u274c DON'T: - Nicht Code-Behind f\u00fcr Filter-Logik - Nicht direkt Collection manipulieren - Nicht ohne Property Change Notifications</p>"},{"location":"admin_tools_search_sort_filter/#testing","title":"Testing","text":""},{"location":"admin_tools_search_sort_filter/#unit-tests-fur-filter-logik","title":"Unit Tests f\u00fcr Filter-Logik","text":"<pre><code>[Fact]\npublic void FilterLogs_WithSearchText_FiltersCorrectly()\n{\n    // Arrange\n    var viewModel = new MainWindowViewModel(_mockApiClient.Object);\n    viewModel.SearchText = \"admin\";\n\n    var log1 = new AuditLogEntry { User = \"admin_user\" };\n    var log2 = new AuditLogEntry { User = \"normal_user\" };\n\n    // Act\n    var result1 = viewModel.FilterLogs(log1);\n    var result2 = viewModel.FilterLogs(log2);\n\n    // Assert\n    Assert.True(result1); // admin_user enth\u00e4lt \"admin\"\n    Assert.False(result2); // normal_user enth\u00e4lt nicht \"admin\"\n}\n</code></pre>"},{"location":"admin_tools_search_sort_filter/#integration-tests","title":"Integration Tests","text":"<pre><code>[Fact]\npublic async Task Search_And_Sort_Integration()\n{\n    // Arrange\n    var viewModel = new MainWindowViewModel(_apiClient);\n    await viewModel.LoadBatchesAsync();\n\n    // Act - Suche\n    viewModel.BatchSearchText = \"batch_123\";\n\n    // Act - Sortierung\n    viewModel.SortBatchesCommand.Execute(\"Timestamp\");\n\n    // Assert\n    var view = CollectionViewSource.GetDefaultView(viewModel.Batches);\n    Assert.True(view.SortDescriptions.Count &gt; 0);\n    Assert.All(viewModel.Batches, b =&gt; \n        Assert.Contains(\"batch_123\", b.BatchId));\n}\n</code></pre>"},{"location":"admin_tools_search_sort_filter/#zukunftige-erweiterungen","title":"Zuk\u00fcnftige Erweiterungen","text":""},{"location":"admin_tools_search_sort_filter/#geplante-features","title":"Geplante Features","text":"<ol> <li>Erweiterte Filter-Builder:</li> <li>UND/ODER-Verkn\u00fcpfungen</li> <li>Regul\u00e4re Ausdr\u00fccke</li> <li> <p>Datumsbereich-Presets (\"Letzte Woche\", \"Letzter Monat\")</p> </li> <li> <p>Gespeicherte Filter:</p> </li> <li>Filter-Profile speichern</li> <li>Favoriten-Filter</li> <li> <p>Team-weite Filter-Templates</p> </li> <li> <p>Export-Optionen:</p> </li> <li>Excel-Export mit Formatierung</li> <li>PDF-Reports mit Charts</li> <li> <p>JSON/XML Export</p> </li> <li> <p>Visualisierung:</p> </li> <li>Histogram f\u00fcr Zeitstempel-Verteilung</li> <li>Pie-Chart f\u00fcr Action-Verteilung</li> <li>Heatmap f\u00fcr Benutzer-Aktivit\u00e4t</li> </ol>"},{"location":"admin_tools_search_sort_filter/#zusammenfassung","title":"Zusammenfassung","text":"<p>Die Such-, Sortier- und Filterlogik in den ThemisDB Admin Tools bietet:</p> <p>\u2705 Echtzeit-Suche \u00fcber alle Spalten \u2705 Multi-Column Sorting mit Toggle \u2705 Kombinierbare Filter (AND-Logik) \u2705 ICollectionView f\u00fcr Performance \u2705 Intelligente Status-Updates \u2705 MVVM-Pattern f\u00fcr Wartbarkeit \u2705 Responsive UI (UpdateSourceTrigger) \u2705 Export gefilterte Daten</p> <p>Diese Implementierung erm\u00f6glicht es Administratoren, gro\u00dfe Datenmengen effizient zu durchsuchen, zu analysieren und zu exportieren.</p>"},{"location":"admin_tools_user_guide/","title":"Themis Admin Tools \u2013 Benutzerhandbuch","text":"<p>Dieses Handbuch beschreibt die sieben Themis Admin-Tools mit einheitlichem Layout (Toolbar | Sidebar | Content | StatusBar) und erkl\u00e4rt die wichtigsten Funktionen und Workflows.</p> <ul> <li>Einheitliches Branding: Rechts oben \u201eThemis\u201c (hellblau) \u00f6ffnet den About-Dialog</li> <li>Hamburger-Men\u00fc: Links oben einklappbare Sidebar</li> <li>StatusBar: Live-Status, Z\u00e4hler und Ladeindikator</li> </ul>"},{"location":"admin_tools_user_guide/#gemeinsame-bedienkonzepte","title":"Gemeinsame Bedienkonzepte","text":"<ul> <li>Themis-Brand-Button: Klick \u00f6ffnet \u201e\u00dcber \u2026\u201c-Dialog mit Version/Build-Hinweisen</li> <li>Hamburger-Button: Sidebar ein-/ausblenden</li> <li>Suche: Textfeld \u00fcber dem Grid filtert die angezeigten Eintr\u00e4ge</li> <li>Export: CSV/PDF/Excel je nach Tool verf\u00fcgbar</li> </ul>"},{"location":"admin_tools_user_guide/#1-audit-log-viewer","title":"1) Audit Log Viewer","text":"<ul> <li>Zweck: Audit-Events sichten, filtern, exportieren</li> <li>Wichtige Aktionen: Aktualisieren, CSV-Export</li> <li>Filter: Datum, Benutzer, Action, Entity</li> <li>Tipps: Multi-Column-Sortierung \u00fcber Spaltenk\u00f6pfe nutzen</li> </ul>"},{"location":"admin_tools_user_guide/#2-saga-verifier","title":"2) SAGA Verifier","text":"<ul> <li>Zweck: SAGA-Batch-Signaturen verifizieren</li> <li>Aktionen: Batches laden, Details ansehen, Signatur pr\u00fcfen, Batch flushen</li> <li>Hinweise: Detail-View zeigt Steps/Ergebnisse; Export-Funktion verf\u00fcgbar</li> </ul>"},{"location":"admin_tools_user_guide/#3-pii-manager","title":"3) PII Manager","text":"<ul> <li>Zweck: Verwaltung von UUID\u2194Pseudonym-Mappings, Art. 17 L\u00f6schung, Export</li> <li>Aktionen: Laden, Export CSV, Filter zur\u00fccksetzen, DSGVO-L\u00f6schung per UUID</li> <li>Grid-Spalten: OriginalUuid, Pseudonym, CreatedAt, UpdatedAt, Active</li> </ul>"},{"location":"admin_tools_user_guide/#4-key-rotation-dashboard","title":"4) Key Rotation Dashboard","text":"<ul> <li>Zweck: \u00dcberblick \u00fcber LEK/KEK/DEK-Keys, Rotations-Status und manuelle Rotation</li> <li>Aktionen: Aktualisieren, Rotieren (gesamt oder je Typ LEK/KEK/DEK)</li> <li>Filter: Schl\u00fcsseltyp, nur abgelaufene Keys</li> <li>StatusBar: Anzahl Schl\u00fcssel und abgelaufene in Rot</li> </ul> <p>Backend-Calls: - Liste laden: GET <code>/keys</code> - Rotation ausl\u00f6sen: POST <code>/keys/rotate</code>     - Parameter: <code>key_id</code> im JSON-Body <code>{ \"key_id\": \"DEK\" }</code> oder als Query <code>?key_id=DEK</code></p> <p>Fehlerf\u00e4lle und Hinweise: - 400 Missing key_id \u2192 Bitte Schl\u00fcssel ausw\u00e4hlen - 503 Keys API not available \u2192 Server-Konfiguration pr\u00fcfen (KeyProvider)</p>"},{"location":"admin_tools_user_guide/#5-retention-manager","title":"5) Retention Manager","text":"<ul> <li>Zweck: Aufbewahrungs-Policies verwalten und Bereinigung ausl\u00f6sen</li> <li>Aktionen: Policies laden, neue Policy erstellen, Bereinigung starten</li> <li>Filter: Status (Aktiv/Inaktiv/Abgelaufen), Entit\u00e4tstyp (AuditLog/Document/\u2026)</li> </ul>"},{"location":"admin_tools_user_guide/#6-classification-dashboard","title":"6) Classification Dashboard","text":"<ul> <li>Zweck: Datenklassifizierung (PUBLIC/INTERNAL/CONFIDENTIAL/RESTRICTED) \u00fcberwachen und testen</li> <li>Aktionen: Aktualisieren, CSV-Export, Compliance-Check, Test-Classification</li> <li>Filter: Klassifizierung, Verschl\u00fcsselung, Compliance-Status, Gaps-only</li> <li>Statistik: Live-Counts in der Sidebar</li> </ul> <p>Backend-Calls: - Regeln laden: GET <code>/classification/rules</code> - Klassifikation testen: POST <code>/classification/test</code>     - Body: <code>{ \"text\": \"&lt;Probeinhalt&gt;\", \"metadata\": { \"source\": \"sample\" } }</code>     - Response: <code>{ \"classification\": \"CONFIDENTIAL\", \"confidence\": 0.92, \"detected_entities\": [ { \"type\": \"EMAIL\", \"value\": \"a@b.c\" } ] }</code></p> <p>Fehlerf\u00e4lle und Hinweise: - 400 Missing JSON body \u2192 Eingabefeld ausf\u00fcllen - 503 Classification API not available \u2192 Server-Konfiguration (PIIDetector) pr\u00fcfen</p>"},{"location":"admin_tools_user_guide/#7-compliance-reports","title":"7) Compliance Reports","text":"<ul> <li>Zweck: Reports (DSGVO, SOX, HIPAA, ISO 27001, PCI-DSS) generieren und exportieren</li> <li>Aktionen: Report generieren, Export (PDF/Excel/CSV)</li> <li>Einstellungen: Zeitraum, Template (Standard/Detailliert/\u2026); Diagramme/Technikdetails</li> </ul> <p>Backend-Calls: - Compliance-\u00dcbersicht laden: GET <code>/reports/compliance?type=overview|dsgvo|sox|hipaa|iso27001|pci</code>     - Response-Beispiel (gek\u00fcrzt): <code>{ \"report_type\": \"overview\", \"generated_at\": \"2025-11-02T14:55:00Z\", \"metrics\": { \"encrypted_entities\": 1234, \"pii_findings\": 42 } }</code></p> <p>Fehlerf\u00e4lle und Hinweise: - 503 Reports API not available \u2192 Server-Berechtigungen/Config pr\u00fcfen</p>"},{"location":"admin_tools_user_guide/#starten-der-tools","title":"Starten der Tools","text":"<ul> <li>Bereitstellung: Ver\u00f6ffentlichte EXEs liegen unter <code>dist/&lt;ToolName&gt;/</code></li> <li>Start: Doppelklick auf die jeweilige EXE</li> <li>Voraussetzung: Themis-Server sollte laufen (Standard: http://localhost:8765)</li> </ul> <p>Routing-Hinweis: - Falls die Tools <code>/api/*</code>-Routen verwenden, richten Sie einen Reverse-Proxy ein, der <code>/api/</code> auf den Server-Root <code>/</code> rewritet (siehe Admin-Guide). Alternativ die Tool-Konfiguration auf prefix-freie Endpunkte anpassen.</p>"},{"location":"admin_tools_user_guide/#haufige-fragen-faq","title":"H\u00e4ufige Fragen (FAQ)","text":"<ul> <li>Die Sidebar ist weg? \u2192 Mit dem \u2630-Button oben links wieder einblenden</li> <li>Export-Datei nicht sichtbar? \u2192 In den Standard-Download-Ordner oder Tool-Verzeichnis schauen; ggf. mit Admin-Rechten starten</li> <li>Keine Daten? \u2192 Server/Endpoint pr\u00fcfen, Logs ansehen, Filter zur\u00fccksetzen</li> </ul>"},{"location":"aql_explain_profile/","title":"AQL EXPLAIN &amp; PROFILE","text":"<p>Version: 1.0 Datum: 28. Oktober 2025 Zweck: Dokumentation der Query-Analyse und Performance-Metriken</p>"},{"location":"aql_explain_profile/#uberblick","title":"\u00dcberblick","text":"<p>THEMIS bietet <code>explain=true</code> zur Abfrage von Query-Pl\u00e4nen und Performance-Metriken f\u00fcr AQL-Queries. Dies ist n\u00fctzlich f\u00fcr:</p> <ul> <li>Query-Optimierung und Index-Auswahl</li> <li>Performance-Debugging</li> <li>BFS-Traversal Pruning-Effektivit\u00e4t</li> <li>Filter Short-Circuit Analyse</li> </ul>"},{"location":"aql_explain_profile/#http-api-usage","title":"HTTP API Usage","text":""},{"location":"aql_explain_profile/#request","title":"Request","text":"<pre><code>POST /query/aql\nContent-Type: application/json\n\n{\n  \"query\": \"FOR v IN 1..3 OUTBOUND 'user1' GRAPH 'social' FILTER v.age &gt; 18 RETURN v\",\n  \"explain\": true\n}\n</code></pre>"},{"location":"aql_explain_profile/#response-traversal","title":"Response (Traversal)","text":"<pre><code>{\n  \"table\": \"graph\",\n  \"count\": 42,\n  \"entities\": [...],\n  \"metrics\": {\n    \"constant_filter_precheck\": false,\n    \"edges_expanded\": 156,\n    \"pruned_last_level\": 23,\n    \"filter_evaluations_total\": 89,\n    \"filter_short_circuits\": 12,\n    \"frontier_processed_per_depth\": {\n      \"0\": 1,\n      \"1\": 5,\n      \"2\": 18,\n      \"3\": 65\n    },\n    \"enqueued_per_depth\": {\n      \"1\": 5,\n      \"2\": 18,\n      \"3\": 65\n    }\n  }\n}\n</code></pre>"},{"location":"aql_explain_profile/#response-relational-query","title":"Response (Relational Query)","text":"<pre><code>{\n  \"table\": \"users\",\n  \"count\": 25,\n  \"entities\": [...],\n  \"query\": \"FOR u IN users FILTER u.age &gt; 18 AND u.city == 'Berlin' RETURN u\",\n  \"ast\": {...},\n  \"plan\": {\n    \"mode\": \"index_optimized\",\n    \"order\": [\n      {\"column\": \"city\", \"value\": \"Berlin\"},\n      {\"column\": \"age\", \"value\": \"18\"}\n    ],\n    \"estimates\": [\n      {\"column\": \"city\", \"value\": \"Berlin\", \"estimatedCount\": 100, \"capped\": false},\n      {\"column\": \"age\", \"value\": \"18\", \"estimatedCount\": 500, \"capped\": false}\n    ]\n  }\n}\n</code></pre>"},{"location":"aql_explain_profile/#traversal-metrics","title":"Traversal Metrics","text":""},{"location":"aql_explain_profile/#constant_filter_precheck","title":"constant_filter_precheck","text":"<ul> <li>Typ: <code>boolean</code></li> <li>Beschreibung: Wurde ein konstanter FILTER (ohne v/e-Referenzen) vorab evaluiert?</li> <li>Nutzung: Zeigt, ob die Query vor BFS abgebrochen wurde (wenn false ergibt)</li> </ul> <p>Beispiel:</p> <pre><code>FOR v IN 1..3 OUTBOUND 'user1' GRAPH 'social' \n  FILTER 1 == 2  -- konstant false\n  RETURN v\n</code></pre> <p>\u2192 <code>constant_filter_precheck: true</code>, Ergebnis sofort leer ohne BFS</p>"},{"location":"aql_explain_profile/#edges_expanded","title":"edges_expanded","text":"<ul> <li>Typ: <code>int</code></li> <li>Beschreibung: Anzahl der inspizierten Adjazenz-Kanten (out/in) w\u00e4hrend BFS</li> <li>Nutzung: Indikator f\u00fcr Traversal-Kosten</li> </ul> <p>Interpretation: - Niedrig: Gut pruned oder kleiner Graph - Hoch: Gro\u00dfer Frontier oder fehlende Pr\u00e4dikate</p>"},{"location":"aql_explain_profile/#pruned_last_level","title":"pruned_last_level","text":"<ul> <li>Typ: <code>int</code></li> <li>Beschreibung: Anzahl der am letzten Level (depth == maxDepth) durch v/e-Pr\u00e4dikate weggeschnittenen Nachbarn</li> <li>Nutzung: Wirksamkeit des konservativen Prunings messen</li> </ul> <p>Beispiel:</p> <pre><code>FOR v IN 1..3 OUTBOUND 'user1' GRAPH 'social' \n  FILTER v.age &gt; 30\n  RETURN v\n</code></pre> <p>\u2192 <code>pruned_last_level: 23</code> \u2013 23 Vertices am letzten Level hatten age &lt;= 30 und wurden nicht eingereiht</p>"},{"location":"aql_explain_profile/#filter_evaluations_total","title":"filter_evaluations_total","text":"<ul> <li>Typ: <code>int</code></li> <li>Beschreibung: Anzahl der FILTER-Evaluierungen pro BFS-Zeile (Knoten + eingehende Kante)</li> <li>Nutzung: Overhead durch komplexe Filter tracken</li> </ul> <p>Interpretation: - Sollte &lt;= frontier_processed_per_depth (Summe) sein - Hoch bei komplexen Bool-Ausdr\u00fccken</p>"},{"location":"aql_explain_profile/#filter_short_circuits","title":"filter_short_circuits","text":"<ul> <li>Typ: <code>int</code></li> <li>Beschreibung: Anzahl der Short-Circuits bei AND/OR (Early Exit)</li> <li>Nutzung: Effizienz der Bool-Logik messen</li> </ul> <p>Beispiel:</p> <pre><code>FILTER v.age &gt; 18 AND v.city == \"Berlin\"\n</code></pre> <p>\u2192 Wenn <code>v.age &gt; 18</code> false ist, wird <code>v.city == \"Berlin\"</code> nicht evaluiert \u2192 <code>filter_short_circuits++</code></p>"},{"location":"aql_explain_profile/#frontier_processed_per_depth","title":"frontier_processed_per_depth","text":"<ul> <li>Typ: <code>object</code> (depth \u2192 count)</li> <li>Beschreibung: Anzahl der verarbeiteten Knoten pro Tiefe</li> <li>Nutzung: BFS-Expansion visualisieren</li> </ul> <p>Beispiel:</p> <pre><code>{\n  \"0\": 1,     // Startknoten\n  \"1\": 5,     // 1. Hop: 5 Nachbarn\n  \"2\": 18,    // 2. Hop: 18 Nachbarn\n  \"3\": 65     // 3. Hop: 65 Nachbarn\n}\n</code></pre> <p>Interpretation: - Exponentielles Wachstum: Dichte Graphen - Lineares Wachstum: Sparse oder gut gefiltert</p>"},{"location":"aql_explain_profile/#enqueued_per_depth","title":"enqueued_per_depth","text":"<ul> <li>Typ: <code>object</code> (depth \u2192 count)</li> <li>Beschreibung: Anzahl der eingereihten Knoten je (depth+1) w\u00e4hrend Expansion</li> <li>Nutzung: Neue Frontier-Gr\u00f6\u00dfe tracken (vor visited-Check)</li> </ul> <p>Beispiel:</p> <pre><code>{\n  \"1\": 5,\n  \"2\": 18,\n  \"3\": 42    // 23 wurden sp\u00e4ter durch Pruning gedroppt (siehe pruned_last_level)\n}\n</code></pre>"},{"location":"aql_explain_profile/#relational-query-plan","title":"Relational Query Plan","text":""},{"location":"aql_explain_profile/#mode","title":"mode","text":"<ul> <li>index_optimized: Optimizer-gesteuerter Plan mit Kardinalit\u00e4tssch\u00e4tzung</li> <li>index_parallel: Parallele Index-Scans mit AND-Merge</li> <li>full_scan_fallback: Sequential Scan (wenn allow_full_scan=true und kein Index)</li> <li>index_rangeaware: Range-Pr\u00e4dikate/ORDER BY nutzen Range-Index direkt</li> </ul>"},{"location":"aql_explain_profile/#order","title":"order","text":"<p>Array von Pr\u00e4dikaten in Evaluierungsreihenfolge (sortiert nach Selektivit\u00e4t bei <code>index_optimized</code>)</p>"},{"location":"aql_explain_profile/#estimates","title":"estimates","text":"<p>Kardinalit\u00e4tssch\u00e4tzung pro Pr\u00e4dikat: - estimatedCount: Gesch\u00e4tzte Anzahl Treffer - capped: Wurde die Sch\u00e4tzung bei MAX_ESTIMATE_LIMIT gecappt?</p>"},{"location":"aql_explain_profile/#cursor-range-scan-metriken-relational","title":"Cursor &amp; Range-Scan Metriken (Relational)","text":"<p>Zus\u00e4tzlich zu Traversal-Metriken stellt THEMIS f\u00fcr relationale Abfragen (Sekund\u00e4rindex-Pfad) optionale Cursor-/Range-Informationen bereit:</p>"},{"location":"aql_explain_profile/#explain-plan-felder-bei-explaintrue","title":"Explain-Plan Felder (bei <code>explain=true</code>)","text":"<ul> <li><code>plan.mode</code>: z. B. <code>index_rangeaware</code>, <code>index_optimized</code>, <code>full_scan_fallback</code>.</li> <li><code>plan.cursor</code> (falls <code>use_cursor=true</code> im Request):</li> <li><code>used</code>: Ob der Cursorpfad angewendet wurde.</li> <li><code>cursor_present</code>: Ob ein Cursor-Token im Request vorhanden war.</li> <li><code>sort_column</code>: Sortierspalte bei ORDER BY.</li> <li><code>effective_limit</code>: Tats\u00e4chlich verwendetes Fetch-Limit (typisch <code>count+1</code> f\u00fcr <code>has_more</code>).</li> <li><code>anchor_set</code>: Ob ein Cursor-Anker <code>(sort_value, pk)</code> in der Engine gesetzt wurde.</li> <li><code>requested_count</code>: Angeforderte Seitengr\u00f6\u00dfe aus LIMIT.</li> </ul>"},{"location":"aql_explain_profile/#prometheus-metriken-get-metrics","title":"Prometheus-Metriken (<code>GET /metrics</code>)","text":"<ul> <li><code>vccdb_cursor_anchor_hits_total</code> (counter)</li> <li>Anzahl der Cursor-Anker-Verwendungen im ORDER BY-Paginationpfad.</li> <li><code>vccdb_range_scan_steps_total</code> (counter)</li> <li>Summe der besuchten Indexeintr\u00e4ge bei Range-Scans (einschlie\u00dflich initialem Anker-Scan).</li> <li><code>vccdb_page_fetch_time_ms_bucket</code>, <code>vccdb_page_fetch_time_ms_sum</code>, <code>vccdb_page_fetch_time_ms_count</code> (histogram)</li> <li>Dauer der Seitenerzeugung in <code>handleQueryAql</code> f\u00fcr Cursoranfragen (Millisekunden). Buckets: 1, 5, 10, 25, 50, 100, 250, 500, 1000, 5000, +Inf.</li> </ul> <p>Hinweise: - LIMIT/OFFSET ohne Cursor bleiben unver\u00e4ndert (post\u2011fetch Slicing im HTTP\u2011Handler). - Cursor mit ORDER BY: Die Engine holt <code>count+1</code> Elemente f\u00fcr <code>has_more</code>. Bei ung\u00fcltigem/inkonsistentem Cursor wird eine leere Seite mit <code>has_more=false</code> zur\u00fcckgegeben.</p>"},{"location":"aql_explain_profile/#best-practices","title":"Best Practices","text":""},{"location":"aql_explain_profile/#1-pruning-effektivitat-prufen","title":"1. Pruning-Effektivit\u00e4t pr\u00fcfen","text":"<pre><code>curl -X POST http://localhost:8080/query/aql \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"FOR v IN 1..3 OUTBOUND \\\"user1\\\" GRAPH \\\"social\\\" FILTER v.age &gt; 30 RETURN v\",\n    \"explain\": true\n  }' | jq '.metrics'\n</code></pre> <p>Erwartetes Ergebnis: - <code>pruned_last_level &gt; 0</code> \u2192 Pruning greift - <code>edges_expanded &lt; enqueued_per_depth (Summe)</code> \u2192 Effizienz durch visited-Set</p>"},{"location":"aql_explain_profile/#2-filter-short-circuits-optimieren","title":"2. Filter Short-Circuits optimieren","text":"<p>Stelle selektive Pr\u00e4dikate zuerst:</p> <pre><code>-- Gut (Stadt zuerst, sehr selektiv)\nFILTER v.city == \"Smalltown\" AND v.age &gt; 18\n\n-- Schlecht (Alter zuerst, wenig selektiv)\nFILTER v.age &gt; 18 AND v.city == \"Smalltown\"\n</code></pre> <p>\u2192 Mehr <code>filter_short_circuits</code> bei optimaler Reihenfolge</p>"},{"location":"aql_explain_profile/#3-frontier-explosion-vermeiden","title":"3. Frontier-Explosion vermeiden","text":"<p>Bei <code>frontier_processed_per_depth</code> mit exponentiellem Wachstum: - maxDepth reduzieren - St\u00e4rkere Pr\u00e4dikate (z. B. Edge-Filter) hinzuf\u00fcgen - Index auf v/e-Felder anlegen</p>"},{"location":"aql_explain_profile/#4-konstante-filter-vorab-eliminieren","title":"4. Konstante Filter vorab eliminieren","text":"<pre><code>-- Ineffizient (BFS l\u00e4uft, obwohl Ergebnis immer leer)\nFOR v IN 1..3 OUTBOUND 'user1' GRAPH 'social' \n  FILTER 1 == 2\n  RETURN v\n</code></pre> <p>\u2192 <code>constant_filter_precheck: true</code>, <code>edges_expanded: 0</code></p>"},{"location":"aql_explain_profile/#metriken-erweitern-roadmap","title":"Metriken erweitern (Roadmap)","text":"<p>Geplante Erweiterungen: - [ ] <code>filter_evaluations_per_depth</code> (Granularit\u00e4t pro Level) - [ ] <code>max_frontier_size</code> (Peak Memory-Indikator) - [ ] <code>path_reconstructions</code> (bei RETURN p) - [ ] <code>entity_loads</code> (RocksDB Get-Calls) - [ ] <code>timing_ms</code> (BFS-Dauer, Filter-Dauer, Serialisierung)</p>"},{"location":"aql_explain_profile/#zusammenfassung","title":"Zusammenfassung","text":"Metrik Bedeutung Optimierungsziel <code>edges_expanded</code> BFS-Kosten Minimieren (durch Filter/Pruning) <code>pruned_last_level</code> Pruning-Erfolg Maximieren (zeigt Filtereffizienz) <code>filter_evaluations_total</code> Filter-Overhead Minimieren (einfache Pr\u00e4dikate bevorzugen) <code>filter_short_circuits</code> Bool-Logik-Effizienz Maximieren (selektive Pr\u00e4dikate zuerst) <code>frontier_processed_per_depth</code> BFS-Expansion Kontrolliert wachsen (nicht exponentiell) <code>enqueued_per_depth</code> Neue Frontier Niedrig halten (visited-Set wirkt) <p>Faustregel: <code>pruned_last_level / edges_expanded</code> sollte &gt; 10% sein f\u00fcr effektives Pruning.</p> <p>Siehe auch: - AQL Syntax - Indexes - Graph Traversal</p>"},{"location":"aql_syntax/","title":"AQL - THEMIS Query Language","text":"<p>Version: 1.0 Datum: 30. Oktober 2025 Inspiriert von: ArangoDB AQL, mit Fokus auf Multi-Modell-Queries</p>"},{"location":"aql_syntax/#uberblick","title":"\u00dcberblick","text":"<p>AQL (Advanced Query Language) ist eine deklarative SQL-\u00e4hnliche Sprache f\u00fcr THEMIS, optimiert f\u00fcr hybride Queries \u00fcber relationale, Graph-, Vektor- und Dokument-Daten.</p> <p>Design-Prinzipien: - \u2705 Einfach: SQL-\u00e4hnliche Syntax f\u00fcr schnelle Adoption - \u2705 M\u00e4chtig: Multi-Modell-Support (Relational, Graph, Vector) - \u2705 Optimierbar: Automatische Index-Auswahl via Optimizer - \u2705 Erweiterbar: Schrittweise Erweiterung (Aggregationen, Joins, Subqueries)</p>"},{"location":"aql_syntax/#syntax-ubersicht","title":"Syntax-\u00dcbersicht","text":""},{"location":"aql_syntax/#grundstruktur","title":"Grundstruktur","text":"<pre><code>FOR variable IN collection\n  [LET var = expression [, ...]]\n  [FILTER condition]\n  [SORT expression [ASC|DESC] [, ...]]\n  [LIMIT offset, count]\n  [RETURN expression]\n</code></pre> <p>Execution-Reihenfolge: 1. <code>FOR</code> - Iteration \u00fcber Collection/Index 2. <code>FILTER</code> - Pr\u00e4dikat-Evaluation (mit Index-Nutzung) 3. <code>SORT</code> - Sortierung (mit Index-Nutzung wenn m\u00f6glich) 4. <code>LIMIT</code> - Pagination/Offset 5. <code>RETURN</code> - Projektion (Felder/Objekte/Arrays)</p>"},{"location":"aql_syntax/#mvp-einschrankungen-und-hinweise","title":"MVP-Einschr\u00e4nkungen und Hinweise","text":"<p>Damit Erwartungen klar sind, hier die wichtigsten Begrenzungen des aktuellen MVP:</p> <ul> <li>Kein generisches OR im Translator. AND wird unterst\u00fctzt; OR ist in Arbeit und wird sp\u00e4ter erg\u00e4nzt.</li> <li>Feld-zu-Feld Vergleiche (z. B. <code>u.city == o.city</code>) sind im Translator nicht allgemein erlaubt. Ein spezieller Join-Pfad erlaubt jedoch Gleichheits\u2011Joins \u00fcber genau zwei FOR\u2011Klauseln (siehe Abschnitt \u201eEinfache Joins (MVP)\u201c).</li> <li>LET in FILTER: Falls einfache LET\u2011Bindungen in FILTER vorkommen, werden diese vor der \u00dcbersetzung extrahiert (\u201epre\u2011extracted\u201c). Bei <code>explain: true</code> signalisiert der Plan dies mit <code>plan.let_pre_extracted = true</code>.</li> <li>Subqueries, OR, komplexe Ausdr\u00fccke/Funktionen sind (noch) eingeschr\u00e4nkt und werden iterativ erweitert.</li> </ul>"},{"location":"aql_syntax/#kern-klauseln","title":"Kern-Klauseln","text":""},{"location":"aql_syntax/#1-for-collection-iteration","title":"1. FOR - Collection Iteration","text":"<pre><code>FOR doc IN users\n  RETURN doc\n\nFOR u IN users\n  FILTER u.age &gt; 18\n  RETURN u.name\n</code></pre> <p>Syntax: - <code>variable</code> - Beliebiger Bezeichner (lowercase empfohlen) - <code>collection</code> - Table-Name aus Storage-Layer</p> <p>Multi-Collection (Joins - MVP seit 31.10.2025):</p> <p>Themis unterst\u00fctzt Nested-Loop-Joins \u00fcber mehrere Collections via sequenzielle <code>FOR</code>-Klauseln:</p> <pre><code>FOR u IN users\n  FOR o IN orders\n    FILTER o.user_id == u._key\n    RETURN {user: u.name, order: o.id}\n</code></pre> <p>Join-Arten (MVP): - Equality Join: Verkn\u00fcpfung \u00fcber <code>FILTER var1.field == var2.field</code> - Cross Product + Filter: Kartesisches Produkt mit nachtr\u00e4glicher Filterung</p> <p>Beispiel - User-City-Join:</p> <pre><code>FOR user IN users\n  FOR city IN cities\n    FILTER user.city_id == city._key\n    RETURN {\n      user_name: user.name,\n      city_name: city.name,\n      country: city.country\n    }\n</code></pre> <p>Performance-Hinweise: - \u26a0\ufe0f Nested-Loop kann teuer sein bei gro\u00dfen Datasets (O(n\u00d7m) Komplexit\u00e4t) - \ud83d\udca1 Empfehlung: FILTER-Bedingungen so spezifisch wie m\u00f6glich - \ud83d\udca1 Zuk\u00fcnftig: Hash-Join-Optimierung f\u00fcr gro\u00dfe Collections geplant - \ud83d\udca1 Verwende Indizes auf Join-Spalten (z.B. <code>city_id</code>) wo m\u00f6glich</p> <p>Multi-FOR Limitierungen (MVP): - Maximal 2-3 FOR-Klauseln empfohlen (Performance) - Join-Bedingung muss in FILTER sein (keine impliziten Joins) - Nur Equality-Joins (<code>==</code>) optimiert</p>"},{"location":"aql_syntax/#2-filter-bedingungen","title":"2. FILTER - Bedingungen","text":"<p>Vergleichsoperatoren:</p> <pre><code>FILTER doc.age == 25          // Gleichheit\nFILTER doc.age != 25          // Ungleichheit\nFILTER doc.age &gt; 18           // Gr\u00f6\u00dfer\nFILTER doc.age &gt;= 18          // Gr\u00f6\u00dfer-Gleich\nFILTER doc.age &lt; 65           // Kleiner\nFILTER doc.age &lt;= 65          // Kleiner-Gleich\n</code></pre> <p>Logische Operatoren:</p> <pre><code>FILTER doc.age &gt; 18 AND doc.city == \"Berlin\"\nFILTER doc.status == \"active\" OR doc.status == \"pending\"   // Hinweis: OR im MVP noch nicht unterst\u00fctzt\nFILTER NOT doc.deleted\n</code></pre> <p>IN-Operator:</p> <pre><code>FILTER doc.status IN [\"active\", \"pending\", \"approved\"]\nFILTER doc.age IN [18, 21, 25, 30]\n</code></pre> <p>String-Operatoren:</p> <pre><code>FILTER LIKE(doc.name, \"Max%\")           // Prefix-Match\nFILTER CONTAINS(doc.description, \"AI\")  // Substring\nFILTER REGEX_TEST(doc.email, \".*@example\\.com\")\n</code></pre> <p>NULL-Checks:</p> <pre><code>FILTER doc.email != null\nFILTER doc.phone == null\n</code></pre>"},{"location":"aql_syntax/#3-sort-sortierung","title":"3. SORT - Sortierung","text":"<p>Einfache Sortierung:</p> <pre><code>SORT doc.age                  // ASC (default)\nSORT doc.age DESC\nSORT doc.created_at DESC\n</code></pre> <p>Multi-Column-Sort:</p> <pre><code>SORT doc.city ASC, doc.age DESC\nSORT doc.priority DESC, doc.created_at ASC\n</code></pre> <p>Index-Nutzung: - Range-Index auf <code>age</code> \u2192 effiziente Sortierung - Composite-Index <code>(city, age)</code> \u2192 optimale Multi-Column-Sort</p>"},{"location":"aql_syntax/#4-limit-pagination","title":"4. LIMIT - Pagination","text":"<p>Syntax:</p> <pre><code>LIMIT count                   // Erste N Ergebnisse\nLIMIT offset, count           // Pagination\n</code></pre> <p>Beispiele:</p> <pre><code>LIMIT 10                      // Erste 10\nLIMIT 20, 10                  // Zeilen 21-30 (Seite 3)\n</code></pre> <p>Best Practices: - Immer mit <code>LIMIT</code> arbeiten (verhindert Full-Scans) - F\u00fcr gro\u00dfe Offsets: Cursor-basierte Pagination bevorzugen</p>"},{"location":"aql_syntax/#5-return-projektion","title":"5. RETURN - Projektion","text":"<p>Ganzes Dokument:</p> <pre><code>RETURN doc\n</code></pre> <p>Einzelne Felder:</p> <pre><code>RETURN doc.name\nRETURN doc.email\n</code></pre> <p>Objekt-Konstruktion:</p> <pre><code>RETURN {\n  name: doc.name,\n  age: doc.age,\n  city: doc.city\n}\n</code></pre> <p>Berechnete Felder:</p> <pre><code>RETURN {\n  name: doc.name,\n  age_in_months: doc.age * 12,\n  full_address: CONCAT(doc.street, \", \", doc.city)\n}\n</code></pre> <p>Arrays:</p> <pre><code>RETURN [doc.name, doc.age, doc.city]\n</code></pre> <p>Unterst\u00fctzte Ausdr\u00fccke im MVP: - Literale: Zahl, String, Bool, null - Variablen und Feldzugriff: <code>doc</code>, <code>doc.field</code> - Objekt- und Array-Literale (verschachtelt m\u00f6glich) - Einfache Let-Bindings pro Zeile (siehe LET)</p>"},{"location":"aql_syntax/#erweiterte-features-phase-11","title":"Erweiterte Features (Phase 1.1+)","text":""},{"location":"aql_syntax/#let-variable-binding-mvp-seit-31102025","title":"LET - Variable Binding (MVP seit 31.10.2025)","text":"<p>Bindet pro Iteration Werte an Variablen, die in <code>FILTER</code> und <code>RETURN</code> genutzt werden k\u00f6nnen.</p> <p>Einfaches Beispiel:</p> <pre><code>FOR u IN users\n  LET city_name = u.city\n  RETURN {name: u.name, city: city_name}\n</code></pre> <p>Berechnungen mit LET:</p> <pre><code>FOR product IN products\n  LET total_value = product.price * product.quantity\n  FILTER total_value &gt; 1000\n  RETURN {\n    product: product.name,\n    value: total_value\n  }\n</code></pre> <p>Mehrere LET-Bindungen:</p> <pre><code>FOR sale IN sales\n  LET net = sale.amount\n  LET tax = net * 0.19\n  LET gross = net + tax\n  RETURN {sale_id: sale._key, net, tax, gross}\n</code></pre> <p>LET in Joins:</p> <pre><code>FOR user IN users\n  FOR order IN orders\n    FILTER order.user_id == user._key\n    LET full_name = CONCAT(user.first_name, \" \", user.last_name)\n    RETURN {customer: full_name, order_id: order._key}\n</code></pre> <p>MVP-Einschr\u00e4nkungen: - Unterst\u00fctzt sind aktuell einfache Ausdr\u00fccke: Literale, Variablen, Feldzugriffe, Bin\u00e4roperationen (+, -, *, /), Objekt-/Array-Literale - LETs werden sequenziell ausgewertet; sp\u00e4tere LETs k\u00f6nnen fr\u00fchere verwenden - Komplexe Funktionen (CONCAT, SUBSTRING, etc.) in Entwicklung - Explain: Wenn <code>LET</code>\u2011Variablen in <code>FILTER</code> zu einfachen Gleichheitspr\u00e4dikaten vor der \u00dcbersetzung extrahiert wurden, enth\u00e4lt der Plan das Flag <code>plan.let_pre_extracted = true</code></p>"},{"location":"aql_syntax/#collect-aggregationen-mvp-seit-31102025","title":"COLLECT - Aggregationen (MVP seit 31.10.2025)","text":"<p>Gruppiert Ergebnisse und berechnet Aggregatfunktionen.</p> <p>Einfaches GROUP BY:</p> <pre><code>FOR user IN users\n  COLLECT city = user.city\n  RETURN {city, count: LENGTH(1)}\n</code></pre> <p>COUNT-Aggregation:</p> <pre><code>FOR user IN users\n  COLLECT city = user.city WITH COUNT INTO total\n  RETURN {city, total}\n</code></pre> <p>SUM-Aggregation:</p> <pre><code>FOR sale IN sales\n  COLLECT category = sale.category\n  AGGREGATE total_revenue = SUM(sale.amount)\n  RETURN {category, total_revenue}\n</code></pre> <p>Mehrere Aggregationen:</p> <pre><code>FOR order IN orders\n  COLLECT status = order.status\n  AGGREGATE \n    total_count = COUNT(),\n    total_amount = SUM(order.amount),\n    avg_amount = AVG(order.amount),\n    min_amount = MIN(order.amount),\n    max_amount = MAX(order.amount)\n  RETURN {status, total_count, total_amount, avg_amount, min_amount, max_amount}\n</code></pre> <p>COLLECT mit FILTER:</p> <pre><code>FOR user IN users\n  FILTER user.age &gt; 18\n  COLLECT city = user.city\n  AGGREGATE adult_count = COUNT()\n  RETURN {city, adult_count}\n</code></pre> <p>Unterst\u00fctzte Aggregatfunktionen (MVP): - <code>COUNT()</code> - Anzahl der Gruppen-Elemente - <code>SUM(expr)</code> - Summe eines numerischen Felds - <code>AVG(expr)</code> - Durchschnitt eines numerischen Felds - <code>MIN(expr)</code> - Minimum eines Felds - <code>MAX(expr)</code> - Maximum eines Felds</p> <p>Performance-Hinweise: - Hash-basiertes Grouping: O(n) Komplexit\u00e4t - FILTER vor COLLECT reduziert Datenvolumen (wird automatisch optimiert) - F\u00fcr sehr gro\u00dfe Gruppen: Memory-Nutzung beachten</p> <p>Geplante Erweiterungen: - <code>STDDEV(expr)</code> - Standardabweichung - <code>VARIANCE(expr)</code> - Varianz - <code>PERCENTILE(expr, n)</code> - n-tes Perzentil - <code>UNIQUE(expr)</code> - Distinct Values</p> <p>Hinweise (MVP): - Gruppierung erfolgt \u00fcber exakte String-Matches der Group-Keys - Mehrere GROUP BY-Felder via Tuple-Keys geplant - HAVING-Clause (Post-Aggregation-Filter) in Entwicklung</p>"},{"location":"aql_syntax/#http-spezifische-parameter-fur-pagination","title":"HTTP-spezifische Parameter f\u00fcr Pagination","text":"<p>Bei Nutzung des HTTP-Endpunkts <code>POST /query/aql</code> k\u00f6nnen optionale Felder zur Pagination mitgegeben werden:</p> <pre><code>{\n  \"query\": \"FOR u IN users SORT u.age ASC LIMIT 10 RETURN u\",\n  \"use_cursor\": true,\n  \"cursor\": \"&lt;token-aus-previous-response&gt;\",\n  \"allow_full_scan\": false\n}\n</code></pre> <ul> <li><code>use_cursor</code> (bool): Aktiviert Cursor-basierte Pagination. Antwortformat enth\u00e4lt <code>{items, has_more, next_cursor, batch_size}</code>.</li> <li><code>cursor</code> (string): Token aus <code>next_cursor</code> der vorherigen Seite. G\u00fcltig nur in Kombination mit <code>use_cursor: true</code>.</li> <li><code>allow_full_scan</code> (bool): Optionaler Fallback f\u00fcr kleine Datenmengen/Tests; f\u00fcr gro\u00dfe Daten wird Index-basierte Sortierung empfohlen.</li> </ul> <p>Weitere Details siehe <code>docs/cursor_pagination.md</code>.</p>"},{"location":"aql_syntax/#spezial-queries","title":"Spezial-Queries","text":""},{"location":"aql_syntax/#graph-traversierung","title":"Graph-Traversierung","text":"<pre><code>FOR v, e, p IN 1..3 OUTBOUND \"users/alice\" edges\n  FILTER v.active == true\n  RETURN {vertex: v, edge: e, path: p}\n</code></pre> <p>Traversal-Richtungen: - <code>OUTBOUND</code> - Ausgehende Kanten (Alice \u2192 Bob) - <code>INBOUND</code> - Eingehende Kanten (Alice \u2190 Bob) - <code>ANY</code> - Beide Richtungen</p> <p>Depth-Limits: - <code>1..1</code> - Nur direkte Nachbarn - <code>1..3</code> - Bis zu 3 Hops - <code>2..5</code> - Min 2, Max 5 Hops</p>"},{"location":"aql_syntax/#vektor-ahnlichkeitssuche","title":"Vektor-\u00c4hnlichkeitssuche","text":"<pre><code>FOR doc IN users\n  NEAR(doc.embedding, @query_vector, 10)\n  FILTER doc.age &gt; 18\n  RETURN {name: doc.name, similarity: SIMILARITY()}\n</code></pre> <p>Funktionen: - <code>NEAR(field, vector, k)</code> - k-NN-Suche - <code>SIMILARITY()</code> - Aktueller Similarity-Score (0.0 - 1.0)</p> <p>Metriken:</p> <pre><code>NEAR(doc.embedding, @query_vector, 10, \"cosine\")    // Cosine Similarity\nNEAR(doc.embedding, @query_vector, 10, \"euclidean\") // L2-Distance\n</code></pre>"},{"location":"aql_syntax/#geo-queries","title":"Geo-Queries","text":"<pre><code>FOR doc IN locations\n  GEO_DISTANCE(doc.lat, doc.lon, 52.52, 13.405) &lt; 5000\n  RETURN {name: doc.name, distance: GEO_DISTANCE(doc.lat, doc.lon, 52.52, 13.405)}\n</code></pre> <p>Funktionen: - <code>GEO_DISTANCE(lat1, lon1, lat2, lon2)</code> - Haversine-Distanz (Meter) - <code>GEO_BOX(lat, lon, minLat, maxLat, minLon, maxLon)</code> - Bounding-Box-Check</p>"},{"location":"aql_syntax/#fulltext-suche","title":"Fulltext-Suche","text":"<pre><code>FOR doc IN articles\n  FULLTEXT(doc.content, \"machine learning AI\")\n  SORT BM25(doc) DESC\n  LIMIT 10\n  RETURN {title: doc.title, score: BM25(doc)}\n</code></pre> <p>Funktionen: - <code>FULLTEXT(field, query)</code> - Tokenisierte Suche - <code>BM25(doc)</code> - Relevanz-Score (0.0+)</p>"},{"location":"aql_syntax/#einfache-joins-mvp","title":"Einfache Joins (MVP)","text":"<p>Unterst\u00fctzt werden Equality-Joins \u00fcber genau zwei <code>FOR</code>-Klauseln mit einem Gleichheitspr\u00e4dikat zwischen Variablen.</p> <pre><code>FOR u IN users\n  FOR o IN orders\n  FILTER u._key == o.user_id\n  RETURN u\n</code></pre> <p>Eigenschaften und Einschr\u00e4nkungen (MVP): - Genau zwei <code>FOR</code>\u2011Klauseln; ein Equality\u2011Pr\u00e4dikat <code>var1.field == var2.field</code> in <code>FILTER</code>. - Zus\u00e4tzliche <code>FILTER</code> pro Seite sind erlaubt und werden vor dem Join angewendet. - <code>RETURN</code> muss aktuell eine der Variablen zur\u00fcckgeben (typisch <code>u</code> oder <code>o</code>). - <code>LIMIT</code> wird nach dem Join angewendet. <code>SORT</code> im Join\u2011Pfad ist derzeit nicht unterst\u00fctzt. - <code>explain: true</code> liefert einen Plan, der den Join\u2011Pfad ausweist; bei LET\u2011Pre\u2011Extraction wird <code>plan.let_pre_extracted = true</code> gesetzt.</p> <p>Projektion mit LET im Join-Kontext:</p> <pre><code>FOR u IN users\n  FOR o IN orders\n  FILTER u._key == o.user_id\n  LET info = { user: u.name, order: o.id }\n  RETURN info\n</code></pre> <p>Hinweis: Komplexe Projektionen k\u00f6nnen je nach Datenvolumen h\u00f6here Kosten verursachen; nutze <code>LIMIT</code> wo sinnvoll.</p>"},{"location":"aql_syntax/#funktionen-operatoren","title":"Funktionen &amp; Operatoren","text":""},{"location":"aql_syntax/#string-funktionen","title":"String-Funktionen","text":"<pre><code>CONCAT(str1, str2, ...)       // \"Hello\" + \" \" + \"World\"\nLOWER(str)                     // \"HELLO\" \u2192 \"hello\"\nUPPER(str)                     // \"hello\" \u2192 \"HELLO\"\nSUBSTRING(str, offset, length) // \"Hello\"[1:4] \u2192 \"ell\"\nLENGTH(str)                    // \"Hello\" \u2192 5\nTRIM(str)                      // \"  Hello  \" \u2192 \"Hello\"\n</code></pre>"},{"location":"aql_syntax/#numeric-funktionen","title":"Numeric-Funktionen","text":"<pre><code>ABS(num)                       // |-5| \u2192 5\nCEIL(num) / FLOOR(num)         // 3.7 \u2192 4 / 3\nROUND(num, decimals)           // 3.14159, 2 \u2192 3.14\nSQRT(num)                      // \u221a16 \u2192 4\nPOW(base, exp)                 // 2^8 \u2192 256\n</code></pre>"},{"location":"aql_syntax/#aggregations-in-collect","title":"Aggregations (in COLLECT)","text":"<pre><code>COUNT()                        // Anzahl Zeilen\nSUM(expr)                      // Summe\nAVG(expr)                      // Durchschnitt\nMIN(expr) / MAX(expr)          // Minimum/Maximum\nSTDDEV(expr)                   // Standardabweichung\nVARIANCE(expr)                 // Varianz\n</code></pre>"},{"location":"aql_syntax/#type-checks","title":"Type-Checks","text":"<pre><code>IS_NULL(value)\nIS_NUMBER(value)\nIS_STRING(value)\nIS_ARRAY(value)\nIS_OBJECT(value)\n</code></pre>"},{"location":"aql_syntax/#beispiel-queries","title":"Beispiel-Queries","text":""},{"location":"aql_syntax/#1-einfache-filterung","title":"1. Einfache Filterung","text":"<pre><code>FOR user IN users\n  FILTER user.age &gt; 18 AND user.city == \"Berlin\"\n  SORT user.created_at DESC\n  LIMIT 10\n  RETURN {\n    name: user.name,\n    email: user.email,\n    age: user.age\n  }\n</code></pre> <p>Optimizer: - Nutzt Composite-Index <code>(city, age)</code> falls vorhanden - Fallback: Equality-Index <code>city</code> + Full-Scan-Filter <code>age</code></p>"},{"location":"aql_syntax/#2-geo-proximity-search","title":"2. Geo-Proximity-Search","text":"<pre><code>FOR loc IN restaurants\n  FILTER GEO_DISTANCE(loc.lat, loc.lon, 52.52, 13.405) &lt; 2000\n  FILTER loc.rating &gt;= 4.0\n  SORT GEO_DISTANCE(loc.lat, loc.lon, 52.52, 13.405) ASC\n  LIMIT 5\n  RETURN {\n    name: loc.name,\n    rating: loc.rating,\n    distance: GEO_DISTANCE(loc.lat, loc.lon, 52.52, 13.405)\n  }\n</code></pre> <p>Optimizer: - Nutzt Geo-Index f\u00fcr Bounding-Box-Scan - Post-Filter f\u00fcr exakte Distanz-Berechnung</p>"},{"location":"aql_syntax/#3-vektor-suche-mit-filter","title":"3. Vektor-Suche mit Filter","text":"<pre><code>FOR product IN products\n  NEAR(product.embedding, @query_vector, 20)\n  FILTER product.price &lt; 100.0 AND product.in_stock == true\n  SORT SIMILARITY() DESC\n  LIMIT 10\n  RETURN {\n    name: product.name,\n    price: product.price,\n    similarity: SIMILARITY()\n  }\n</code></pre> <p>Pre-Filtering vs Post-Filtering: - Pre-Filter: Bitset f\u00fcr <code>price &lt; 100 AND in_stock == true</code> \u2192 k-NN - Post-Filter: k-NN (20) \u2192 Filter \u2192 Top-10</p>"},{"location":"aql_syntax/#4-aggregationen","title":"4. Aggregationen","text":"<pre><code>FOR order IN orders\n  FILTER order.created_at &gt;= \"2025-01-01\"\n  COLLECT city = order.city\n  AGGREGATE \n    total_revenue = SUM(order.amount),\n    avg_order = AVG(order.amount),\n    order_count = COUNT()\n  SORT total_revenue DESC\n  LIMIT 10\n  RETURN {\n    city,\n    total_revenue,\n    avg_order,\n    order_count\n  }\n</code></pre>"},{"location":"aql_syntax/#5-graph-traversierung","title":"5. Graph-Traversierung","text":"<pre><code>FOR vertex, edge, path IN 1..3 OUTBOUND \"users/alice\" friendships\n  FILTER vertex.active == true\n  RETURN {\n    friend: vertex.name,\n    connection_type: edge.type,\n    path_length: LENGTH(path.edges)\n  }\n</code></pre>"},{"location":"aql_syntax/#query-execution-optimizer","title":"Query-Execution &amp; Optimizer","text":""},{"location":"aql_syntax/#explain-plan","title":"Explain-Plan","text":"<pre><code>POST /query/aql\n{\n  \"query\": \"FOR u IN users FILTER u.age &gt; 18 SORT u.created_at DESC LIMIT 10\",\n  \"explain\": true\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"plan\": {\n    \"mode\": \"range_aware\",\n    \"order\": [\n      { \"column\": \"created_at\", \"value\": \"DESC\" }\n    ],\n    \"estimates\": [\n      { \"column\": \"age\", \"value\": \"&gt; 18\", \"estimatedCount\": 1200, \"capped\": false }\n    ],\n    \"let_pre_extracted\": true\n  }\n}\n</code></pre>"},{"location":"aql_syntax/#index-hints-spater","title":"Index-Hints (sp\u00e4ter)","text":"<pre><code>FOR doc IN users USE INDEX idx_age_city\n  FILTER doc.age &gt; 18\n  RETURN doc\n</code></pre>"},{"location":"aql_syntax/#ast-struktur-internal","title":"AST-Struktur (Internal)","text":"<pre><code>// AST-Node-Typen\nenum class ASTNodeType {\n    ForNode,          // FOR variable IN collection\n    FilterNode,       // FILTER condition\n    SortNode,         // SORT expr [ASC|DESC]\n    LimitNode,        // LIMIT offset, count\n    ReturnNode,       // RETURN expression\n\n    // Expressions\n    BinaryOp,         // ==, !=, &gt;, &lt;, &gt;=, &lt;=, AND, OR\n    UnaryOp,          // NOT, -\n    FunctionCall,     // CONCAT, SUM, etc.\n    FieldAccess,      // doc.field\n    Literal,          // \"string\", 123, true, null\n    Variable          // doc, user, etc.\n};\n\n// Beispiel-AST f\u00fcr: FOR u IN users FILTER u.age &gt; 18 RETURN u.name\nForNode {\n    variable: \"u\",\n    collection: \"users\",\n\n    filter: FilterNode {\n        condition: BinaryOp {\n            op: \"&gt;\",\n            left: FieldAccess(\"u\", \"age\"),\n            right: Literal(18)\n        }\n    },\n\n    return_expr: ReturnNode {\n        expression: FieldAccess(\"u\", \"name\")\n    }\n}\n</code></pre>"},{"location":"aql_syntax/#implementierungs-phasen","title":"Implementierungs-Phasen","text":""},{"location":"aql_syntax/#phase-1-mvp-woche-1-2","title":"Phase 1 (MVP - Woche 1-2):","text":"<ul> <li>\u2705 FOR, FILTER (Equality, Range, IN), SORT, LIMIT, RETURN</li> <li>\u2705 Parser (PEGTL)</li> <li>\u2705 AST \u2192 QueryEngine-Translation</li> <li>\u2705 HTTP-Endpoint <code>/query/aql</code></li> <li>\u2705 Unit-Tests</li> </ul>"},{"location":"aql_syntax/#phase-2-woche-3-4","title":"Phase 2 (Woche 3-4):","text":"<ul> <li>LET (Variable Binding)</li> <li>COLLECT (Aggregationen: COUNT, SUM, AVG)</li> <li>String-/Numeric-Funktionen</li> <li>Explain-Plan-Integration</li> </ul>"},{"location":"aql_syntax/#phase-3-woche-5-6","title":"Phase 3 (Woche 5-6):","text":"<ul> <li>Graph-Traversierung (FOR v, e, p IN ... OUTBOUND)</li> <li>Vektor-Suche (NEAR, SIMILARITY)</li> <li>Geo-Queries (GEO_DISTANCE, GEO_BOX)</li> <li>Fulltext (FULLTEXT, BM25)</li> </ul>"},{"location":"aql_syntax/#phase-4-spater","title":"Phase 4 (sp\u00e4ter):","text":"<ul> <li>Joins (Multi-Collection)</li> <li>Subqueries</li> <li>Transactions (BEGIN, COMMIT, ROLLBACK)</li> <li>INSERT, UPDATE, DELETE via AQL</li> </ul>"},{"location":"aql_syntax/#performance-uberlegungen","title":"Performance-\u00dcberlegungen","text":"<p>Index-Nutzung: - FILTER mit <code>==</code> \u2192 Equality-Index - FILTER mit <code>&gt;</code>, <code>&lt;</code> \u2192 Range-Index - FILTER mit <code>IN</code> \u2192 Batch-Lookup - SORT \u2192 Range-Index (wenn vorhanden)</p> <p>Optimizer-Strategien: - Filter-Pushdown: FILTER vor SORT (reduziert Sortier-Kosten) - Index-Auswahl: Kleinster gesch\u00e4tzter Index zuerst - Short-Circuit: LIMIT fr\u00fch anwenden (z.B. Top-K)</p> <p>Vermeiden: - Full-Table-Scans ohne LIMIT - Sortierung ohne Index auf gro\u00dfen Datasets - Aggregationen ohne COLLECT (ineffizient)</p>"},{"location":"aql_syntax/#kompatibilitat-erweiterungen","title":"Kompatibilit\u00e4t &amp; Erweiterungen","text":"<p>ArangoDB AQL: - \u00c4hnliche Syntax (FOR, FILTER, SORT, LIMIT, RETURN) - Unterschiede: THEMIS nutzt natives MVCC, kein <code>_key</code> zwingend</p> <p>SQL-Vergleich:</p> <pre><code>-- SQL\nSELECT name, age FROM users WHERE age &gt; 18 ORDER BY created_at DESC LIMIT 10;\n\n-- AQL\nFOR user IN users\n  FILTER user.age &gt; 18\n  SORT user.created_at DESC\n  LIMIT 10\n  RETURN {name: user.name, age: user.age}\n</code></pre> <p>Vorteile AQL: - Multi-Modell (Graph, Vector, Geo in einer Query) - Explizite Execution-Reihenfolge (leichter zu optimieren) - Schemalos (flexible Felder)</p>"},{"location":"aql_syntax/#fehlerbehandlung","title":"Fehlerbehandlung","text":"<p>Syntax-Errors:</p> <pre><code>{\n  \"error\": \"Syntax error at line 2, column 10: Expected 'IN' after variable name\",\n  \"query\": \"FOR user users FILTER ...\",\n  \"line\": 2,\n  \"column\": 10\n}\n</code></pre> <p>Semantic-Errors:</p> <pre><code>{\n  \"error\": \"Collection 'userz' does not exist (did you mean 'users'?)\",\n  \"query\": \"FOR u IN userz RETURN u\"\n}\n</code></pre> <p>Runtime-Errors:</p> <pre><code>{\n  \"error\": \"Division by zero in expression: amount / quantity\",\n  \"entity_key\": \"orders:12345\"\n}\n</code></pre>"},{"location":"aql_syntax/#referenz-links","title":"Referenz-Links","text":"<ul> <li>Parser: PEGTL (https://github.com/taocpp/PEGTL)</li> <li>Inspiration: ArangoDB AQL (https://www.arangodb.com/docs/stable/aql/)</li> <li>Optimizer: docs/query_optimizer.md</li> <li>Index-Typen: docs/indexes.md</li> </ul> <p>Status: \u2705 Syntax-Definition vollst\u00e4ndig N\u00e4chster Schritt: Parser-Implementation mit PEGTL</p>"},{"location":"aql_syntax/#vollstandige-beispiele-mvp-features","title":"Vollst\u00e4ndige Beispiele (MVP Features)","text":""},{"location":"aql_syntax/#beispiel-1-user-city-join-mit-aggregation","title":"Beispiel 1: User-City-Join mit Aggregation","text":"<p>Szenario: Finde alle User in ihren St\u00e4dten, gruppiert nach Land mit Z\u00e4hlung:</p> <pre><code>FOR user IN users\n  FOR city IN cities\n    FILTER user.city_id == city._key\n    COLLECT country = city.country\n    AGGREGATE user_count = COUNT()\n    RETURN {country, user_count}\n</code></pre> <p>Ergebnis:</p> <pre><code>[\n  {\"country\": \"Germany\", \"user_count\": 125},\n  {\"country\": \"France\", \"user_count\": 87},\n  {\"country\": \"Spain\", \"user_count\": 43}\n]\n</code></pre>"},{"location":"aql_syntax/#beispiel-2-sales-analyse-mit-let-und-aggregation","title":"Beispiel 2: Sales-Analyse mit LET und Aggregation","text":"<p>Szenario: Berechne Netto/Brutto-Ums\u00e4tze pro Kategorie:</p> <pre><code>FOR sale IN sales\n  LET net = sale.amount\n  LET tax = net * 0.19\n  LET gross = net + tax\n  COLLECT category = sale.category\n  AGGREGATE \n    total_net = SUM(net),\n    total_gross = SUM(gross),\n    count = COUNT()\n  RETURN {\n    category,\n    total_net,\n    total_gross,\n    avg_sale: total_net / count,\n    count\n  }\n</code></pre>"},{"location":"aql_syntax/#beispiel-3-top-10-stadte-nach-user-count","title":"Beispiel 3: Top-10 St\u00e4dte nach User-Count","text":"<p>Szenario: H\u00e4ufigste St\u00e4dte finden:</p> <pre><code>FOR user IN users\n  COLLECT city_id = user.city_id WITH COUNT INTO user_count\n  SORT user_count DESC\n  LIMIT 10\n  RETURN {city_id, user_count}\n</code></pre>"},{"location":"aql_syntax/#performance-best-practices-mvp","title":"Performance-Best-Practices (MVP)","text":""},{"location":"aql_syntax/#1-join-optimierung","title":"1. JOIN-Optimierung","text":"<p>** Schlecht: Kartesisches Produkt ohne Filter ** Gut: Spezifische FILTER-Bedingungen, LIMIT verwenden</p>"},{"location":"aql_syntax/#2-let-fur-wiederverwendung","title":"2. LET f\u00fcr Wiederverwendung","text":"<p>Berechnungen einmal durchf\u00fchren, mehrfach nutzen:</p> <pre><code>FOR sale IN sales\n  LET net = sale.amount\n  LET tax = net * 0.19\n  RETURN {net, tax, gross: net + tax}\n</code></pre>"},{"location":"aql_syntax/#3-filter-vor-collect","title":"3. FILTER vor COLLECT","text":"<p>Datenvolumen reduzieren bevor gruppiert wird.</p>"},{"location":"aql_syntax/#implementation-status-31102025","title":"Implementation-Status (31.10.2025)","text":"Feature Status Notes FOR (Single) Production Vollst\u00e4ndig optimiert FOR (Multi/Join) MVP Nested-Loop, Hash-Join geplant FILTER Production Equality + Range + AND SORT Production Index-optimiert LIMIT Production Offset + Count RETURN Production Field/Object/Array LET MVP Basis-Expressions, Arithmetik COLLECT MVP Hash-Grouping, COUNT/SUM/AVG/MIN/MAX OR-Operator Planned Index-Merge geplant Subqueries Planned Phase 1.2 <p>Dokumentations-Version: 1.1 (31. Oktober 2025) Letzte Aktualisierung: JOIN/LET/COLLECT MVP-Features dokumentiert</p>"},{"location":"architecture/","title":"THEMIS Architecture","text":""},{"location":"architecture/#system-overview","title":"System Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         HTTP/REST API                            \u2502\n\u2502                      (Boost.Beast - Port 8765)                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502               \u2502               \u2502\n        \u25bc               \u25bc               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Entity     \u2502 \u2502   Query    \u2502 \u2502   Index     \u2502\n\u2502   Manager    \u2502 \u2502   Engine   \u2502 \u2502   Manager   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502               \u2502                \u2502\n       \u2502        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510        \u2502\n       \u2502        \u2502             \u2502        \u2502\n       \u25bc        \u25bc             \u25bc        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Index Projections                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Secondary  \u2502 \u2502   Graph   \u2502 \u2502  Vector  \u2502 \u2502   Spatial    \u2502 \u2502\n\u2502  \u2502   Index    \u2502 \u2502   Index   \u2502 \u2502  Index   \u2502 \u2502    Index     \u2502 \u2502\n\u2502  \u2502 (Equality, \u2502 \u2502 (Outdex/  \u2502 \u2502 (HNSW/   \u2502 \u2502 (Geo, R*Tree)\u2502 \u2502\n\u2502  \u2502  Range,    \u2502 \u2502  Indeg)   \u2502 \u2502  Faiss)  \u2502 \u2502              \u2502 \u2502\n\u2502  \u2502 Composite, \u2502 \u2502           \u2502 \u2502          \u2502 \u2502              \u2502 \u2502\n\u2502  \u2502 Fulltext)  \u2502 \u2502           \u2502 \u2502          \u2502 \u2502              \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Base Entity Layer                           \u2502\n\u2502               (Canonical Storage Format)                      \u2502\n\u2502                                                               \u2502\n\u2502  Key Schema: table:primary_key                                \u2502\n\u2502  Value: JSON blob (simdjson deserialization)                  \u2502\n\u2502  Metadata: version, timestamp, blob_size                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    RocksDB LSM-Tree                           \u2502\n\u2502                                                               \u2502\n\u2502  \u2022 Write Buffer: 256 MB memtable                              \u2502\n\u2502  \u2022 Block Cache: 1 GB (LRU)                                    \u2502\n\u2502  \u2022 Compression: LZ4 (L0-L5), ZSTD (L6 bottommost)             \u2502\n\u2502  \u2022 Compaction: Level-based (7 levels)                         \u2502\n\u2502  \u2022 Bloom Filters: 10 bits per key                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                        \u25bc\n                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u2502  Disk   \u2502\n                  \u2502 Storage \u2502\n                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#data-flow","title":"Data Flow","text":""},{"location":"architecture/#write-path-put-entitiestablepk","title":"Write Path (PUT /entities/table:pk)","text":"<pre><code>Client Request\n     \u2502\n     \u251c\u2500\u2500&gt; 1. HTTP Handler (http_server.cpp)\n     \u2502\n     \u251c\u2500\u2500&gt; 2. Deserialize JSON blob\n     \u2502         \u2514\u2500&gt; Extract indexed fields (_from, _to, columns)\n     \u2502\n     \u251c\u2500\u2500&gt; 3. Base Entity Layer (base_entity.cpp)\n     \u2502         \u2514\u2500&gt; Serialize to RocksDB format (key: table:pk)\n     \u2502\n     \u251c\u2500\u2500&gt; 4. Index Updates (parallel with TBB)\n     \u2502         \u251c\u2500&gt; Secondary Indexes (equality, range, composite)\n     \u2502         \u251c\u2500&gt; Graph Indexes (outdex/indeg if _from/_to present)\n     \u2502         \u2514\u2500&gt; Vector Indexes (if embedding present)\n     \u2502\n     \u2514\u2500\u2500&gt; 5. RocksDB Write\n               \u251c\u2500&gt; Write to memtable (in-memory)\n               \u251c\u2500&gt; Write to WAL (durability)\n               \u2514\u2500&gt; Response to client (async)\n</code></pre>"},{"location":"architecture/#read-path-post-query","title":"Read Path (POST /query)","text":"<pre><code>Client Query\n     \u2502\n     \u251c\u2500\u2500&gt; 1. Query Parser (query_parser.cpp)\n     \u2502         \u2514\u2500&gt; Parse predicates, range, order_by\n     \u2502\n     \u251c\u2500\u2500&gt; 2. Query Optimizer (query_optimizer.cpp)\n     \u2502         \u251c\u2500&gt; Index selection (selectivity analysis)\n     \u2502         \u251c\u2500&gt; Predicate reordering (most selective first)\n     \u2502         \u2514\u2500&gt; Execution plan generation\n     \u2502\n     \u251c\u2500\u2500&gt; 3. Query Executor (query_engine.cpp)\n     \u2502         \u251c\u2500&gt; Parallel index scans (TBB task_group)\n     \u2502         \u2502    \u2514\u2500&gt; For each predicate: index.get(table, column, value)\n     \u2502         \u2502\n     \u2502         \u251c\u2500&gt; Intersection of candidate sets (sorted merge)\n     \u2502         \u2502    \u2514\u2500&gt; Early termination on empty intermediate results\n     \u2502         \u2502\n     \u2502         \u2514\u2500&gt; Parallel entity loading (batch processing)\n     \u2502              \u251c\u2500&gt; Batch size: 50 entities\n     \u2502              \u251c\u2500&gt; Threshold: 100 entities (parallelization overhead)\n     \u2502              \u2514\u2500&gt; TBB task_group for concurrent RocksDB gets\n     \u2502\n     \u2514\u2500\u2500&gt; 4. Result Serialization\n               \u251c\u2500&gt; return: \"keys\" \u2192 JSON array of primary keys\n               \u2514\u2500&gt; return: \"entities\" \u2192 JSON array of blob contents\n</code></pre>"},{"location":"architecture/#index-rebuild-flow-post-indexrebuild","title":"Index Rebuild Flow (POST /index/rebuild)","text":"<pre><code>Rebuild Request\n     \u2502\n     \u251c\u2500\u2500&gt; 1. Drop existing index keys (range delete in RocksDB)\n     \u2502\n     \u251c\u2500\u2500&gt; 2. Scan all entities in table (prefix scan: table:*)\n     \u2502\n     \u251c\u2500\u2500&gt; 3. Parallel reindexing (batch processing)\n     \u2502         \u251c\u2500&gt; Batch size: 1000 entities\n     \u2502         \u251c\u2500&gt; For each batch:\n     \u2502         \u2502    \u251c\u2500&gt; Deserialize entity\n     \u2502         \u2502    \u251c\u2500&gt; Extract indexed field value\n     \u2502         \u2502    \u2514\u2500&gt; Write index entry (index:table:column:value -&gt; pk)\n     \u2502         \u2502\n     \u2502         \u2514\u2500&gt; TBB parallel_for across batches\n     \u2502\n     \u2514\u2500\u2500&gt; 4. Update metrics\n               \u251c\u2500&gt; rebuild_count++\n               \u251c\u2500&gt; rebuild_duration_ms\n               \u2514\u2500&gt; rebuild_entities_processed\n</code></pre>"},{"location":"architecture/#thread-model","title":"Thread Model","text":""},{"location":"architecture/#http-server-boostbeast","title":"HTTP Server (Boost.Beast)","text":"<ul> <li>I/O Threads: 8 threads (configurable)</li> <li>Accept Loop: Async accept on main thread</li> <li>Request Handling: Each connection handled by worker thread</li> <li>Connection Pool: Reused connections (keep-alive)</li> </ul>"},{"location":"architecture/#query-engine-intel-tbb","title":"Query Engine (Intel TBB)","text":"<ul> <li>Task Scheduling: Work-stealing scheduler (automatic load balancing)</li> <li>Index Scans: <code>tbb::task_group</code> for parallel predicate evaluation</li> <li>Entity Loading: Batch-based parallelization (threshold: 100 entities)   <code>cpp   std::vector&lt;std::vector&lt;BaseEntity&gt;&gt; batches;   tbb::task_group tg;   for (size_t batch_idx = 0; batch_idx &lt; num_batches; ++batch_idx) {       tg.run([&amp;, batch_idx]() {           // Load entities from RocksDB (batch_size = 50)           // Deserialize JSON blobs       });   }   tg.wait(); // Barrier   // Merge results</code></li> <li>Parallelization Benefit: Up to 3.5x speedup on 8-core systems</li> </ul>"},{"location":"architecture/#rocksdb-internal-threads","title":"RocksDB Internal Threads","text":"<ul> <li>Flush Threads: 2 (memtable \u2192 SST files)</li> <li>Compaction Threads: 4 (LSM-Tree level compaction)</li> <li>WAL Sync: Background thread (fsync batching)</li> </ul>"},{"location":"architecture/#memory-hierarchy","title":"Memory Hierarchy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  L1: TBB Task Scheduler (per-thread allocation)             \u2502\n\u2502      - Lock-free task queues                                 \u2502\n\u2502      - Work-stealing deques                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  L2: RocksDB Memtable (256 MB)                               \u2502\n\u2502      - SkipList structure (sorted by key)                    \u2502\n\u2502      - Write-ahead Log (WAL) for durability                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  L3: Block Cache (1 GB LRU)                                  \u2502\n\u2502      - Decompressed SST blocks                               \u2502\n\u2502      - Index/filter blocks (pinned)                          \u2502\n\u2502      - Bloom filters (10 bits/key)                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  L4: Operating System Page Cache                             \u2502\n\u2502      - Memory-mapped SST files                               \u2502\n\u2502      - Kernel read-ahead                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  L5: Disk Storage (SSD/NVMe)                                 \u2502\n\u2502      - SST files (2-64 MB per file)                          \u2502\n\u2502      - 7 levels (L0-L6)                                      \u2502\n\u2502      - LZ4 compression (L0-L5), ZSTD (L6)                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Memory Budget (Typical Configuration): - Memtable: 256 MB - Block Cache: 1024 MB - TBB Scheduler: ~50 MB (8 threads) - HTTP Buffers: ~32 MB (8 connections \u00d7 4 MB) - Total: ~1.36 GB RAM</p> <p>See memory_tuning.md for tuning guidelines.</p>"},{"location":"architecture/#index-key-schemas","title":"Index Key Schemas","text":""},{"location":"architecture/#secondary-index-equality","title":"Secondary Index (Equality)","text":"<pre><code>Format: index:table:column:value -&gt; primary_key\nExample: index:users:city:Berlin -&gt; alice,bob,charlie\n</code></pre>"},{"location":"architecture/#range-index","title":"Range Index","text":"<pre><code>Format: range:table:column:value -&gt; primary_key\nExample: range:products:price:00000999 -&gt; p1,p2\nNote: Values are zero-padded for lexicographic ordering\n</code></pre>"},{"location":"architecture/#graph-index-outdex","title":"Graph Index (Outdex)","text":"<pre><code>Format: outdeg:from_vertex -&gt; to_vertex1,to_vertex2,...\nExample: outdeg:user:alice -&gt; user:bob,user:charlie\n</code></pre>"},{"location":"architecture/#graph-index-indeg","title":"Graph Index (Indeg)","text":"<pre><code>Format: indeg:to_vertex -&gt; from_vertex1,from_vertex2,...\nExample: indeg:user:bob -&gt; user:alice,user:dave\n</code></pre>"},{"location":"architecture/#composite-index","title":"Composite Index","text":"<pre><code>Format: composite:table:col1:col2:val1:val2 -&gt; primary_key\nExample: composite:orders:customer:status:alice:pending -&gt; o1,o5\n</code></pre>"},{"location":"architecture/#query-optimization","title":"Query Optimization","text":""},{"location":"architecture/#selectivity-estimation","title":"Selectivity Estimation","text":"<pre><code>// Index statistics: sample-based cardinality estimation\nstruct IndexStats {\n    uint64_t unique_values;    // Distinct values in index\n    uint64_t total_entries;    // Total indexed entities\n    uint64_t sample_size;      // Sample used for estimation\n};\n\n// Selectivity calculation\ndouble selectivity = unique_values / (double)total_entries;\nuint64_t estimated_results = total_entries * selectivity;\n</code></pre>"},{"location":"architecture/#predicate-reordering","title":"Predicate Reordering","text":"<pre><code>Input Query:\n  predicates: [\n    {column: \"department\", value: \"Engineering\"},  // 1000 results\n    {column: \"level\", value: \"Senior\"}             // 50 results\n  ]\n\nAfter Optimization:\n  execution_order: [\n    {column: \"level\", value: \"Senior\"},            // Start with most selective\n    {column: \"department\", value: \"Engineering\"}   // Intersect with smaller set\n  ]\n\nBenefit: 50 vs 1000 initial candidates (20x reduction)\n</code></pre>"},{"location":"architecture/#execution-modes","title":"Execution Modes","text":"<ol> <li>Index-Accelerated (predicates with indexes):</li> <li>Parallel index scans \u2192 intersection \u2192 entity loading</li> <li> <p>Typical latency: 0.1-2 ms (depending on result set size)</p> </li> <li> <p>Range-Aware (range predicates + ORDER BY):</p> </li> <li>Direct range scan \u2192 sorted results (no intersection)</li> <li> <p>Typical latency: 0.5-5 ms (depends on range width)</p> </li> <li> <p>Full-Scan Fallback (no indexes, allow_full_scan: true):</p> </li> <li>Sequential table scan \u2192 filter in memory</li> <li>Typical latency: 10-500 ms (depends on table size)</li> <li>Warning: Expensive for large tables (&gt;10K entities)</li> </ol>"},{"location":"architecture/#compression-strategy","title":"Compression Strategy","text":""},{"location":"architecture/#write-amplification-vs-storage-savings","title":"Write Amplification vs Storage Savings","text":"<pre><code>Level   | Compression | Write Amp | Use Case\n--------|-------------|-----------|----------------------------------\nL0-L5   | LZ4         | 1.05x     | Hot data (frequent compaction)\nL6      | ZSTD        | 1.15x     | Cold data (infrequent compaction)\n</code></pre> <p>Rationale: - LZ4: Fast compression (33.8 MB/s write throughput, 2.1x ratio) - ZSTD: Better ratio (32.3 MB/s, 2.8x ratio) but slower \u2192 only for bottommost level - Hybrid strategy: Balance performance and storage efficiency</p> <p>See memory_tuning.md for benchmark results.</p>"},{"location":"architecture/#deployment-patterns","title":"Deployment Patterns","text":""},{"location":"architecture/#standalone-server","title":"Standalone Server","text":"<pre><code>THEMIS Server (Port 8765)\n     \u2502\n     \u251c\u2500&gt; Data Directory: ./data/themis_server\n     \u251c\u2500&gt; Config: ./config/config.json\n     \u2514\u2500&gt; Logs: stdout (spdlog)\n</code></pre>"},{"location":"architecture/#docker-container","title":"Docker Container","text":"<pre><code>Docker Host\n     \u2502\n     \u251c\u2500&gt; Container: vccdb:latest\n     \u2502    \u251c\u2500&gt; Port Mapping: 8765:8765\n     \u2502    \u251c\u2500&gt; Volume: /data (persistent storage)\n     \u2502    \u2514\u2500&gt; Config Mount: /etc/vccdb/config.json\n     \u2502\n     \u2514\u2500&gt; External Access: http://localhost:8765\n</code></pre>"},{"location":"architecture/#monitoring-stack-prometheus-grafana","title":"Monitoring Stack (Prometheus + Grafana)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   THEMIS    \u2502\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502 Prometheus  \u2502\u2500\u2500\u2500\u2500\u2500\u2500&gt;\u2502 Grafana  \u2502\n\u2502 (Port 8765)\u2502 scrape\u2502 (Port 9090) \u2502 query \u2502 (Port    \u2502\n\u2502  /metrics  \u2502       \u2502             \u2502       \u2502  3000)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nPrometheus Scrape Config:\n  scrape_interval: 15s\n  metrics_path: /metrics\n  targets: ['vccdb:8765']\n\nGrafana Dashboards:\n  - QPS, Error Rate, Latency (p50/p95/p99)\n  - RocksDB: Cache Hit Rate, Compaction Stats, Memtable Size\n  - System: CPU, Memory, Disk I/O\n</code></pre>"},{"location":"architecture/#performance-tuning","title":"Performance Tuning","text":""},{"location":"architecture/#rocksdb-configuration","title":"RocksDB Configuration","text":"<p>For Write-Heavy Workloads:</p> <pre><code>{\n  \"memtable_size_mb\": 512,      // Larger write buffer\n  \"max_write_buffer_number\": 4,  // More concurrent memtables\n  \"compression\": \"lz4\"           // Fast compression\n}\n</code></pre> <p>For Read-Heavy Workloads:</p> <pre><code>{\n  \"block_cache_size_mb\": 4096,   // Larger read cache\n  \"enable_bloom_filters\": true,  // Reduce disk seeks\n  \"compression\": \"zstd\"          // Better compression ratio\n}\n</code></pre>"},{"location":"architecture/#query-engine-tuning","title":"Query Engine Tuning","text":"<p>Batch Processing Thresholds:</p> <pre><code>// Adjust in query_engine.cpp\nconstexpr size_t PARALLEL_THRESHOLD = 100;  // Entities before parallelization\nconstexpr size_t BATCH_SIZE = 50;           // Entities per batch\n\n// For low-latency use cases:\nPARALLEL_THRESHOLD = 50;   // More aggressive parallelization\nBATCH_SIZE = 25;           // Smaller batches (lower latency variance)\n\n// For high-throughput use cases:\nPARALLEL_THRESHOLD = 200;  // Less overhead\nBATCH_SIZE = 100;          // Larger batches (better CPU utilization)\n</code></pre>"},{"location":"architecture/#index-maintenance","title":"Index Maintenance","text":"<p>Rebuild Strategy: - Periodic: Weekly rebuild for active tables (prevents fragmentation) - On-Demand: After bulk inserts (&gt;10K entities) - Parallel: Use <code>bench_index_rebuild</code> pattern for large tables</p> <p>TTL Cleanup:</p> <pre><code>// Automatic expiration (no manual cleanup needed)\n// TTL indexes prune expired entries during range scans\n</code></pre>"},{"location":"architecture/#observability","title":"Observability","text":""},{"location":"architecture/#health-check","title":"Health Check","text":"<pre><code>curl http://localhost:8765/health\n# Response: {\"status\":\"ok\",\"timestamp\":\"2025-10-28T10:30:00Z\"}\n</code></pre>"},{"location":"architecture/#configuration-inspection","title":"Configuration Inspection","text":"<pre><code>curl http://localhost:8765/config | jq .\n# Returns: server config, RocksDB config, runtime stats, metrics\n</code></pre>"},{"location":"architecture/#metrics-export","title":"Metrics Export","text":"<pre><code>curl http://localhost:8765/metrics\n# Prometheus text format with 25+ metrics\n</code></pre>"},{"location":"architecture/#statistics-analysis","title":"Statistics Analysis","text":"<pre><code>curl http://localhost:8765/stats | jq .storage.rocksdb\n# Detailed RocksDB stats: cache hit rate, compaction, files per level\n</code></pre>"},{"location":"architecture/#references","title":"References","text":"<ul> <li>Base Entity Layer</li> <li>Memory Tuning Guide</li> <li>Index Documentation</li> <li>OpenAPI Specification</li> </ul>"},{"location":"base_entity/","title":"Basismodell der Datenbank","text":"<p>Version: 1.1 Status: Implementiert Letzte Aktualisierung: 28. Oktober 2025</p>"},{"location":"base_entity/#uberblick","title":"\u00dcberblick","text":"<p>Das Basismodell von THEMIS definiert die fundamentale Speichereinheit f\u00fcr alle Datenmodelle (relational, document, graph, vector). Jede logische Entit\u00e4t wird als BaseEntity gespeichert \u2013 ein einzelnes bin\u00e4res Blob mit effizienter Serialisierung und schnellem Feldzugriff.</p>"},{"location":"base_entity/#kernkonzepte","title":"Kernkonzepte","text":"<ol> <li>BaseEntity: Kanonische Speichereinheit (ein Blob pro Entit\u00e4t)</li> <li>Primary Key: Eindeutige Identifikation innerhalb eines Namespace (table/collection/graph)</li> <li>Key Schema: Hierarchisches Schl\u00fcssel-System f\u00fcr Multi-Modell-Zugriff</li> <li>TTL/Retention: Automatische Ablauf-Mechanik \u00fcber TTL-Indizes</li> <li>Path Constraints: Geplante Constraints f\u00fcr Graph-Traversals (siehe Path Constraints)</li> </ol>"},{"location":"base_entity/#1-baseentity-die-speichereinheit","title":"1. BaseEntity \u2013 Die Speichereinheit","text":""},{"location":"base_entity/#11-architektur","title":"1.1 Architektur","text":"<p><code>BaseEntity</code> ist die zentrale Klasse f\u00fcr alle persistierten Daten:</p> <pre><code>class BaseEntity {\npublic:\n    using Blob = std::vector&lt;uint8_t&gt;;\n    using FieldMap = std::map&lt;std::string, Value&gt;;\n\n    enum class Format { BINARY, JSON };\n\n    // Prim\u00e4rschl\u00fcssel\n    const std::string&amp; getPrimaryKey() const;\n    void setPrimaryKey(std::string_view pk);\n\n    // Feld-Zugriff (lazy parsing)\n    std::optional&lt;Value&gt; getField(std::string_view field_name) const;\n    void setField(std::string_view field_name, const Value&amp; value);\n\n    // Serialisierung\n    Blob serialize() const;\n    std::string toJson() const;\n\n    // Factory-Methoden\n    static BaseEntity fromJson(std::string_view pk, std::string_view json_str);\n    static BaseEntity fromFields(std::string_view pk, const FieldMap&amp; fields);\n    static BaseEntity deserialize(std::string_view pk, const Blob&amp; blob);\n\nprivate:\n    std::string primary_key_;\n    Blob blob_;\n    Format format_ = Format::BINARY;\n    mutable std::shared_ptr&lt;FieldMap&gt; field_cache_;\n};\n</code></pre>"},{"location":"base_entity/#12-value-typsystem","title":"1.2 Value-Typsystem","text":"<p><code>Value</code> ist ein <code>std::variant</code> mit folgenden Typen:</p> Typ C++ Typ Verwendung null <code>std::monostate</code> Fehlende/leere Werte bool <code>bool</code> Wahrheitswerte int <code>int64_t</code> Ganzzahlen double <code>double</code> Gleitkommazahlen string <code>std::string</code> Texte vector <code>std::vector&lt;float&gt;</code> Embeddings (optimiert f\u00fcr ANN-Indizes) binary <code>std::vector&lt;uint8_t&gt;</code> Bin\u00e4rdaten <p>Hinweis: Nested Objects/Arrays sind aktuell nicht unterst\u00fctzt (geplant f\u00fcr zuk\u00fcnftige Version).</p>"},{"location":"base_entity/#2-key-schema-namespacing-hierarchie","title":"2. Key Schema \u2013 Namespacing &amp; Hierarchie","text":""},{"location":"base_entity/#21-multi-modell-schlussel","title":"2.1 Multi-Modell-Schl\u00fcssel","text":"<p>THEMIS nutzt ein hierarchisches Schl\u00fcssel-System mit Pr\u00e4fixen, um alle Datenmodelle in einer RocksDB zu vereinen:</p> <pre><code>class KeySchema {\npublic:\n    enum class KeyType {\n        RELATIONAL,        // Tabellenzeilen\n        DOCUMENT,          // Dokumente\n        GRAPH_NODE,        // Graph-Knoten\n        GRAPH_EDGE,        // Graph-Kanten\n        VECTOR,            // Vektor-Objekte\n        SECONDARY_INDEX,   // Sekund\u00e4rindizes\n        GRAPH_OUTDEX,      // Outgoing Edges\n        GRAPH_INDEX        // Incoming Edges\n    };\n\n    // Key-Konstruktion\n    static std::string makeRelationalKey(std::string_view table, std::string_view pk);\n    static std::string makeGraphNodeKey(std::string_view pk);\n    static std::string makeSecondaryIndexKey(\n        std::string_view table,\n        std::string_view column,\n        std::string_view value,\n        std::string_view pk\n    );\n};\n</code></pre>"},{"location":"base_entity/#22-schlussel-formate","title":"2.2 Schl\u00fcssel-Formate","text":"Datenmodell Schl\u00fcsselformat Beispiel Relational <code>entity:table:pk</code> <code>entity:users:alice</code> Document <code>entity:collection:pk</code> <code>entity:orders:order_123</code> Graph Node <code>entity:node:pk</code> <code>entity:node:user_456</code> Graph Edge <code>entity:edge:pk</code> <code>entity:edge:follows_789</code> Vector <code>entity:vectors:pk</code> <code>entity:vectors:doc_abc</code> Secondary Index <code>idx:table:column:value:pk</code> <code>idx:users:age:30:alice</code> Range Index <code>ridx:table:column:value:pk</code> <code>ridx:products:price:99.99:prod_1</code> Spatial Index <code>sidx:table:geohash:pk</code> <code>sidx:locations:u33dc1:berlin</code> TTL Index <code>ttlidx:table:column:timestamp:pk</code> <code>ttlidx:sessions:created_at:1730000000:sess_1</code> Fulltext Index <code>ftidx:table:column:token:pk</code> <code>ftidx:articles:body:search:art_42</code> Graph Outdex <code>graph:out:pk_start:pk_edge</code> <code>graph:out:alice:follows_789</code> Graph Indeg <code>graph:in:pk_target:pk_edge</code> <code>graph:in:bob:follows_789</code> Changefeed <code>changefeed:pk:seqno</code> <code>changefeed:alice:0000000001</code> Time-Series <code>ts:metric:entity:timestamp</code> <code>ts:cpu:server1:1730000000000</code> <p>Separator: Alle Schl\u00fcssel verwenden <code>:</code> als Trennzeichen.</p>"},{"location":"base_entity/#23-primary-key-extraktion","title":"2.3 Primary Key Extraktion","text":"<pre><code>// Aus beliebigem Schl\u00fcssel PK extrahieren\nstd::string pk = KeySchema::extractPrimaryKey(\"idx:users:age:30:alice\");\n// Ergebnis: \"alice\"\n\nKeyType type = KeySchema::parseKeyType(\"entity:users:alice\");\n// Ergebnis: KeyType::RELATIONAL\n</code></pre> <p>Siehe auch: RocksDB Storage Layout f\u00fcr Details zu Key Prefixes und Column Families.</p>"},{"location":"base_entity/#3-ttl-retention-automatisches-ablaufen","title":"3. TTL &amp; Retention \u2013 Automatisches Ablaufen","text":""},{"location":"base_entity/#31-ttl-index-konzept","title":"3.1 TTL-Index-Konzept","text":"<p>THEMIS unterst\u00fctzt Time-To-Live (TTL) f\u00fcr Entit\u00e4ten \u00fcber spezielle TTL-Indizes:</p> <pre><code>// TTL-Index erstellen (Sessions laufen nach 3600 Sekunden ab)\nidx.createTTLIndex(\"sessions\", \"created_at\", /*ttl_seconds=*/3600);\n\n// Entity einf\u00fcgen (TTL wird automatisch berechnet)\nBaseEntity session(\"sess_123\");\nsession.setField(\"user\", \"alice\");\nsession.setField(\"created_at\", \"2025-10-27T10:00:00Z\");\nidx.put(\"sessions\", session);\n// \u2192 TTL-Eintrag: ttlidx:sessions:created_at:1730034000:sess_123\n\n// Periodisch Cleanup aufrufen (z. B. CRON/Timer alle 60s)\nauto [status, deletedCount] = idx.cleanupExpiredEntities(\"sessions\", \"created_at\");\n</code></pre>"},{"location":"base_entity/#32-mechanik","title":"3.2 Mechanik","text":"<p>Beim Put: 1. Aktueller Timestamp: <code>now = std::chrono::system_clock::now()</code> 2. Expire-Timestamp: <code>expire = now + ttl_seconds</code> 3. TTL-Index-Key: <code>ttlidx:table:column:{expire}:pk</code> 4. Atomare WriteBatch: Entity + TTL-Index-Eintrag</p> <p>Beim Cleanup: 1. Scan TTL-Index: <code>ttlidx:table:column:0</code> bis <code>ttlidx:table:column:{current_time}</code> 2. F\u00fcr jeden PK: L\u00f6sche Entity + alle Indizes (atomar per WriteBatch) 3. R\u00fcckgabe: Anzahl gel\u00f6schter Entities</p>"},{"location":"base_entity/#33-retention-fur-time-series","title":"3.3 Retention f\u00fcr Time-Series","text":"<p>Zus\u00e4tzlich gibt es eine Retention Policy f\u00fcr Time-Series-Daten (TSStore):</p> <pre><code>RetentionPolicy policy;\npolicy.per_metric[\"cpu\"] = std::chrono::hours(24);      // CPU-Daten 24h\npolicy.per_metric[\"logs\"] = std::chrono::hours(72);     // Logs 72h\n\nRetentionManager mgr(&amp;tsstore, policy);\nsize_t deleted = mgr.apply();  // L\u00f6scht alte Datenpunkte pro Metrik\n</code></pre> <p>Hinweis: TTL-Indizes sind f\u00fcr Entities (Dokumente, Sessions, Cache), Retention ist f\u00fcr Time-Series (Metriken, Logs).</p> <p>Siehe auch: - Index Stats &amp; Maintenance f\u00fcr TTL-Index-Details - Time-Series f\u00fcr Retention Policies</p>"},{"location":"base_entity/#4-verwendungsbeispiele","title":"4. Verwendungsbeispiele","text":""},{"location":"base_entity/#41-entity-erstellen-persistieren","title":"4.1 Entity erstellen &amp; persistieren","text":"<pre><code>// Von Field Map erstellen\nBaseEntity::FieldMap fields;\nfields[\"name\"] = std::string(\"Alice\");\nfields[\"age\"] = int64_t(30);\nfields[\"active\"] = true;\n\nBaseEntity user = BaseEntity::fromFields(\"alice\", fields);\n\n// Von JSON erstellen\nstd::string json = R\"({\"name\":\"Bob\",\"age\":25})\";\nBaseEntity user2 = BaseEntity::fromJson(\"bob\", json);\n\n// Serialisieren &amp; speichern\nstd::string key = KeySchema::makeRelationalKey(\"users\", user.getPrimaryKey());\nauto blob = user.serialize();\ndb.put(key, blob);\n</code></pre>"},{"location":"base_entity/#42-entity-laden-felder-lesen","title":"4.2 Entity laden &amp; Felder lesen","text":"<pre><code>// Von RocksDB laden\nauto blob = db.get(\"entity:users:alice\");\nBaseEntity user = BaseEntity::deserialize(\"alice\", *blob);\n\n// Felder lesen (typsicher)\nauto name = user.getFieldAsString(\"name\");    // std::optional&lt;std::string&gt;\nauto age = user.getFieldAsInt(\"age\");         // std::optional&lt;int64_t&gt;\nauto active = user.getFieldAsBool(\"active\");  // std::optional&lt;bool&gt;\n\nif (name &amp;&amp; age) {\n    std::cout &lt;&lt; *name &lt;&lt; \" ist \" &lt;&lt; *age &lt;&lt; \" Jahre alt\\n\";\n}\n\n// Alle Felder extrahieren (f\u00fcr Index-Updates)\nauto attrs = user.extractAllFields();\nfor (const auto&amp; [field, value] : attrs) {\n    // Index-Eintr\u00e4ge erstellen\n}\n</code></pre>"},{"location":"base_entity/#43-vector-embeddings","title":"4.3 Vector-Embeddings","text":"<pre><code>// Entity mit Embedding erstellen\nstd::vector&lt;float&gt; embedding = {0.1f, 0.2f, 0.3f, 0.4f};\nBaseEntity doc(\"doc_123\");\ndoc.setField(\"title\", std::string(\"Artikel \u00fcber KI\"));\ndoc.setField(\"embedding\", embedding);\n\n// Embedding f\u00fcr ANN-Index extrahieren\nauto vec = doc.extractVector(\"embedding\");\nif (vec) {\n    hnsw_index.add(*vec, doc.getPrimaryKey());\n}\n</code></pre>"},{"location":"base_entity/#44-index-updates-secondary-index","title":"4.4 Index-Updates (Secondary Index)","text":"<pre><code>// Entity + Secondary Index atomar updaten\nauto batch = db.createWriteBatch();\n\n// Entity speichern\nstd::string entityKey = KeySchema::makeRelationalKey(\"users\", \"alice\");\nbatch-&gt;put(entityKey, user.serialize());\n\n// Secondary Index f\u00fcr age=30\nstd::string idxKey = KeySchema::makeSecondaryIndexKey(\"users\", \"age\", \"30\", \"alice\");\nbatch-&gt;put(idxKey, \"alice\");  // PK als Value\n\nbatch-&gt;commit();  // Atomar!\n</code></pre>"},{"location":"base_entity/#5-performance-implementierung","title":"5. Performance &amp; Implementierung","text":""},{"location":"base_entity/#51-lazy-parsing-field-cache","title":"5.1 Lazy Parsing (Field Cache)","text":"<ul> <li>Field Cache wird beim ersten Feldzugriff bef\u00fcllt</li> <li>Nachfolgende Zugriffe nutzen Cache (keine erneute Deserialisierung)</li> <li>Cache wird invalidiert bei Blob-Modifikation (<code>setField()</code>)</li> </ul> <pre><code>// Erstes getField() \u2192 Parse Blob \u2192 Cache f\u00fcllen\nauto name = entity.getField(\"name\");  // Parse!\n\n// Zweites getField() \u2192 Cache verwenden\nauto age = entity.getField(\"age\");    // Cache Hit!\n\n// setField() \u2192 Cache invalidieren\nentity.setField(\"status\", std::string(\"online\"));  // Cache invalidiert\n</code></pre>"},{"location":"base_entity/#52-simdjson-integration-json-format","title":"5.2 simdjson Integration (JSON Format)","text":"<ul> <li>JSON Format nutzt simdjson on-demand API</li> <li>Feld-Extraktion ohne vollst\u00e4ndigen Parse (O(1))</li> <li>Parsing-Throughput: Multi-GB/s auf modernen CPUs</li> </ul> <pre><code>// JSON-Entity laden (lazy parsing)\nBaseEntity entity = BaseEntity::fromJson(\"alice\", json_string);\n\n// Einzelne Felder extrahieren (simdjson on-demand)\nauto name = entity.extractField(\"name\");  // Kein vollst\u00e4ndiger Parse!\n</code></pre>"},{"location":"base_entity/#53-binary-format-effizienz","title":"5.3 Binary Format Effizienz","text":"Eigenschaft JSON Binary Gr\u00f6\u00dfe 100% ~60% (kompakter) Parse-Overhead Mittel (simdjson) Minimal (direkter Zugriff) Vector-Encoding Base64/String Native Float-Array Lesbarkeit Hoch Niedrig <p>Empfehlung: Binary f\u00fcr Produktiv-Storage, JSON f\u00fcr Debugging/Export.</p>"},{"location":"base_entity/#54-binary-format-struktur","title":"5.4 Binary Format Struktur","text":"<pre><code>&lt;Object&gt;\n  &lt;num_fields: uint32&gt;           // Anzahl Felder\n  &lt;field_1&gt;\n    &lt;name_length: uint32&gt;        // Feldname-L\u00e4nge\n    &lt;name: bytes&gt;                // Feldname (UTF-8)\n    &lt;type_tag: uint8&gt;            // Typ (siehe Type Tags)\n    &lt;value: varies by type&gt;      // Wert (typ-abh\u00e4ngig)\n  &lt;field_2&gt;\n    ...\n</code></pre> <p>Type Tags:</p> <pre><code>NULL_VALUE    = 0x00\nBOOL_FALSE    = 0x01\nBOOL_TRUE     = 0x02\nINT64         = 0x11\nDOUBLE        = 0x21\nSTRING        = 0x30\nBINARY        = 0x40\nVECTOR_FLOAT  = 0x70  // Optimiert f\u00fcr Embeddings (ohne extra Encoding)\n</code></pre>"},{"location":"base_entity/#6-best-practices","title":"6. Best Practices","text":""},{"location":"base_entity/#61-storage-format-wahl","title":"6.1 Storage-Format-Wahl","text":"<ul> <li>Binary Format: Immer f\u00fcr RocksDB-Storage (Standard, kompakt, schnell)</li> <li>JSON Format: Nur f\u00fcr Debugging, Export, HTTP-Responses</li> </ul> <pre><code>// Produktiv: Binary\nauto blob = entity.serialize();          // Binary (Standard)\ndb.put(key, blob);\n\n// Debugging: JSON\nstd::string json = entity.toJson();      // F\u00fcr Logs\nTHEMIS_DEBUG(\"Entity: {}\", json);\n</code></pre>"},{"location":"base_entity/#62-feld-extraktion-fur-index-updates","title":"6.2 Feld-Extraktion f\u00fcr Index-Updates","text":"<pre><code>// Schnell: Einzelne Felder extrahieren (ohne Full Parse)\nauto name = entity.extractField(\"name\");\nauto age = entity.extractField(\"age\");\n\n// Langsamer: Alle Felder (Full Parse)\nauto attrs = entity.extractAllFields();\n</code></pre> <p>Regel: <code>extractField()</code> f\u00fcr gezielte Updates, <code>extractAllFields()</code> nur wenn alle Felder ben\u00f6tigt.</p>"},{"location":"base_entity/#63-batch-updates-atomaritat","title":"6.3 Batch-Updates (Atomarit\u00e4t)","text":"<pre><code>// \u2705 RICHTIG: Atomare Updates via WriteBatch\nauto batch = db.createWriteBatch();\nbatch-&gt;put(entity_key, entity.serialize());\nbatch-&gt;put(idx_key1, idx_value1);\nbatch-&gt;put(idx_key2, idx_value2);\nbatch-&gt;commit();  // Alles oder nichts!\n\n// \u274c FALSCH: Einzelne Puts (nicht atomar)\ndb.put(entity_key, entity.serialize());\ndb.put(idx_key1, idx_value1);  // Fehler hier \u2192 Inkonsistenz!\n</code></pre>"},{"location":"base_entity/#64-vector-embeddings-optimieren","title":"6.4 Vector-Embeddings optimieren","text":"<pre><code>// \u2705 RICHTIG: Native float-Vektoren (kein Encoding)\nstd::vector&lt;float&gt; embedding = model.encode(text);\nentity.setField(\"embedding\", embedding);\n\n// \u274c FALSCH: String-Encoding (langsam, gro\u00df)\nstd::string encoded = serializeFloats(embedding);\nentity.setField(\"embedding\", encoded);\n</code></pre>"},{"location":"base_entity/#65-thread-safety","title":"6.5 Thread Safety","text":"<ul> <li>Ein <code>BaseEntity</code> pro Thread (keine Shared Ownership)</li> <li>simdjson-Parser ist thread-local (automatisch)</li> <li>Bei Shared Access: Locks verwenden</li> </ul> <pre><code>// \u2705 RICHTIG: Separate Instanzen\nstd::thread t1([&amp;]() {\n    BaseEntity e1 = BaseEntity::deserialize(\"alice\", blob);\n});\nstd::thread t2([&amp;]() {\n    BaseEntity e2 = BaseEntity::deserialize(\"bob\", blob);\n});\n\n// \u274c FALSCH: Shared Instanz ohne Lock\nBaseEntity shared(\"user\");\nstd::thread t1([&amp;]() { shared.getField(\"name\"); });  // Race Condition!\nstd::thread t2([&amp;]() { shared.setField(\"age\", 30); });\n</code></pre>"},{"location":"base_entity/#7-zukunftige-erweiterungen","title":"7. Zuk\u00fcnftige Erweiterungen","text":"<ul> <li>[ ] Kompression: LZ4/Snappy f\u00fcr gro\u00dfe Blobs</li> <li>[ ] Schema-Validation: Optionale JSON-Schema-Pr\u00fcfung</li> <li>[ ] Nested Objects: Support f\u00fcr verschachtelte Maps/Arrays</li> <li>[ ] Custom Types: Erweiterbare Type Tags (z. B. Geo-Points, UUIDs)</li> <li>[ ] Memory-Mapped Access: F\u00fcr sehr gro\u00dfe Entities (&gt;1MB)</li> <li>[ ] Path Constraints: Graph-Traversal-Constraints (siehe Path Constraints)</li> </ul>"},{"location":"base_entity/#referenzen","title":"Referenzen","text":"<ul> <li>Implementation: <code>include/storage/base_entity.h</code></li> <li>Key Schema: <code>include/storage/key_schema.h</code></li> <li>simdjson: https://github.com/simdjson/simdjson</li> <li>RocksDB Storage: RocksDB Layout</li> <li>TTL-Indizes: Index Stats &amp; Maintenance</li> <li>Retention: Time-Series</li> <li>Path Constraints: Graph Traversal Constraints</li> </ul>"},{"location":"cdc/","title":"Cdc","text":""},{"location":"cdc/#change-data-capture-cdc","title":"Change Data Capture (CDC)","text":"<p>Diese Seite ist veraltet. Bitte nutze die konsolidierte und code\u2011abgeglichene Doku:</p> <ul> <li>Change Data Capture (aktuell): <code>docs/change_data_capture.md</code></li> </ul> <p>Hinweis: Die neue Seite beschreibt alle derzeit implementierten Endpunkte (GET <code>/changefeed</code>, GET <code>/changefeed/stats</code>, POST <code>/changefeed/retention</code>) sowie das experimentelle SSE\u2011Streaming (<code>GET /changefeed/stream</code>).</p>"},{"location":"chain_of_thought_storage/","title":"Chain-of-Thought (CoT) Storage - LLM Interaction Store","text":"<p>Status: \u2705 Vollst\u00e4ndig implementiert und validiert (30. Oktober 2025)</p>"},{"location":"chain_of_thought_storage/#uberblick","title":"\u00dcberblick","text":"<p>Der LLM Interaction Store speichert strukturierte LLM-Interaktionen mit Chain-of-Thought Reasoning Steps. Dies erm\u00f6glicht: - Reasoning Transparency: Schritt-f\u00fcr-Schritt Nachvollziehbarkeit von LLM-Antworten - Audit Trail: Vollst\u00e4ndige Historie aller LLM-Interaktionen - Performance Analytics: Token-Verbrauch, Latenz-Tracking - Prompt Engineering: Template-Versioning und A/B-Testing</p>"},{"location":"chain_of_thought_storage/#implementierung","title":"Implementierung","text":""},{"location":"chain_of_thought_storage/#dateien","title":"Dateien","text":"<ul> <li>Header: <code>include/llm/llm_interaction_store.h</code></li> <li>Implementation: <code>src/llm/llm_interaction_store.cpp</code></li> <li>HTTP Handlers: <code>src/server/http_server.cpp</code> (handleLlmInteractionPost, handleLlmInteractionList, handleLlmInteractionGet)</li> </ul>"},{"location":"chain_of_thought_storage/#datenmodell","title":"Datenmodell","text":"<pre><code>struct Interaction {\n    std::string id;                        // Auto-generated UUID\n    std::string prompt_template_id;        // Template reference (optional)\n    std::string prompt;                    // Actual prompt sent to LLM\n    std::vector&lt;std::string&gt; reasoning_chain; // CoT steps\n    std::string response;                  // Final LLM response\n    std::string model_version;             // e.g., \"gpt-4\", \"gpt-3.5\"\n    int64_t timestamp_ms;                  // Creation timestamp\n    int latency_ms;                        // Response time in ms\n    int token_count;                       // Total tokens used\n    nlohmann::json metadata;               // Custom fields (user_id, session_id, etc.)\n};\n</code></pre>"},{"location":"chain_of_thought_storage/#storage","title":"Storage","text":"<ul> <li>RocksDB: Default Column Family</li> <li>Key Format: <code>\"llm_interaction:{interaction_id}\"</code></li> <li>Value Format: JSON serialization</li> <li>ID Generation: <code>{timestamp_hex}-{random_hex}</code> (UUID-like)</li> </ul>"},{"location":"chain_of_thought_storage/#http-api","title":"HTTP API","text":""},{"location":"chain_of_thought_storage/#post-llminteraction","title":"POST /llm/interaction","text":"<p>Purpose: Create new LLM interaction with reasoning chain</p> <p>Request:</p> <pre><code>{\n  \"prompt\": \"Explain the capital of France\",\n  \"reasoning_chain\": [\n    \"Step 1: France is a country in Europe\",\n    \"Step 2: Paris is the largest city in France\",\n    \"Step 3: Paris has been the capital since the 12th century\"\n  ],\n  \"response\": \"The capital of France is Paris.\",\n  \"model_version\": \"gpt-4\",\n  \"latency_ms\": 1200,\n  \"token_count\": 45,\n  \"metadata\": {\n    \"user_id\": \"test_user\",\n    \"session_id\": \"abc123\"\n  }\n}\n</code></pre> <p>Response (201 Created):</p> <pre><code>{\n  \"success\": true,\n  \"interaction\": {\n    \"id\": \"019a3545f06b-f2f8d28537acc860\",\n    \"prompt\": \"Explain the capital of France\",\n    \"reasoning_chain\": [\"Step 1: ...\", \"Step 2: ...\", \"Step 3: ...\"],\n    \"response\": \"The capital of France is Paris.\",\n    \"model_version\": \"gpt-4\",\n    \"timestamp_ms\": 1761830233433,\n    \"latency_ms\": 1200,\n    \"token_count\": 45,\n    \"metadata\": {\"user_id\": \"test_user\", \"session_id\": \"abc123\"}\n  }\n}\n</code></pre>"},{"location":"chain_of_thought_storage/#get-llminteractionid","title":"GET /llm/interaction/:id","text":"<p>Purpose: Retrieve specific interaction by ID</p> <p>Response (200 OK):</p> <pre><code>{\n  \"id\": \"019a3545f06b-f2f8d28537acc860\",\n  \"prompt\": \"Explain the capital of France\",\n  \"reasoning_chain\": [\n    \"Step 1: France is a country in Europe\",\n    \"Step 2: Paris is the largest city in France\",\n    \"Step 3: Paris has been the capital since the 12th century\"\n  ],\n  \"response\": \"The capital of France is Paris.\",\n  \"model_version\": \"gpt-4\",\n  \"timestamp_ms\": 1761830233433,\n  \"latency_ms\": 1200,\n  \"token_count\": 45,\n  \"metadata\": {\"user_id\": \"test_user\", \"session_id\": \"abc123\"}\n}\n</code></pre>"},{"location":"chain_of_thought_storage/#get-llminteraction","title":"GET /llm/interaction","text":"<p>Purpose: List interactions with optional filtering</p> <p>Query Parameters: - <code>limit</code> (default: 100) - Max interactions to return - <code>start_after_id</code> - Pagination cursor - <code>filter_model</code> - Filter by model version - <code>since_timestamp_ms</code> - Filter by time</p> <p>Response (200 OK):</p> <pre><code>{\n  \"interactions\": [\n    {\n      \"id\": \"019a3545f06b-f2f8d28537acc860\",\n      \"prompt\": \"...\",\n      \"reasoning_chain\": [\"...\"],\n      \"response\": \"...\",\n      \"model_version\": \"gpt-4\",\n      \"timestamp_ms\": 1761830233433,\n      \"latency_ms\": 1200,\n      \"token_count\": 45,\n      \"metadata\": {}\n    }\n  ],\n  \"total_count\": 5\n}\n</code></pre>"},{"location":"chain_of_thought_storage/#test-ergebnisse-30102025","title":"Test-Ergebnisse (30.10.2025)","text":""},{"location":"chain_of_thought_storage/#manuelle-http-tests","title":"Manuelle HTTP-Tests","text":"Test Ergebnis Details POST /llm/interaction \u2705 Success Created interaction with 3-step reasoning chain GET /llm/interaction/:id \u2705 Success Retrieved interaction with all fields intact Batch Creation \u2705 Success Created 3 additional interactions List Interactions \u2705 Success Retrieved 5 interactions total Complex CoT (6 steps) \u2705 Success Reasoning chain with 6 steps preserved perfectly"},{"location":"chain_of_thought_storage/#validierte-features","title":"Validierte Features","text":"<ul> <li>\u2705 Auto-ID Generation: UUID-like IDs <code>{timestamp}-{random}</code></li> <li>\u2705 Timestamp Auto-Set: Millisecond precision</li> <li>\u2705 Reasoning Chain Storage: Arrays preserved exactly</li> <li>\u2705 Metadata Flexibility: Arbitrary JSON supported</li> <li>\u2705 Pagination: Cursor-based listing works</li> <li>\u2705 JSON Serialization: Round-trip without data loss</li> </ul>"},{"location":"chain_of_thought_storage/#anwendungsfalle","title":"Anwendungsf\u00e4lle","text":""},{"location":"chain_of_thought_storage/#1-chain-of-thought-prompting","title":"1. Chain-of-Thought Prompting","text":"<pre><code>{\n  \"prompt\": \"Solve: 8x + 7 = 23\",\n  \"reasoning_chain\": [\n    \"Subtract 7 from both sides: 8x = 16\",\n    \"Divide both sides by 8: x = 2\",\n    \"Verify: 8(2) + 7 = 16 + 7 = 23 \u2713\"\n  ],\n  \"response\": \"x = 2\"\n}\n</code></pre>"},{"location":"chain_of_thought_storage/#2-multi-step-problem-solving","title":"2. Multi-Step Problem Solving","text":"<pre><code>{\n  \"prompt\": \"Complex reasoning task\",\n  \"reasoning_chain\": [\n    \"Analyze problem\",\n    \"Break into subproblems\",\n    \"Solve step 1: Data gathering\",\n    \"Solve step 2: Processing\",\n    \"Solve step 3: Synthesis\",\n    \"Conclusion\"\n  ],\n  \"response\": \"Final answer after 6 reasoning steps\",\n  \"metadata\": {\"complexity\": \"high\", \"domain\": \"mathematics\"}\n}\n</code></pre>"},{"location":"chain_of_thought_storage/#3-prompt-template-versioning","title":"3. Prompt Template Versioning","text":"<pre><code>{\n  \"prompt_template_id\": \"summarize_v2.3\",\n  \"prompt\": \"Summarize: {text}\",\n  \"model_version\": \"gpt-4-turbo\",\n  \"metadata\": {\n    \"template_version\": \"2.3\",\n    \"experiment_id\": \"ab_test_42\"\n  }\n}\n</code></pre>"},{"location":"chain_of_thought_storage/#performance-analytics","title":"Performance &amp; Analytics","text":"<p>Tracked Metrics: - <code>token_count</code> - Cost estimation and quota management - <code>latency_ms</code> - Response time analysis - <code>model_version</code> - Model performance comparison - <code>timestamp_ms</code> - Time-series analysis</p> <p>Statistics API (getStats):</p> <pre><code>struct Stats {\n    size_t total_interactions;\n    int64_t total_tokens;\n    double avg_latency_ms;\n    size_t total_size_bytes;\n};\n</code></pre>"},{"location":"chain_of_thought_storage/#privacy-security","title":"Privacy &amp; Security","text":"<ul> <li>Privacy-Safe: No PII required in metadata</li> <li>Exportierbar: JSON format enables easy data export</li> <li>Audit Trail: Complete immutable history</li> <li>Retention Control: Manual cleanup via <code>deleteInteraction()</code>, <code>clear()</code></li> </ul>"},{"location":"chain_of_thought_storage/#integration-mit-rag-pipeline","title":"Integration mit RAG-Pipeline","text":"<pre><code>graph LR\n    A[User Query] --&gt; B[Prompt Template]\n    B --&gt; C[LLM API]\n    C --&gt; D[Chain-of-Thought Response]\n    D --&gt; E[LLMInteractionStore]\n    E --&gt; F[POST /llm/interaction]\n    F --&gt; G[RocksDB]\n\n    H[Analytics Dashboard] --&gt; I[GET /llm/interaction]\n    I --&gt; G\n</code></pre>"},{"location":"chain_of_thought_storage/#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ul> <li>\u2705 Implementierung vollst\u00e4ndig</li> <li>\u2705 HTTP API validiert</li> <li>\u2705 Reasoning Chain Storage funktional</li> <li>\u23f3 Statistics API Testing</li> <li>\u23f3 Prometheus Metrics (token_usage, latency_histogram)</li> <li>\u23f3 Bulk Export API (CSV/JSONL)</li> <li>\u23f3 Dedicated Column Family (<code>llm_interactions</code>)</li> </ul>"},{"location":"chain_of_thought_storage/#zusammenfassung","title":"Zusammenfassung","text":"<p>Der LLM Interaction Store ist produktionsbereit und bietet: - \u2705 Strukturierte Chain-of-Thought Speicherung - \u2705 Flexibles Metadata-Schema - \u2705 Vollst\u00e4ndige HTTP API (Create, Read, List) - \u2705 Auto-ID &amp; Timestamp Generation - \u2705 Token &amp; Latency Tracking - \u2705 Template Versioning Support</p> <p>Deployment: Server startet mit aktiviertem LLM Store, Endpoints unter <code>/llm/interaction</code> verf\u00fcgbar.</p>"},{"location":"change_data_capture/","title":"Change Data Capture (CDC) - Themis","text":""},{"location":"change_data_capture/#overview","title":"Overview","text":"<p>Themis' Change Data Capture (CDC) implementation provides a minimal, append-only event log that tracks all data mutations (PUT/DELETE) in the database. This enables real-time data synchronization, audit trails, and stream processing use cases.</p> <p>Key Features (MVP, Stand jetzt): - Sequence-basiertes Ordering (monoton steigende <code>sequence</code>) - Automatische Erfassung f\u00fcr Entity-Operationen PUT/DELETE - Inkrementeller Abruf mit Checkpointing (<code>from_seq</code>) - Filterung per <code>key_prefix</code>; optionaler Event-Typ-Filter auf API-Ebene - Ereignisse mit Timestamp und frei erweiterbarem <code>metadata</code> - Long-Polling zur Latenzreduktion; experimentelles SSE-Streaming</p>"},{"location":"change_data_capture/#architecture","title":"Architecture","text":""},{"location":"change_data_capture/#data-model","title":"Data Model","text":"<p>ChangeEvent Structure:</p> <pre><code>{\n  \"sequence\": 42,\n  \"type\": \"PUT\",\n  \"key\": \"user:alice\",\n  \"value\": \"{\\\"name\\\":\\\"Alice\\\",\\\"email\\\":\\\"alice@example.com\\\"}\",\n  \"timestamp_ms\": 1730294567123,\n  \"metadata\": {\n    \"table\": \"user\",\n    \"pk\": \"alice\"\n  }\n}\n</code></pre> <p>Hinweise zu Feldern: - <code>sequence</code>: Monoton steigende ID (uint64) - <code>type</code>: <code>PUT</code> oder <code>DELETE</code> (Typen <code>TRANSACTION_COMMIT</code>/<code>TRANSACTION_ROLLBACK</code> sind definiert, werden aktuell aber nicht emittiert) - <code>key</code>: Vollst\u00e4ndiger Schl\u00fcssel, z. B. <code>table:pk</code> - <code>value</code>: JSON-String bei PUT, <code>null</code> bei DELETE - <code>timestamp_ms</code>: Millisekunden seit Epoch - <code>metadata</code>: Freies JSON (z. B. <code>table</code>, <code>pk</code>)</p>"},{"location":"change_data_capture/#storage","title":"Storage","text":"<ul> <li>Column Family: Default CF (or dedicated CF if configured)</li> <li>Key Format: <code>changefeed:{sequence_number}</code> (zero-padded for lexicographic ordering)</li> <li>Sequence Tracking: Atomic counter stored at key <code>changefeed_sequence</code></li> </ul>"},{"location":"change_data_capture/#http-api","title":"HTTP API","text":""},{"location":"change_data_capture/#1-query-changefeed-events","title":"1. Query Changefeed Events","text":"<p>Retrieve change events with optional filtering and pagination.</p> <p>Endpoint: <code>GET /changefeed</code></p> <p>Query Parameters: - <code>from_seq</code> (optional): Start after this sequence number (default: 0) - <code>limit</code> (optional): Maximum events to return (default: 100) - <code>long_poll_ms</code> (optional): Long-poll timeout in milliseconds (default: 0 = immediate) - <code>key_prefix</code> (optional): Filter events by key prefix (e.g., <code>user:</code>)</p> <p>Request Example:</p> <pre><code># Get all events\ncurl \"http://localhost:8765/changefeed?from_seq=0&amp;limit=20\"\n\n# Incremental query from checkpoint\ncurl \"http://localhost:8765/changefeed?from_seq=42&amp;limit=10\"\n\n# Filter by key prefix\ncurl \"http://localhost:8765/changefeed?from_seq=0&amp;limit=50&amp;key_prefix=user:\"\n\n# Long-poll for new events\ncurl \"http://localhost:8765/changefeed?from_seq=100&amp;limit=10&amp;long_poll_ms=5000\"\n</code></pre> <p>Response:</p> <pre><code>{\n  \"events\": [\n    {\n      \"sequence\": 1,\n      \"type\": \"PUT\",\n      \"key\": \"user:alice\",\n      \"value\": \"{\\\"name\\\":\\\"Alice\\\",\\\"email\\\":\\\"alice@example.com\\\"}\",\n      \"timestamp_ms\": 1730294567123,\n      \"metadata\": {\"table\": \"user\", \"pk\": \"alice\"}\n    },\n    {\n      \"sequence\": 2,\n      \"type\": \"DELETE\",\n      \"key\": \"user:bob\",\n      \"value\": null,\n      \"timestamp_ms\": 1730294568456,\n      \"metadata\": {\"table\": \"user\", \"pk\": \"bob\"}\n    }\n  ],\n  \"count\": 2,\n  \"latest_sequence\": 42\n}\n</code></pre> <p>Antwortfelder: - <code>events</code>: Liste von ChangeEvent-Objekten - <code>count</code>: Anzahl der zur\u00fcckgegebenen Events - <code>latest_sequence</code>: Aktuell letzter Sequence-Wert in der DB (f\u00fcr Checkpointing hilfreich)</p>"},{"location":"change_data_capture/#validation-tests-30102025","title":"Validation Tests (30.10.2025)","text":""},{"location":"change_data_capture/#test-1-automatic-cdc-recording","title":"Test 1: Automatic CDC Recording","text":"<p>Status: \u2705 PASSED</p> <ul> <li>Created 4 entities via PUT \u2192 4 CDC PUT events recorded</li> <li>Deleted 1 entity \u2192 1 CDC DELETE event recorded</li> <li>Result: All mutations automatically tracked without manual intervention</li> </ul>"},{"location":"change_data_capture/#test-2-query-api","title":"Test 2: Query API","text":"<p>Status: \u2705 PASSED</p> <ul> <li>Full Query: Retrieved all events with <code>from_seq=0&amp;limit=20</code></li> <li>Incremental Query: Retrieved only new events after checkpoint</li> <li>Key Prefix Filter: Successfully filtered events by <code>user:</code> prefix</li> <li>Pagination: Limit parameter correctly restricts result size</li> <li>Result: Query API fully functional with all parameters</li> </ul>"},{"location":"change_data_capture/#test-3-event-structure","title":"Test 3: Event Structure","text":"<p>Status: \u2705 PASSED</p> <ul> <li>Event Types: PUT and DELETE events correctly distinguished</li> <li>Metadata: Table and PK correctly embedded in each event</li> <li>Timestamps: Millisecond precision timestamps present</li> <li>Value Handling: PUT events include value, DELETE events have <code>value: null</code></li> <li>Result: Event structure matches specification</li> </ul>"},{"location":"change_data_capture/#test-4-checkpointing-pattern","title":"Test 4: Checkpointing Pattern","text":"<p>Status: \u2705 PASSED</p> <p>Scenario: Consumer reads batch \u2192 updates checkpoint \u2192 resumes from checkpoint</p> <pre><code>1. Consume events 1-5, checkpoint = 5\n2. New events 6-7 arrive\n3. Resume from checkpoint 5, receive events 6-7\n</code></pre> <p>Result: Sequential consumption with checkpointing works correctly</p>"},{"location":"change_data_capture/#use-cases","title":"Use Cases","text":""},{"location":"change_data_capture/#1-real-time-data-synchronization","title":"1. Real-Time Data Synchronization","text":"<p>Stream database changes to external systems (analytics, search, caching):</p> <pre><code>let checkpoint = 0;\nsetInterval(async () =&gt; {\n  const res = await fetch(`/changefeed?from_seq=${checkpoint}&amp;limit=100`);\n  const data = await res.json();\n\n  for (const event of data.events) {\n    await externalSystem.sync(event);\n    checkpoint = event.sequence;\n  }\n}, 1000);\n</code></pre>"},{"location":"change_data_capture/#2-audit-trail-compliance","title":"2. Audit Trail &amp; Compliance","text":"<p>Track all data mutations for compliance (GDPR, HIPAA):</p> <pre><code>-- Query all user data modifications\nSELECT * FROM changefeed \nWHERE key LIKE 'user:%' AND timestamp_ms &gt; '2025-01-01';\n</code></pre>"},{"location":"change_data_capture/#3-materialized-views","title":"3. Materialized Views","text":"<p>Maintain denormalized views automatically:</p> <pre><code>// Maintain user count by role\nfor (const event of events) {\n  if (event.key.startsWith('user:')) {\n    if (event.type === 'PUT') {\n      const user = JSON.parse(event.value);\n      roleCountMap[user.role] = (roleCountMap[user.role] || 0) + 1;\n    } else if (event.type === 'DELETE') {\n      // Decrement count\n    }\n  }\n}\n</code></pre>"},{"location":"change_data_capture/#4-event-sourcing","title":"4. Event Sourcing","text":"<p>Rebuild application state from event log:</p> <pre><code>// Rebuild state from beginning\nconst events = await fetch('/changefeed?from_seq=0&amp;limit=1000');\nconst state = {};\nfor (const event of events.events) {\n  applyEvent(state, event);\n}\n</code></pre>"},{"location":"change_data_capture/#performance-skalierung","title":"Performance &amp; Skalierung","text":"<p>Aktueller Stand (MVP): - Einfache, direkte Speicherung in RocksDB (append-only) - Sequenzvergabe zentral; ausreichend f\u00fcr moderate Schreibraten - Long-Poll als einfaches Warten mit kurzer Sleep-Periode (~50ms)</p> <p>M\u00f6gliche Erweiterungen (zuk\u00fcnftig): 1. RocksDB WAL Tailing f\u00fcr geringere Latenz 2. Batch-Sequenzvergabe (z. B. Bl\u00f6cke reservieren) 3. Dedizierte Column Family f\u00fcr CDC 4. Automatische Retention/TTL 5. Push-basierte Benachrichtigungen (WebSocket) 6. Integration in Kafka</p>"},{"location":"change_data_capture/#retention-cleanup","title":"Retention &amp; Cleanup","text":""},{"location":"change_data_capture/#retention-cleanup_1","title":"Retention &amp; Cleanup","text":"<p>Aktuell: Admin-Endpoint <code>POST /changefeed/retention</code> mit Body <code>{ \"before_sequence\": &lt;uint64&gt; }</code> l\u00f6scht Events mit kleinerer Sequence. Statistiken \u00fcber <code>GET /changefeed/stats</code>.</p> <p>Zuk\u00fcnftig m\u00f6glich: TTL-/Zeit-basierte Retention und automatische Bereinigung.</p>"},{"location":"change_data_capture/#limitations-trade-offs","title":"Limitations &amp; Trade-offs","text":""},{"location":"change_data_capture/#current-limitations","title":"Current Limitations","text":"<ol> <li>No Transaction Isolation: Events are recorded per-mutation, not per-transaction</li> <li>No Backpressure: Unlimited event accumulation (manual cleanup required)</li> <li>Sequential Sequence Generation: Single point of contention at high write rates</li> <li>Polling-based Long-poll: 50ms granularity, not instant</li> </ol>"},{"location":"change_data_capture/#trade-offs","title":"Trade-offs","text":"Feature Benefit Cost Append-only log Simple, reliable, never loses events Linear storage growth Automatic tracking Zero code changes, transparent Cannot disable for specific entities Sequence-based Guaranteed order, easy checkpointing Sequential bottleneck Default CF storage Simple deployment No isolation from application data"},{"location":"change_data_capture/#integration-examples","title":"Integration Examples","text":""},{"location":"change_data_capture/#powershell-consumer","title":"PowerShell Consumer","text":"<pre><code>$checkpoint = 0\nwhile ($true) {\n    $r = Invoke-RestMethod -Uri \"http://localhost:8765/changefeed?from_seq=$checkpoint&amp;limit=100\"\n\n    foreach ($event in $r.events) {\n        Write-Host \"[$($event.sequence)] $($event.type) $($event.key)\"\n\n        # Process event\n        if ($event.type -eq \"PUT\") {\n            $data = $event.value | ConvertFrom-Json\n            # Sync to external system\n        }\n\n        $checkpoint = $event.sequence\n    }\n\n    Start-Sleep -Seconds 1\n}\n</code></pre>"},{"location":"change_data_capture/#python-consumer","title":"Python Consumer","text":"<pre><code>import requests\nimport time\n\ncheckpoint = 0\nwhile True:\n    r = requests.get(f'http://localhost:8765/changefeed?from_seq={checkpoint}&amp;limit=100')\n    data = r.json()\n\n    for event in data['events']:\n        print(f\"[{event['sequence']}] {event['type']} {event['key']}\")\n\n        # Process event\n        if event['type'] == 'PUT':\n            value = json.loads(event['value'])\n            # Sync to external system\n\n        checkpoint = event['sequence']\n\n    time.sleep(1)\n</code></pre>"},{"location":"change_data_capture/#nodejs-consumer-with-long-poll","title":"Node.js Consumer with Long-Poll","text":"<pre><code>let checkpoint = 0;\n\nasync function consumeChangefeed() {\n  while (true) {\n    const res = await fetch(\n      `http://localhost:8765/changefeed?from_seq=${checkpoint}&amp;limit=100&amp;long_poll_ms=5000`\n    );\n    const data = await res.json();\n\n    for (const event of data.events) {\n      console.log(`[${event.sequence}] ${event.type} ${event.key}`);\n\n      // Process event\n      if (event.type === 'PUT') {\n        const value = JSON.parse(event.value);\n        await processEvent(value);\n      }\n\n      checkpoint = event.sequence;\n    }\n\n    // Long-poll handles waiting, no need to sleep\n  }\n}\n\nconsumeChangefeed();\n</code></pre>"},{"location":"change_data_capture/#configuration","title":"Configuration","text":""},{"location":"change_data_capture/#enable-cdc-feature","title":"Enable CDC Feature","text":"<p>config/config.json:</p> <pre><code>{\n  \"features\": {\n    \"cdc\": true\n  }\n}\n</code></pre>"},{"location":"change_data_capture/#verify-cdc-status","title":"Verify CDC Status","text":"<p>Check logs on server startup:</p> <pre><code>[INFO] Changefeed initialized using default CF\n</code></pre> <p>Query an endpoint to verify feature is enabled:</p> <pre><code>curl http://localhost:8765/changefeed?from_seq=0&amp;limit=1\n# Should return events, not 404\n</code></pre>"},{"location":"change_data_capture/#next-steps","title":"Next Steps","text":""},{"location":"change_data_capture/#geplante-erweiterungen","title":"Geplante Erweiterungen","text":"<ol> <li>RocksDB WAL Tailing: Real-time event streaming</li> <li>Transaction-level Events: Group mutations by transaction</li> <li>Event Notifications: WebSocket/SSE for push-based updates</li> <li>Kafka Integration: Stream to Kafka topics</li> <li>Schema Evolution: Track schema changes in metadata</li> </ol>"},{"location":"change_data_capture/#summary","title":"Summary","text":"<p>Zusammenfassung:</p> <ul> <li>Sequence-basiertes append-only Log</li> <li>Automatisches Tracking f\u00fcr PUT/DELETE</li> <li>GET /changefeed mit Filter/Pagination + Long-Poll</li> <li>Experimentelles SSE-Streaming (<code>/changefeed/stream</code>) mit Keep-Alive/Heartbeats</li> </ul> <p>Einsatz: Echtzeit-Sync, Audit-Trails, Event Sourcing \u2013 produktionsnah nutzbar; f\u00fcr sehr hohe Last ggf. Erweiterungen einplanen.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>Alle nennenswerten \u00c4nderungen dieses Projekts werden in diesem Dokument festgehalten. Das Format orientiert sich lose an Keep a Changelog.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>RBAC/Authorization (MVP): Token-basierte Zugriffskontrolle mit Scopes (admin, config:write, cdc:read, metrics:read)</li> <li>AuthMiddleware Klasse mit Scope-Pr\u00fcfung und Metriken</li> <li>Dokumentation: <code>docs/rbac_authorization.md</code></li> <li>Tests: <code>tests/test_auth_middleware.cpp</code></li> <li>HNSW Persistenz &amp; Warmstart: Vektorindex-Persistierung f\u00fcr schnellere Startzeiten</li> <li><code>saveIndex()</code>, <code>loadIndex()</code>, <code>setAutoSavePath()</code>, <code>shutdown()</code> APIs</li> <li>Automatisches Laden beim Init, Auto-Save bei Shutdown</li> <li>Dokumentation: <code>docs/hnsw_persistence.md</code></li> <li>Konsolidierte Seite \u201ePerformance &amp; Benchmarks\" mit Kompression, Pagination, MVCC/WriteBatch, Index-Rebuilds, Vector-Tuning</li> <li>Vector-Benchmarks: <code>BM_VectorSearch_efSearch</code>, <code>BM_VectorInsert_Batch100</code></li> <li>Qualit\u00e4tssicherung (QA) Dokument mit Teststrategie, CI/CD, Coverage, Static Analysis</li> <li>Security/Compliance Review Seite mit Checkliste und Verlinkungen</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Navigation (mkdocs.yml) um RBAC, HNSW Persistenz, Performance, QA, Security Review, Roadmap &amp; Changelog erweitert</li> <li>Pagination/Kompressionsdokus erg\u00e4nzt und verlinkt</li> </ul>"},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>Diverse Dokumentverlinkungen (Deployment, CDC, Index-Metriken) bereinigt</li> <li>MkDocs-Build-Fehler behoben (YAML-Indentation, docs_dir entfernt)</li> </ul>"},{"location":"changelog/#010-2025-10-20","title":"[0.1.0] - 2025-10-20","text":"<p>Erste konsolidierte Doku-Fassung (Architektur, Storage &amp; MVCC, Query Engine &amp; AQL, Indexe, Content Pipeline, Deployment &amp; Betrieb).</p>"},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Grundlegende Seitenstruktur und Navigation</li> <li>OpenAPI und Admin-Tools Dokus</li> </ul>"},{"location":"column_encryption/","title":"Column-Level Encryption Design","text":"<p>Status: Design Phase (Sprint C.3) Datum: 30. Oktober 2025 Autor: Themis Development Team</p>"},{"location":"column_encryption/#1-uberblick","title":"1. \u00dcberblick","text":"<p>Column-Level Encryption erm\u00f6glicht die Verschl\u00fcsselung sensibler Datenfelder at-rest in der Datenbank. Dies erf\u00fcllt Compliance-Anforderungen (DSGVO, HIPAA) und sch\u00fctzt vor Insider-Threats und Storage-Compromise-Szenarien.</p>"},{"location":"column_encryption/#11-ziele","title":"1.1 Ziele","text":"<ul> <li>Data-at-Rest Protection: Sensible Felder (Email, SSN, Kreditkarten) verschl\u00fcsselt speichern</li> <li>Transparent Usage: Entwickler arbeiten mit <code>EncryptedField&lt;T&gt;</code>, Verschl\u00fcsselung automatisch</li> <li>Key Rotation: Unterst\u00fctzung f\u00fcr periodischen Schl\u00fcsselwechsel ohne Downtime</li> <li>Minimal Performance Impact: &lt;10ms Overhead f\u00fcr Encrypt/Decrypt Operationen</li> <li>Pluggable Key Management: Interface f\u00fcr HashiCorp Vault, AWS KMS, Azure Key Vault</li> </ul>"},{"location":"column_encryption/#12-nicht-ziele-v1","title":"1.2 Nicht-Ziele (v1)","text":"<ul> <li>\u274c Encryption-in-Transit (wird durch TLS abgedeckt)</li> <li>\u274c Homomorphic Encryption (zu langsam f\u00fcr produktive Nutzung)</li> <li>\u274c Searchable Encryption (zuk\u00fcnftiger Sprint)</li> <li>\u274c Database-Level Encryption (alternative Strategie via RocksDB encryption)</li> </ul>"},{"location":"column_encryption/#2-threat-model","title":"2. Threat Model","text":""},{"location":"column_encryption/#21-bedrohungsszenarien","title":"2.1 Bedrohungsszenarien","text":"Threat Beschreibung Mitigation durch Column Encryption Storage Compromise Angreifer erh\u00e4lt Zugriff auf RocksDB SST-Files \u2705 Daten sind verschl\u00fcsselt, Keys separat gespeichert Backup Leakage Backup-Files werden versehentlich \u00f6ffentlich \u2705 Verschl\u00fcsselte Daten unlesbar ohne Keys Insider Threat DB-Admin mit Disk-Zugriff \u2705 Keys nur in Key Management System, nicht auf Disk Memory Dump Angreifer liest RAM-Inhalte \u26a0\ufe0f Teilweise - entschl\u00fcsselte Daten tempor\u00e4r im RAM SQL Injection Angreifer extrahiert Daten via Query \u274c Nicht gesch\u00fctzt - AppSec Verantwortung"},{"location":"column_encryption/#22-trust-boundaries","title":"2.2 Trust Boundaries","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Application Layer (Trusted)                             \u2502\n\u2502 - EncryptedField&lt;T&gt; Templates                           \u2502\n\u2502 - Plaintext briefly in memory during operations         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n                    \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Encryption Layer (Trusted)                              \u2502\n\u2502 - FieldEncryption: AES-256-GCM Encrypt/Decrypt          \u2502\n\u2502 - Key Cache: In-memory cache (max 1000 keys, 1h TTL)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u25bc                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 KeyProvider      \u2502  \u2502 Storage Layer        \u2502\n\u2502 (External/Vault) \u2502  \u2502 (Untrusted)          \u2502\n\u2502 - Stores KEKs    \u2502  \u2502 - Encrypted Data     \u2502\n\u2502 - Access Control \u2502  \u2502 - Metadata (key ID)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Annahmen: - Application-Memory ist vertrauensw\u00fcrdig (OS-Level Security) - Key Management System (Vault/KMS) ist extern und geh\u00e4rtet - Netzwerk zwischen App und KMS ist TLS-gesichert</p>"},{"location":"column_encryption/#3-architektur","title":"3. Architektur","text":""},{"location":"column_encryption/#31-komponenten-ubersicht","title":"3.1 Komponenten-\u00dcbersicht","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Application Code                       \u2502\n\u2502  User user;                                              \u2502\n\u2502  user.email = EncryptedField&lt;std::string&gt;(\"foo@bar.com\");\u2502\n\u2502  std::string plaintext = user.email.decrypt();          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              EncryptedField&lt;T&gt; Template                  \u2502\n\u2502  - Stores: {ciphertext, key_id, key_version, iv, tag}   \u2502\n\u2502  - Methods: T decrypt(), void encrypt(T plaintext)      \u2502\n\u2502  - Serialization: toJson() / fromJson()                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               FieldEncryption Class                      \u2502\n\u2502  - encrypt(plaintext, key_id) -&gt; EncryptedBlob          \u2502\n\u2502  - decrypt(EncryptedBlob) -&gt; plaintext                  \u2502\n\u2502  - Algorithm: AES-256-GCM (AEAD)                        \u2502\n\u2502  - IV: Random 12 bytes per encryption                   \u2502\n\u2502  - Tag: 16 bytes authentication tag                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              KeyProvider Interface                       \u2502\n\u2502  virtual std::vector&lt;uint8_t&gt; getKey(std::string id) = 0\u2502\n\u2502  virtual void rotateKey(std::string id) = 0             \u2502\n\u2502  virtual std::vector&lt;KeyMetadata&gt; listKeys() = 0        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n      \u25bc                 \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502MockKeyProvider\u2502 \u2502VaultKeyProvider  \u2502\n\u2502(In-Memory)    \u2502 \u2502(HashiCorp Vault) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"column_encryption/#32-datenstrukturen","title":"3.2 Datenstrukturen","text":""},{"location":"column_encryption/#321-encryptedblob","title":"3.2.1 EncryptedBlob","text":"<pre><code>struct EncryptedBlob {\n    std::string key_id;           // \"user_pii_v1\"\n    uint32_t key_version;         // 2 (for rotation)\n    std::vector&lt;uint8_t&gt; iv;      // 12 bytes (AES-GCM standard)\n    std::vector&lt;uint8_t&gt; ciphertext;\n    std::vector&lt;uint8_t&gt; tag;     // 16 bytes authentication tag\n\n    // Serialization: base64(key_id:version:iv:ciphertext:tag)\n    std::string toBase64() const;\n    static EncryptedBlob fromBase64(const std::string&amp; b64);\n};\n</code></pre>"},{"location":"column_encryption/#322-keymetadata","title":"3.2.2 KeyMetadata","text":"<pre><code>struct KeyMetadata {\n    std::string key_id;\n    uint32_t version;\n    std::string algorithm;        // \"AES-256-GCM\"\n    int64_t created_at_ms;\n    int64_t expires_at_ms;        // 0 = never\n    KeyStatus status;             // ACTIVE, ROTATING, DEPRECATED\n};\n</code></pre>"},{"location":"column_encryption/#4-encryption-flow","title":"4. Encryption Flow","text":""},{"location":"column_encryption/#41-encryption-write-path","title":"4.1 Encryption (Write Path)","text":"<pre><code>1. Application sets value:\n   user.email = EncryptedField&lt;string&gt;(\"alice@example.com\");\n\n2. EncryptedField&lt;string&gt;::operator=()\n   \u251c\u2500&gt; FieldEncryption::encrypt(\"alice@example.com\", \"user_pii\")\n   \u2502   \u251c\u2500&gt; KeyProvider::getKey(\"user_pii\") -&gt; 32 bytes DEK\n   \u2502   \u251c\u2500&gt; Generate random IV (12 bytes)\n   \u2502   \u251c\u2500&gt; OpenSSL EVP_EncryptInit_ex(AES-256-GCM)\n   \u2502   \u251c\u2500&gt; EVP_EncryptUpdate(plaintext)\n   \u2502   \u251c\u2500&gt; EVP_EncryptFinal_ex() -&gt; ciphertext + tag\n   \u2502   \u2514\u2500&gt; return EncryptedBlob{key_id, version, iv, ciphertext, tag}\n   \u2514\u2500&gt; Store EncryptedBlob internally\n\n3. Storage Layer:\n   \u251c\u2500&gt; user.toJson() -&gt; {\"email\": \"base64(blob)\"}\n   \u2514\u2500&gt; RocksDB Put(\"d:users:123\", json_string)\n</code></pre> <p>Performance: - Key lookup: ~1ms (cached) / ~50ms (Vault API call) - AES-256-GCM encryption: ~0.5ms for 1KB plaintext - Total: ~1.5ms (cached) / ~50ms (cold)</p>"},{"location":"column_encryption/#42-decryption-read-path","title":"4.2 Decryption (Read Path)","text":"<pre><code>1. Application reads value:\n   std::string email = user.email.decrypt();\n\n2. EncryptedField&lt;string&gt;::decrypt()\n   \u251c\u2500&gt; FieldEncryption::decrypt(stored_blob)\n   \u2502   \u251c\u2500&gt; KeyProvider::getKey(blob.key_id, blob.key_version)\n   \u2502   \u251c\u2500&gt; OpenSSL EVP_DecryptInit_ex(AES-256-GCM)\n   \u2502   \u251c\u2500&gt; EVP_DecryptUpdate(ciphertext)\n   \u2502   \u251c\u2500&gt; EVP_CIPHER_CTX_ctrl(EVP_CTRL_GCM_SET_TAG, tag)\n   \u2502   \u251c\u2500&gt; EVP_DecryptFinal_ex() -&gt; plaintext (or AUTH_FAILED)\n   \u2502   \u2514\u2500&gt; return plaintext\n   \u2514\u2500&gt; return std::string\n\n3. Error Handling:\n   \u251c\u2500&gt; Authentication failure -&gt; throw DecryptionException\n   \u251c\u2500&gt; Key not found -&gt; throw KeyNotFoundException\n   \u2514\u2500&gt; Invalid base64 -&gt; throw DecodingException\n</code></pre>"},{"location":"column_encryption/#5-key-management","title":"5. Key Management","text":""},{"location":"column_encryption/#51-key-hierarchy","title":"5.1 Key Hierarchy","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Key Encryption Key (KEK)                        \u2502\n\u2502 - Stored in: Vault/KMS                          \u2502\n\u2502 - Rotation: Annually                            \u2502\n\u2502 - Access: Restricted to App Service Principal   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502 (encrypts)\n                 \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Data Encryption Keys (DEK)                      \u2502\n\u2502 - Per field type: \"user_pii\", \"payment_info\"   \u2502\n\u2502 - Versioned: v1, v2, ... (for rotation)         \u2502\n\u2502 - Size: 256 bits (32 bytes)                     \u2502\n\u2502 - Cache: In-memory, 1h TTL, max 1000 keys       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Rationale: - KEK in Vault erm\u00f6glicht zentrale Kontrolle und Auditing - DEKs gecached f\u00fcr Performance (1ms statt 50ms) - Versionierung erlaubt sanfte Key Rotation ohne Re-Encryption</p>"},{"location":"column_encryption/#52-key-rotation-process","title":"5.2 Key Rotation Process","text":"<p>Scenario: Rotate \"user_pii\" key from v2 to v3</p> <pre><code>Phase 1: Dual-Write (Week 1-2)\n1. Admin: vault_client.createKey(\"user_pii\", version=3)\n2. Config: Set write_key_version=3, read_key_versions=[2,3]\n3. New data: Encrypted with v3\n4. Old data: Still readable with v2\n\nPhase 2: Background Re-Encryption (Week 3-4)\n1. Job: SELECT id FROM users WHERE email_key_version = 2\n2. For each row:\n   \u251c\u2500&gt; plaintext = decrypt(email, key_v2)\n   \u251c\u2500&gt; encrypted = encrypt(plaintext, key_v3)\n   \u2514\u2500&gt; UPDATE users SET email = encrypted WHERE id = ?\n3. Progress tracking: \"23,456 / 1,000,000 rows (2.3%)\"\n\nPhase 3: Deprecation (Week 5)\n1. Config: read_key_versions=[3]\n2. Admin: vault_client.deprecateKey(\"user_pii\", version=2)\n3. Monitoring: Alert if v2 decrypt attempts &gt; 0\n\nPhase 4: Deletion (Week 8+)\n1. Admin: vault_client.deleteKey(\"user_pii\", version=2)\n2. Audit log: \"user_pii_v2 deleted by admin@example.com\"\n</code></pre> <p>Rollback Safety: - Alle Key-Versionen bleiben 30 Tage nach Deprecation verf\u00fcgbar - Re-Encryption ist idempotent (kann wiederholt werden) - Config-Changes sind Feature-Flagged (sofort revertierbar)</p>"},{"location":"column_encryption/#53-keyprovider-implementations","title":"5.3 KeyProvider Implementations","text":""},{"location":"column_encryption/#mockkeyprovider-testing","title":"MockKeyProvider (Testing)","text":"<pre><code>class MockKeyProvider : public KeyProvider {\nprivate:\n    std::map&lt;std::string, std::map&lt;uint32_t, std::vector&lt;uint8_t&gt;&gt;&gt; keys_;\n    std::mutex mutex_;\n\npublic:\n    // Generates random 256-bit key\n    void createKey(const std::string&amp; key_id, uint32_t version);\n\n    // Returns key or throws KeyNotFoundException\n    std::vector&lt;uint8_t&gt; getKey(const std::string&amp; key_id, \n                                 uint32_t version) override;\n\n    // Not implemented (testing only)\n    void rotateKey(const std::string&amp; key_id) override { \n        throw NotImplementedException();\n    }\n};\n</code></pre>"},{"location":"column_encryption/#vaultkeyprovider-production-interface-only","title":"VaultKeyProvider (Production - Interface Only)","text":"<pre><code>class VaultKeyProvider : public KeyProvider {\nprivate:\n    std::string vault_addr_;      // \"https://vault.example.com:8200\"\n    std::string vault_token_;     // Service principal token\n    std::unique_ptr&lt;KeyCache&gt; cache_;\n\npublic:\n    // Authenticates via AppRole or K8s Service Account\n    void authenticate();\n\n    // GET /v1/secret/data/encryption/{key_id}/v{version}\n    std::vector&lt;uint8_t&gt; getKey(const std::string&amp; key_id, \n                                 uint32_t version) override;\n\n    // POST /v1/secret/data/encryption/{key_id}/v{next_version}\n    void rotateKey(const std::string&amp; key_id) override;\n\n    // Cache hit ratio metric\n    double getCacheHitRate() const;\n};\n</code></pre>"},{"location":"column_encryption/#6-performance-considerations","title":"6. Performance Considerations","text":""},{"location":"column_encryption/#61-benchmarks-target","title":"6.1 Benchmarks (Target)","text":"Operation Latency (p50) Latency (p99) Throughput Encrypt (1KB) 0.5ms 2ms 2000 ops/sec Decrypt (1KB) 0.5ms 2ms 2000 ops/sec Key Lookup (cached) 0.01ms 0.1ms 100k ops/sec Key Lookup (Vault) 50ms 200ms 20 ops/sec"},{"location":"column_encryption/#62-optimizations","title":"6.2 Optimizations","text":"<p>1. Key Caching Strategy</p> <pre><code>class KeyCache {\n    struct Entry {\n        std::vector&lt;uint8_t&gt; key;\n        int64_t expires_at_ms;\n        uint64_t access_count;\n    };\n\n    std::map&lt;std::string, Entry&gt; cache_;  // key_id:version -&gt; Entry\n    size_t max_size_ = 1000;\n    int64_t ttl_ms_ = 3600000;  // 1 hour\n\n    // LRU eviction when cache full\n    void evictLRU();\n};\n</code></pre> <p>2. Batch Encryption</p> <pre><code>// Instead of:\nfor (auto&amp; user : users) {\n    user.email.encrypt();  // 1000 key lookups!\n}\n\n// Use:\nauto key = key_provider-&gt;getKey(\"user_pii\");\nfor (auto&amp; user : users) {\n    user.email.encryptWithKey(key);  // 1 key lookup\n}\n</code></pre> <p>3. Lazy Decryption</p> <pre><code>template&lt;typename T&gt;\nclass EncryptedField {\n    mutable std::optional&lt;T&gt; cached_plaintext_;\n\n    T decrypt() const {\n        if (!cached_plaintext_) {\n            cached_plaintext_ = field_encryption_-&gt;decrypt(blob_);\n        }\n        return *cached_plaintext_;\n    }\n};\n</code></pre>"},{"location":"column_encryption/#63-monitoring-metrics","title":"6.3 Monitoring Metrics","text":"<pre><code>// Prometheus metrics\nencryption_operations_total{operation=\"encrypt\",key_id=\"user_pii\"} 45234\nencryption_operations_total{operation=\"decrypt\",key_id=\"user_pii\"} 128956\nencryption_duration_seconds{operation=\"encrypt\",quantile=\"0.5\"} 0.0005\nencryption_duration_seconds{operation=\"encrypt\",quantile=\"0.99\"} 0.002\nkey_cache_hit_rate{key_id=\"user_pii\"} 0.98\nkey_lookup_errors_total{error=\"key_not_found\"} 12\n</code></pre>"},{"location":"column_encryption/#7-security-best-practices","title":"7. Security Best Practices","text":""},{"location":"column_encryption/#71-dos","title":"7.1 Dos","text":"<p>\u2705 Use authenticated encryption (AES-GCM) - Prevents tampering \u2705 Generate random IV per encryption - Prevents pattern analysis \u2705 Cache keys with TTL - Balance performance and key rotation \u2705 Log all key accesses - Audit trail for compliance \u2705 Encrypt in application layer - Database never sees plaintext \u2705 Use separate keys per field type - Limits blast radius \u2705 Implement key versioning - Enables rotation without downtime  </p>"},{"location":"column_encryption/#72-donts","title":"7.2 Don'ts","text":"<p>\u274c Never store keys with encrypted data - Defeats purpose \u274c Don't use ECB mode - Vulnerable to pattern attacks \u274c Don't reuse IVs - Breaks GCM security guarantees \u274c Don't skip authentication tags - Allows tampering \u274c Don't log plaintext - Audit logs must be redacted \u274c Don't use hardcoded keys - Security nightmare \u274c Don't encrypt everything - Performance &amp; operational overhead  </p>"},{"location":"column_encryption/#73-field-selection-criteria","title":"7.3 Field Selection Criteria","text":"<p>Encrypt: - Personally Identifiable Information (PII): Email, Phone, SSN, Address - Financial Data: Credit Cards, Bank Accounts, Salaries - Health Records: Medical IDs, Diagnoses, Prescriptions - Secrets: API Keys, Passwords (already hashed), OAuth Tokens</p> <p>Don't Encrypt: - Primary Keys / Foreign Keys (needed for joins/indexes) - Timestamps (used in range queries) - Status Flags (frequent filtering) - Non-sensitive Metadata (created_by, updated_at)</p>"},{"location":"column_encryption/#8-example-usage","title":"8. Example Usage","text":""},{"location":"column_encryption/#81-schema-definition","title":"8.1 Schema Definition","text":"<pre><code>struct User {\n    std::string id;                              // Plaintext (PK)\n    std::string username;                        // Plaintext (indexed)\n    EncryptedField&lt;std::string&gt; email;          // Encrypted (PII)\n    EncryptedField&lt;std::string&gt; phone;          // Encrypted (PII)\n    std::string country;                         // Plaintext (indexed)\n    int64_t created_at;                         // Plaintext (range queries)\n\n    nlohmann::json toJson() const {\n        return {\n            {\"id\", id},\n            {\"username\", username},\n            {\"email\", email.toBase64()},        // Serialized encrypted\n            {\"phone\", phone.toBase64()},\n            {\"country\", country},\n            {\"created_at\", created_at}\n        };\n    }\n\n    static User fromJson(const nlohmann::json&amp; j) {\n        User u;\n        u.id = j[\"id\"];\n        u.username = j[\"username\"];\n        u.email = EncryptedField&lt;std::string&gt;::fromBase64(j[\"email\"]);\n        u.phone = EncryptedField&lt;std::string&gt;::fromBase64(j[\"phone\"]);\n        u.country = j[\"country\"];\n        u.created_at = j[\"created_at\"];\n        return u;\n    }\n};\n</code></pre>"},{"location":"column_encryption/#82-write-path","title":"8.2 Write Path","text":"<pre><code>// Initialize encryption system\nauto key_provider = std::make_shared&lt;VaultKeyProvider&gt;(\n    \"https://vault.prod.example.com:8200\",\n    vault_token\n);\nauto field_encryption = std::make_shared&lt;FieldEncryption&gt;(key_provider);\nEncryptedField&lt;std::string&gt;::setFieldEncryption(field_encryption);\n\n// Create user with encrypted fields\nUser user;\nuser.id = \"u_12345\";\nuser.username = \"alice\";\nuser.email = EncryptedField&lt;std::string&gt;(\"alice@example.com\", \"user_pii\");\nuser.phone = EncryptedField&lt;std::string&gt;(\"+1-555-0123\", \"user_pii\");\nuser.country = \"US\";\nuser.created_at = getCurrentTimeMs();\n\n// Store in database\nauto json_str = user.toJson().dump();\ndb-&gt;put(\"d:users:\" + user.id, json_str);\n</code></pre>"},{"location":"column_encryption/#83-read-path","title":"8.3 Read Path","text":"<pre><code>// Retrieve from database\nauto json_str = db-&gt;get(\"d:users:u_12345\");\nUser user = User::fromJson(nlohmann::json::parse(json_str));\n\n// Access encrypted fields (automatic decryption)\nstd::string email = user.email.decrypt();  // \"alice@example.com\"\nstd::string phone = user.phone.decrypt();  // \"+1-555-0123\"\n\n// Plaintext fields accessible directly\nstd::cout &lt;&lt; user.username;  // \"alice\"\n</code></pre>"},{"location":"column_encryption/#9-testing-strategy","title":"9. Testing Strategy","text":""},{"location":"column_encryption/#91-unit-tests-teststest_encryptioncpp","title":"9.1 Unit Tests (tests/test_encryption.cpp)","text":"<pre><code>TEST(KeyProviderTest, MockProvider_StoresAndRetrievesKeys) {\n    auto provider = std::make_shared&lt;MockKeyProvider&gt;();\n    provider-&gt;createKey(\"test_key\", 1);\n\n    auto key = provider-&gt;getKey(\"test_key\", 1);\n    EXPECT_EQ(key.size(), 32);  // 256 bits\n}\n\nTEST(FieldEncryptionTest, EncryptDecrypt_Roundtrip) {\n    auto provider = std::make_shared&lt;MockKeyProvider&gt;();\n    provider-&gt;createKey(\"test\", 1);\n\n    FieldEncryption enc(provider);\n    std::string plaintext = \"sensitive data\";\n\n    auto blob = enc.encrypt(plaintext, \"test\");\n    auto decrypted = enc.decrypt(blob);\n\n    EXPECT_EQ(plaintext, decrypted);\n}\n\nTEST(FieldEncryptionTest, Decrypt_WithWrongKey_ThrowsException) {\n    auto provider = std::make_shared&lt;MockKeyProvider&gt;();\n    provider-&gt;createKey(\"key1\", 1);\n    provider-&gt;createKey(\"key2\", 1);\n\n    FieldEncryption enc(provider);\n    auto blob = enc.encrypt(\"data\", \"key1\");\n    blob.key_id = \"key2\";  // Tamper\n\n    EXPECT_THROW(enc.decrypt(blob), DecryptionException);\n}\n\nTEST(EncryptedFieldTest, StringField_SerializeDeserialize) {\n    auto provider = std::make_shared&lt;MockKeyProvider&gt;();\n    provider-&gt;createKey(\"test\", 1);\n    auto enc = std::make_shared&lt;FieldEncryption&gt;(provider);\n    EncryptedField&lt;std::string&gt;::setFieldEncryption(enc);\n\n    EncryptedField&lt;std::string&gt; field(\"alice@example.com\", \"test\");\n    std::string b64 = field.toBase64();\n\n    auto field2 = EncryptedField&lt;std::string&gt;::fromBase64(b64);\n    EXPECT_EQ(field2.decrypt(), \"alice@example.com\");\n}\n\nTEST(KeyRotationTest, DecryptWithOldKey_AfterRotation) {\n    auto provider = std::make_shared&lt;MockKeyProvider&gt;();\n    provider-&gt;createKey(\"key\", 1);\n\n    FieldEncryption enc(provider);\n    auto blob_v1 = enc.encrypt(\"data\", \"key\");  // Uses v1\n\n    provider-&gt;createKey(\"key\", 2);  // Rotate to v2\n\n    // Old data still decryptable\n    EXPECT_EQ(enc.decrypt(blob_v1), \"data\");\n}\n</code></pre>"},{"location":"column_encryption/#92-integration-tests","title":"9.2 Integration Tests","text":"<pre><code>TEST(EncryptionIntegrationTest, UserCRUD_WithEncryptedFields) {\n    auto db = std::make_shared&lt;RocksDBWrapper&gt;(test_config);\n    auto provider = std::make_shared&lt;MockKeyProvider&gt;();\n    provider-&gt;createKey(\"user_pii\", 1);\n    // ... setup encryption ...\n\n    // Create\n    User user = createTestUser();\n    db-&gt;put(\"d:users:\" + user.id, user.toJson().dump());\n\n    // Read\n    auto json = db-&gt;get(\"d:users:\" + user.id);\n    User loaded = User::fromJson(nlohmann::json::parse(json));\n    EXPECT_EQ(loaded.email.decrypt(), user.email.decrypt());\n\n    // Update\n    loaded.phone = EncryptedField&lt;std::string&gt;(\"+1-999-9999\", \"user_pii\");\n    db-&gt;put(\"d:users:\" + loaded.id, loaded.toJson().dump());\n\n    // Verify\n    auto updated = User::fromJson(nlohmann::json::parse(db-&gt;get(\"d:users:\" + user.id)));\n    EXPECT_EQ(updated.phone.decrypt(), \"+1-999-9999\");\n}\n</code></pre>"},{"location":"column_encryption/#93-performance-tests","title":"9.3 Performance Tests","text":"<pre><code>TEST(EncryptionPerformanceTest, EncryptDecrypt_1000Operations) {\n    auto provider = std::make_shared&lt;MockKeyProvider&gt;();\n    provider-&gt;createKey(\"perf\", 1);\n    FieldEncryption enc(provider);\n\n    auto start = std::chrono::high_resolution_clock::now();\n\n    for (int i = 0; i &lt; 1000; i++) {\n        auto blob = enc.encrypt(\"test data \" + std::to_string(i), \"perf\");\n        enc.decrypt(blob);\n    }\n\n    auto duration = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(\n        std::chrono::high_resolution_clock::now() - start\n    ).count();\n\n    EXPECT_LT(duration, 2000);  // &lt;2ms per operation\n}\n</code></pre>"},{"location":"column_encryption/#10-rollout-plan","title":"10. Rollout Plan","text":""},{"location":"column_encryption/#phase-1-core-implementation-week-1","title":"Phase 1: Core Implementation (Week 1)","text":"<ul> <li>[ ] Implement KeyProvider interface + MockKeyProvider</li> <li>[ ] Implement FieldEncryption (AES-256-GCM)</li> <li>[ ] Unit tests (15+ tests)</li> <li>[ ] Deliverable: <code>include/security/</code>, <code>src/security/</code>, <code>tests/test_encryption.cpp</code></li> </ul>"},{"location":"column_encryption/#phase-2-template-integration-week-2","title":"Phase 2: Template &amp; Integration (Week 2)","text":"<ul> <li>[ ] Implement EncryptedField template <li>[ ] Add serialization (toBase64/fromBase64)</li> <li>[ ] Integration tests with User struct</li> <li>[ ] Deliverable: Working PoC with 2-3 encrypted fields</li>"},{"location":"column_encryption/#phase-3-vaultkeyprovider-interface-week-3","title":"Phase 3: VaultKeyProvider Interface (Week 3)","text":"<ul> <li>[ ] Define VaultKeyProvider interface (no implementation)</li> <li>[ ] Document Vault API integration requirements</li> <li>[ ] Add key cache implementation</li> <li>[ ] Deliverable: <code>include/security/vault_key_provider.h</code> (header-only)</li> </ul>"},{"location":"column_encryption/#phase-4-documentation-review-week-4","title":"Phase 4: Documentation &amp; Review (Week 4)","text":"<ul> <li>[ ] Performance benchmarks</li> <li>[ ] Security review</li> <li>[ ] Operator documentation (key rotation playbook)</li> <li>[ ] Deliverable: This document + ops runbook</li> </ul>"},{"location":"column_encryption/#11-open-questions","title":"11. Open Questions","text":"<ol> <li>Key Storage Location: Vault on-premise vs. Cloud KMS vs. Both?</li> <li> <p>Recommendation: Start with MockKeyProvider, add Vault interface for production readiness</p> </li> <li> <p>Searchable Encryption: Support for encrypted field queries?</p> </li> <li> <p>Recommendation: Phase 2 feature - use deterministic encryption or bloom filters</p> </li> <li> <p>Bulk Re-Encryption: 10M+ rows, acceptable downtime?</p> </li> <li> <p>Recommendation: Online migration with dual-write (see Section 5.2)</p> </li> <li> <p>Compliance: FIPS 140-2 certification required?</p> </li> <li>Recommendation: Use OpenSSL FIPS module if needed (build-time flag)</li> </ol>"},{"location":"column_encryption/#12-references","title":"12. References","text":"<ul> <li>NIST SP 800-38D - GCM Mode Specification</li> <li>RFC 5084 - AES-GCM and AES-CCM Algorithms</li> <li>HashiCorp Vault Encryption as a Service</li> <li>Google Cloud KMS Best Practices</li> <li>AWS KMS Developer Guide</li> <li>Azure Key Vault Documentation</li> </ul> <p>Next Steps: 1. Review and approval of this design document 2. Create GitHub issues for Phase 1-4 tasks 3. Allocate 2-3 week sprint for implementation 4. Security team review before production deployment</p>"},{"location":"compliance_audit/","title":"Compliance &amp; Audit: PKI-Signing und Audit Logger","text":""},{"location":"compliance_audit/#uberblick","title":"\u00dcberblick","text":"<p>Dieses Dokument beschreibt die ersten Schritte der Compliance- und Audit-Implementierung: - PKI Client: Minimale Schnittstelle zum Signieren und Verifizieren von Hashes (Stub). - AuditLogger: Encrypt-then-Sign f\u00fcr strukturierte Audit-Logs.</p>"},{"location":"compliance_audit/#1-pki-client-vccpkiclient","title":"1. PKI Client (<code>VCCPKIClient</code>)","text":""},{"location":"compliance_audit/#zweck","title":"Zweck","text":"<p>Bietet eine zentrale Schnittstelle zum Signieren von Daten-Hashes (z. B. SHA-256 \u00fcber verschl\u00fcsselte Audit-Logs). Sp\u00e4ter erweiterbar auf echte PKI-Backends (HSM, Remote-Signing-Dienst).</p>"},{"location":"compliance_audit/#konfiguration","title":"Konfiguration","text":"<pre><code>PKIConfig pki_cfg;\npki_cfg.service_id = \"audit_service\";\npki_cfg.endpoint = \"https://pki.example.com/api/v1\";  // optional\npki_cfg.cert_path = \"/path/to/cert.pem\";              // optional\npki_cfg.key_path = \"/path/to/key.pem\";                // optional\npki_cfg.signature_algorithm = \"RSA-SHA256\";           // Standard\n</code></pre>"},{"location":"compliance_audit/#verwendung","title":"Verwendung","text":"<pre><code>auto pki = std::make_shared&lt;VCCPKIClient&gt;(pki_cfg);\n\n// 1. Berechne SHA-256 \u00fcber Daten\nstd::vector&lt;uint8_t&gt; hash = sha256(ciphertext);\n\n// 2. Signiere Hash\nauto sig = pki-&gt;signHash(hash);\nif (sig.ok) {\n    // sig.signature_id, sig.signature_b64, sig.cert_serial verf\u00fcgbar\n}\n\n// 3. Verifiziere Signatur\nbool valid = pki-&gt;verifyHash(hash, sig);\n</code></pre>"},{"location":"compliance_audit/#stub-verhalten-aktuell","title":"Stub-Verhalten (aktuell)","text":"<ul> <li>signHash: Gibt Base64-kodierten Hash zur\u00fcck (kein echtes Signing).</li> <li>verifyHash: Vergleicht Base64(hash) mit gespeicherter Signatur.</li> <li>F\u00fcr Produktion: Echte Kryptografie \u00fcber OpenSSL oder HSM integrieren.</li> </ul>"},{"location":"compliance_audit/#2-auditlogger","title":"2. AuditLogger","text":""},{"location":"compliance_audit/#zweck_1","title":"Zweck","text":"<p>Strukturierte, nachvollziehbare Protokollierung sicherheitskritischer Ereignisse mit Encrypt-then-Sign: 1. Verschl\u00fcssle Event-JSON mit AES-256-GCM (<code>FieldEncryption</code>). 2. Hash Verschl\u00fcsselter Blob (iv || ciphertext || tag). 3. Signiere Hash \u00fcber PKI Client. 4. Schreibe JSONL-Record mit Payload, Signatur und Metadaten.</p>"},{"location":"compliance_audit/#konfiguration_1","title":"Konfiguration","text":"<pre><code>AuditLoggerConfig cfg;\ncfg.enabled = true;\ncfg.encrypt_then_sign = true;        // Aktiviere Encrypt-then-Sign\ncfg.log_path = \"data/logs/audit.jsonl\";\ncfg.key_id = \"saga_log\";             // Key f\u00fcr Log-Verschl\u00fcsselung\n\nauto logger = std::make_shared&lt;AuditLogger&gt;(field_enc, pki, cfg);\n</code></pre>"},{"location":"compliance_audit/#verwendung_1","title":"Verwendung","text":"<pre><code>nlohmann::json event = {\n    {\"user\", \"admin\"},\n    {\"action\", \"read\"},\n    {\"resource\", \"/content/doc123\"},\n    {\"classification\", \"VS-NfD\"},\n    {\"result\", \"success\"},\n    {\"ip\", \"192.168.1.42\"}\n};\n\nlogger-&gt;logEvent(event);\n</code></pre>"},{"location":"compliance_audit/#log-format","title":"Log-Format","text":""},{"location":"compliance_audit/#encrypt-then-sign-standard","title":"Encrypt-then-Sign (Standard)","text":"<pre><code>{\n  \"ts\": 1700000000123,\n  \"category\": \"AUDIT\",\n  \"payload\": {\n    \"type\": \"ciphertext\",\n    \"key_id\": \"saga_log\",\n    \"key_version\": 1,\n    \"iv_b64\": \"abc123...\",\n    \"ciphertext_b64\": \"xyz789...\",\n    \"tag_b64\": \"def456...\"\n  },\n  \"signature\": {\n    \"ok\": true,\n    \"id\": \"sig_a1b2c3d4\",\n    \"algorithm\": \"RSA-SHA256\",\n    \"sig_b64\": \"base64(...)\",\n    \"cert_serial\": \"DEMO-CERT-SERIAL\"\n  }\n}\n</code></pre>"},{"location":"compliance_audit/#plaintext-sign-fur-weniger-sensitive-logs","title":"Plaintext-Sign (f\u00fcr weniger sensitive Logs)","text":"<p>Setze <code>encrypt_then_sign = false</code>:</p> <pre><code>{\n  \"ts\": 1700000000456,\n  \"category\": \"AUDIT\",\n  \"payload\": {\n    \"type\": \"plaintext\",\n    \"data_b64\": \"eyJ1c2VyIjoidXNlcjEiLCAi...\"\n  },\n  \"signature\": {\n    \"ok\": true,\n    \"id\": \"sig_xyz\",\n    ...\n  }\n}\n</code></pre>"},{"location":"compliance_audit/#wiederherstellungverifikation","title":"Wiederherstellung/Verifikation","text":"<pre><code># Beispiel in Python (zur Demonstration)\nimport json\nimport base64\nfrom cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n\nwith open(\"data/logs/audit.jsonl\") as f:\n    for line in f:\n        record = json.loads(line)\n\n        # 1. Hole Ciphertext und Signatur\n        payload = record[\"payload\"]\n        signature = record[\"signature\"]\n\n        # 2. Verifiziere Signatur \u00fcber hash(iv||ct||tag)\n        iv = base64.b64decode(payload[\"iv_b64\"])\n        ct = base64.b64decode(payload[\"ciphertext_b64\"])\n        tag = base64.b64decode(payload[\"tag_b64\"])\n\n        to_verify = iv + ct + tag\n        hash_bytes = sha256(to_verify)\n\n        # Verifikation via PKI (hier stub):\n        # verify_signature(hash_bytes, signature[\"sig_b64\"])\n\n        # 3. Entschl\u00fcssele mit Key\n        key = get_key(payload[\"key_id\"], payload[\"key_version\"])\n        cipher = Cipher(algorithms.AES(key), modes.GCM(iv, tag))\n        decryptor = cipher.decryptor()\n        plaintext = decryptor.update(ct) + decryptor.finalize()\n\n        event = json.loads(plaintext)\n        print(event)  # Original Event\n</code></pre>"},{"location":"compliance_audit/#integration-in-http-server","title":"Integration in HTTP Server","text":""},{"location":"compliance_audit/#automatische-initialisierung","title":"Automatische Initialisierung","text":"<p>Der HTTP-Server initialisiert den AuditLogger automatisch beim Start:</p> <pre><code>// Aus HttpServer::HttpServer() Konstruktor:\nauto key_provider = std::make_shared&lt;MockKeyProvider&gt;();\nkey_provider-&gt;createKey(\"saga_log\", 1);\nauto field_enc = std::make_shared&lt;FieldEncryption&gt;(key_provider);\n\nthemis::utils::PKIConfig pki_cfg;\npki_cfg.service_id = \"themis_server\";\npki_cfg.signature_algorithm = \"RSA-SHA256\";\nauto pki_client = std::make_shared&lt;themis::utils::VCCPKIClient&gt;(pki_cfg);\n\nthemis::utils::AuditLoggerConfig audit_cfg;\naudit_cfg.enabled = true;\naudit_cfg.encrypt_then_sign = true;\naudit_cfg.log_path = \"data/logs/audit.jsonl\";\naudit_cfg.key_id = \"saga_log\";\n\naudit_logger_ = std::make_shared&lt;themis::utils::AuditLogger&gt;(\n    field_enc, pki_client, audit_cfg);\n\n// Verbinde mit PolicyEngine\npolicy_engine_-&gt;setAuditLogger(audit_logger_);\n</code></pre>"},{"location":"compliance_audit/#automatisches-logging-durch-policyengine","title":"Automatisches Logging durch PolicyEngine","text":"<p>Die <code>PolicyEngine</code> loggt automatisch alle Enforcement-Entscheidungen:</p> <pre><code>// In PolicyEngine::evaluate():\nif (audit_logger_ &amp;&amp; d.mode == \"enforce\") {\n    nlohmann::json audit_event = {\n        {\"event_type\", \"policy_evaluation\"},\n        {\"route\", route},\n        {\"classification\", d.classification},\n        {\"mode\", d.mode},\n        {\"require_content_encryption\", d.require_content_encryption},\n        {\"encrypt_logs\", d.encrypt_logs},\n        {\"redaction\", d.redaction},\n        {\"retention_days\", d.retention_days},\n        {\"timestamp\", getCurrentTimeMs()}\n    };\n\n    if (headers.find(\"X-User-Id\") != headers.end()) {\n        audit_event[\"user_id\"] = headers[\"X-User-Id\"];\n    }\n\n    audit_logger_-&gt;logEvent(audit_event);\n}\n</code></pre>"},{"location":"compliance_audit/#szenario-log-alle-vs-nfd-content-zugriffe","title":"Szenario: Log alle VS-NfD+ Content-Zugriffe","text":"<pre><code>// In handleContentImport:\nif (audit_logger_ &amp;&amp; (pdec.classification == \"vs-nfd\" || \n                      pdec.classification == \"geheim\" || \n                      pdec.classification == \"streng-geheim\")) {\n    nlohmann::json audit_event = {\n        {\"event_type\", \"content_import\"},\n        {\"classification\", pdec.classification},\n        {\"mode\", pdec.mode},\n        {\"require_encryption\", pdec.require_content_encryption},\n        {\"content_id\", content_id},\n        {\"timestamp\", getCurrentTimeMs()}\n    };\n\n    if (user_id_header.has_value()) {\n        audit_event[\"user_id\"] = user_id_header.value();\n    }\n\n    audit_logger_-&gt;logEvent(audit_event);\n}\n</code></pre>"},{"location":"compliance_audit/#szenario-blob-zugriff-logging","title":"Szenario: Blob-Zugriff Logging","text":"<pre><code>// In handleGetContentBlob:\nif (audit_logger_) {\n    nlohmann::json audit_event = {\n        {\"event_type\", \"content_blob_access\"},\n        {\"content_id\", id},\n        {\"timestamp\", getCurrentTimeMs()}\n    };\n\n    // Optional: User-ID aus Headers extrahieren\n    if (req.contains(\"X-User-Id\")) {\n        audit_event[\"user_id\"] = req[\"X-User-Id\"];\n    }\n\n    audit_logger_-&gt;logEvent(audit_event);\n}\n</code></pre>"},{"location":"compliance_audit/#retention-archivierung-roadmap","title":"Retention &amp; Archivierung (Roadmap)","text":""},{"location":"compliance_audit/#retention-manager","title":"Retention Manager","text":"<pre><code>RetentionManager mgr(cfg.log_path, policy_engine);\n\n// Archiviere Logs \u00e4lter als 90 Tage (nach Klassifikation)\nmgr.archiveOldLogs(90);\n\n// L\u00f6sche nach 7 Jahren (gesetzlich)\nmgr.purgeExpiredLogs();\n</code></pre>"},{"location":"compliance_audit/#signatur-verkettung-chain-of-custody","title":"Signatur-Verkettung (Chain-of-Custody)","text":"<pre><code>// In logEvent:\n// Berechne Hash \u00fcber vorherigem Record + aktuellem Event\nauto prev_hash = readLastRecordHash();\nauto chain_input = prev_hash + current_event_json;\nauto sig = pki_-&gt;signHash(sha256(chain_input));\n</code></pre>"},{"location":"compliance_audit/#testen","title":"Testen","text":"<pre><code># AuditLogger Tests\nctest -C Release -R \"^AuditLoggerTest\\.\" --output-on-failure\n\n# Governance + Audit Integration Tests\nctest -C Release -R \"^HttpGovernanceTest\\.|^AuditLoggerTest\\.\" --output-on-failure\n</code></pre> <p>Alle Tests bestehen (19/19): - AuditLogger-Tests (4/4):   - <code>EncryptThenSignFlow</code>: Verschl\u00fcsselter Log mit Signatur   - <code>PlaintextSignFlow</code>: Nur signierter Log   - <code>DisabledLogger</code>: Logging deaktiviert (keine Datei)   - <code>MultipleEvents</code>: Mehrere Events in JSONL - Governance-Tests (15/15): Alle Klassifikationen, Resource-Mappings und Policy-Header validiert</p>"},{"location":"compliance_audit/#live-test-audit-logs-uberprufen","title":"Live-Test: Audit-Logs \u00fcberpr\u00fcfen","text":"<pre><code># Server starten\n./themis_server\n\n# Content mit VS-NfD klassifizieren\ncurl -X POST http://localhost:8080/content/import \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-Classification: VS-NfD\" \\\n  -H \"X-User-Id: admin\" \\\n  -d '{\n    \"content\": {\n      \"id\": \"test123\",\n      \"mime_type\": \"text/plain\",\n      \"category\": \"document\"\n    },\n    \"blob\": \"Sensitive document content\"\n  }'\n\n# Audit-Log pr\u00fcfen\ncat data/logs/audit.jsonl\n</code></pre> <p>Erwartete Log-Eintr\u00e4ge: 1. Policy Evaluation (automatisch durch PolicyEngine):    <code>json    {      \"ts\": 1700000000123,      \"category\": \"AUDIT\",      \"payload\": {        \"type\": \"ciphertext\",        \"key_id\": \"saga_log\",        \"key_version\": 1,        \"iv_b64\": \"...\",        \"ciphertext_b64\": \"...\",        \"tag_b64\": \"...\"      },      \"signature\": {        \"ok\": true,        \"id\": \"sig_abc123\",        \"algorithm\": \"RSA-SHA256\",        \"sig_b64\": \"...\",        \"cert_serial\": \"DEMO-CERT-SERIAL\"      }    }</code></p> <ol> <li>Content Import (bei VS-NfD+ Klassifikation):</li> <li>\u00c4hnliche Struktur mit verschl\u00fcsseltem Event-JSON</li> </ol> <p>Entschl\u00fcsseltes Event-JSON (f\u00fcr Demonstration):</p> <pre><code>{\n  \"event_type\": \"policy_evaluation\",\n  \"route\": \"/content/import\",\n  \"classification\": \"vs-nfd\",\n  \"mode\": \"enforce\",\n  \"require_content_encryption\": true,\n  \"encrypt_logs\": true,\n  \"redaction\": \"standard\",\n  \"retention_days\": 365,\n  \"timestamp\": 1700000000123,\n  \"user_id\": \"admin\"\n}\n</code></pre>"},{"location":"compliance_audit/#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ol> <li>Echtes PKI-Signing: OpenSSL RSA-Signaturen \u00fcber SHA-256-Hash.</li> <li>PII Detection: Automatische Erkennung und Markierung von PII-Feldern in Logs.</li> <li>Retention Manager: Automatische Archivierung/L\u00f6schung basierend auf <code>retention_days</code>.</li> <li>Governance Integration: Automatisches Logging bei enforce-Verst\u00f6\u00dfen.</li> <li>Redaction: PII-Redaction in Logs f\u00fcr niedrigere Klassifikationen.</li> <li>Compliance Reports: Aggregierte Audit-Reports f\u00fcr Compliance-Checks.</li> </ol>"},{"location":"compliance_audit/#referenzen","title":"Referenzen","text":"<ul> <li><code>include/utils/pki_client.h</code></li> <li><code>src/utils/pki_client.cpp</code></li> <li><code>include/utils/audit_logger.h</code></li> <li><code>src/utils/audit_logger.cpp</code></li> <li><code>tests/test_audit_logger.cpp</code></li> </ul>"},{"location":"compliance_governance_strategy/","title":"Compliance &amp; Governance-Strategie f\u00fcr ThemisDB","text":""},{"location":"compliance_governance_strategy/#executive-summary","title":"Executive Summary","text":"<p>Ziel: Umfassende Compliance- und Governance-Architektur f\u00fcr ThemisDB mit PKI-signiertem Audit-Trail, DSGVO-by-Design, automatischer PII-Erkennung und konfigurierbaren Governance-Policies.</p> <p>Kernprinzipien: - \ud83d\udcdd Unver\u00e4nderlicher Audit-Trail: SAGA-Log regelm\u00e4\u00dfig PKI-signiert, Log-Keys sicher gespeichert - \ud83d\udd10 DSGVO by Design: Automatische PII-Erkennung, UUID-Ersetzung, Original-Blob zugriffsbeschr\u00e4nkt - \u2696\ufe0f Regulatory Compliance: GDPR/DSGVO, HIPAA, BSI C5, SOC2 Unterst\u00fctzung - \ud83c\udfaf Policy-Driven: Alle Governance-Regeln in YAML/JSON konfigurierbar - \ud83d\udd0d Transparenz: Vollst\u00e4ndige Nachvollziehbarkeit aller Datenoperationen</p>"},{"location":"compliance_governance_strategy/#1-architektur-ubersicht","title":"1. Architektur-\u00dcbersicht","text":""},{"location":"compliance_governance_strategy/#11-compliance-komponenten","title":"1.1 Compliance-Komponenten","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    ThemisDB Compliance Layer                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502 SAGA Logger  \u2502  \u2502 PII Detector \u2502  \u2502 Retention    \u2502      \u2502\n\u2502  \u2502 + PKI Sign   \u2502  \u2502 + Anonymizer \u2502  \u2502 Manager      \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502         \u2502                  \u2502                  \u2502              \u2502\n\u2502         \u25bc                  \u25bc                  \u25bc              \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502  \u2502         Governance Policy Engine (GPE)            \u2502       \u2502\n\u2502  \u2502   - Policy Validation &amp; Enforcement               \u2502       \u2502\n\u2502  \u2502   - Config-Driven Rules (YAML/JSON)              \u2502       \u2502\n\u2502  \u2502   - Audit Trail Generation                        \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502                                                               \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502  \u2502 VCC-PKI      \u2502  \u2502 VCC-User     \u2502  \u2502 Encryption   \u2502      \u2502\n\u2502  \u2502 Integration  \u2502  \u2502 Integration  \u2502  \u2502 Layer        \u2502      \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"compliance_governance_strategy/#12-threat-model-compliance-perspektive","title":"1.2 Threat Model (Compliance-Perspektive)","text":"<p>Was wird gesch\u00fctzt: - \u2705 Audit-Integrit\u00e4t: SAGA-Logs unver\u00e4nderlich durch PKI-Signaturen - \u2705 PII-Schutz: Automatische Erkennung und Anonymisierung sensibler Daten - \u2705 Rechtssicherheit: Vollst\u00e4ndige Nachvollziehbarkeit aller Operationen - \u2705 Datensouver\u00e4nit\u00e4t: On-Premise mit VCC-PKI/User Integration</p> <p>Compliance-Szenarien: 1. \u2705 DSGVO Artikel 17 (Recht auf Vergessenwerden): PII durch UUID ersetzt, Original-Zugriff widerrufbar 2. \u2705 DSGVO Artikel 30 (Verarbeitungsverzeichnis): SAGA-Log als l\u00fcckenloser Audit-Trail 3. \u2705 DSGVO Artikel 32 (Datensicherheit): Verschl\u00fcsselung + PKI-Signaturen 4. \u2705 HIPAA Audit Controls: Strukturierte JSON-Logs mit medizinischen Daten-Tags 5. \u2705 BSI C5 Logging: Zeitstempel, User-ID, Operation, Result in jedem Log-Entry</p>"},{"location":"compliance_governance_strategy/#2-saga-log-pki-signierung","title":"2. SAGA-Log PKI-Signierung","text":""},{"location":"compliance_governance_strategy/#21-konzept","title":"2.1 Konzept","text":"<p>Problem: SAGA-Logs (Transaktions-Kompensationen) m\u00fcssen manipulationssicher sein f\u00fcr rechtliche Nachweisbarkeit.</p> <p>L\u00f6sung: Regelm\u00e4\u00dfige PKI-Signierung von Log-Batches mit VCC-PKI Intermediate CA.</p> <pre><code>// Beispiel: SAGA-Log Entry (vor Signierung)\n{\n  \"saga_id\": \"tx_20251031_123456_789\",\n  \"timestamp\": \"2025-10-31T14:23:45.123Z\",\n  \"operation\": \"vectorAdd\",\n  \"entity_pk\": \"doc_12345\",\n  \"user_id\": \"user_alice@example.com\",\n  \"compensated\": false,\n  \"duration_ms\": 42,\n  \"status\": \"success\"\n}\n</code></pre>"},{"location":"compliance_governance_strategy/#22-signierungsprozess","title":"2.2 Signierungsprozess","text":"<p>Workflow: 1. Batch-Collection: Alle SAGA-Steps seit letzter Signierung sammeln (z.B. 1000 Eintr\u00e4ge oder 5 Minuten) 2. Canonical JSON: Sortierte Keys, UTF-8, keine Whitespace \u2192 deterministischer Klartext 3. AES-Verschl\u00fcsselung (LEK): Klartext-Batch mit t\u00e4glichem LEK per AES-256-GCM verschl\u00fcsseln \u2192 Ciphertext + IV + Tag 4. SHA-256 Hash (\u00fcber Ciphertext): <code>hash = SHA256(ciphertext_batch)</code>  \u2190 Encrypt-then-Hash 5. PKI-Signierung (Ciphertext-Hash): VCC-PKI REST API aufrufen \u2192 <code>POST /api/v1/sign</code> <code>json    {      \"service_id\": \"themis-db\",      \"data_hash\": \"abcdef123456...\",      \"signature_type\": \"RSA-SHA256\"    }</code> 6. Signatur speichern: In RocksDB unter <code>saga:signature:&lt;timestamp&gt;</code> <code>json    {      \"batch_id\": \"batch_20251031_142300\",      \"log_entries\": 1000,      \"first_saga_id\": \"tx_...\",      \"last_saga_id\": \"tx_...\",      \"hash\": \"abcdef...\",                    \"signature\": \"MIIBIjANBg...\",      \"cert_serial\": \"03:A5:B2:...\",      \"signed_at\": \"2025-10-31T14:25:00Z\",      \"signer\": \"themis-service-cert\",      \"enc\": {        \"alg\": \"AES-256-GCM\",        \"lek_id\": \"lek:20251031\",        \"iv\": \"base64(...)\",        \"tag\": \"base64(...)\"      }    }</code></p> <p>Verifizierung (Ciphertext zuerst):</p> <pre><code>bool verifySAGABatch(const std::string&amp; batch_id) {\n    // 1. Lade Signatur-Metadata\n    auto sig_data = db_.get(\"saga:signature:\" + batch_id);\n\n    // 2. Lade gespeicherten Ciphertext-Batch (ohne Entschl\u00fcsselung)\n    std::string ciphertext = loadEncryptedBatch(sig_data[\"batch_id\"]);\n\n    // 3. Hash \u00fcber Ciphertext bilden\n    std::string hash = sha256(ciphertext);\n\n    // 4. VCC-PKI Signature Verify (Ciphertext-Hash)\n    return vcc_pki_client_-&gt;verify(\n        hash, \n        sig_data[\"signature\"], \n        sig_data[\"cert_serial\"]\n    );\n}\n</code></pre>"},{"location":"compliance_governance_strategy/#23-log-key-management","title":"2.3 Log-Key Management","text":"<p>Problem: Log-Eintr\u00e4ge k\u00f6nnen sensitive Daten enthalten (vor Anonymisierung) \u2192 Verschl\u00fcsselung erforderlich.</p> <p>L\u00f6sung: Separater Log-Encryption-Key (LEK) pro Zeitperiode (z.B. t\u00e4glich).</p> <pre><code># config/governance.yaml\nsaga_log:\n  signature:\n    enabled: true\n    batch_size: 1000\n    batch_interval_minutes: 5\n    algorithm: \"RSA-SHA256\"\n    pki_service: \"https://localhost:8443/api/v1\"\n\n  encryption:\n    enabled: true\n    key_rotation: \"daily\"  # daily, weekly, monthly\n    algorithm: \"AES-256-GCM\"\n    key_storage: \"rocksdb\"  # Key encrypted with KEK from PKI\n\n  retention:\n    keep_signed_logs_days: 2555  # 7 Jahre (DSGVO Artikel 17)\n    archive_to_cold_storage: true\n    cold_storage_path: \"/mnt/archive/saga_logs\"\n</code></pre> <p>LEK-Ablauf: 1. T\u00e4gliche KEK-Ableitung: VCC-PKI Service-Zertifikat \u2192 HKDF \u2192 KEK(date) 2. LEK-Generierung: Zuf\u00e4llige 256-bit AES-Key \u2192 LEK(date) 3. LEK-Speicherung: <code>lek:20251031 = AES-GCM-Encrypt(KEK, LEK)</code> in RocksDB 4. Log-Verschl\u00fcsselung: Jeder SAGA-Entry \u2192 <code>AES-GCM-Encrypt(LEK, canonical_json)</code> 5. Dekodierung: Bei Audit-Anfrage \u2192 Lade LEK \u2192 Entschl\u00fcssele Logs</p> <p>Vorteil: Bei Daten-Leak nur aktuelle LEK kompromittiert, nicht gesamte Historie.</p>"},{"location":"compliance_governance_strategy/#3-dsgvo-by-design-pii-erkennung-anonymisierung","title":"3. DSGVO by Design: PII-Erkennung &amp; Anonymisierung","text":""},{"location":"compliance_governance_strategy/#31-konzept","title":"3.1 Konzept","text":"<p>DSGVO Artikel 25 (Data Protection by Design): - Sensitive PII automatisch erkennen - Original-Entit\u00e4t durch UUID ersetzen (Pseudonymisierung) - Original-Blob bleibt verschl\u00fcsselt, Zugriff nur mit User-Berechtigung - L\u00f6schung: UUID-Mapping l\u00f6schen \u2192 Original unwiederbringlich</p>"},{"location":"compliance_governance_strategy/#32-pii-detection-engine","title":"3.2 PII-Detection Engine","text":"<p>Multi-Strategy-Ansatz:</p> <pre><code>class PIIDetector {\npublic:\n    enum class PIIType {\n        EMAIL,           // RFC 5322 Email-Regex\n        PHONE,           // E.164 + lokale Formate\n        SSN,             // Social Security Number (US, DE, etc.)\n        IBAN,            // International Bank Account Number\n        CREDIT_CARD,     // Luhn-Algorithm Validation\n        PASSPORT,        // Country-specific patterns\n        IP_ADDRESS,      // IPv4/IPv6\n        MEDICAL_ID,      // Krankenversicherungsnummer\n        TAX_ID,          // Steuernummer, UID\n        CUSTOM           // User-defined regex\n    };\n\n    struct PIIMatch {\n        PIIType type;\n        std::string field_path;  // e.g., \"user.profile.email\"\n        std::string original_value;\n        std::string anonymized_value;  // UUID\n        size_t offset;\n        size_t length;\n    };\n\n    std::vector&lt;PIIMatch&gt; detectPII(\n        const json&amp; entity_data,\n        const PIIConfig&amp; config\n    );\n};\n</code></pre> <p>Detection-Strategien:</p> <ol> <li>Regex-Based Detection (schnell, hohe Pr\u00e4zision):    ```cpp    const std::regex EMAIL_REGEX(        R\"(\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+.[A-Z|a-z]{2,}\\b)\"    );</li> </ol> <p>const std::regex IBAN_REGEX(        R\"([A-Z]{2}\\d{2}[A-Z0-9]{10,30})\"    );    ```</p> <ol> <li>NER (Named Entity Recognition) (Machine Learning, optional):</li> <li>Integration mit lokalen NER-Modellen (z.B. spaCy, Flair)</li> <li> <p>Erkennung von Namen, Adressen, Organisationen in Freitext</p> </li> <li> <p>Schema-Based Detection (Metadaten):    ```yaml    # config/pii_schema.yaml    field_annotations:</p> <ul> <li>field: \"email\"    type: EMAIL    auto_anonymize: true</li> <li>field: \"phone_number\"    type: PHONE    auto_anonymize: true</li> <li>field: \"medical_records.patient_id\"    type: MEDICAL_ID    auto_anonymize: true    retention_days: 3650  # 10 Jahre HIPAA    ```</li> </ul> </li> </ol>"},{"location":"compliance_governance_strategy/#33-anonymisierung-workflow","title":"3.3 Anonymisierung-Workflow","text":"<p>Beispiel: Graph-Entity mit PII</p> <pre><code>// Original-Entity (vor Import)\n{\n  \"pk\": \"patient_001\",\n  \"name\": \"Max Mustermann\",\n  \"email\": \"max.mustermann@example.com\",\n  \"ssn\": \"123-45-6789\",\n  \"diagnosis\": \"...\"\n}\n\n// Nach PII-Detection &amp; Anonymisierung\n{\n  \"pk\": \"patient_001\",\n  \"name\": \"pii_uuid_7a3f2e1b-4c5d-6a7b-8c9d-0e1f2a3b4c5d\",\n  \"email\": \"pii_uuid_9f8e7d6c-5b4a-3c2d-1e0f-a9b8c7d6e5f4\",\n  \"ssn\": \"pii_uuid_3e2d1c0b-a9f8-e7d6-c5b4-a3f2e1d0c9b8\",\n  \"diagnosis\": \"...\"\n}\n\n// PII-Mapping in separater CF (RocksDB Column Family)\nKey: pii_uuid_7a3f2e1b-4c5d-6a7b-8c9d-0e1f2a3b4c5d\nValue: {\n  \"original_value\": \"Max Mustermann\",  // AES-256-GCM encrypted\n  \"field\": \"name\",\n  \"entity_pk\": \"patient_001\",\n  \"pii_type\": \"PERSON_NAME\",\n  \"detected_at\": \"2025-10-31T14:30:00Z\",\n  \"detected_by\": \"regex_ner\",\n  \"retention_policy\": \"gdpr_erasure\",\n  \"access_control\": {\n    \"allowed_roles\": [\"doctor\", \"admin\"],\n    \"audit_access\": true\n  }\n}\n</code></pre> <p>Zugriff auf Original:</p> <pre><code>std::string revealPII(\n    const std::string&amp; pii_uuid,\n    const UserContext&amp; user\n) {\n    // 1. Lade PII-Mapping\n    auto pii_data = db_.get(\"pii:\" + pii_uuid);\n\n    // 2. ACL-Check\n    if (!checkAccess(pii_data[\"access_control\"], user)) {\n        THEMIS_AUDIT_LOG(\"PII_ACCESS_DENIED\", {\n            {\"pii_uuid\", pii_uuid},\n            {\"user_id\", user.id},\n            {\"timestamp\", now()}\n        });\n        throw AuthorizationException(\"Access to PII denied\");\n    }\n\n    // 3. Audit-Log\n    THEMIS_AUDIT_LOG(\"PII_ACCESS_GRANTED\", {\n        {\"pii_uuid\", pii_uuid},\n        {\"user_id\", user.id},\n        {\"field\", pii_data[\"field\"]},\n        {\"entity_pk\", pii_data[\"entity_pk\"]}\n    });\n\n    // 4. Entschl\u00fcsseln &amp; Zur\u00fcckgeben\n    std::string encrypted = pii_data[\"original_value\"];\n    return decryptField(encrypted, user.field_key);\n}\n</code></pre> <p>Recht auf Vergessenwerden (DSGVO Artikel 17):</p> <pre><code>void erasePII(const std::string&amp; entity_pk) {\n    // 1. Finde alle PII-UUIDs f\u00fcr Entity\n    auto pii_uuids = findPIIForEntity(entity_pk);\n\n    // 2. L\u00f6sche PII-Mappings (Original unwiederbringlich)\n    for (const auto&amp; uuid : pii_uuids) {\n        db_.delete(\"pii:\" + uuid);\n\n        THEMIS_AUDIT_LOG(\"PII_ERASED\", {\n            {\"pii_uuid\", uuid},\n            {\"entity_pk\", entity_pk},\n            {\"timestamp\", now()},\n            {\"reason\", \"gdpr_article_17\"}\n        });\n    }\n\n    // 3. Entity bleibt mit UUIDs (Pseudonymisiert, aber nutzbar f\u00fcr Statistik)\n}\n</code></pre>"},{"location":"compliance_governance_strategy/#4-audit-trail-structured-logging","title":"4. Audit-Trail &amp; Structured Logging","text":""},{"location":"compliance_governance_strategy/#41-log-kategorien","title":"4.1 Log-Kategorien","text":"<p>ThemisDB unterscheidet mehrere Log-Typen:</p> Kategorie Zweck Signiert Verschl\u00fcsselt Retention SAGA Transaktions-Kompensationen \u2705 Ja \u2705 Ja 7 Jahre AUDIT Datenzugriffe, ACL-Pr\u00fcfungen \u2705 Ja \u2705 Ja (Encrypt-then-Sign bei Query-Daten) 7 Jahre SECURITY Auth-Failures, Anomalien \u2705 Ja \u274c Nein 10 Jahre OPERATIONAL Performance, Errors \u274c Nein \u274c Nein 90 Tage DEBUG Entwickler-Traces \u274c Nein \u274c Nein 7 Tage ### 4.4 Vertraulichkeitswahrende Signierung (Encrypt-then-Sign) <p>F\u00fcr alle Log-Kategorien, die Query-Daten, Query-Parameter, Result-Samples oder PII enthalten k\u00f6nnen (insb. AUDIT, SAGA), gilt:</p> <ul> <li>Erst wird der Log-Eintrag als Canonical JSON serialisiert</li> <li>Dann wird der Klartext mit dem tagesaktuellen LEK via AES-256-GCM verschl\u00fcsselt</li> <li>Der Hash f\u00fcr die PKI-Signatur wird \u00fcber den Ciphertext gebildet (nicht \u00fcber den Klartext)</li> <li>Signatur und AES-Metadaten (iv, tag, lek_id, optional aad) werden gemeinsam persistiert</li> <li>Eine redaktierte, nicht sensible Kurzform wird optional in stdout/file geloggt</li> </ul> <p>Diese Reihenfolge verhindert, dass sensible Daten in Signaturvorlagen, SIEM-Pipelines oder Transportebenen im Klartext erscheinen.</p>"},{"location":"compliance_governance_strategy/#42-structured-json-logging","title":"4.2 Structured JSON-Logging","text":"<p>Standard-Schema:</p> <pre><code>{\n  \"log_id\": \"uuid_v7\",\n  \"timestamp\": \"2025-10-31T14:45:32.123Z\",\n  \"category\": \"AUDIT\",\n  \"severity\": \"INFO\",\n  \"service\": \"themis-server\",\n  \"host\": \"themis-prod-01\",\n  \"user\": {\n    \"id\": \"user_alice@example.com\",\n    \"role\": \"analyst\",\n    \"ip\": \"192.168.1.42\",\n    \"session_id\": \"jwt_...\"\n  },\n  \"operation\": {\n    \"type\": \"query\",\n    \"resource\": \"graph:patients\",\n    \"action\": \"read\",\n    \"query_aql\": \"FOR p IN patients FILTER p.age &gt; 50 RETURN p\",\n    \"result_count\": 42,\n    \"duration_ms\": 156\n  },\n  \"compliance\": {\n    \"pii_accessed\": [\"email\", \"ssn\"],\n    \"purpose\": \"medical_research\",\n    \"legal_basis\": \"gdpr_article_6_1_e\"\n  },\n  \"metadata\": {\n    \"saga_id\": \"tx_...\",\n    \"trace_id\": \"otel_...\",\n    \"correlation_id\": \"req_...\"\n  }\n}\n</code></pre> <p>Log-Sink Integration:</p> <pre><code>// include/utils/audit_logger.h\nclass AuditLogger {\npublic:\n    static void logDataAccess(\n        const UserContext&amp; user,\n        const std::string&amp; resource,\n        const std::string&amp; action,\n        const std::vector&lt;std::string&gt;&amp; pii_fields,\n        int64_t duration_ms\n    );\n\n    static void logSecurityEvent(\n        const std::string&amp; event_type,\n        const json&amp; details\n    );\n\n    static void logSAGAStep(\n        const Saga::Step&amp; step,\n        const std::string&amp; saga_id\n    );\n};\n</code></pre> <p>spdlog Integration (Encrypt-then-Sign):</p> <pre><code>// src/utils/audit_logger.cpp\nvoid AuditLogger::logDataAccess(...) {\n  json log_entry = {\n        {\"log_id\", generate_uuid_v7()},\n        {\"timestamp\", iso8601_now()},\n        {\"category\", \"AUDIT\"},\n        {\"user\", {\n            {\"id\", user.id},\n            {\"role\", user.role},\n            {\"ip\", user.ip_address}\n        }},\n        {\"operation\", {\n            {\"resource\", resource},\n            {\"action\", action},\n            {\"duration_ms\", duration_ms}\n        }},\n        {\"compliance\", {\n            {\"pii_accessed\", pii_fields}\n        }}\n    };\n\n  // 1) Canonical JSON\n  std::string canonical = toCanonicalJSON(log_entry);\n\n  // 2) Encrypt with LEK (AES-256-GCM) if category contains query data\n  if (governance_-&gt;shouldEncryptLogs(\"AUDIT\")) {\n    AAD aad{ {\"log_id\", log_entry[\"log_id\"]}, {\"category\", \"AUDIT\"}, {\"timestamp\", log_entry[\"timestamp\"]} };\n    auto enc = aes_gcm_encrypt(lek_manager_.current(), canonical, aad);\n\n    // 3) Hash ciphertext and queue for signing (Encrypt-then-Sign)\n    auto hash = sha256(enc.ciphertext);\n    queueForSigning(hash, enc.meta); // enc.meta carries iv, tag, lek_id, aad\n\n    // 4) Persist encrypted envelope for audit storage\n    persistEncryptedAudit(enc, log_entry[\"log_id\"]);\n\n    // 5) Emit redacted line to console/file sinks only\n    auto logger = spdlog::get(\"audit\");\n    logger-&gt;info(\"{{\\\"log_id\\\":\\\"{}\\\",\\\"category\\\":\\\"AUDIT\\\",\\\"encrypted\\\":true}}\", (std::string)log_entry[\"log_id\"]);\n  } else {\n    // Non-sensitive: plain JSON to sinks and to signing queue (still encrypted if policy enforces)\n    auto logger = spdlog::get(\"audit\");\n    logger-&gt;info(canonical);\n    addToPendingSAGABatch(log_entry);\n  }\n}\n</code></pre>"},{"location":"compliance_governance_strategy/#43-siem-integration","title":"4.3 SIEM-Integration","text":"<p>Export zu externen SIEM-Systemen:</p> <pre><code># config/governance.yaml\naudit_export:\n  enabled: true\n  destinations:\n    - type: syslog\n      host: \"siem.internal.vcc\"\n      port: 514\n      protocol: \"TCP\"\n      tls: true\n      categories: [\"AUDIT\", \"SECURITY\"]\n      encryption:\n        encrypt_payloads: true\n        sign_ciphertext: true\n        redact_console_output: true\n\n    - type: elasticsearch\n      url: \"https://elastic.internal.vcc:9200\"\n      index: \"themis-audit-{date}\"\n      auth_type: \"api_key\"\n      api_key_env: \"ELASTIC_API_KEY\"\n      encryption:\n        encrypt_payloads: true\n        sign_ciphertext: true\n\n    - type: file\n      path: \"/var/log/themis/audit_{date}.json.gz\"\n      rotation: \"daily\"\n      compression: true\n      max_size_mb: 500\n      encryption:\n        encrypt_payloads: true\n        sign_ciphertext: true\n</code></pre>"},{"location":"compliance_governance_strategy/#5-governance-policy-engine-gpe","title":"5. Governance Policy Engine (GPE)","text":""},{"location":"compliance_governance_strategy/#51-policy-definition-yaml","title":"5.1 Policy-Definition (YAML)","text":"<p>Zentrale Governance-Konfiguration:</p> <pre><code># config/governance_policies.yaml\ngovernance:\n  version: \"1.0\"\n  effective_date: \"2025-11-01\"\n\n  # ========== DATA CLASSIFICATION ==========\n  data_classification:\n    levels:\n      - name: \"public\"\n        encryption_required: false\n        pii_detection: false\n        retention_days: 365\n\n      - name: \"internal\"\n        encryption_required: true\n        pii_detection: true\n        retention_days: 2555  # 7 Jahre\n        access_control: \"role_based\"\n\n      - name: \"confidential\"\n        encryption_required: true\n        pii_detection: true\n        retention_days: 3650  # 10 Jahre\n        access_control: \"attribute_based\"\n        audit_all_access: true\n\n      - name: \"restricted\"\n        encryption_required: true\n        encryption_algorithm: \"AES-256-GCM\"\n        pii_detection: true\n        pii_auto_anonymize: true\n        retention_days: 3650\n        access_control: \"multi_factor\"\n        audit_all_access: true\n        require_approval: true\n\n  # ========== PII DETECTION RULES ==========\n  pii_detection:\n    enabled: true\n    strategies:\n      - type: \"regex\"\n        patterns:\n          email: '\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n          phone_de: '\\+49\\s?\\d{2,5}\\s?\\d{3,10}'\n          iban: '[A-Z]{2}\\d{2}[A-Z0-9]{10,30}'\n          ssn_us: '\\d{3}-\\d{2}-\\d{4}'\n\n      - type: \"schema_annotation\"\n        fields:\n          - path: \"*.email\"\n            type: EMAIL\n          - path: \"patient.medical_id\"\n            type: MEDICAL_ID\n          - path: \"user.ssn\"\n            type: SSN\n\n    anonymization:\n      method: \"uuid_replacement\"\n      uuid_prefix: \"pii_uuid_\"\n      store_mapping: true\n      mapping_encryption: true\n\n    access_control:\n      default_deny: true\n      allowed_roles:\n        - \"gdpr_officer\"\n        - \"compliance_admin\"\n      audit_all_reveals: true\n\n  # ========== RETENTION POLICIES ==========\n  retention:\n    default_days: 2555  # 7 Jahre DSGVO\n\n    overrides:\n      - resource_pattern: \"medical_records.*\"\n        retention_days: 3650  # 10 Jahre HIPAA\n        legal_basis: \"HIPAA_164_316\"\n\n      - resource_pattern: \"financial.*\"\n        retention_days: 3650  # 10 Jahre HGB\n        legal_basis: \"HGB_257\"\n\n      - resource_pattern: \"debug_logs.*\"\n        retention_days: 7\n        auto_purge: true\n\n    archive:\n      enabled: true\n      after_days: 365\n      storage: \"cold_storage\"\n      compression: \"zstd\"\n      encryption: true\n\n  # ========== SAGA LOG SIGNING ==========\n  saga_signing:\n    enabled: true\n    batch_size: 1000\n    batch_interval_minutes: 5\n    signature_algorithm: \"RSA-SHA256\"\n    pki_endpoint: \"https://localhost:8443/api/v1/sign\"\n    cert_service_id: \"themis-db\"\n    encrypt_then_sign: true   # Erzwingt: erst AES-256-GCM verschl\u00fcsseln, dann Ciphertext hash/sign\n    categories:\n      encrypt_before_sign: [\"SAGA\", \"AUDIT\"]\n\n    verification:\n      on_query: true  # Bei Audit-Anfragen automatisch verifizieren\n      periodic_check: true\n      check_interval_hours: 24\n\n  # ========== COMPLIANCE FRAMEWORKS ==========\n  compliance_frameworks:\n    gdpr:\n      enabled: true\n      data_protection_officer: \"dpo@example.com\"\n      article_30_register: \"/var/themis/gdpr_register.json\"\n      breach_notification_hours: 72\n\n    hipaa:\n      enabled: true\n      covered_entity: true\n      business_associate: false\n      security_officer: \"ciso@example.com\"\n\n    bsi_c5:\n      enabled: true\n      attestation_level: \"Type 2\"\n      audit_frequency_months: 12\n\n    soc2:\n      enabled: false\n\n  # ========== DE (VS) KLASSIFIZIERUNG ==========\n  vs_classification:\n    levels:\n      - name: \"offen\"\n        encryption_profile:\n          required: false\n          algorithm: \"AES-256-GCM\"\n          double_encrypt: false\n          hsm_only: false\n        logs:\n          encrypt_then_sign: false\n          redact: false\n        vector_policy: \"allow\"\n        export_policy: \"allow\"\n        cache_policy: { persistent: true, ttl_seconds: 86400 }\n\n      - name: \"vs-nfd\"\n        encryption_profile:\n          required: true\n          algorithm: \"AES-256-GCM\"\n          double_encrypt: false\n          hsm_only: false\n        logs:\n          encrypt_then_sign: true\n          lek_rotation: \"daily\"\n          redact: true\n        vector_policy: \"allow_metadata_only\"\n        export_policy: \"allow_with_approval\"\n        cache_policy: { persistent: false, ttl_seconds: 3600 }\n\n      - name: \"geheim\"\n        encryption_profile:\n          required: true\n          algorithm: \"AES-256-GCM\"\n          double_encrypt: true\n          hsm_only: true\n        logs:\n          encrypt_then_sign: true\n          lek_rotation: \"daily\"\n          redact: \"strict\"\n        vector_policy: \"restricted\"   # keine Klartext-Embeddings-Exporte\n        export_policy: \"approval_only\"\n        cache_policy: { persistent: false, ttl_seconds: 0 }\n\n      - name: \"streng-geheim\"\n        encryption_profile:\n          required: true\n          algorithm: \"AES-256-GCM\"\n          double_encrypt: true\n          hsm_only: true\n        logs:\n          encrypt_then_sign: true\n          lek_rotation: \"daily\"\n          redact: \"strict\"\n          minimal_plain_meta: [\"log_id\", \"category\", \"timestamp\"]\n        vector_policy: \"disable_ann\"\n        export_policy: \"forbidden\"\n        cache_policy: { persistent: false, ttl_seconds: 0 }\n\n  enforcement:\n    default_classification: \"vs-nfd\"\n    map_resources:\n      - resource_pattern: \"patients.*\"\n        classification: \"geheim\"\n      - resource_pattern: \"intelligence.*\"\n        classification: \"streng-geheim\"\n      - resource_pattern: \"public_docs.*\"\n        classification: \"offen\"\n    endpoint_switches:\n      headers:\n        classification: \"X-Classification\"   # offen|vs-nfd|geheim|streng-geheim\n        governance_mode: \"X-Governance-Mode\" # enforce|simulate\n        encrypt_logs: \"X-Encrypt-Logs\"       # on|off|auto\n        redaction_level: \"X-Redaction-Level\" # none|standard|strict\n      response_headers:\n        policy: \"X-Themis-Policy\"\n        integrity: \"X-Themis-Integrity\"\n</code></pre>"},{"location":"compliance_governance_strategy/#52-policy-validation-enforcement","title":"5.2 Policy Validation &amp; Enforcement","text":"<pre><code>// include/governance/policy_engine.h\nclass GovernancePolicyEngine {\npublic:\n    explicit GovernancePolicyEngine(const std::string&amp; config_path);\n\n    // Policy-Validierung\n    bool validateOperation(\n        const UserContext&amp; user,\n        const std::string&amp; resource,\n        const std::string&amp; action\n    );\n\n    // Data Classification\n    std::string getClassificationLevel(const std::string&amp; resource);\n\n    // Retention\n    int getRetentionDays(const std::string&amp; resource);\n    bool shouldArchive(const std::string&amp; resource, int age_days);\n    bool shouldPurge(const std::string&amp; resource, int age_days);\n\n    // PII\n    bool shouldDetectPII(const std::string&amp; resource);\n    bool shouldAutoAnonymize(const std::string&amp; resource);\n    std::vector&lt;std::string&gt; getAllowedPIIRoles();\n\n    // Audit\n    bool shouldAuditAccess(const std::string&amp; resource);\n    std::vector&lt;std::string&gt; getComplianceFrameworks();\n\n  // VS-Classification helpers\n  std::string resolveClassification(const std::string&amp; resource, const std::optional&lt;std::string&gt;&amp; header_cls);\n  EncryptionProfile getEncryptionProfile(const std::string&amp; classification);\n  LogRules getLogRules(const std::string&amp; classification);\n  VectorPolicy getVectorPolicy(const std::string&amp; classification);\n  bool isExportAllowed(const std::string&amp; classification, bool hasApproval);\n\nprivate:\n    json config_;\n    std::unordered_map&lt;std::string, json&gt; classification_cache_;\n};\n</code></pre> <p>Endpoint-Durchsetzung (Skizze):</p> <pre><code>auto hdr_cls = req.header(\"X-Classification\");\nauto cls = gpe.resolveClassification(resource, hdr_cls);\nauto enc = gpe.getEncryptionProfile(cls);\nauto logs = gpe.getLogRules(cls);\nauto vecp = gpe.getVectorPolicy(cls);\n\nif (vecp == VectorPolicy::DISABLE_ANN) {\n  return Status::PermissionDenied(\"ANN disabled for classification: \" + cls);\n}\n\napplyEncryptionProfile(entity, enc, user);\nauditLogger.logWithRules(user, resource, action, logs);\n</code></pre> <p>Verwendung im Query-Engine:</p> <pre><code>// src/query/query_executor.cpp\nStatus QueryExecutor::executeQuery(\n    const AQLQuery&amp; query,\n    const UserContext&amp; user,\n    QueryResult&amp; result\n) {\n    auto start = std::chrono::steady_clock::now();\n\n    // 1. Policy-Check\n    for (const auto&amp; collection : query.collections) {\n        if (!gpe_-&gt;validateOperation(user, collection, \"read\")) {\n            THEMIS_AUDIT_LOG(\"QUERY_DENIED\", {\n                {\"user\", user.id},\n                {\"collection\", collection},\n                {\"reason\", \"policy_violation\"}\n            });\n            return Status::PermissionDenied(\"Access to \" + collection + \" denied\");\n        }\n    }\n\n    // 2. PII-Detection aktivieren?\n    bool detect_pii = gpe_-&gt;shouldDetectPII(query.collections[0]);\n\n    // 3. Query ausf\u00fchren\n    auto status = executor_-&gt;execute(query, result);\n\n    // 4. PII-Anonymisierung (wenn konfiguriert)\n    if (detect_pii &amp;&amp; gpe_-&gt;shouldAutoAnonymize(query.collections[0])) {\n        anonymizePIIInResult(result, user);\n    }\n\n    // 5. Audit-Log\n    auto duration = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(\n        std::chrono::steady_clock::now() - start\n    );\n\n    if (gpe_-&gt;shouldAuditAccess(query.collections[0])) {\n        AuditLogger::logDataAccess(\n            user,\n            query.collections[0],\n            \"query\",\n            extractPIIFields(result),\n            duration.count()\n        );\n    }\n\n    return status;\n}\n</code></pre>"},{"location":"compliance_governance_strategy/#6-data-retention-archival","title":"6. Data Retention &amp; Archival","text":""},{"location":"compliance_governance_strategy/#61-retention-manager","title":"6.1 Retention Manager","text":"<pre><code>// include/governance/retention_manager.h\nclass RetentionManager {\npublic:\n    struct RetentionPolicy {\n        std::string resource_pattern;  // Regex: \"medical_records.*\"\n        int retention_days;\n        bool auto_archive;\n        int archive_after_days;\n        bool auto_purge;\n        std::string legal_basis;\n    };\n\n    explicit RetentionManager(\n        RocksDBWrapper&amp; db,\n        const GovernancePolicyEngine&amp; gpe\n    );\n\n    // Background-Task (t\u00e4glich ausgef\u00fchrt)\n    void runRetentionSweep();\n\n    // Manuelle Operationen\n    std::vector&lt;std::string&gt; findExpiredEntities(const std::string&amp; collection);\n    void archiveEntity(const std::string&amp; pk);\n    void purgeEntity(const std::string&amp; pk);\n\nprivate:\n    RocksDBWrapper&amp; db_;\n    const GovernancePolicyEngine&amp; gpe_;\n};\n</code></pre> <p>Workflow:</p> <pre><code>void RetentionManager::runRetentionSweep() {\n    THEMIS_INFO(\"Starting retention sweep\");\n\n    // Alle Collections durchlaufen\n    for (const auto&amp; collection : getAllCollections()) {\n        auto policy = gpe_.getRetentionPolicy(collection);\n\n        // Finde alte Entities (via created_at/modified_at)\n        auto expired = findExpiredEntities(collection);\n\n        for (const auto&amp; pk : expired) {\n            auto age_days = getEntityAgeDays(pk);\n\n            // Archivierung?\n            if (policy.auto_archive &amp;&amp; age_days &gt;= policy.archive_after_days) {\n                archiveEntity(pk);\n                THEMIS_AUDIT_LOG(\"ENTITY_ARCHIVED\", {\n                    {\"pk\", pk},\n                    {\"collection\", collection},\n                    {\"age_days\", age_days},\n                    {\"legal_basis\", policy.legal_basis}\n                });\n            }\n\n            // L\u00f6schung?\n            if (policy.auto_purge &amp;&amp; age_days &gt;= policy.retention_days) {\n                purgeEntity(pk);\n                THEMIS_AUDIT_LOG(\"ENTITY_PURGED\", {\n                    {\"pk\", pk},\n                    {\"collection\", collection},\n                    {\"age_days\", age_days},\n                    {\"legal_basis\", policy.legal_basis}\n                });\n            }\n        }\n    }\n\n    THEMIS_INFO(\"Retention sweep completed\");\n}\n</code></pre>"},{"location":"compliance_governance_strategy/#62-cold-storage-export","title":"6.2 Cold Storage Export","text":"<p>Archivierung zu externem Storage:</p> <pre><code>void RetentionManager::archiveEntity(const std::string&amp; pk) {\n    // 1. Lade vollst\u00e4ndige Entity-Daten\n    auto entity = loadFullEntity(pk);  // Mit Graph-Kanten, Content-Blobs, etc.\n\n    // 2. Serialize als JSON\n    json archive_entry = {\n        {\"pk\", pk},\n        {\"archived_at\", iso8601_now()},\n        {\"original_data\", entity},\n        {\"metadata\", {\n            {\"collection\", entity[\"_collection\"]},\n            {\"created_at\", entity[\"created_at\"]},\n            {\"data_classification\", gpe_.getClassificationLevel(pk)}\n        }}\n    };\n\n    // 3. Kompression (ZSTD)\n    auto json_str = archive_entry.dump();\n    auto compressed = zstd_compress(json_str.data(), json_str.size(), 19);\n\n    // 4. Verschl\u00fcsselung (optional, je nach Policy)\n    auto encrypted = encryptArchive(compressed);\n\n    // 5. Export zu Cold Storage\n    std::string archive_path = config_[\"cold_storage_path\"].get&lt;std::string&gt;() \n                             + \"/\" + getCurrentDatePath() \n                             + \"/\" + pk + \".zst.enc\";\n    writeToFile(archive_path, encrypted);\n\n    // 6. Markiere in DB als archived (nicht l\u00f6schen, nur Flag)\n    db_.put(pk + \":metadata\", json{{\"archived\", true}, {\"archive_path\", archive_path}}.dump());\n}\n</code></pre>"},{"location":"compliance_governance_strategy/#7-compliance-reports","title":"7. Compliance-Reports","text":""},{"location":"compliance_governance_strategy/#71-dsgvo-artikel-30-verarbeitungsverzeichnis","title":"7.1 DSGVO Artikel 30: Verarbeitungsverzeichnis","text":"<p>Automatische Generierung:</p> <pre><code>json generateGDPRArticle30Register() {\n    json reg = {\n        {\"controller\", {\n            {\"name\", \"VCC GmbH\"},\n            {\"contact\", \"dpo@example.com\"},\n            {\"address\", \"Musterstra\u00dfe 1, 12345 Berlin\"}\n        }},\n        {\"processing_activities\", json::array()}\n    };\n\n    // Alle Collections analysieren\n    for (const auto&amp; collection : getAllCollections()) {\n        auto classification = gpe_.getClassificationLevel(collection);\n        auto retention = gpe_.getRetentionDays(collection);\n\n        json activity = {\n            {\"purpose\", collection + \" data processing\"},\n            {\"legal_basis\", \"GDPR Article 6(1)(e)\"},  // Public interest\n            {\"data_categories\", getDataCategories(collection)},\n            {\"recipients\", \"Internal staff only\"},\n            {\"retention_period\", std::to_string(retention) + \" days\"},\n            {\"security_measures\", {\n                \"AES-256-GCM encryption\",\n                \"PKI-signed audit logs\",\n                \"Role-based access control\",\n                \"PII auto-anonymization\"\n            }},\n            {\"data_subjects\", \"EU citizens\"}\n        };\n\n        reg[\"processing_activities\"].push_back(activity);\n    }\n\n    return reg;\n}\n</code></pre> <p>Export:</p> <pre><code># HTTP Endpoint\nGET /api/compliance/gdpr/article30\n\n# CLI Tool\n$ themis-cli compliance gdpr-register --format json &gt; gdpr_register.json\n$ themis-cli compliance gdpr-register --format pdf &gt; gdpr_register.pdf\n</code></pre>"},{"location":"compliance_governance_strategy/#72-audit-trail-report","title":"7.2 Audit-Trail-Report","text":"<pre><code>json generateAuditReport(\n    const std::string&amp; start_date,\n    const std::string&amp; end_date,\n    const std::vector&lt;std::string&gt;&amp; categories\n) {\n    json report = {\n        {\"period\", {{\"start\", start_date}, {\"end\", end_date}}},\n        {\"categories\", categories},\n        {\"entries\", json::array()},\n        {\"summary\", {}}\n    };\n\n    // Lade SAGA-Logs aus Zeitraum\n    auto logs = loadSAGALogs(start_date, end_date, categories);\n\n    // Verifiziere Signaturen\n    int verified = 0, failed = 0;\n    for (const auto&amp; batch : getSAGABatches(start_date, end_date)) {\n        if (verifySAGABatch(batch.id)) {\n            verified++;\n        } else {\n            failed++;\n            report[\"integrity_violations\"].push_back({\n                {\"batch_id\", batch.id},\n                {\"signed_at\", batch.signed_at}\n            });\n        }\n    }\n\n    report[\"summary\"] = {\n        {\"total_entries\", logs.size()},\n        {\"verified_batches\", verified},\n        {\"failed_batches\", failed},\n        {\"pii_accesses\", countPIIAccesses(logs)},\n        {\"security_events\", countSecurityEvents(logs)}\n    };\n\n    report[\"entries\"] = logs;\n\n    return report;\n}\n</code></pre>"},{"location":"compliance_governance_strategy/#8-implementation-roadmap","title":"8. Implementation Roadmap","text":""},{"location":"compliance_governance_strategy/#phase-1-audit-logging-saga-signierung-woche-1-2","title":"Phase 1: Audit-Logging &amp; SAGA-Signierung (Woche 1-2)","text":"<p>Deliverables: - \u2705 <code>AuditLogger</code> Klasse mit spdlog JSON-Output - \u2705 SAGA-Log-Erweiterung mit Batch-Collection - \u2705 VCC-PKI Client f\u00fcr Signierung (<code>POST /api/v1/sign</code>) - \u2705 LEK (Log Encryption Key) Management mit t\u00e4glicher Rotation - \u2705 <code>verifySAGABatch()</code> Funktion f\u00fcr Signatur-Validierung</p> <p>Config:</p> <pre><code># config/governance.yaml (initial)\nsaga_log:\n  signature:\n    enabled: true\n    batch_size: 1000\n    batch_interval_minutes: 5\n  encryption:\n    enabled: true\n    key_rotation: daily\n</code></pre>"},{"location":"compliance_governance_strategy/#phase-2-pii-detection-anonymisierung-woche-3-4","title":"Phase 2: PII-Detection &amp; Anonymisierung (Woche 3-4)","text":"<p>Deliverables: - \u2705 <code>PIIDetector</code> Klasse mit Regex + Schema-Strategien - \u2705 UUID-Replacement-Logik in Entity-Import - \u2705 PII-Mapping-Storage in separater RocksDB CF - \u2705 <code>revealPII()</code> mit ACL-Check + Audit-Log - \u2705 <code>erasePII()</code> f\u00fcr DSGVO Artikel 17</p> <p>Config:</p> <pre><code>pii_detection:\n  enabled: true\n  strategies:\n    - type: regex\n    - type: schema_annotation\n  anonymization:\n    method: uuid_replacement\n</code></pre>"},{"location":"compliance_governance_strategy/#phase-3-governance-policy-engine-woche-5-6","title":"Phase 3: Governance Policy Engine (Woche 5-6)","text":"<p>Deliverables: - \u2705 <code>GovernancePolicyEngine</code> Klasse mit YAML-Parsing - \u2705 Data Classification API - \u2705 Policy-Validation in Query-Engine - \u2705 Retention-Policy-Integration - \u2705 Multi-Framework Support (GDPR, HIPAA, BSI C5)</p> <p>Config:</p> <pre><code>governance:\n  data_classification:\n    levels: [public, internal, confidential, restricted]\n  compliance_frameworks:\n    gdpr: {enabled: true}\n    hipaa: {enabled: true}\n</code></pre>"},{"location":"compliance_governance_strategy/#phase-4-retention-archival-woche-7-8","title":"Phase 4: Retention &amp; Archival (Woche 7-8)","text":"<p>Deliverables: - \u2705 <code>RetentionManager</code> Klasse - \u2705 Background-Task f\u00fcr Daily Sweep - \u2705 Cold-Storage-Export (ZSTD + Verschl\u00fcsselung) - \u2705 Archiv-Metadata in RocksDB - \u2705 Compliance-Reports (GDPR Artikel 30, Audit-Trails)</p> <p>Config:</p> <pre><code>retention:\n  default_days: 2555\n  archive:\n    enabled: true\n    storage: /mnt/archive/themis\n</code></pre>"},{"location":"compliance_governance_strategy/#phase-5-testing-compliance-validation-woche-9-10","title":"Phase 5: Testing &amp; Compliance Validation (Woche 9-10)","text":"<p>Tests: - \u2705 SAGA-Signatur-Roundtrip (Sign \u2192 Verify) - \u2705 PII-Detection f\u00fcr alle Typen (Email, Phone, SSN, etc.) - \u2705 Anonymisierung + Reveal + Erase Workflow - \u2705 Policy-Engine mit allen Klassifizierungen - \u2705 Retention-Sweep mit Archivierung - \u2705 GDPR Artikel 30 Register-Generierung - \u2705 Multi-User Audit-Trail (verschiedene Rollen)</p> <p>Performance: - Benchmark: SAGA-Signierung Overhead (&lt;5% bei Batch=1000) - Benchmark: PII-Detection Latenz (&lt;1ms pro Entity) - Load-Test: 1M Entities mit Retention-Sweep (&lt;10min)</p>"},{"location":"compliance_governance_strategy/#9-configuration-examples","title":"9. Configuration Examples","text":""},{"location":"compliance_governance_strategy/#91-produktions-konfiguration","title":"9.1 Produktions-Konfiguration","text":"<pre><code># config/governance.yaml (Production)\ngovernance:\n  version: \"1.0\"\n  environment: \"production\"\n\n  # Audit-Logging\n  audit:\n    enabled: true\n    categories:\n      - SAGA\n      - AUDIT\n      - SECURITY\n    sinks:\n      - type: file\n        path: /var/log/themis/audit.json\n      - type: syslog\n        host: siem.internal.vcc\n        port: 514\n        tls: true\n      - type: elasticsearch\n        url: https://elastic.internal.vcc:9200\n        index: themis-audit-{date}\n\n  # SAGA-Signierung\n  saga_signing:\n    enabled: true\n    batch_size: 1000\n    batch_interval_minutes: 5\n    signature_algorithm: RSA-SHA256\n    pki_endpoint: https://pki.internal.vcc:8443/api/v1/sign\n    cert_service_id: themis-db-prod\n    encrypt_then_sign: true\n    categories:\n      encrypt_before_sign: [SAGA, AUDIT]\n    verification:\n      on_query: true\n      periodic_check: true\n      check_interval_hours: 24\n\n  # Log-Verschl\u00fcsselung\n  log_encryption:\n    enabled: true\n    key_rotation: daily\n    algorithm: AES-256-GCM\n    key_storage: rocksdb\n    aad_fields: [log_id, category, timestamp]\n    encrypt_categories: [SAGA, AUDIT]\n\n  # PII-Erkennung\n  pii_detection:\n    enabled: true\n    strategies:\n      - type: regex\n        patterns_file: /etc/themis/pii_patterns.yaml\n      - type: schema_annotation\n        schema_file: /etc/themis/pii_schema.yaml\n    anonymization:\n      method: uuid_replacement\n      uuid_prefix: \"pii_\"\n      store_mapping: true\n      mapping_encryption: true\n    access_control:\n      default_deny: true\n      allowed_roles: [gdpr_officer, compliance_admin, legal]\n      audit_all_reveals: true\n\n  # Data Classification\n  data_classification:\n    levels:\n      - name: public\n        encryption_required: false\n        pii_detection: false\n        retention_days: 365\n      - name: internal\n        encryption_required: true\n        pii_detection: true\n        retention_days: 2555  # 7 Jahre\n        access_control: role_based\n      - name: confidential\n        encryption_required: true\n        pii_detection: true\n        retention_days: 3650  # 10 Jahre\n        access_control: attribute_based\n        audit_all_access: true\n      - name: restricted\n        encryption_required: true\n        encryption_algorithm: AES-256-GCM\n        pii_detection: true\n        pii_auto_anonymize: true\n        retention_days: 3650\n        access_control: multi_factor\n        audit_all_access: true\n        require_approval: true\n\n  # Retention\n  retention:\n    default_days: 2555\n    archive:\n      enabled: true\n      after_days: 365\n      storage: /mnt/cold_storage/themis\n      compression: zstd\n      encryption: true\n    policies:\n      - resource_pattern: \"medical_records.*\"\n        retention_days: 3650\n        legal_basis: HIPAA_164_316\n      - resource_pattern: \"financial.*\"\n        retention_days: 3650\n        legal_basis: HGB_257\n      - resource_pattern: \"debug_logs.*\"\n        retention_days: 7\n        auto_purge: true\n\n  # Compliance-Frameworks\n  compliance_frameworks:\n    gdpr:\n      enabled: true\n      data_protection_officer: dpo@vcc.internal\n      article_30_register: /var/themis/gdpr_register.json\n      breach_notification_hours: 72\n    hipaa:\n      enabled: true\n      covered_entity: true\n      security_officer: ciso@vcc.internal\n    bsi_c5:\n      enabled: true\n      attestation_level: Type 2\n      audit_frequency_months: 12\n</code></pre>"},{"location":"compliance_governance_strategy/#92-development-konfiguration","title":"9.2 Development-Konfiguration","text":"<pre><code># config/governance.dev.yaml\ngovernance:\n  version: \"1.0\"\n  environment: \"development\"\n\n  saga_signing:\n    enabled: false  # Schnelleres Testing\n\n  log_encryption:\n    enabled: false\n\n  pii_detection:\n    enabled: true\n    strategies:\n      - type: regex\n        patterns:\n          email: '\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n    anonymization:\n      method: uuid_replacement\n      store_mapping: true\n      mapping_encryption: false  # Dev: PII in Klartext f\u00fcr Debugging\n    access_control:\n      default_deny: false  # Dev: Offener Zugriff\n\n  retention:\n    default_days: 7  # Kurze Retention f\u00fcr Dev-DB\n    archive:\n      enabled: false\n\n  compliance_frameworks:\n    gdpr:\n      enabled: true\n    hipaa:\n      enabled: false\n</code></pre>"},{"location":"compliance_governance_strategy/#10-security-best-practices","title":"10. Security Best Practices","text":""},{"location":"compliance_governance_strategy/#101-least-privilege-fur-pii-zugriff","title":"10.1 Least Privilege f\u00fcr PII-Zugriff","text":"<pre><code># config/rbac_policies.yaml\nroles:\n  - name: analyst\n    permissions:\n      - resource: \"patients.*\"\n        actions: [read]\n        pii_reveal: false  # Sieht nur UUIDs\n\n  - name: doctor\n    permissions:\n      - resource: \"patients.*\"\n        actions: [read, write]\n        pii_reveal: true  # Kann PII entschl\u00fcsseln\n        pii_types: [EMAIL, PHONE, MEDICAL_ID]\n\n  - name: gdpr_officer\n    permissions:\n      - resource: \"*\"\n        actions: [read, write, delete]\n        pii_reveal: true\n        pii_erase: true  # Kann DSGVO-L\u00f6schung durchf\u00fchren\n\n  - name: compliance_admin\n    permissions:\n      - resource: \"*\"\n        actions: [read]\n        pii_reveal: true\n        audit_access: true\n        compliance_reports: true\n</code></pre>"},{"location":"compliance_governance_strategy/#102-signature-verification-bei-audit-anfragen","title":"10.2 Signature-Verification bei Audit-Anfragen","text":"<pre><code>// Automatische Verifizierung bei /api/audit/logs Anfragen\nGET /api/audit/logs?start=2025-10-01&amp;end=2025-10-31\n\nResponse:\n{\n  \"logs\": [...],\n  \"signature_verification\": {\n    \"total_batches\": 42,\n    \"verified\": 42,\n    \"failed\": 0,\n    \"integrity_status\": \"OK\"\n  }\n}\n</code></pre>"},{"location":"compliance_governance_strategy/#103-immutable-audit-logs-rocksdb-sst-sealing","title":"10.3 Immutable Audit-Logs (RocksDB SST-Sealing)","text":"<p>Optional: RocksDB SST-Files als Read-Only nach Signierung:</p> <pre><code>void sealSignedSAGABatch(const std::string&amp; batch_id) {\n    // 1. Force Flush to SST\n    db_.flush();\n\n    // 2. Hole SST-File-Pfad f\u00fcr Batch\n    auto sst_file = getSSTFileForBatch(batch_id);\n\n    // 3. Setze Read-Only (OS-Level)\n    chmod(sst_file.c_str(), 0444);  // r--r--r--\n\n    // 4. Optional: Kopiere zu WORM-Storage (Write-Once-Read-Many)\n    copyToWORMStorage(sst_file);\n}\n</code></pre>"},{"location":"compliance_governance_strategy/#11-compliance-verification-checklist","title":"11. Compliance Verification Checklist","text":""},{"location":"compliance_governance_strategy/#dsgvo-gdpr","title":"DSGVO (GDPR)","text":"Anforderung Artikel Implementierung Status Verschl\u00fcsselung at-rest Art. 32 AES-256-GCM \u2705 Audit-Trail Art. 30 PKI-signierte SAGA-Logs \u2705 Recht auf Vergessenwerden Art. 17 <code>erasePII()</code> mit UUID-L\u00f6schung \u2705 Datenminimierung Art. 5(1)(c) Auto-Anonymisierung \u2705 Privacy by Design Art. 25 PII-Detection bei Import \u2705 Meldepflicht Datenpanne Art. 33 Security-Event-Logging \u2705 Verarbeitungsverzeichnis Art. 30 Auto-Generierung <code>/compliance/gdpr/article30</code> \u2705"},{"location":"compliance_governance_strategy/#hipaa","title":"HIPAA","text":"Anforderung Section Implementierung Status Access Controls \u00a7164.312(a)(1) RBAC + ABAC \u2705 Audit Controls \u00a7164.312(b) Structured Audit-Logs \u2705 Integrity Controls \u00a7164.312(c)(1) PKI-Signaturen \u2705 Transmission Security \u00a7164.312(e)(1) TLS 1.3 + mTLS \u2705 Encryption at Rest \u00a7164.312(a)(2)(iv) AES-256-GCM \u2705 Log Retention \u00a7164.316(b)(2)(i) 10 Jahre f\u00fcr Medical Records \u2705"},{"location":"compliance_governance_strategy/#bsi-c5","title":"BSI C5","text":"Kontrolle Beschreibung Implementierung Status ORP-4 Datenschutzbeauftragter Config: <code>dpo@example.com</code> \u2705 OPS-11 Protokollierung Structured JSON-Logs \u2705 OPS-12 \u00dcberwachung SIEM-Export \u2705 IAM-01 Identit\u00e4tsmanagement VCC-User Integration \u2705 IAM-03 Zugriffsrechte RBAC + Policy Engine \u2705 CRY-01 Verschl\u00fcsselung AES-256-GCM \u2705 CRY-02 Schl\u00fcsselmanagement VCC-PKI Integration \u2705"},{"location":"compliance_governance_strategy/#12-next-steps","title":"12. Next Steps","text":""},{"location":"compliance_governance_strategy/#immediate-woche-1-2","title":"Immediate (Woche 1-2)","text":"<ol> <li>\u2705 SAGA-Log-Erweiterung mit Batch-Collection</li> <li>\u2705 VCC-PKI REST-Client f\u00fcr Signierung</li> <li>\u2705 LEK (Log Encryption Key) Rotation-Logik</li> <li>\u2705 <code>AuditLogger</code> mit spdlog JSON-Output</li> </ol>"},{"location":"compliance_governance_strategy/#short-term-woche-3-6","title":"Short-Term (Woche 3-6)","text":"<ol> <li>\u2705 <code>PIIDetector</code> mit Regex + Schema-Strategien</li> <li>\u2705 UUID-Replacement in Entity-Import</li> <li>\u2705 <code>GovernancePolicyEngine</code> mit YAML-Config</li> <li>\u2705 Policy-Validation in Query-Engine</li> </ol>"},{"location":"compliance_governance_strategy/#medium-term-woche-7-10","title":"Medium-Term (Woche 7-10)","text":"<ol> <li>\u2705 <code>RetentionManager</code> mit Background-Sweep</li> <li>\u2705 Cold-Storage-Export mit ZSTD + Encryption</li> <li>\u2705 Compliance-Report-Generierung (GDPR, HIPAA)</li> <li>\u2705 Integration-Tests f\u00fcr alle Compliance-Features</li> </ol>"},{"location":"compliance_governance_strategy/#long-term-woche-11","title":"Long-Term (Woche 11+)","text":"<ol> <li>\u274c NER (Named Entity Recognition) f\u00fcr ML-basierte PII-Detection</li> <li>\u274c Blockchain-Anchoring f\u00fcr SAGA-Signaturen (zus\u00e4tzliche Unver\u00e4nderlichkeit)</li> <li>\u274c GDPR-DSR-Workflow (Data Subject Request Automation)</li> <li>\u274c Compliance-Dashboard (Web-UI f\u00fcr DPO/CISO)</li> </ol>"},{"location":"compliance_governance_strategy/#zusammenfassung","title":"Zusammenfassung","text":"<p>Diese Strategie definiert eine umfassende Compliance &amp; Governance-Architektur f\u00fcr ThemisDB:</p> <ul> <li>\ud83d\udcdd PKI-signierte SAGA-Logs f\u00fcr unver\u00e4nderliche Audit-Trails</li> <li>\ud83d\udd10 DSGVO by Design mit automatischer PII-Erkennung und UUID-Anonymisierung</li> <li>\u2696\ufe0f Multi-Framework-Support (GDPR, HIPAA, BSI C5)</li> <li>\ud83c\udfaf Policy-Driven mit YAML/JSON-Konfiguration f\u00fcr alle Governance-Regeln</li> <li>\ud83d\udd12 Log-Verschl\u00fcsselung mit t\u00e4glicher LEK-Rotation</li> <li>\ud83d\udce6 Retention &amp; Archival mit Cold-Storage-Export</li> <li>\ud83d\udd0d Audit-Reports mit automatischer Signatur-Verifizierung</li> </ul> <p>Kerntechnologien: - VCC-PKI f\u00fcr Signierung &amp; Verschl\u00fcsselung - RocksDB f\u00fcr unver\u00e4nderliche Log-Storage - spdlog f\u00fcr Structured JSON-Logging - YAML/JSON f\u00fcr Policy-Konfiguration</p> <p>Die Implementierung erfolgt in 10 Wochen mit vollst\u00e4ndiger Integration in bestehende ThemisDB-Infrastruktur (Encryption, VCC-PKI, VCC-User).</p>"},{"location":"compliance_integration/","title":"Themis Compliance Integration Guide","text":""},{"location":"compliance_integration/#ubersicht","title":"\u00dcbersicht","text":"<p>Themis bietet eine vollst\u00e4ndige Compliance-Pipeline f\u00fcr DSGVO/eIDAS-konforme Datenverarbeitung:</p> <ol> <li>Data Governance: Klassifizierung nach VS-NfD/Geheim/Streng Geheim</li> <li>PII Detection: Automatische Erkennung personenbezogener Daten</li> <li>Audit Logging: Encrypt-then-Sign mit PKI</li> <li>Retention Management: Automatische Archivierung und L\u00f6schung</li> </ol>"},{"location":"compliance_integration/#1-data-governance","title":"1. Data Governance","text":""},{"location":"compliance_integration/#klassifizierungsstufen","title":"Klassifizierungsstufen","text":"Level Beschreibung Regeln <code>offen</code> \u00d6ffentliche Daten Keine Einschr\u00e4nkungen <code>vs-nfd</code> Verschlusssache - Nur f\u00fcr den Dienstgebrauch Verschl\u00fcsselung erforderlich <code>geheim</code> Geheime Daten Verschl\u00fcsselung + Zugriffskontrolle + kein ANN <code>streng_geheim</code> Streng geheim Maximale Sicherheit + Audit-Trail"},{"location":"compliance_integration/#http-header","title":"HTTP-Header","text":"<pre><code>X-Data-Classification: geheim\nX-Governance-Mode: enforce\n</code></pre>"},{"location":"compliance_integration/#governance-policies","title":"Governance-Policies","text":"<pre><code>{\n  \"classification\": \"geheim\",\n  \"encryption_required\": true,\n  \"retention_days\": 90,\n  \"allow_ann_indexing\": false,\n  \"require_audit\": true,\n  \"cache_policy\": \"no-cache\",\n  \"export_policy\": \"deny\"\n}\n</code></pre>"},{"location":"compliance_integration/#beispiel-klassifizierter-request","title":"Beispiel: Klassifizierter Request","text":"<pre><code>curl -X POST http://localhost:8765/entities \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-Data-Classification: vs-nfd\" \\\n  -H \"X-Governance-Mode: enforce\" \\\n  -d '{\n    \"object_type\": \"patient_record\",\n    \"name\": \"Max Mustermann\",\n    \"ssn\": \"123-45-6789\",\n    \"created_at\": 1730505600\n  }'\n</code></pre> <p>Response Headers:</p> <pre><code>X-Data-Classification: vs-nfd\nX-Encryption-Required: true\nX-Retention-Days: 365\nX-Allow-ANN: false\n</code></pre>"},{"location":"compliance_integration/#2-pii-detection","title":"2. PII Detection","text":""},{"location":"compliance_integration/#unterstutzte-pii-typen","title":"Unterst\u00fctzte PII-Typen","text":"Typ Beispiel Regex-Pattern <code>EMAIL</code> <code>user@example.com</code> RFC 5322 <code>PHONE</code> <code>+49 123 456789</code>, <code>(555) 123-4567</code> International + US <code>SSN</code> <code>123-45-6789</code> US Social Security <code>CREDIT_CARD</code> <code>4532-1234-5678-9010</code> Luhn-validiert <code>IBAN</code> <code>DE89370400440532013000</code> IBAN-Format <code>IP_ADDRESS</code> <code>192.168.1.1</code> IPv4 <code>URL</code> <code>https://example.com/path</code> HTTP(S) URLs"},{"location":"compliance_integration/#yaml-konfiguration","title":"YAML-Konfiguration","text":"<pre><code># config/pii_detection.yaml\nengines:\n  - name: regex_engine\n    type: regex\n    enabled: true\n    patterns:\n      - type: CREDIT_CARD\n        pattern: '\\b\\d{4}[- ]?\\d{4}[- ]?\\d{4}[- ]?\\d{4}\\b'\n        validate_luhn: true\n      - type: EMAIL\n        pattern: '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n</code></pre>"},{"location":"compliance_integration/#automatische-pii-erkennung","title":"Automatische PII-Erkennung","text":"<pre><code>#include \"utils/pii_detector.h\"\n\nvcc::PIIDetector detector(\"./config/pii_detection.yaml\");\n\nnlohmann::json data = {\n    {\"email\", \"john.doe@example.com\"},\n    {\"phone\", \"+49 30 12345678\"},\n    {\"ssn\", \"123-45-6789\"},\n    {\"credit_card\", \"4532123456789010\"}\n};\n\nauto findings = detector.detectInJson(data);\n\nfor (const auto&amp; finding : findings) {\n    std::cout &lt;&lt; \"Found \" &lt;&lt; finding.type \n              &lt;&lt; \" at \" &lt;&lt; finding.json_path \n              &lt;&lt; \": \" &lt;&lt; finding.value &lt;&lt; \"\\n\";\n\n    // Redact based on classification\n    auto redacted = detector.maskValue(finding.value, finding.type, \n                                       vcc::PIIDetector::RedactionMode::PARTIAL);\n    std::cout &lt;&lt; \"Redacted: \" &lt;&lt; redacted &lt;&lt; \"\\n\";\n}\n</code></pre> <p>Output:</p> <pre><code>Found EMAIL at $.email: john.doe@example.com\nRedacted: j***@example.com\nFound PHONE at $.phone: +49 30 12345678\nRedacted: +49 *** *** **78\nFound SSN at $.ssn: 123-45-6789\nRedacted: ***-**-6789\nFound CREDIT_CARD at $.credit_card: 4532123456789010\nRedacted: 4532-****-****-9010\n</code></pre>"},{"location":"compliance_integration/#field-hint-klassifizierung","title":"Field-Hint-Klassifizierung","text":"<pre><code>// Automatische Erkennung via Feldnamen\nauto hint = detector.classifyFieldName(\"user_email\");\n// hint = PIIType::EMAIL\n\nauto hint2 = detector.classifyFieldName(\"credit_card_number\");\n// hint2 = PIIType::CREDIT_CARD\n</code></pre>"},{"location":"compliance_integration/#3-audit-logging","title":"3. Audit Logging","text":""},{"location":"compliance_integration/#konfiguration","title":"Konfiguration","text":"<pre><code>#include \"utils/audit_logger.h\"\n#include \"utils/pki_client.h\"\n#include \"security/encryption.h\"\n\n// Setup\nauto key_provider = std::make_shared&lt;MockKeyProvider&gt;();\nkey_provider-&gt;createKey(\"audit_key\", 32);\n\nauto field_enc = std::make_shared&lt;FieldEncryption&gt;(key_provider);\n\nPKIConfig pki_cfg;\npki_cfg.service_id = \"themis-audit\";\npki_cfg.endpoint = \"https://pki.example.com\";\nauto pki_client = std::make_shared&lt;VCCPKIClient&gt;(pki_cfg);\n\nAuditLoggerConfig cfg;\ncfg.enabled = true;\ncfg.encrypt_then_sign = true;\ncfg.log_path = \"data/logs/audit.jsonl\";\ncfg.key_id = \"audit_key\";\n\nauto audit_logger = std::make_shared&lt;AuditLogger&gt;(field_enc, pki_client, cfg);\n</code></pre>"},{"location":"compliance_integration/#ereignis-loggen","title":"Ereignis loggen","text":"<pre><code>nlohmann::json event;\nevent[\"action\"] = \"DATA_ACCESS\";\nevent[\"user_id\"] = \"user_12345\";\nevent[\"resource\"] = \"/entities/patient_123\";\nevent[\"classification\"] = \"geheim\";\nevent[\"timestamp\"] = std::time(nullptr);\nevent[\"ip_address\"] = \"192.168.1.42\";\n\naudit_logger-&gt;logEvent(event);\n</code></pre>"},{"location":"compliance_integration/#audit-log-format-jsonl","title":"Audit-Log-Format (JSONL)","text":"<pre><code>{\"encrypted_data\":\"base64...\", \"signature\":\"base64...\", \"key_id\":\"audit_key\", \"algorithm\":\"RSA-SHA256\"}\n{\"encrypted_data\":\"base64...\", \"signature\":\"base64...\", \"key_id\":\"audit_key\", \"algorithm\":\"RSA-SHA256\"}\n</code></pre>"},{"location":"compliance_integration/#4-retention-management","title":"4. Retention Management","text":""},{"location":"compliance_integration/#policy-konfiguration","title":"Policy-Konfiguration","text":"<pre><code># config/retention_policies.yaml\npolicies:\n  - name: user_personal_data\n    retention_period: 365d\n    archive_after: 180d\n    auto_purge_enabled: true\n    require_audit_trail: true\n    classification_level: geheim\n    metadata:\n      legal_basis: \"DSGVO Art. 17\"\n\n  - name: transaction_logs\n    retention_period: 2555d  # 7 Jahre\n    archive_after: 1095d     # 3 Jahre\n    auto_purge_enabled: false\n    require_audit_trail: true\n    classification_level: vs-nfd\n    metadata:\n      legal_basis: \"HGB \u00a7257\"\n</code></pre>"},{"location":"compliance_integration/#server-konfiguration","title":"Server-Konfiguration","text":"<pre><code>// config/config.json\n{\n  \"features\": {\n    \"retention\": {\n      \"enabled\": true,\n      \"interval_hours\": 24,\n      \"policies_path\": \"./config/retention_policies.yaml\"\n    }\n  }\n}\n</code></pre>"},{"location":"compliance_integration/#automatischer-retention-check","title":"Automatischer Retention-Check","text":"<p>Der Server f\u00fchrt automatisch t\u00e4glich (konfigurierbar) Retention-Checks durch:</p> <pre><code>[INFO] Retention worker started (interval: 24h)\n[INFO] [Retention] Completed: scanned=1523, archived=42, purged=18, retained=1463, errors=0\n</code></pre>"},{"location":"compliance_integration/#manuelle-retention-prufung","title":"Manuelle Retention-Pr\u00fcfung","text":"<pre><code>#include \"utils/retention_manager.h\"\n\nRetentionManager mgr(\"./config/retention_policies.yaml\");\n\n// Pr\u00fcfe einzelne Entity\nauto created_at = std::chrono::system_clock::now() - std::chrono::hours(24 * 200);\n\nif (mgr.shouldArchive(\"entity_123\", created_at, \"user_personal_data\")) {\n    auto archive_handler = [](const std::string&amp; id) {\n        // Export to S3, Tape, etc.\n        return true;\n    };\n    mgr.archiveEntity(\"entity_123\", \"user_personal_data\", archive_handler);\n}\n\nif (mgr.shouldPurge(\"entity_456\", created_at, \"user_personal_data\")) {\n    auto purge_handler = [](const std::string&amp; id) {\n        // Delete from DB\n        return true;\n    };\n    mgr.purgeEntity(\"entity_456\", \"user_personal_data\", purge_handler);\n}\n</code></pre>"},{"location":"compliance_integration/#5-end-to-end-beispiel","title":"5. End-to-End-Beispiel","text":""},{"location":"compliance_integration/#szenario-dsgvo-konforme-patientendaten-verarbeitung","title":"Szenario: DSGVO-konforme Patientendaten-Verarbeitung","text":""},{"location":"compliance_integration/#1-daten-empfangen-klassifizieren","title":"1. Daten empfangen &amp; klassifizieren","text":"<pre><code>curl -X POST http://localhost:8765/entities \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-Data-Classification: geheim\" \\\n  -H \"X-Governance-Mode: enforce\" \\\n  -d '{\n    \"object_type\": \"patient\",\n    \"name\": \"Anna Schmidt\",\n    \"email\": \"anna.schmidt@example.de\",\n    \"ssn\": \"123-45-6789\",\n    \"credit_card\": \"4532123456789010\",\n    \"diagnosis\": \"Diabetes Typ 2\",\n    \"created_at\": 1730505600\n  }'\n</code></pre> <p>Governance-Response:</p> <pre><code>{\n  \"status\": \"ok\",\n  \"entity_id\": \"patient_789\",\n  \"governance\": {\n    \"classification\": \"geheim\",\n    \"encryption_required\": true,\n    \"retention_days\": 365,\n    \"allow_ann\": false,\n    \"audit_logged\": true\n  }\n}\n</code></pre>"},{"location":"compliance_integration/#2-pii-detection-im-hintergrund","title":"2. PII-Detection im Hintergrund","text":"<pre><code>// Server-seitig automatisch\nauto findings = pii_detector.detectInJson(request_body);\n// Findings: EMAIL, SSN, CREDIT_CARD\n\nfor (const auto&amp; finding : findings) {\n    nlohmann::json audit_pii;\n    audit_pii[\"action\"] = \"PII_DETECTED\";\n    audit_pii[\"type\"] = finding.type;\n    audit_pii[\"path\"] = finding.json_path;\n    audit_pii[\"entity_id\"] = \"patient_789\";\n    audit_logger-&gt;logEvent(audit_pii);\n}\n</code></pre>"},{"location":"compliance_integration/#3-verschlusselte-speicherung","title":"3. Verschl\u00fcsselte Speicherung","text":"<pre><code>// Sensitive Felder verschl\u00fcsseln\nEncryptedField&lt;std::string&gt; encrypted_ssn(key_provider, \"patient_key\");\nencrypted_ssn.encrypt(\"123-45-6789\");\n\nEncryptedField&lt;std::string&gt; encrypted_cc(key_provider, \"patient_key\");\nencrypted_cc.encrypt(\"4532123456789010\");\n\n// In DB speichern\nentity.setField(\"ssn_encrypted\", encrypted_ssn.toBase64());\nentity.setField(\"credit_card_encrypted\", encrypted_cc.toBase64());\n</code></pre>"},{"location":"compliance_integration/#4-audit-log-bei-zugriff","title":"4. Audit-Log bei Zugriff","text":"<pre><code>// Bei jedem Zugriff\nnlohmann::json access_event;\naccess_event[\"action\"] = \"DATA_ACCESS\";\naccess_event[\"user_id\"] = request.headers[\"X-User-ID\"];\naccess_event[\"entity_id\"] = \"patient_789\";\naccess_event[\"classification\"] = \"geheim\";\naccess_event[\"timestamp\"] = std::time(nullptr);\naccess_event[\"ip\"] = request.remote_addr;\n\naudit_logger-&gt;logEvent(access_event);\n</code></pre>"},{"location":"compliance_integration/#5-automatische-retention","title":"5. Automatische Retention","text":"<p>Nach 180 Tagen (archive_after):</p> <pre><code>[INFO] [Retention] Archive entity patient_789\n[INFO] Audit: {\"action\":\"RETENTION_ARCHIVE\",\"entity_id\":\"patient_789\"}\n</code></pre> <p>Nach 365 Tagen (retention_period):</p> <pre><code>[INFO] [Retention] Purge entity patient_789\n[INFO] Audit: {\"action\":\"RETENTION_PURGE\",\"entity_id\":\"patient_789\"}\n</code></pre>"},{"location":"compliance_integration/#6-compliance-checkliste","title":"6. Compliance-Checkliste","text":""},{"location":"compliance_integration/#dsgvo-art-5-17-25-32","title":"DSGVO (Art. 5, 17, 25, 32)","text":"<ul> <li>\u2705 Datenminimierung: PII-Detection hilft, nur n\u00f6tige Daten zu erheben</li> <li>\u2705 Speicherbegrenzung: Retention-Policies mit auto-purge</li> <li>\u2705 Recht auf Vergessenwerden: Purge-Handler l\u00f6scht Daten unwiderruflich</li> <li>\u2705 Privacy by Design: Verschl\u00fcsselung per Governance-Policy erzwungen</li> <li>\u2705 Sicherheit der Verarbeitung: AES-256-GCM + PKI-Signierung</li> <li>\u2705 Rechenschaftspflicht: Audit-Logs mit Zeitstempel + Integrit\u00e4t</li> </ul>"},{"location":"compliance_integration/#eidas-vertrauensdienste","title":"eIDAS (Vertrauensdienste)","text":"<ul> <li>\u2705 Signatur: PKI-Client f\u00fcr qualifizierte Signaturen</li> <li>\u2705 Zeitstempel: Audit-Events mit pr\u00e4ziser Zeiterfassung</li> <li>\u2705 Langzeitarchivierung: Archive-Handler f\u00fcr 7-10 Jahre Retention</li> <li>\u2705 Nachweisbarkeit: Encrypt-then-Sign f\u00fcr manipulationssichere Logs</li> </ul>"},{"location":"compliance_integration/#hgb-257-aufbewahrungsfristen","title":"HGB \u00a7257 (Aufbewahrungsfristen)","text":"<ul> <li>\u2705 Gesch\u00e4ftsbriefe: 6 Jahre (konfigurierbar via YAML)</li> <li>\u2705 Buchungsbelege: 10 Jahre (transaction_logs Policy)</li> <li>\u2705 Inventare: 10 Jahre (inventory Policy)</li> </ul>"},{"location":"compliance_integration/#7-monitoring-debugging","title":"7. Monitoring &amp; Debugging","text":""},{"location":"compliance_integration/#governance-metriken","title":"Governance-Metriken","text":"<pre><code>curl http://localhost:8765/metrics | grep governance\n</code></pre> <pre><code>themis_governance_requests_total{classification=\"geheim\"} 1523\nthemis_governance_encryption_enforced_total 892\nthemis_governance_ann_blocked_total 234\n</code></pre>"},{"location":"compliance_integration/#retention-statistiken","title":"Retention-Statistiken","text":"<pre><code>auto stats = retention_mgr.getPolicyStats(\"user_personal_data\");\nstd::cout &lt;&lt; \"Archived: \" &lt;&lt; stats.archived_count &lt;&lt; \"\\n\";\nstd::cout &lt;&lt; \"Purged: \" &lt;&lt; stats.purged_count &lt;&lt; \"\\n\";\nstd::cout &lt;&lt; \"Retained: \" &lt;&lt; stats.retained_count &lt;&lt; \"\\n\";\n</code></pre>"},{"location":"compliance_integration/#audit-log-analyse","title":"Audit-Log-Analyse","text":"<pre><code># Anzahl PII-Detections\ngrep \"PII_DETECTED\" data/logs/audit.jsonl | wc -l\n\n# Retention-Aktionen\ngrep \"RETENTION_\" data/logs/retention_audit.jsonl | jq '.action' | sort | uniq -c\n</code></pre>"},{"location":"compliance_integration/#8-best-practices","title":"8. Best Practices","text":""},{"location":"compliance_integration/#1-klassifizierung-fruh-festlegen","title":"1. Klassifizierung fr\u00fch festlegen","text":"<pre><code>// Bei Entity-Erstellung\nentity.setField(\"_classification\", \"geheim\");\nentity.setField(\"_created_at\", std::time(nullptr));\n</code></pre>"},{"location":"compliance_integration/#2-pii-detection-in-cicd","title":"2. PII-Detection in CI/CD","text":"<pre><code># Pre-commit Hook\n./bin/pii_scan --config=pii_detection.yaml --input=dump.json\n</code></pre>"},{"location":"compliance_integration/#3-retention-tests","title":"3. Retention-Tests","text":"<pre><code>// Unit-Test f\u00fcr Policy-Compliance\nTEST(RetentionTest, GDPR_Article17_RightToErasure) {\n    RetentionManager mgr;\n    auto policy = mgr.getPolicy(\"user_personal_data\");\n    ASSERT_TRUE(policy-&gt;auto_purge_enabled);\n    ASSERT_EQ(policy-&gt;retention_period, std::chrono::hours(24 * 365));\n}\n</code></pre>"},{"location":"compliance_integration/#4-audit-log-rotation","title":"4. Audit-Log-Rotation","text":"<pre><code># Logrotate-Config\n/var/log/themis/audit.jsonl {\n    daily\n    rotate 365\n    compress\n    delaycompress\n    notifempty\n    create 0640 themis themis\n}\n</code></pre>"},{"location":"compliance_integration/#9-troubleshooting","title":"9. Troubleshooting","text":""},{"location":"compliance_integration/#pii-nicht-erkannt","title":"PII nicht erkannt","text":"<p>Problem: Kreditkarte <code>4532-1234-5678-9010</code> wird nicht erkannt</p> <p>L\u00f6sung: Luhn-Validierung pr\u00fcfen</p> <pre><code>auto is_valid = vcc::validateLuhn(\"4532123456789010\"); // true\nauto is_invalid = vcc::validateLuhn(\"1234123412341234\"); // false\n</code></pre>"},{"location":"compliance_integration/#retention-lauft-nicht","title":"Retention l\u00e4uft nicht","text":"<p>Problem: Keine Retention-Logs im Server</p> <p>L\u00f6sung: Config pr\u00fcfen</p> <pre><code>{\n  \"features\": {\n    \"retention\": {\n      \"enabled\": true  // &lt;- muss true sein\n    }\n  }\n}\n</code></pre>"},{"location":"compliance_integration/#audit-log-verschlusselt-nicht","title":"Audit-Log verschl\u00fcsselt nicht","text":"<p>Problem: Plaintext in audit.jsonl</p> <p>L\u00f6sung: encrypt_then_sign aktivieren</p> <pre><code>AuditLoggerConfig cfg;\ncfg.encrypt_then_sign = true; // &lt;- wichtig!\ncfg.enabled = true;\n</code></pre>"},{"location":"compliance_integration/#10-weiterfuhrende-ressourcen","title":"10. Weiterf\u00fchrende Ressourcen","text":"<ul> <li>DSGVO-Volltext</li> <li>eIDAS-Verordnung</li> <li>BSI IT-Grundschutz</li> <li>HGB Aufbewahrungsfristen</li> </ul> <p>Version: 0.1.0 Letztes Update: 1. November 2025 Maintainer: Themis Compliance Team</p>"},{"location":"compression_benchmarks/","title":"Kompressionsvalidierung und Benchmarks","text":"<p>Datum: 27. Oktober 2025 System: Windows 11, MSVC 19.44, 20 CPU cores @ 3.7 GHz</p>"},{"location":"compression_benchmarks/#validierung","title":"Validierung","text":"<p>Die Kompression wurde zur Laufzeit verifiziert: - none: <code>default=none, bottommost=none</code> - lz4: <code>default=lz4, bottommost=lz4</code> - zstd: <code>default=zstd, bottommost=zstd</code></p> <p>RocksDB nutzt die in vcpkg.json aktivierten Features (<code>lz4</code>, <code>zstd</code>) korrekt.</p>"},{"location":"compression_benchmarks/#benchmark-ergebnisse","title":"Benchmark-Ergebnisse","text":""},{"location":"compression_benchmarks/#sequential-write-1000-keys-per-iteration","title":"Sequential Write (1000 keys per iteration)","text":"Compression Blob Size Time/Iter Throughput (MB/s) Items/s none 512B 23.6 ms 22.7 MB/s 46.4k lz4 512B 22.0 ms 24.1 MB/s 49.3k zstd 512B 21.9 ms 25.6 MB/s 52.5k none 4KB 29.7 ms 147.7 MB/s 37.8k lz4 4KB 31.2 ms 141.0 MB/s 36.1k zstd 4KB 31.6 ms 148.6 MB/s 38.1k none 16KB 49.8 ms 348.8 MB/s 22.3k lz4 16KB 54.1 ms 289.5 MB/s 18.5k zstd 16KB 53.4 ms 294.1 MB/s 18.8k"},{"location":"compression_benchmarks/#random-read-warm-cache-1000-pre-populated-keys","title":"Random Read (warm cache, 1000 pre-populated keys)","text":"Compression Blob Size Latency (\u00b5s) Items/s none 4KB 2.32 434k lz4 4KB 2.63 383k zstd 4KB 2.61 412k"},{"location":"compression_benchmarks/#interpretation","title":"Interpretation","text":""},{"location":"compression_benchmarks/#write-performance","title":"Write Performance","text":"<ul> <li> <p>Kleine Blobs (512B):   ZSTD und LZ4 schneller als <code>none</code> (~7-13% Verbesserung). Die Kompression reduziert I/O und Write Amplification st\u00e4rker als die CPU-Kosten wiegen.</p> </li> <li> <p>Mittlere Blobs (4KB):   Alle drei Varianten \u00e4hnlich (~147 MB/s). ZSTD minimal schneller bei hoher Kompressibilit\u00e4t.</p> </li> <li> <p>Gro\u00dfe Blobs (16KB): <code>none</code> deutlich schneller (+20% gegen\u00fcber LZ4/ZSTD). CPU-Kosten f\u00fcr Kompression \u00fcberwiegen I/O-Einsparungen bei gro\u00dfen Payloads.</p> </li> </ul>"},{"location":"compression_benchmarks/#read-performance","title":"Read Performance","text":"<ul> <li>LZ4 und ZSTD f\u00fcgen ~14% Latenz hinzu (Dekompressions-Overhead).</li> <li>Bei Cache-Hits (reiner memcpy) ist <code>none</code> am schnellsten.</li> <li>Im realen Betrieb mit Disk-I/O kann Kompression durch geringere Datenmengen schneller sein.</li> </ul>"},{"location":"compression_benchmarks/#empfehlungen","title":"Empfehlungen","text":"<ol> <li> <p>F\u00fcr hohen Write-Throughput mit kleineren Entities (&lt; 1KB):    \u2192 ZSTD (default) oder LZ4 (bottommost) nutzen</p> </li> <li> <p>F\u00fcr gro\u00dfe BLOBs (&gt; 8KB) oder read-heavy Workloads:    \u2192 LZ4 f\u00fcr Reads mit weniger Latenz; oder none f\u00fcr maximalen Read-Durchsatz</p> </li> <li> <p>Hybrid-Konfiguration (empfohlen): <code>json    \"compression\": {      \"default\": \"lz4\",      \"bottommost\": \"zstd\"    }</code>    Frische Daten (L0) mit LZ4 schnell komprimiert; \u00e4ltere Levels (bottommost) mit ZSTD platzsparend.</p> </li> </ol>"},{"location":"compression_benchmarks/#write-amplification","title":"Write Amplification","text":"<p>Ohne direkte Messung l\u00e4sst sich aus den Benchmarks ableiten: - Kompression reduziert SSTable-Gr\u00f6\u00dfe \u2192 weniger Compaction-Aufwand - Bei kompressiblen JSON-Daten (Faktor ~3-5x) f\u00fchrt Kompression zu niedrigerer Write Amplification</p> <p>F\u00fcr genaue Werte: RocksDB-Property <code>rocksdb.total-sst-files-size</code> vor/nach Schreibvorg\u00e4ngen pr\u00fcfen.</p>"},{"location":"compression_benchmarks/#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ul> <li>[ ] Write Amplification mit RocksDB <code>GetProperty(\"rocksdb.total-sst-files-size\")</code> messen</li> <li>[ ] Disk-I/O Benchmarks (cold cache) mit verschiedenen Kompressionen</li> <li>[ ] Speicherplatzvergleich nach 10k/100k Entities</li> </ul>"},{"location":"compression_strategy/","title":"Komprimierungsstrategie f\u00fcr ThemisDB","text":""},{"location":"compression_strategy/#executive-summary","title":"Executive Summary","text":"<p>Aktueller Stand: - \u2705 RocksDB Block-Kompression: LZ4 (Level 0-5) + ZSTD (Level 6+) IMPLEMENTIERT - \u2705 Gorilla Time-Series Codec: IMPLEMENTIERT (Roundtrip-Fix f\u00fcr Windows/MSVC) - \ud83d\udfe1 Vector-Quantisierung (SQ8): IMPLEMENTIERT (auto ab 1M) - \u2705 Gorilla-Integration in TSStore: IMPLEMENTIERT - \u2705 Content-Blob-Kompression (ZSTD): IMPLEMENTIERT</p> <p>Komprimierungs-Potenziale mit Geschwindigkeitseinbu\u00dfen:</p> Datentyp Aktuell Vorschlag Ratio CPU-Overhead Speed-Impact Priorit\u00e4t Time-Series Keine Gorilla 10-20x +15% -5% read/write \ud83d\udd34 HOCH Vektoren (Embeddings) Keine Scalar Quantization (int8) 4x +20% -10% search \ud83d\udfe1 MITTEL Vektoren (Embeddings) Keine Product Quantization (PQ) 8-32x +50% -25% search \ud83d\udfe2 NIEDRIG (nur &gt;100M Vektoren) Content-Blobs (Dokumente) RocksDB LZ4/ZSTD Separates ZSTD (Level 19) 1.5-2x +30% -15% upload \ud83d\udfe1 MITTEL JSON Metadata RocksDB LZ4 RocksDB LZ4 (optimal) \u2014 \u2014 \u2014 \u2705 OPTIMAL Graph-Kanten RocksDB LZ4 RocksDB LZ4 (optimal) \u2014 \u2014 \u2014 \u2705 OPTIMAL"},{"location":"compression_strategy/#1-time-series-gorilla-compression-hohe-prioritat","title":"1. Time-Series: Gorilla Compression \u26a1 HOHE PRIORIT\u00c4T","text":""},{"location":"compression_strategy/#status-quo","title":"Status Quo","text":"<ul> <li>Gorilla Codec: Vollst\u00e4ndig implementiert (<code>include/timeseries/gorilla.h</code>, Roundtrip-Tests bestehen)</li> <li>TSStore: Gorilla-Integration aktiv (Chunk-basiert, dual-scan raw+compressed)</li> </ul>"},{"location":"compression_strategy/#benchmark-daten-industrie","title":"Benchmark-Daten (Industrie)","text":"<ul> <li>Ratio: 10-20x f\u00fcr typische Metriken (CPU, Memory, Temperatur)</li> <li>CPU-Overhead: +10-15% Encode, +5% Decode</li> <li>Latenz: +2ms/10k Punkte (encode), +1ms/10k Punkte (decode)</li> </ul>"},{"location":"compression_strategy/#implementierungsvorschlag","title":"Implementierungsvorschlag","text":"<pre><code>// In TSStore::put()\nif (config.compression == \"gorilla\") {\n    std::vector&lt;uint8_t&gt; compressed = GorillaCodec::encode(timestamps, values);\n    db_.put(key, compressed); // Statt raw float64-Array\n}\n\n// In TSStore::query()\nif (header.compression == \"gorilla\") {\n    auto [ts, vals] = GorillaCodec::decode(blob);\n    return vals;\n}\n</code></pre>"},{"location":"compression_strategy/#konfiguration","title":"Konfiguration","text":"<pre><code>{\n  \"timeseries\": {\n    \"compression\": \"gorilla\",        // \"none\", \"gorilla\", \"zstd\"\n    \"chunk_size_hours\": 24           // 24h-Chunks optimal f\u00fcr Gorilla\n  }\n}\n</code></pre>"},{"location":"compression_strategy/#trade-offs","title":"Trade-offs","text":"<ul> <li>\u2705 Speicherersparnis: 10-20x (100GB \u2192 5-10GB)</li> <li>\u2705 I/O-Reduktion: Weniger Disk-IOPS \u2192 schnellere Aggregationen</li> <li>\u26a0\ufe0f CPU-Kosten: +15% bei Ingestion, +5% bei Queries</li> <li>\u26a0\ufe0f Latenz: +1-2ms/Query (akzeptabel f\u00fcr Time-Series-Workloads)</li> </ul> <p>Empfehlung: \u2705 IMPLEMENTIEREN \u2014 Time-Series-Workloads sind I/O-bound, nicht CPU-bound. Gorilla zahlt sich aus!</p>"},{"location":"compression_strategy/#2-vektoren-quantisierung-embeddings","title":"2. Vektoren: Quantisierung (Embeddings)","text":""},{"location":"compression_strategy/#status-quo_1","title":"Status Quo","text":"<ul> <li>Storage: Float32-Vektoren in BaseEntity; ab Schwellwert auto-quantisiert (SQ8) beim Persistieren</li> <li>Compression: SQ8 mit per-Vektor-Scale auf Disk; In-Memory-Cache bleibt float32 f\u00fcr Suche</li> <li>HNSWlib: Unver\u00e4ndert; Vektoren werden beim Laden dequantisiert</li> </ul>"},{"location":"compression_strategy/#best-practice-scalar-quantization-int8","title":"Best-Practice: Scalar Quantization (int8)","text":"<p>Was ist das? - Konvertiere <code>float32 \u2192 int8</code> via Min-Max-Skalierung oder Learned Quantization - Ratio: 4x Speicherersparnis (32 Bit \u2192 8 Bit) - Genauigkeit: 95-98% Recall@10 (je nach Datenverteilung)</p> <p>FAISS-Benchmark (768-dim Embeddings, 1M Vektoren):</p> <pre><code>Index Type          Memory (GB)    Search (ms/query)    Recall@10\n------------------------------------------------------------------\nFlat (float32)           3.0             45                100%\nSQ8 (int8)               0.75            38                 97%\nPQ16 (16 Codes)          0.1             12                 92%\n</code></pre> <p>HNSWlib-Integration: - HNSWlib unterst\u00fctzt KEINE native Quantisierung - Manuelle Implementierung n\u00f6tig:   1. Quantisiere Vektoren vor <code>addPoint()</code>   2. Speichere Quantisierungsparameter (min/max, codebook)   3. Quantisiere Queryvektoren vor <code>searchKnn()</code></p> <p>CPU-Overhead: - Encode: +20% (quantize on insert) - Decode: +10% (dequantize on search) - Search: -10% schneller (weniger Speicher \u2192 bessere Cache-Nutzung)</p> <p>Implementierungs-Aufwand: \ud83d\udd34 HOCH (~3-5 Tage, komplexe API-\u00c4nderungen)</p>"},{"location":"compression_strategy/#best-practice-product-quantization-pq","title":"Best-Practice: Product Quantization (PQ)","text":"<p>Was ist das? - Teile Vektor in Subvektoren (z.B. 768-dim \u2192 16x48-dim) - Clustere jeden Subvektor (k-means mit 256 Clustern) - Speichere nur Cluster-IDs (16 Bytes statt 3072 Bytes) - Ratio: 8-32x Speicherersparnis</p> <p>Wann sinnvoll? - \u274c NICHT f\u00fcr Themis: PQ lohnt sich erst ab &gt;10M Vektoren - \u2705 Nur f\u00fcr Hyperscaler: Google, Meta, Pinecone nutzen PQ - \u26a0\ufe0f Recall-Verlust: 85-95% Recall@10 (schlechter als SQ8)</p> <p>Empfehlung: \ud83d\udeab SKIP \u2014 Zu komplex f\u00fcr Themis, nur f\u00fcr &gt;10M Vektoren relevant</p>"},{"location":"compression_strategy/#vector-compression-empfehlung","title":"Vector Compression: Empfehlung","text":"Vektoranzahl Empfehlung Ratio Recall Aufwand &lt; 100k Keine Quantisierung 1x 100% \u2014 100k - 1M Scalar Quantization (int8) 4x 97% \ud83d\udfe1 Mittel &gt; 1M Product Quantization (PQ) 8-32x 92% \ud83d\udd34 Hoch <p>Aktuelle Themis-Empfehlung:  - \u2705 Default: Auto-SQ8 ab 1M Vektoren (konfigurierbar via <code>config:vector</code> \u2192 <code>{ \"quantization\": \"auto|none|sq8\", \"auto_threshold\": 1000000 }</code>) - \u2705 F\u00fcr &lt;1M: Float32 (kein Qualit\u00e4tsverlust, minimaler CPU-Overhead)</p>"},{"location":"compression_strategy/#3-content-blobs-dedizierte-kompression","title":"3. Content-Blobs: Dedizierte Kompression","text":""},{"location":"compression_strategy/#status-quo_2","title":"Status Quo","text":"<ul> <li>Storage: RocksDB BlobDB mit <code>blob_size_threshold = 4096</code> (&gt;4KB \u2192 Blob-Datei)</li> <li>Compression: RocksDB Block-Kompression (LZ4/ZSTD) auf gesamten LSM-Tree</li> <li>Problem: BlobDB-Dateien werden NICHT komprimiert (RocksDB Bug/Limitation)</li> </ul>"},{"location":"compression_strategy/#implementiert-explizite-zstd-kompression-vor-blobdb","title":"Implementiert: Explizite ZSTD-Kompression vor BlobDB","text":"<pre><code>// In ContentManager::importContent()\nif (blob.size() &gt; 4096 &amp;&amp; config.compress_blobs) {\n    std::vector&lt;uint8_t&gt; compressed = zstd_compress(blob, level=19); // Max-Ratio\n    std::string bkey = \"content_blob:\" + meta.id;\n    storage_-&gt;put(bkey, compressed);\n    meta.compressed = true;\n    meta.compression_type = \"zstd\";\n}\n</code></pre>"},{"location":"compression_strategy/#trade-offs_1","title":"Trade-offs","text":"Dokumenttyp Ratio (ZSTD Level 19) Encode (MB/s) Decode (MB/s) CPU-Overhead PDF 3-5x 20 150 +30% write DOCX 1.2x (schon ZIP) 50 200 +10% write TXT 4-8x 30 180 +25% write JSON 5-10x 25 160 +30% write Images (JPEG/PNG) 1.0x (schon komprimiert) \u2014 \u2014 \u2014 <p>Wann komprimieren?</p> <pre><code>bool should_compress_blob(const std::string&amp; mime_type, size_t size) {\n    // Skip f\u00fcr bereits komprimierte Formate\n    if (mime_type.find(\"image/\") == 0) return false; // JPEG, PNG, WebP\n    if (mime_type.find(\"video/\") == 0) return false; // MP4, WebM\n    if (mime_type == \"application/zip\") return false;\n    if (mime_type == \"application/gzip\") return false;\n\n    // Komprimiere Text/JSON/XML/PDF\n    if (size &gt; 4096) return true; // Nur &gt;4KB\n    return false;\n}\n</code></pre>"},{"location":"compression_strategy/#benchmark-szenario","title":"Benchmark-Szenario","text":"<p>10.000 PDF-Dokumente \u00e0 500KB (5GB total):</p> <pre><code>Storage Method          Disk Size    Write (MB/s)    Read (MB/s)\n-----------------------------------------------------------------\nRocksDB LZ4 (Block)          3.5 GB         120            250\nRocksDB ZSTD (Block)         2.8 GB         100            220\nZSTD Level 19 (Blob)         1.5 GB          50            180\n</code></pre> <p>Status / Empfehlung:  - \u2705 IMPLEMENTIERT (ContentManager komprimiert ZSTD wenn <code>config:content.compress_blobs=true</code> und <code>size&gt;4KB</code>, MIME-Filter m\u00f6glich) - \u2699\ufe0f Config-Keys in DB: <code>config:content</code> \u2192 <code>{ \"compress_blobs\": true, \"compression_level\": 19, \"skip_compressed_mimes\": [\"image/\", \"video/\", \"application/zip\", \"application/gzip\"] }</code> - \u26a0\ufe0f Skip f\u00fcr Images/Videos (schon komprimiert)</p>"},{"location":"compression_strategy/#4-json-metadata-optimal-keine-anderung-notig","title":"4. JSON Metadata: Optimal (keine \u00c4nderung n\u00f6tig)","text":""},{"location":"compression_strategy/#status-quo_3","title":"Status Quo","text":"<ul> <li>ContentMeta, ChunkMeta, BaseEntity: Gespeichert als JSON-Strings in RocksDB</li> <li>Compression: RocksDB Block-Kompression (LZ4) \u2192 optimal f\u00fcr JSON</li> </ul>"},{"location":"compression_strategy/#benchmark","title":"Benchmark","text":"<p>10.000 ContentMeta-Objekte \u00e0 2KB (20MB total):</p> <pre><code>Compression         Disk Size    Ratio    CPU-Overhead\n-------------------------------------------------------\nNone                  20 MB       1.0x         \u2014\nLZ4                    8 MB       2.5x        +5%\nZSTD                   6 MB       3.3x       +15%\n</code></pre> <p>Empfehlung: \u2705 KEINE \u00c4NDERUNG \u2014 RocksDB LZ4 ist optimal f\u00fcr JSON-Metadaten</p>"},{"location":"compression_strategy/#5-graph-kanten-optimal-keine-anderung-notig","title":"5. Graph-Kanten: Optimal (keine \u00c4nderung n\u00f6tig)","text":""},{"location":"compression_strategy/#status-quo_4","title":"Status Quo","text":"<ul> <li>Graph-Edges: BaseEntity mit <code>from</code>, <code>to</code>, <code>label</code>, <code>weight</code>, <code>properties</code></li> <li>Storage: RocksDB mit Key-Prefix <code>graph:edge:</code></li> <li>Compression: RocksDB LZ4 (Block-Kompression)</li> </ul>"},{"location":"compression_strategy/#benchmark_1","title":"Benchmark","text":"<p>100.000 Kanten \u00e0 500 Bytes (50MB total):</p> <pre><code>Compression         Disk Size    Ratio    CPU-Overhead\n-------------------------------------------------------\nNone                  50 MB       1.0x         \u2014\nLZ4                   22 MB       2.3x        +5%\nZSTD                  18 MB       2.8x       +12%\n</code></pre> <p>Empfehlung: \u2705 KEINE \u00c4NDERUNG \u2014 RocksDB LZ4 ist optimal f\u00fcr Graph-Daten</p>"},{"location":"compression_strategy/#implementierungsplan-priorisiert","title":"Implementierungsplan (Priorisiert)","text":""},{"location":"compression_strategy/#phase-1-time-series-gorilla-high-priority-done","title":"Phase 1: Time-Series Gorilla (HIGH PRIORITY) \ud83d\udd34 \u2705 DONE","text":"<p>Aufwand: ~1-2 Tage Impact: 10-20x Speicherersparnis, +15% CPU Tasks: 1. \u2705 Gorilla Codec implementiert + getestet 2. \u2705 TSStore Integration (Config, Header, Encode/Decode) 3. \u274c HTTP-Endpoint <code>/timeseries/compression/config</code> (GET/PUT) \u2014 optional 4. \u2705 Benchmarks (compression_ratio, encode_time, decode_time)</p> <p>Status: Integration abgeschlossen; l\u00e4uft defaultm\u00e4\u00dfig (Gorilla-Chunk-basiert) in <code>TSStore</code>.</p>"},{"location":"compression_strategy/#phase-2-content-blob-zstd-medium-priority-done","title":"Phase 2: Content-Blob ZSTD (MEDIUM PRIORITY) \ud83d\udfe1 \u2705 DONE","text":"<p>Aufwand: ~1 Tag Impact: 1.5-2x Speicherersparnis f\u00fcr Text-Dokumente, +30% CPU Tasks: 1. \u2705 ZSTD-Wrapper (<code>utils/zstd_codec.h</code> / <code>.cpp</code>) 2. \u2705 ContentManager-Integration (Pre-compress vor Speicherung) 3. \u2705 MIME-Type-Filter (skip Images/Videos) 4. \u2705 Config-Option <code>config:content.compress_blobs</code>, <code>compression_level</code>, <code>skip_compressed_mimes</code> 5. \u2705 Tests (roundtrip, verschiedene Dokumenttypen) \u2014 Manuelle Pr\u00fcfung</p> <p>Status: ZSTD-Kompression integriert in <code>ContentManager::importContent()</code>; Transparente Dekompression in <code>getContentBlob()</code>.</p>"},{"location":"compression_strategy/#phase-3-vector-scalar-quantization-low-priority-done","title":"Phase 3: Vector Scalar Quantization (LOW PRIORITY) \ud83d\udfe2 \u2705 DONE","text":"<p>Aufwand: ~3-5 Tage Impact: ~4x Speicherersparnis (Disk), -3% Search-Qualit\u00e4t (estimated) Condition: Automatisch aktiviert ab 1M Vektoren; konfigurierbar via DB-Key <code>config:vector</code> Tasks: 1. \u2705 Quantizer-Logik (Per-Vektor Symmetric Quant int8) 2. \u2705 VectorIndexManager-Integration (quantize on persist) 3. \u2705 Dequantisierung in <code>rebuildFromStorage</code> und <code>bruteForceSearch_</code> f\u00fcr on-demand loads 4. \u274c Benchmarks (recall@k, speed, memory) \u2014 Future work</p> <p>Status: SQ8 implementiert in <code>VectorIndexManager::addEntity</code>-Varianten; Disk-Storage nutzt <code>embedding_q</code> (bytes) + <code>embedding_scale</code> (double) statt <code>embedding</code> (vec). In-Memory-Cache bleibt float32."},{"location":"compression_strategy/#konfigurationsbeispiel-vollstandig","title":"Konfigurationsbeispiel (vollst\u00e4ndig)","text":"<pre><code>{\n  \"storage\": {\n    \"db_path\": \"./data/themis\",\n    \"compression_default\": \"lz4\",     // \u2705 OPTIMAL f\u00fcr JSON/Graph\n    \"compression_bottommost\": \"zstd\", // \u2705 OPTIMAL f\u00fcr alte Daten\n    \"blob_size_threshold\": 4096       // \u2705 &gt;4KB \u2192 BlobDB\n  },\n  \"timeseries\": {\n    \"compression\": \"gorilla\",          // \ud83d\udd34 TODO: IMPLEMENTIEREN\n    \"chunk_size_hours\": 24\n  },\n  \"content\": {\n    \"compress_blobs\": true,            // \u2705 IMPLEMENTIERT (via config:content in DB)\n    \"compression_level\": 19,           // ZSTD Level\n    \"skip_compressed_mimes\": [\n      \"image/\", \"video/\", \"application/zip\", \"application/gzip\"\n    ]\n  },\n  \"vector\": {\n    \"quantization\": \"auto\",            // \u2705 IMPLEMENTIERT: \"none\", \"sq8\", \"auto\" (via config:vector in DB)\n    \"auto_threshold\": 1000000,         // auto SQ8 ab 1M Vektoren\n    \"dimension\": 768\n  }\n}\n</code></pre>"},{"location":"compression_strategy/#best-practice-check-vector-compression","title":"Best-Practice-Check: Vector Compression \u2705","text":""},{"location":"compression_strategy/#industrie-standards","title":"Industrie-Standards","text":"System Vector Count Quantization Warum? Pinecone &gt;100M PQ + HNSW Speicher-Kosten dominant Weaviate &lt;10M Float32 Qualit\u00e4t &gt; Speicher Milvus &gt;1M SQ8/PQ (optional) Hybrid-Ansatz Qdrant &lt;1M Float32 (default) Performance &gt; Speicher <p>Themis Position: &lt;1M Vektoren \u2192 Float32 ist Best-Practice \u2705</p>"},{"location":"compression_strategy/#wann-quantisierung","title":"Wann Quantisierung?","text":"<pre><code>IF vector_count &gt; 1M AND memory_cost &gt; compute_cost:\n    USE scalar_quantization (SQ8)\nELIF vector_count &gt; 10M AND recall_tolerance &lt; 95%:\n    USE product_quantization (PQ)\nELSE:\n    USE float32 (OPTIMAL)\n</code></pre> <p>Themis: Aktuell &lt;1M Vektoren \u2192 Keine Quantisierung n\u00f6tig \u2705</p>"},{"location":"compression_strategy/#zusammenfassung","title":"Zusammenfassung","text":"Feature Status Priorit\u00e4t Aufwand Ratio CPU-Overhead RocksDB LZ4/ZSTD \u2705 Implementiert \u2014 \u2014 2.4x +5% Gorilla Time-Series \u2705 Implementiert \ud83d\udd34 HOCH \u2014 10-20x +15% Content-Blob ZSTD \u2705 Implementiert \ud83d\udfe1 MITTEL \u2014 1.5-2x +30% Vector SQ8 \u2705 Implementiert (auto \u22651M) \ud83d\udfe2 NIEDRIG \u2014 ~4x (Disk) +20% Vector PQ \ud83d\udeab Skip \u2014 \u2014 8-32x +50% <p>Empfohlene Reihenfolge: 1. \u2705 Gorilla f\u00fcr Time-Series (DONE \u2013 gr\u00f6\u00dfter Impact, niedrige Komplexit\u00e4t) 2. \u2705 Content-Blob ZSTD (DONE \u2013 mittlerer Impact, niedrige Komplexit\u00e4t) 3. \u2705 Vector SQ8 (DONE \u2013 auto ab 1M, hohe Komplexit\u00e4t nun implementiert)</p> <p>N\u00e4chste Schritte: - Recall/Speed-Benchmarks f\u00fcr SQ8 nachmessen - Optional: HTTP-Endpoint <code>/ts/config</code> f\u00fcr Gorilla-Optionen - Migration Tool f\u00fcr bestehende Float32-Vektoren \u2192 SQ8</p>"},{"location":"content_architecture/","title":"Content Manager Architektur","text":"<p>Version: 1.0 Datum: 28. Oktober 2025 Status: Design Phase</p>"},{"location":"content_architecture/#1-uberblick","title":"1. \u00dcberblick","text":"<p>Das Content Manager System ist eine universelle Schicht f\u00fcr die Verwaltung heterogener Datentypen in THEMIS. Es abstrahiert die Komplexit\u00e4t der Verarbeitung verschiedener Content-Typen (Text, Bilder, Audio, Geo-Daten, CAD-Modelle, etc.) hinter einer einheitlichen API.</p>"},{"location":"content_architecture/#11-ziele","title":"1.1 Ziele","text":"<ul> <li>Erweiterbarkeit: Neue Datentypen k\u00f6nnen \u00fcber Plugins hinzugef\u00fcgt werden</li> <li>Wiederverwendbarkeit: Gemeinsame Operationen (Hashing, Chunking, Graph-Erstellung) nur einmal implementiert</li> <li>Typsicherheit: Klare Trennung zwischen generischen und typspezifischen Operationen</li> <li>Produktivit\u00e4t: Entwickler m\u00fcssen nicht f\u00fcr jeden Datentyp eine vollst\u00e4ndige Pipeline implementieren</li> </ul>"},{"location":"content_architecture/#12-architektur-prinzipien","title":"1.2 Architektur-Prinzipien","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    HTTP API Layer                               \u2502\n\u2502  POST /content/upload, GET /content/:id, POST /content/search   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    ContentManager                               \u2502\n\u2502  \u2022 Unified ingestion pipeline                                   \u2502\n\u2502  \u2022 Processor routing by category                                \u2502\n\u2502  \u2022 Graph construction (parent, next/prev, hierarchical)         \u2502\n\u2502  \u2022 Deduplication (SHA-256 hash)                                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502            \u2502            \u2502            \u2502            \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Text    \u2502  \u2502  Image   \u2502 \u2502   Geo   \u2502 \u2502   CAD    \u2502 \u2502  Audio  \u2502\n\u2502 Processor \u2502  \u2502Processor \u2502 \u2502Processor\u2502 \u2502Processor \u2502 \u2502Processor\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502            \u2502            \u2502            \u2502            \u2502\n       \u2502  \u2022 extract()  \u2022 chunk()  \u2022 generateEmbedding()   \u2502\n       \u2502                                                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Storage Layer                                \u2502\n\u2502  \u2022 RocksDB (metadata + blobs)                                   \u2502\n\u2502  \u2022 VectorIndex (embeddings)                                     \u2502\n\u2502  \u2022 GraphIndex (parent, next/prev, assembly hierarchy)           \u2502\n\u2502  \u2022 SecondaryIndex (tags, mime_type, hash for dedup)             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"content_architecture/#2-core-components","title":"2. Core Components","text":""},{"location":"content_architecture/#21-contenttyperegistry","title":"2.1 ContentTypeRegistry","text":"<p>Verantwortlichkeit: MIME-Type \u2192 Category Mapping</p> <p>Funktionen: - MIME-Type-Erkennung (manuelle Angabe, Magic Bytes, Dateiendung) - Kategorisierung (TEXT, IMAGE, AUDIO, VIDEO, GEO, CAD, STRUCTURED, BINARY) - Feature Flags (supports_text_extraction, supports_embedding, geospatial, hierarchical)</p> <p>Beispiel:</p> <pre><code>ContentType pdf_type;\npdf_type.mime_type = \"application/pdf\";\npdf_type.category = ContentCategory::TEXT;\npdf_type.extensions = {\".pdf\"};\npdf_type.supports_text_extraction = true;\npdf_type.supports_chunking = true;\npdf_type.binary_storage_required = true;\n\nContentTypeRegistry::instance().registerType(pdf_type);\n</code></pre> <p>Default Types (Pre-Registered):</p> Category MIME Types Features TEXT <code>text/plain</code>, <code>text/markdown</code>, <code>text/html</code>, <code>application/json</code>, <code>text/x-python</code> text_extraction, chunking, embedding IMAGE <code>image/jpeg</code>, <code>image/png</code>, <code>image/svg+xml</code>, <code>image/tiff</code> metadata_extraction (EXIF), embedding (CLIP) AUDIO <code>audio/mpeg</code>, <code>audio/wav</code>, <code>audio/flac</code> metadata_extraction (ID3), temporal VIDEO <code>video/mp4</code>, <code>video/webm</code> metadata_extraction, temporal, multimodal GEO <code>application/geo+json</code>, <code>application/gpx+xml</code>, <code>image/tiff</code> (GeoTIFF) geospatial, metadata_extraction CAD <code>model/step</code>, <code>model/iges</code>, <code>model/stl</code>, <code>application/dxf</code> hierarchical, metadata_extraction STRUCTURED <code>text/csv</code>, <code>application/vnd.apache.parquet</code>, <code>application/vnd.apache.arrow</code> text_extraction, chunking (row-level) ARCHIVE <code>application/zip</code>, <code>application/x-tar</code> hierarchical (extract members recursively) BINARY Fallback f\u00fcr unbekannte Typen binary_storage_required"},{"location":"content_architecture/#22-icontentprocessor-plugin-interface","title":"2.2 IContentProcessor (Plugin Interface)","text":"<p>Verantwortlichkeit: Typ-spezifische Verarbeitung</p> <p>Kernmethoden:</p> <pre><code>class IContentProcessor {\npublic:\n    // Extrahiere strukturierte Daten aus Blob\n    virtual ExtractionResult extract(\n        const std::string&amp; blob,\n        const ContentType&amp; content_type\n    ) = 0;\n\n    // Chunking (z.B. Text \u2192 Paragraphen, CAD \u2192 Parts, CSV \u2192 Rows)\n    virtual std::vector&lt;json&gt; chunk(\n        const ExtractionResult&amp; extraction_result,\n        int chunk_size,\n        int overlap\n    ) = 0;\n\n    // Embedding-Generierung (z.B. Text \u2192 Sentence-BERT, Image \u2192 CLIP)\n    virtual std::vector&lt;float&gt; generateEmbedding(\n        const std::string&amp; chunk_data\n    ) = 0;\n\n    virtual std::vector&lt;ContentCategory&gt; getSupportedCategories() const = 0;\n};\n</code></pre> <p>Implementierte Processors:</p>"},{"location":"content_architecture/#textprocessor","title":"TextProcessor","text":"<ul> <li>Extraction: UTF-8 Normalisierung, Markdown \u2192 Plain Text, Code Syntax-Highlighting</li> <li>Chunking: Fixed-size (512 Tokens) mit Overlap (50 Tokens), Sentence-Boundary-Preserving</li> <li>Embedding: Sentence-Transformers (z.B. <code>all-mpnet-base-v2</code>, 768D)</li> </ul>"},{"location":"content_architecture/#imageprocessor","title":"ImageProcessor","text":"<ul> <li>Extraction: EXIF Metadata (Camera, GPS, Timestamp), Dimensions, Color Profile</li> <li>Chunking: Keine (Bild als ganzes) oder Region-Proposals (f\u00fcr Object Detection)</li> <li>Embedding: CLIP (<code>openai/clip-vit-base-patch32</code>, 512D)</li> </ul>"},{"location":"content_architecture/#geoprocessor","title":"GeoProcessor","text":"<ul> <li>Extraction: GeoJSON \u2192 Coordinates, Properties; GPX \u2192 Tracks/Waypoints; GeoTIFF \u2192 Raster + Projection</li> <li>Chunking: Feature-Level (jedes GeoJSON Feature = 1 Chunk)</li> <li>Embedding: Geo2Vec (Lat/Lon \u2192 Embedding) oder Text-Embedding der Properties</li> </ul>"},{"location":"content_architecture/#cadprocessor","title":"CADProcessor","text":"<ul> <li>Extraction: STEP \u2192 Assembly Hierarchy, Parts, BOM; STL \u2192 Mesh Geometry</li> <li>Chunking: Part-Level (jedes Part = 1 Chunk)</li> <li>Embedding: PartNet (3D Shape \u2192 Embedding) oder Property-Text-Embedding</li> </ul>"},{"location":"content_architecture/#audioprocessor","title":"AudioProcessor","text":"<ul> <li>Extraction: ID3 Tags (Title, Artist, Album), Duration, Bitrate, Codec</li> <li>Chunking: Time-based (z.B. 30s Segmente) oder Speech-Transcript-based</li> <li>Embedding: Wav2Vec2 (Audio \u2192 Embedding) oder Text-Embedding des Transcripts</li> </ul>"},{"location":"content_architecture/#structuredprocessor","title":"StructuredProcessor","text":"<ul> <li>Extraction: CSV \u2192 Schema + Rows, Parquet \u2192 Arrow Table</li> <li>Chunking: Row-Level (jede Zeile = 1 Chunk) oder Batch (z.B. 100 Zeilen)</li> <li>Embedding: Column-Embeddings (f\u00fcr Schema) + Row-Embeddings (f\u00fcr Data)</li> </ul>"},{"location":"content_architecture/#binaryprocessor-fallback","title":"BinaryProcessor (Fallback)","text":"<ul> <li>Extraction: Nur Metadata (Size, Hash, Magic Bytes)</li> <li>Chunking: Keine (gesamter Blob)</li> <li>Embedding: Keine (Binary-Daten nicht semantisch suchbar)</li> </ul>"},{"location":"content_architecture/#23-contentmanager-orchestrator","title":"2.3 ContentManager (Orchestrator)","text":"<p>Verantwortlichkeit: Unified Ingestion Pipeline</p> <p>Ingestion Flow:</p> <pre><code>IngestionResult ContentManager::ingestContent(\n    const std::string&amp; blob,\n    const std::optional&lt;std::string&gt;&amp; mime_type,\n    const std::string&amp; filename,\n    const json&amp; user_metadata,\n    const IngestionConfig&amp; config\n) {\n    // 1. Content-Type Detection\n    const ContentType* type = detectContentType(blob, mime_type, filename);\n\n    // 2. Deduplication Check (SHA-256 Hash)\n    std::string hash = computeSHA256(blob);\n    if (auto existing = checkDuplicateByHash(hash)) {\n        return {.ok=true, .content_id=*existing, .message=\"Duplicate\"};\n    }\n\n    // 3. Processor Routing\n    auto* processor = getProcessor(type-&gt;category);\n    if (!processor) {\n        // Fallback to BinaryProcessor\n        processor = getProcessor(ContentCategory::BINARY);\n    }\n\n    // 4. Extraction\n    auto extraction = processor-&gt;extract(blob, *type);\n    if (!extraction.ok) {\n        return {.ok=false, .message=extraction.error_message};\n    }\n\n    // 5. Store Blob (Optional)\n    std::string content_id = generateUuid();\n    if (config.store_blob) {\n        BaseEntity content_entity(\"content:\" + content_id);\n        content_entity.setBlob(blob);\n        storage_-&gt;put(\"content:\" + content_id, content_entity.serialize());\n    }\n\n    // 6. Chunking\n    std::vector&lt;json&gt; chunks;\n    if (config.generate_chunks &amp;&amp; type-&gt;supports_chunking) {\n        chunks = processor-&gt;chunk(extraction, config.chunk_size, config.chunk_overlap);\n    }\n\n    // 7. Embedding Generation + VectorIndex Insertion\n    std::vector&lt;std::string&gt; chunk_ids;\n    if (config.generate_embeddings) {\n        for (int i = 0; i &lt; chunks.size(); i++) {\n            std::string chunk_id = generateUuid();\n            chunk_ids.push_back(chunk_id);\n\n            auto embedding = processor-&gt;generateEmbedding(chunks[i][\"text\"]);\n\n            // Insert into VectorIndex\n            BaseEntity chunk_entity(\"chunk:\" + chunk_id);\n            chunk_entity.set(\"content_id\", content_id);\n            chunk_entity.set(\"seq_num\", i);\n            chunk_entity.set(\"text\", chunks[i][\"text\"]);\n            chunk_entity.set(\"embedding\", embedding);\n\n            storage_-&gt;put(\"chunk:\" + chunk_id, chunk_entity.serialize());\n            vector_index_-&gt;addEntity(chunk_entity, embedding);\n        }\n    }\n\n    // 8. Graph Construction\n    if (config.build_graph) {\n        createChunkGraph(chunk_ids, content_id, \"text_chunk\");\n    }\n\n    // 9. Store Metadata\n    ContentMeta meta;\n    meta.id = content_id;\n    meta.mime_type = type-&gt;mime_type;\n    meta.category = type-&gt;category;\n    meta.original_filename = filename;\n    meta.size_bytes = blob.size();\n    meta.hash_sha256 = hash;\n    meta.chunk_count = chunks.size();\n    meta.extracted_metadata = extraction.metadata;\n    meta.user_metadata = user_metadata;\n\n    storage_-&gt;put(\"meta:\" + content_id, meta.toJson().dump());\n\n    return {.ok=true, .content_id=content_id, .chunks_created=(int)chunks.size()};\n}\n</code></pre>"},{"location":"content_architecture/#3-graph-strukturen","title":"3. Graph-Strukturen","text":""},{"location":"content_architecture/#31-chunk-graph-fur-rag","title":"3.1 Chunk-Graph (f\u00fcr RAG)","text":"<p>Vertex-Typen: - <code>content:&lt;uuid&gt;</code>: Content-Item (Document, Image, etc.) - <code>chunk:&lt;uuid&gt;</code>: Chunk</p> <p>Edge-Typen: - <code>parent</code>: <code>chunk -&gt; content</code> (N:1, jeder Chunk geh\u00f6rt zu genau einem Content-Item) - <code>next</code>: <code>chunk -&gt; chunk</code> (sequentielle Reihenfolge, z.B. Paragraph 1 \u2192 Paragraph 2) - <code>prev</code>: <code>chunk -&gt; chunk</code> (R\u00fcckw\u00e4rts-Navigation)</p> <p>Beispiel: Text-Dokument mit 3 Chunks</p> <pre><code>content:doc123 (Document)\n   \u251c\u2500 chunk:c1 (Paragraph 1) \u2500\u2500next\u2500\u2500&gt; chunk:c2 (Paragraph 2) \u2500\u2500next\u2500\u2500&gt; chunk:c3 (Paragraph 3)\n   \u2502                             \u2191                             \u2191                             \u2191\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500parent\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500parent\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500parent\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Query: Vector-Search + Graph-Expansion</p> <pre><code>-- 1. Vector-Suche: Top-K Chunks\nLET top_chunks = VECTOR_KNN('chunks', @query_vec, 10)\n\n-- 2. Graph-Expansion: Lade Kontext (prev/next)\nFOR chunk IN top_chunks\n  FOR neighbor IN 1..1 ANY chunk GRAPH 'content_graph'\n    FILTER neighbor._type == 'chunk'\n    RETURN DISTINCT neighbor\n</code></pre>"},{"location":"content_architecture/#32-hierarchical-graph-fur-cadarchive","title":"3.2 Hierarchical Graph (f\u00fcr CAD/Archive)","text":"<p>Vertex-Typen: - <code>content:assembly</code> (CAD Assembly) - <code>content:part1</code>, <code>content:part2</code>, ... (CAD Parts)</p> <p>Edge-Typen: - <code>contains</code>: <code>assembly -&gt; part</code> (1:N, Assembly enth\u00e4lt Parts) - <code>sibling</code>: <code>part -&gt; part</code> (Parts auf gleicher Hierarchie-Ebene)</p> <p>Beispiel: CAD Assembly</p> <pre><code>content:assembly (Getriebe)\n   \u251c\u2500\u2500\u2500 contains \u2500\u2500&gt; content:part1 (Zahnrad A)\n   \u251c\u2500\u2500\u2500 contains \u2500\u2500&gt; content:part2 (Zahnrad B)\n   \u2514\u2500\u2500\u2500 contains \u2500\u2500&gt; content:part3 (Welle)\n</code></pre> <p>Query: Finde alle Parts eines Assemblies</p> <pre><code>FOR part IN 1..1 OUTBOUND 'content:assembly' GRAPH 'cad_graph'\n  FILTER part._type == 'part'\n  RETURN part\n</code></pre>"},{"location":"content_architecture/#33-geo-graph-fur-gis-daten","title":"3.3 Geo-Graph (f\u00fcr GIS-Daten)","text":"<p>Vertex-Typen: - <code>content:layer</code> (GeoJSON Layer) - <code>content:feature1</code>, <code>content:feature2</code>, ... (GeoJSON Features)</p> <p>Edge-Typen: - <code>member_of</code>: <code>feature -&gt; layer</code> - <code>spatially_near</code>: <code>feature -&gt; feature</code> (basierend auf Geohash-Proximity)</p> <p>Beispiel: GeoJSON Layer mit Features</p> <pre><code>content:layer (St\u00e4dte Deutschland)\n   \u251c\u2500\u2500\u2500 member_of \u2500\u2500&gt; content:feature1 (Berlin)\n   \u251c\u2500\u2500\u2500 member_of \u2500\u2500&gt; content:feature2 (Hamburg)\n   \u2514\u2500\u2500\u2500 member_of \u2500\u2500&gt; content:feature3 (M\u00fcnchen)\n\ncontent:feature1 (Berlin) \u2500\u2500spatially_near\u2500\u2500&gt; content:feature4 (Potsdam)\n</code></pre>"},{"location":"content_architecture/#4-embedding-strategien","title":"4. Embedding-Strategien","text":""},{"location":"content_architecture/#41-text-embeddings-sentence-transformers","title":"4.1 Text-Embeddings (Sentence-Transformers)","text":"<p>Modell: <code>all-mpnet-base-v2</code> (768D, hohe Qualit\u00e4t) Alternative: <code>all-MiniLM-L6-v2</code> (384D, schneller)</p> <p>Integration:</p> <pre><code>// Externe API (z.B. Python Microservice mit Flask)\nstd::vector&lt;float&gt; TextProcessor::generateEmbedding(const std::string&amp; text) {\n    // HTTP POST to embedding service\n    json request = {{\"text\", text}};\n    auto response = http_client_-&gt;post(\"http://localhost:5000/embed\", request);\n    return response[\"embedding\"];\n}\n</code></pre> <p>Mock f\u00fcr Tests:</p> <pre><code>std::vector&lt;float&gt; TextProcessor::generateEmbedding(const std::string&amp; text) {\n    // Simple hash-based mock embedding\n    std::vector&lt;float&gt; embedding(768, 0.0f);\n    std::hash&lt;std::string&gt; hasher;\n    size_t hash = hasher(text);\n    for (int i = 0; i &lt; 768; i++) {\n        embedding[i] = ((hash &gt;&gt; i) &amp; 1) ? 1.0f : -1.0f;\n    }\n    return embedding;\n}\n</code></pre>"},{"location":"content_architecture/#42-image-embeddings-clip","title":"4.2 Image-Embeddings (CLIP)","text":"<p>Modell: <code>openai/clip-vit-base-patch32</code> (512D)</p> <p>Integration:</p> <pre><code># Embedding Service (Python Flask)\nfrom transformers import CLIPProcessor, CLIPModel\nimport torch\n\nmodel = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\nprocessor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n\n@app.route('/embed/image', methods=['POST'])\ndef embed_image():\n    image_bytes = request.files['image'].read()\n    image = Image.open(io.BytesIO(image_bytes))\n    inputs = processor(images=image, return_tensors=\"pt\")\n    with torch.no_grad():\n        embedding = model.get_image_features(**inputs)\n    return jsonify({'embedding': embedding[0].tolist()})\n</code></pre>"},{"location":"content_architecture/#43-cad-embeddings-partnet-custom","title":"4.3 CAD-Embeddings (PartNet / Custom)","text":"<p>Ansatz:  - Option 1: Render CAD-Part als Bild (Multiple Views), dann CLIP-Embedding - Option 2: Extract Properties (Volume, Surface Area, Material) \u2192 Text-Embedding - Option 3: PartNet (3D Shape Encoder, research-basiert)</p> <p>MVP: Text-Embedding der BOM/Properties</p> <pre><code>std::vector&lt;float&gt; CADProcessor::generateEmbedding(const std::string&amp; chunk_data) {\n    // chunk_data = JSON with CAD properties\n    json props = json::parse(chunk_data);\n    std::string text = \"Part: \" + props[\"name\"].get&lt;std::string&gt;() +\n                       \", Material: \" + props[\"material\"].get&lt;std::string&gt;() +\n                       \", Volume: \" + std::to_string(props[\"volume\"].get&lt;double&gt;());\n\n    // Delegate to TextProcessor\n    TextProcessor text_proc;\n    return text_proc.generateEmbedding(text);\n}\n</code></pre>"},{"location":"content_architecture/#5-api-design","title":"5. API Design","text":""},{"location":"content_architecture/#51-http-endpoints","title":"5.1 HTTP Endpoints","text":"<p>Upload Content</p> <pre><code>POST /content/upload\nContent-Type: multipart/form-data\n\nForm fields:\n- file: binary file\n- mime_type: (optional) override MIME detection\n- metadata: (optional) JSON with user metadata\n- tags: (optional) comma-separated tags\n- config: (optional) JSON with IngestionConfig\n\nResponse:\n{\n  \"ok\": true,\n  \"content_id\": \"uuid-1234\",\n  \"chunks_created\": 15,\n  \"message\": \"Content ingested successfully\"\n}\n</code></pre> <p>Get Content Metadata</p> <pre><code>GET /content/:id\n\nResponse:\n{\n  \"id\": \"uuid-1234\",\n  \"mime_type\": \"application/pdf\",\n  \"category\": \"TEXT\",\n  \"original_filename\": \"report.pdf\",\n  \"size_bytes\": 1048576,\n  \"created_at\": 1730120400,\n  \"chunk_count\": 15,\n  \"extracted_metadata\": {\n    \"pages\": 10,\n    \"author\": \"John Doe\"\n  },\n  \"user_metadata\": {\n    \"project\": \"Alpha\"\n  },\n  \"tags\": [\"report\", \"2025\"]\n}\n</code></pre> <p>Download Content Blob</p> <pre><code>GET /content/:id/blob\n\nResponse:\nContent-Type: application/pdf\nContent-Disposition: attachment; filename=\"report.pdf\"\nContent-Length: 1048576\n\n&lt;binary data&gt;\n</code></pre> <p>Search Content</p> <pre><code>POST /content/search\nContent-Type: application/json\n\n{\n  \"query\": \"machine learning techniques\",\n  \"k\": 10,\n  \"filters\": {\n    \"category\": \"TEXT\",\n    \"tags\": [\"research\"]\n  },\n  \"expansion\": {\n    \"enabled\": true,\n    \"hops\": 1\n  }\n}\n\nResponse:\n{\n  \"results\": [\n    {\n      \"chunk_id\": \"chunk-uuid-1\",\n      \"content_id\": \"uuid-1234\",\n      \"score\": 0.95,\n      \"text\": \"Machine learning techniques have revolutionized...\",\n      \"seq_num\": 5,\n      \"metadata\": {\n        \"filename\": \"ml_paper.pdf\",\n        \"page\": 3\n      }\n    },\n    ...\n  ],\n  \"total\": 10,\n  \"query_time_ms\": 45\n}\n</code></pre> <p>Get Content Chunks</p> <pre><code>GET /content/:id/chunks\n\nResponse:\n{\n  \"chunks\": [\n    {\n      \"id\": \"chunk-uuid-1\",\n      \"seq_num\": 0,\n      \"text\": \"Introduction...\",\n      \"start_offset\": 0,\n      \"end_offset\": 512,\n      \"embedding_indexed\": true\n    },\n    ...\n  ]\n}\n</code></pre> <p>Delete Content</p> <pre><code>DELETE /content/:id\n\nResponse:\n{\n  \"ok\": true,\n  \"message\": \"Content and 15 chunks deleted\"\n}\n</code></pre>"},{"location":"content_architecture/#6-erweiterung-neue-datentypen-hinzufugen","title":"6. Erweiterung: Neue Datentypen hinzuf\u00fcgen","text":""},{"location":"content_architecture/#beispiel-video-processor","title":"Beispiel: Video-Processor","text":"<p>1. Content-Type registrieren</p> <pre><code>ContentType video_mp4;\nvideo_mp4.mime_type = \"video/mp4\";\nvideo_mp4.category = ContentCategory::VIDEO;\nvideo_mp4.extensions = {\".mp4\", \".m4v\"};\nvideo_mp4.supports_text_extraction = false; // (au\u00dfer mit Speech-to-Text)\nvideo_mp4.supports_chunking = true;         // Time-based chunks\nvideo_mp4.supports_embedding = true;        // Video embeddings (VideoMAE, etc.)\nvideo_mp4.features.temporal = true;\nvideo_mp4.features.multimodal = true;       // Audio + Frames\n\nContentTypeRegistry::instance().registerType(video_mp4);\n</code></pre> <p>2. VideoProcessor implementieren</p> <pre><code>class VideoProcessor : public IContentProcessor {\npublic:\n    ExtractionResult extract(const std::string&amp; blob, const ContentType&amp; type) override {\n        ExtractionResult result;\n\n        // Extract metadata with FFmpeg\n        result.metadata = extractVideoMetadata(blob);\n        result.media_data = MediaData{\n            .duration_seconds = result.metadata[\"duration\"],\n            .width = result.metadata[\"width\"],\n            .height = result.metadata[\"height\"],\n            .codec = result.metadata[\"codec\"]\n        };\n\n        result.ok = true;\n        return result;\n    }\n\n    std::vector&lt;json&gt; chunk(const ExtractionResult&amp; extraction, int chunk_size, int overlap) override {\n        // Chunk by time (e.g., 10-second segments)\n        int duration = extraction.media_data-&gt;duration_seconds;\n        std::vector&lt;json&gt; chunks;\n\n        for (int i = 0; i &lt; duration; i += chunk_size) {\n            json chunk = {\n                {\"type\", \"video_segment\"},\n                {\"start_time\", i},\n                {\"end_time\", std::min(i + chunk_size, duration)},\n                {\"frame_ref\", \"video_frames_\" + std::to_string(i)}\n            };\n            chunks.push_back(chunk);\n        }\n\n        return chunks;\n    }\n\n    std::vector&lt;float&gt; generateEmbedding(const std::string&amp; chunk_data) override {\n        // Extract representative frame, encode with CLIP or VideoMAE\n        json chunk = json::parse(chunk_data);\n        int start_time = chunk[\"start_time\"];\n\n        // External call to video embedding service\n        return callVideoEmbeddingService(start_time);\n    }\n\n    std::vector&lt;ContentCategory&gt; getSupportedCategories() const override {\n        return {ContentCategory::VIDEO};\n    }\n};\n</code></pre> <p>3. Processor registrieren</p> <pre><code>content_manager-&gt;registerProcessor(std::make_unique&lt;VideoProcessor&gt;());\n</code></pre> <p>4. Verwenden</p> <pre><code>auto result = content_manager-&gt;ingestContent(\n    video_blob,\n    \"video/mp4\",\n    \"tutorial.mp4\",\n    json::object(),\n    IngestionConfig{\n        .chunk_size = 10,  // 10 seconds per chunk\n        .chunk_overlap = 2  // 2 seconds overlap\n    }\n);\n</code></pre>"},{"location":"content_architecture/#7-performance-uberlegungen","title":"7. Performance-\u00dcberlegungen","text":""},{"location":"content_architecture/#71-blob-storage","title":"7.1 Blob-Storage","text":"<p>Problem: Gro\u00dfe Dateien (GB-Range) sollten nicht komplett in RocksDB gespeichert werden.</p> <p>L\u00f6sung: Hybrid-Storage</p> <pre><code>struct BlobStorageConfig {\n    int64_t inline_threshold_bytes = 1024 * 1024; // 1 MB\n    std::string external_storage_path = \"./data/blobs/\";\n};\n\n// In ContentManager::ingestContent()\nif (blob.size() &lt; config.inline_threshold_bytes) {\n    // Store inline in RocksDB\n    entity.setBlob(blob);\n} else {\n    // Store externally (filesystem or S3)\n    std::string blob_path = external_storage_path + content_id + \".blob\";\n    writeToFile(blob_path, blob);\n    entity.set(\"blob_ref\", blob_path);\n}\n</code></pre>"},{"location":"content_architecture/#72-embedding-batch-processing","title":"7.2 Embedding-Batch-Processing","text":"<p>Problem: Sequentielle Embedding-Generierung ist langsam.</p> <p>L\u00f6sung: Batch-API</p> <pre><code>std::vector&lt;std::vector&lt;float&gt;&gt; generateEmbeddingsBatch(const std::vector&lt;std::string&gt;&amp; texts) {\n    json request = {{\"texts\", texts}};\n    auto response = http_client_-&gt;post(\"http://localhost:5000/embed/batch\", request);\n    return response[\"embeddings\"];\n}\n</code></pre>"},{"location":"content_architecture/#73-async-ingestion","title":"7.3 Async-Ingestion","text":"<p>Problem: Gro\u00dfe Dateien blockieren HTTP-Response.</p> <p>L\u00f6sung: Job-Queue</p> <pre><code>IngestionResult ContentManager::ingestContentAsync(/*...*/) {\n    std::string job_id = generateUuid();\n\n    // Queue job\n    job_queue_-&gt;enqueue({\n        .job_id = job_id,\n        .blob = blob,\n        .mime_type = mime_type,\n        // ...\n    });\n\n    return {.ok=true, .content_id=job_id, .message=\"Queued for processing\"};\n}\n\n// Background worker\nvoid processJobs() {\n    while (true) {\n        auto job = job_queue_-&gt;dequeue();\n        auto result = ingestContent(job.blob, job.mime_type, /*...*/);\n        updateJobStatus(job.job_id, result);\n    }\n}\n</code></pre>"},{"location":"content_architecture/#8-testing-strategie","title":"8. Testing-Strategie","text":""},{"location":"content_architecture/#81-unit-tests-pro-processor","title":"8.1 Unit Tests (pro Processor)","text":"<pre><code>TEST(TextProcessorTest, ExtractsTextFromPlainText) {\n    TextProcessor processor;\n    std::string blob = \"Hello, world!\";\n    ContentType type = {.mime_type=\"text/plain\", .category=ContentCategory::TEXT};\n\n    auto result = processor.extract(blob, type);\n\n    ASSERT_TRUE(result.ok);\n    EXPECT_EQ(result.text, \"Hello, world!\");\n}\n\nTEST(TextProcessorTest, ChunksTextWithOverlap) {\n    TextProcessor processor;\n    ExtractionResult extraction;\n    extraction.text = \"Lorem ipsum dolor sit amet...\"; // 1000 chars\n\n    auto chunks = processor.chunk(extraction, 512, 50);\n\n    ASSERT_GE(chunks.size(), 2);\n    // Verify overlap\n    std::string end_of_chunk1 = chunks[0][\"text\"].get&lt;std::string&gt;().substr(462, 50);\n    std::string start_of_chunk2 = chunks[1][\"text\"].get&lt;std::string&gt;().substr(0, 50);\n    EXPECT_EQ(end_of_chunk1, start_of_chunk2);\n}\n</code></pre>"},{"location":"content_architecture/#82-integration-tests","title":"8.2 Integration Tests","text":"<pre><code>TEST(ContentManagerTest, IngestTextDocumentEndToEnd) {\n    auto storage = std::make_shared&lt;RocksDBWrapper&gt;(\"./test_db\");\n    auto vector_index = std::make_shared&lt;VectorIndexManager&gt;(/*...*/);\n    auto graph_index = std::make_shared&lt;GraphIndexManager&gt;(/*...*/);\n    auto secondary_index = std::make_shared&lt;SecondaryIndexManager&gt;(/*...*/);\n\n    ContentManager manager(storage, vector_index, graph_index, secondary_index);\n    manager.registerProcessor(std::make_unique&lt;TextProcessor&gt;());\n\n    std::string blob = \"This is a test document. It has multiple sentences.\";\n    auto result = manager.ingestContent(blob, \"text/plain\", \"test.txt\");\n\n    ASSERT_TRUE(result.ok);\n    EXPECT_GT(result.chunks_created, 0);\n\n    // Verify metadata stored\n    auto meta = manager.getContentMeta(result.content_id);\n    ASSERT_TRUE(meta.has_value());\n    EXPECT_EQ(meta-&gt;mime_type, \"text/plain\");\n\n    // Verify chunks stored\n    auto chunks = manager.getContentChunks(result.content_id);\n    EXPECT_EQ(chunks.size(), result.chunks_created);\n\n    // Verify graph edges\n    auto neighbors = graph_index-&gt;getOutNeighbors(\"chunk:\" + chunks[0].id);\n    EXPECT_GT(neighbors.size(), 0); // Has 'next' edge\n}\n</code></pre>"},{"location":"content_architecture/#83-performance-benchmarks","title":"8.3 Performance Benchmarks","text":"<pre><code>BENCHMARK(BM_IngestLargeDocument) {\n    std::string large_doc(10 * 1024 * 1024, 'A'); // 10 MB\n    for (auto _ : state) {\n        content_manager-&gt;ingestContent(large_doc, \"text/plain\", \"large.txt\");\n    }\n}\n\nBENCHMARK(BM_SearchWithExpansion) {\n    for (auto _ : state) {\n        content_manager-&gt;searchWithExpansion(\"machine learning\", 10, 1);\n    }\n}\n</code></pre>"},{"location":"content_architecture/#9-migration-plan","title":"9. Migration-Plan","text":""},{"location":"content_architecture/#phase-1-foundation-woche-1-2","title":"Phase 1: Foundation (Woche 1-2)","text":"<ul> <li>[ ] ContentType + ContentTypeRegistry implementieren</li> <li>[ ] IContentProcessor Interface + BinaryProcessor (Fallback)</li> <li>[ ] ContentManager Grundstruktur (ohne Processors)</li> <li>[ ] Unit Tests f\u00fcr ContentTypeRegistry</li> </ul>"},{"location":"content_architecture/#phase-2-text-processor-woche-3","title":"Phase 2: Text-Processor (Woche 3)","text":"<ul> <li>[ ] TextProcessor implementieren (extract, chunk, embedding mit Mock)</li> <li>[ ] Integration in ContentManager</li> <li>[ ] HTTP Endpoint: POST /content/upload (nur TEXT)</li> <li>[ ] Integration Tests</li> </ul>"},{"location":"content_architecture/#phase-3-imagegeocad-processors-woche-4-5","title":"Phase 3: Image/Geo/CAD-Processors (Woche 4-5)","text":"<ul> <li>[ ] ImageProcessor (EXIF extraction, CLIP embedding via external service)</li> <li>[ ] GeoProcessor (GeoJSON parsing)</li> <li>[ ] CADProcessor (STEP parsing mit Open CASCADE)</li> <li>[ ] HTTP Endpoints erweitern</li> </ul>"},{"location":"content_architecture/#phase-4-hybrid-queries-woche-6","title":"Phase 4: Hybrid-Queries (Woche 6)","text":"<ul> <li>[ ] AQL VECTOR_KNN() Function</li> <li>[ ] Graph-Expansion in ContentManager::searchWithExpansion()</li> <li>[ ] Benchmarks</li> </ul>"},{"location":"content_architecture/#phase-5-production-hardening-woche-7","title":"Phase 5: Production-Hardening (Woche 7+)","text":"<ul> <li>[ ] Async-Ingestion (Job-Queue)</li> <li>[ ] External Blob-Storage (Filesystem/S3)</li> <li>[ ] Monitoring/Metrics</li> <li>[ ] Documentation</li> </ul>"},{"location":"content_architecture/#10-fazit","title":"10. Fazit","text":"<p>Das Content Manager System bietet eine skalierbare, erweiterbare Architektur f\u00fcr heterogene Datentypen. Durch die Trennung von generischen Operationen (Hashing, Graph-Erstellung) und typ-spezifischer Verarbeitung (via Processors) bleibt das System wartbar und einfach erweiterbar.</p> <p>Key Benefits: - Einheitliche API: Ein Upload-Endpoint f\u00fcr alle Datentypen - Wiederverwendbare Komponenten: Chunking-Logik, Graph-Erstellung, Deduplication - Typ-Sicherheit: ContentTypeRegistry verhindert falsche Verarbeitung - Produktivit\u00e4t: Neue Datentypen in &lt; 1 Tag integrierbar (nur Processor implementieren) - RAG-Ready: Graph-Expansion f\u00fcr kontextuelle Suche out-of-the-box</p>"},{"location":"content_pipeline/","title":"Content Pipeline","text":""},{"location":"content_pipeline/#uberblick","title":"\u00dcberblick","text":"<p>Die Content Pipeline ist das zentrale System f\u00fcr die Verarbeitung heterogener Datentypen in THEMIS. Sie erm\u00f6glicht es, beliebige Inhalte (Text, Bilder, Geodaten, CAD, Audio, strukturierte Daten) zu importieren, zu transformieren und f\u00fcr Vektor-, Graph- und Attributsuche bereitzustellen.</p> <p>Kernkonzepte:</p> <ul> <li>Modulare Architektur: Typ-spezifische Prozessoren (<code>IContentProcessor</code>) f\u00fcr jede Datenkategorie</li> <li>Einheitliche API: Ein Import-Endpoint (<code>POST /content/import</code>) f\u00fcr alle Datentypen</li> <li>Wiederverwendbare Komponenten: Deduplication, Chunking, Graph-Erstellung, Embedding-Generierung</li> <li>Kanonisches Schema: Strukturiertes JSON-Format (Content/Chunks/Edges) f\u00fcr alle Modalit\u00e4ten</li> <li>RAG-Ready: Automatische Graph-Konstruktion mit <code>parent</code>, <code>next</code>, <code>prev</code>, <code>contains</code>, <code>sibling</code> Edges f\u00fcr kontextuelle Suche</li> </ul> <p>Architektur-Diagramm:</p> <pre><code>Client \u2192 POST /content/import\n           \u2193\n    ContentManager (Orchestrator)\n           \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  ContentTypeRegistry     \u2502  MIME \u2192 Category Mapping\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Processor Routing       \u2502  Category \u2192 IContentProcessor\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Prozessoren (TextProcessor, ImageProcessor,  \u2502\n    \u2502  GeoProcessor, CADProcessor, AudioProcessor,  \u2502\n    \u2502  StructuredProcessor, BinaryProcessor)        \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Storage Layer           \u2502\n    \u2502  \u2022 RocksDB (Metadata)    \u2502\n    \u2502  \u2022 VectorIndex (HNSW)    \u2502\n    \u2502  \u2022 GraphIndex (Edges)    \u2502\n    \u2502  \u2022 SecondaryIndex (Tags) \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"content_pipeline/#1-content-type-system","title":"1. Content-Type-System","text":""},{"location":"content_pipeline/#11-contentcategory","title":"1.1 ContentCategory","text":"<p>THEMIS unterst\u00fctzt 9 Content-Kategorien:</p> Kategorie Beschreibung Beispiel-MIME-Types <code>TEXT</code> Textdokumente, Code, Markdown <code>text/plain</code>, <code>application/json</code>, <code>text/xml</code> <code>IMAGE</code> Fotos, Diagramme, Screenshots <code>image/jpeg</code>, <code>image/png</code>, <code>image/webp</code> <code>AUDIO</code> Musik, Podcasts, Sprachchips <code>audio/mpeg</code>, <code>audio/wav</code>, <code>audio/flac</code> <code>VIDEO</code> Videos <code>video/mp4</code>, <code>video/webm</code> <code>GEO</code> Geodaten, GIS <code>application/geo+json</code>, <code>application/gpx</code> <code>CAD</code> 3D-Modelle, CAD-Zeichnungen <code>model/step</code>, <code>model/iges</code>, <code>model/stl</code> <code>STRUCTURED</code> Tabellarische Daten <code>text/csv</code>, <code>application/parquet</code> <code>ARCHIVE</code> Archive, Container <code>application/zip</code>, <code>application/tar+gzip</code> <code>BINARY</code> Unbekannte Bin\u00e4rdaten (Fallback) <code>application/octet-stream</code>"},{"location":"content_pipeline/#12-contenttyperegistry","title":"1.2 ContentTypeRegistry","text":"<p>Die <code>ContentTypeRegistry</code> mappt MIME-Types auf Kategorien und speichert Metadaten \u00fcber F\u00e4higkeiten:</p> <pre><code>struct ContentType {\n    std::string mime_type;\n    ContentCategory category;\n    std::vector&lt;std::string&gt; extensions;  // z.B. {\".txt\", \".md\"}\n    bool supports_text_extraction;        // Kann Text extrahiert werden?\n    bool supports_chunking;               // Kann in Chunks zerlegt werden?\n    bool supports_embedding;              // Kann Embedding generiert werden?\n\n    struct Features {\n        bool hierarchical;   // Hat Hierarchie (CAD Assembly, Archive)\n        bool spatial;        // Hat r\u00e4umliche Koordinaten (Geo, GeoTIFF)\n        bool temporal;       // Hat zeitliche Dimension (Audio, Video)\n        bool multimodal;     // Mehrere Modalit\u00e4ten (Video = Audio + Frames)\n    };\n    Features features;\n};\n</code></pre> <p>Beispiel-Registrierung:</p> <pre><code>ContentType text_plain;\ntext_plain.mime_type = \"text/plain\";\ntext_plain.category = ContentCategory::TEXT;\ntext_plain.extensions = {\".txt\", \".log\", \".md\"};\ntext_plain.supports_text_extraction = true;\ntext_plain.supports_chunking = true;\ntext_plain.supports_embedding = true;\ntext_plain.features.hierarchical = false;\n\nContentTypeRegistry::instance().registerType(text_plain);\n</code></pre>"},{"location":"content_pipeline/#2-content-prozessoren","title":"2. Content-Prozessoren","text":""},{"location":"content_pipeline/#21-icontentprocessor-interface","title":"2.1 IContentProcessor Interface","text":"<p>Jeder Prozessor implementiert 3 Kernmethoden:</p> <pre><code>class IContentProcessor {\npublic:\n    // 1. Extraktion: Blob \u2192 Strukturierte Daten\n    virtual ExtractionResult extract(\n        const std::string&amp; blob,\n        const ContentType&amp; content_type\n    ) = 0;\n\n    // 2. Chunking: Extraktion \u2192 Viele kleine Chunks\n    virtual std::vector&lt;json&gt; chunk(\n        const ExtractionResult&amp; extraction_result,\n        int chunk_size,\n        int overlap\n    ) = 0;\n\n    // 3. Embedding: Chunk \u2192 Vektorrepr\u00e4sentation\n    virtual std::vector&lt;float&gt; generateEmbedding(\n        const std::string&amp; chunk_data\n    ) = 0;\n};\n</code></pre> <p>ExtractionResult-Struktur:</p> <pre><code>struct ExtractionResult {\n    bool ok;\n    std::string text;              // Extrahierter Plain-Text\n    json metadata;                 // EXIF, ID3, CAD-Properties, etc.\n    std::vector&lt;float&gt; embedding;  // Optional: Pre-computed Embedding\n    std::string error_message;\n\n    // Typ-spezifische Daten\n    std::optional&lt;GeoData&gt; geo_data;      // Koordinaten, Projektion, Properties\n    std::optional&lt;MediaData&gt; media_data;  // Duration, Width, Height, Codec\n    std::optional&lt;CADData&gt; cad_data;      // Parts, BOM, Dimensionen\n};\n</code></pre>"},{"location":"content_pipeline/#22-textprocessor","title":"2.2 TextProcessor","text":"<p>Verantwortlichkeiten:</p> <ul> <li>Text-Normalisierung (Whitespace, Newlines)</li> <li>Sentenz-basiertes Chunking mit Overlap</li> <li>Embedding via Sentence-Transformers (768D)</li> </ul> <p>Chunking-Strategie:</p> <pre><code>std::vector&lt;json&gt; TextProcessor::chunk(\n    const ExtractionResult&amp; extraction,\n    int chunk_size,      // z.B. 512 Tokens\n    int overlap          // z.B. 50 Tokens\n) {\n    std::string text = normalizeText(extraction.text);\n    std::vector&lt;std::string&gt; sentences = splitIntoSentences(text);\n\n    std::vector&lt;json&gt; chunks;\n    std::string current_chunk;\n    int current_tokens = 0;\n\n    for (const auto&amp; sentence : sentences) {\n        int tokens = countTokens(sentence);\n\n        if (current_tokens + tokens &gt; chunk_size &amp;&amp; !current_chunk.empty()) {\n            // Save chunk\n            chunks.push_back({\n                {\"type\", \"text\"},\n                {\"text\", current_chunk},\n                {\"tokens\", current_tokens}\n            });\n\n            // Overlap: Behalte letzte N Tokens\n            current_chunk = getLastNTokens(current_chunk, overlap) + \" \" + sentence;\n            current_tokens = overlap + tokens;\n        } else {\n            current_chunk += \" \" + sentence;\n            current_tokens += tokens;\n        }\n    }\n\n    return chunks;\n}\n</code></pre> <p>Embedding:</p> <pre><code>std::vector&lt;float&gt; TextProcessor::generateEmbedding(const std::string&amp; chunk_data) {\n    json chunk = json::parse(chunk_data);\n    std::string text = chunk[\"text\"];\n\n    // Aufruf an externes Embedding-Service (z.B. FastAPI mit Sentence-Transformers)\n    json request = {{\"text\", text}};\n    auto response = http_client_-&gt;post(\"http://localhost:5000/embed\", request);\n    return response[\"embedding\"].get&lt;std::vector&lt;float&gt;&gt;(); // 768D\n}\n</code></pre>"},{"location":"content_pipeline/#23-imageprocessor","title":"2.3 ImageProcessor","text":"<p>Verantwortlichkeiten:</p> <ul> <li>EXIF-Metadaten extrahieren (GPS, DateTime, Camera Model)</li> <li>Bild-Dimensionen, Format, Kompression erkennen</li> <li>Embedding via CLIP (512D)</li> </ul> <p>Extraktion:</p> <pre><code>ExtractionResult ImageProcessor::extract(const std::string&amp; blob, const ContentType&amp; type) {\n    ExtractionResult result;\n\n    // EXIF-Tags parsen\n    result.metadata = extractEXIF(blob);\n\n    // Dimensionen\n    auto [width, height] = getImageDimensions(blob);\n    result.media_data = MediaData{\n        .duration_seconds = 0,\n        .width = width,\n        .height = height,\n        .codec = type.mime_type\n    };\n\n    // OCR (optional, falls Text im Bild)\n    if (config.enable_ocr) {\n        result.text = performOCR(blob);\n    }\n\n    result.ok = true;\n    return result;\n}\n</code></pre> <p>Chunking: Bilder werden i.d.R. als ein Chunk gespeichert. Bei gro\u00dfen Bildern k\u00f6nnte Tiling erfolgen:</p> <pre><code>std::vector&lt;json&gt; ImageProcessor::chunk(const ExtractionResult&amp; extraction, int chunk_size, int overlap) {\n    // F\u00fcr MVP: Ein Chunk pro Bild\n    json chunk = {\n        {\"type\", \"image\"},\n        {\"width\", extraction.media_data-&gt;width},\n        {\"height\", extraction.media_data-&gt;height},\n        {\"exif\", extraction.metadata}\n    };\n\n    // Falls OCR-Text vorhanden, separater Text-Chunk\n    std::vector&lt;json&gt; chunks = {chunk};\n    if (!extraction.text.empty()) {\n        chunks.push_back({\n            {\"type\", \"ocr_text\"},\n            {\"text\", extraction.text}\n        });\n    }\n\n    return chunks;\n}\n</code></pre> <p>Embedding:</p> <pre><code>std::vector&lt;float&gt; ImageProcessor::generateEmbedding(const std::string&amp; chunk_data) {\n    // CLIP: Bild \u2192 512D Vektor\n    // blob muss als Base64 oder Dateipfad \u00fcbermittelt werden\n    json request = {{\"image_base64\", base64Encode(blob)}};\n    auto response = http_client_-&gt;post(\"http://localhost:5000/embed/image\", request);\n    return response[\"embedding\"].get&lt;std::vector&lt;float&gt;&gt;(); // 512D\n}\n</code></pre>"},{"location":"content_pipeline/#24-geoprocessor","title":"2.4 GeoProcessor","text":"<p>Verantwortlichkeiten:</p> <ul> <li>GeoJSON, GPX, GeoTIFF parsen</li> <li>Koordinaten-Extraktion, Projektion (EPSG/SRID), Bounding Box</li> <li>Spatial Embeddings via Geo2Vec oder TileDB</li> </ul> <p>Extraktion:</p> <pre><code>ExtractionResult GeoProcessor::extract(const std::string&amp; blob, const ContentType&amp; type) {\n    ExtractionResult result;\n\n    if (type.mime_type == \"application/geo+json\") {\n        result.geo_data = parseGeoJSON(blob);\n    } else if (type.mime_type.find(\"gpx\") != std::string::npos) {\n        result.geo_data = parseGPX(blob);\n    }\n\n    // Metadata: SRID, Feature-Count, BBox\n    result.metadata = {\n        {\"srid\", result.geo_data-&gt;projection},\n        {\"feature_count\", result.geo_data-&gt;coordinates.size()},\n        {\"bbox\", computeBBox(result.geo_data-&gt;coordinates)}\n    };\n\n    result.ok = true;\n    return result;\n}\n</code></pre> <p>Chunking: Ein Chunk pro Feature (bei FeatureCollection):</p> <pre><code>std::vector&lt;json&gt; GeoProcessor::chunk(const ExtractionResult&amp; extraction, int chunk_size, int overlap) {\n    std::vector&lt;json&gt; chunks;\n\n    for (size_t i = 0; i &lt; extraction.geo_data-&gt;coordinates.size(); ++i) {\n        auto [lat, lon] = extraction.geo_data-&gt;coordinates[i];\n        json properties = extraction.geo_data-&gt;properties[i]; // Annahme: properties pro Feature\n\n        chunks.push_back({\n            {\"type\", \"geo_feature\"},\n            {\"geometry\", {{\"type\", \"Point\"}, {\"coordinates\", {lon, lat}}}},\n            {\"srid\", extraction.geo_data-&gt;projection},\n            {\"properties\", properties}\n        });\n    }\n\n    return chunks;\n}\n</code></pre> <p>Embedding:</p> <pre><code>std::vector&lt;float&gt; GeoProcessor::generateEmbedding(const std::string&amp; chunk_data) {\n    json chunk = json::parse(chunk_data);\n    auto coords = chunk[\"geometry\"][\"coordinates\"];\n    double lon = coords[0], lat = coords[1];\n\n    // Geo2Vec: [lon, lat] \u2192 128D Vektor\n    json request = {{\"lon\", lon}, {\"lat\", lat}};\n    auto response = http_client_-&gt;post(\"http://localhost:5000/embed/geo\", request);\n    return response[\"embedding\"].get&lt;std::vector&lt;float&gt;&gt;();\n}\n</code></pre>"},{"location":"content_pipeline/#25-cadprocessor","title":"2.5 CADProcessor","text":"<p>Verantwortlichkeiten:</p> <ul> <li>STEP, IGES, STL, DXF parsen</li> <li>Assembly-Hierarchie extrahieren (Parent-Child-Beziehungen)</li> <li>Bill of Materials (BOM), Dimensionen, Constraints</li> </ul> <p>Extraktion:</p> <pre><code>ExtractionResult CADProcessor::extract(const std::string&amp; blob, const ContentType&amp; type) {\n    ExtractionResult result;\n\n    if (type.mime_type == \"model/step\") {\n        json step_data = parseSTEP(blob);\n        result.cad_data = CADData{\n            .part_ids = extractPartIDs(step_data),\n            .bom = extractBOM(step_data),\n            .dimensions = extractDimensions(step_data)\n        };\n    }\n\n    result.metadata = {\n        {\"format\", \"STEP\"},\n        {\"part_count\", result.cad_data-&gt;part_ids.size()}\n    };\n\n    result.ok = true;\n    return result;\n}\n</code></pre> <p>Chunking: Ein Chunk pro Part (Hierarchie via Edges):</p> <pre><code>std::vector&lt;json&gt; CADProcessor::chunk(const ExtractionResult&amp; extraction, int chunk_size, int overlap) {\n    std::vector&lt;json&gt; chunks;\n\n    for (const auto&amp; part_id : extraction.cad_data-&gt;part_ids) {\n        json part_info = extraction.cad_data-&gt;bom[part_id];\n\n        chunks.push_back({\n            {\"type\", \"cad_part\"},\n            {\"part_id\", part_id},\n            {\"name\", part_info[\"name\"]},\n            {\"material\", part_info[\"material\"]},\n            {\"dimensions\", part_info[\"dimensions\"]}\n        });\n    }\n\n    return chunks;\n}\n</code></pre> <p>Graph-Edges: <code>contains</code> (Assembly \u2192 Part), <code>sibling</code> (Parts im gleichen Assembly)</p>"},{"location":"content_pipeline/#26-audioprocessor","title":"2.6 AudioProcessor","text":"<p>Verantwortlichkeiten:</p> <ul> <li>ID3-Tags extrahieren (Titel, Artist, Album)</li> <li>Duration, Bitrate, Codec erkennen</li> <li>Speech-to-Text (optional)</li> <li>Embedding via Wav2Vec2 (768D)</li> </ul> <p>Chunking: Zeit-basiert (z.B. 10-Sekunden-Segmente):</p> <pre><code>std::vector&lt;json&gt; AudioProcessor::chunk(const ExtractionResult&amp; extraction, int chunk_size, int overlap) {\n    int duration = extraction.media_data-&gt;duration_seconds;\n    std::vector&lt;json&gt; chunks;\n\n    for (int i = 0; i &lt; duration; i += chunk_size) {\n        int end_time = std::min(i + chunk_size, duration);\n\n        chunks.push_back({\n            {\"type\", \"audio_segment\"},\n            {\"start_time\", i},\n            {\"end_time\", end_time},\n            {\"transcript\", extractTranscript(i, end_time)} // Optional: Whisper ASR\n        });\n    }\n\n    return chunks;\n}\n</code></pre>"},{"location":"content_pipeline/#27-structuredprocessor","title":"2.7 StructuredProcessor","text":"<p>Verantwortlichkeiten:</p> <ul> <li>CSV, Parquet, Arrow parsen</li> <li>Schema-Inferenz (Spaltentypen)</li> <li>Row-Level Chunking</li> <li>Spalten-Embeddings (f\u00fcr Table-QA)</li> </ul> <p>Chunking:</p> <pre><code>std::vector&lt;json&gt; StructuredProcessor::chunk(const ExtractionResult&amp; extraction, int chunk_size, int overlap) {\n    auto rows = parseCSV(extraction.text);\n    json schema = extractSchema(rows);\n\n    std::vector&lt;json&gt; chunks;\n\n    // Header als separater Chunk\n    chunks.push_back({\n        {\"type\", \"table_schema\"},\n        {\"schema\", schema}\n    });\n\n    // Rows in Batches\n    for (size_t i = 1; i &lt; rows.size(); i += chunk_size) {\n        json row_batch = json::array();\n        for (size_t j = i; j &lt; std::min(i + chunk_size, rows.size()); ++j) {\n            row_batch.push_back(rows[j]);\n        }\n\n        chunks.push_back({\n            {\"type\", \"table_rows\"},\n            {\"rows\", row_batch},\n            {\"row_range\", {i, std::min(i + chunk_size, rows.size())}}\n        });\n    }\n\n    return chunks;\n}\n</code></pre>"},{"location":"content_pipeline/#28-binaryprocessor-fallback","title":"2.8 BinaryProcessor (Fallback)","text":"<p>Falls kein spezialisierter Prozessor vorhanden, nutzt <code>BinaryProcessor</code> nur Hash + Gr\u00f6\u00dfe:</p> <pre><code>ExtractionResult BinaryProcessor::extract(const std::string&amp; blob, const ContentType&amp; type) {\n    ExtractionResult result;\n    result.metadata = {\n        {\"size_bytes\", blob.size()},\n        {\"hash_sha256\", computeSHA256(blob)}\n    };\n    result.ok = true;\n    return result;\n}\n</code></pre>"},{"location":"content_pipeline/#3-import-pipeline-post-contentimport","title":"3. Import-Pipeline (POST /content/import)","text":"<p>Ab MVP 2.0 wird die Ingestion client-seitig durchgef\u00fchrt. Der Server erwartet vorverarbeitete JSON-Objekte mit einem kanonischen Schema.</p>"},{"location":"content_pipeline/#31-import-schema","title":"3.1 Import-Schema","text":"<pre><code>{\n  \"content\": {\n    \"id\": \"content-uuid\",\n    \"mime_type\": \"text/plain\",\n    \"category\": \"TEXT\",\n    \"original_filename\": \"doc.txt\",\n    \"size_bytes\": 1024,\n    \"hash_sha256\": \"abc123...\",\n    \"created_at\": 1672531200,\n    \"user_metadata\": {\"author\": \"John Doe\"},\n    \"tags\": [\"documentation\", \"v1.0\"]\n  },\n  \"chunks\": [\n    {\n      \"id\": \"chunk-uuid-1\",\n      \"content_id\": \"content-uuid\",\n      \"seq_num\": 0,\n      \"chunk_type\": \"text\",\n      \"text\": \"This is the first chunk...\",\n      \"start_offset\": 0,\n      \"end_offset\": 512,\n      \"embedding\": [0.12, -0.45, ...]  // 768D\n    },\n    {\n      \"id\": \"chunk-uuid-2\",\n      \"content_id\": \"content-uuid\",\n      \"seq_num\": 1,\n      \"chunk_type\": \"text\",\n      \"text\": \"This is the second chunk...\",\n      \"start_offset\": 462,\n      \"end_offset\": 974,\n      \"embedding\": [0.34, 0.67, ...]\n    }\n  ],\n  \"edges\": [\n    {\n      \"from\": \"chunk-uuid-1\",\n      \"to\": \"chunk-uuid-2\",\n      \"type\": \"next\",\n      \"weight\": 1.0\n    },\n    {\n      \"from\": \"chunk-uuid-2\",\n      \"to\": \"chunk-uuid-1\",\n      \"type\": \"prev\",\n      \"weight\": 1.0\n    }\n  ],\n  \"blob\": \"&lt;base64-encoded-binary&gt;\"  // Optional: Original-Blob\n}\n</code></pre>"},{"location":"content_pipeline/#32-server-seitige-import-verarbeitung","title":"3.2 Server-seitige Import-Verarbeitung","text":"<pre><code>Status ContentManager::importContent(const json&amp; spec, const std::optional&lt;std::string&gt;&amp; blob) {\n    // 1. Validierung\n    if (!spec.contains(\"content\") || !spec.contains(\"chunks\")) {\n        return Status::Error(\"Invalid schema: missing 'content' or 'chunks'\");\n    }\n\n    // 2. Content-Metadata speichern\n    ContentMeta meta = ContentMeta::fromJson(spec[\"content\"]);\n    BaseEntity content_entity(meta.id, \"content\");\n    content_entity.set(\"mime_type\", meta.mime_type);\n    content_entity.set(\"category\", static_cast&lt;int&gt;(meta.category));\n    content_entity.set(\"original_filename\", meta.original_filename);\n    // ... (weitere Felder)\n    storage_-&gt;put(content_entity);\n\n    // 3. Blob speichern (falls vorhanden)\n    if (blob.has_value()) {\n        BaseEntity blob_entity(meta.id, \"content_blob\");\n        blob_entity.setBlob(*blob);\n        storage_-&gt;put(blob_entity);\n    }\n\n    // 4. Chunks speichern + VectorIndex aktualisieren\n    for (const auto&amp; chunk_json : spec[\"chunks\"]) {\n        ChunkMeta chunk = ChunkMeta::fromJson(chunk_json);\n\n        BaseEntity chunk_entity(chunk.id, \"chunk\");\n        chunk_entity.set(\"content_id\", chunk.content_id);\n        chunk_entity.set(\"seq_num\", chunk.seq_num);\n        chunk_entity.set(\"chunk_type\", chunk.chunk_type);\n        chunk_entity.set(\"text\", chunk.text);\n        storage_-&gt;put(chunk_entity);\n\n        // VectorIndex: Embedding einf\u00fcgen\n        if (!chunk.embedding.empty()) {\n            vector_index_-&gt;addVector(chunk.id, chunk.embedding);\n        }\n    }\n\n    // 5. Graph-Edges speichern\n    if (spec.contains(\"edges\")) {\n        for (const auto&amp; edge : spec[\"edges\"]) {\n            graph_index_-&gt;addEdge(\n                edge[\"from\"],\n                edge[\"to\"],\n                edge[\"type\"],\n                edge.value(\"weight\", 1.0)\n            );\n        }\n    }\n\n    return Status::OK();\n}\n</code></pre>"},{"location":"content_pipeline/#33-http-endpoint","title":"3.3 HTTP-Endpoint","text":"<pre><code>// In main_server.cpp\napp.post(\"/content/import\", [&amp;](const Request&amp; req, Response&amp; res) {\n    json spec = json::parse(req.body);\n\n    std::optional&lt;std::string&gt; blob;\n    if (spec.contains(\"blob\")) {\n        blob = base64Decode(spec[\"blob\"].get&lt;std::string&gt;());\n    }\n\n    auto status = content_manager-&gt;importContent(spec, blob);\n\n    if (status.ok) {\n        res.status = 200;\n        res.set_content(json{{\"ok\", true}, {\"content_id\", spec[\"content\"][\"id\"]}}.dump(), \"application/json\");\n    } else {\n        res.status = 400;\n        res.set_content(json{{\"error\", status.message}}.dump(), \"application/json\");\n    }\n});\n</code></pre>"},{"location":"content_pipeline/#4-batching-bulk-import","title":"4. Batching &amp; Bulk-Import","text":""},{"location":"content_pipeline/#41-motivation","title":"4.1 Motivation","text":"<p>Beim Import vieler Dokumente (z.B. 10.000 PDFs) ist sequentielles Einf\u00fcgen ineffizient. Batching gruppiert mehrere Operationen:</p> <ul> <li>Embedding-Batch-API: Generierung von 100 Embeddings in einem Request</li> <li>RocksDB WriteBatch: Atomare Transaktionen f\u00fcr mehrere Entities</li> <li>VectorIndex Bulk-Insert: HNSW-Build via Batch-Add</li> </ul>"},{"location":"content_pipeline/#42-batch-import-schema","title":"4.2 Batch-Import-Schema","text":"<pre><code>{\n  \"batch\": [\n    {\n      \"content\": {...},\n      \"chunks\": [...],\n      \"edges\": [...],\n      \"blob\": \"...\"\n    },\n    {\n      \"content\": {...},\n      \"chunks\": [...],\n      \"edges\": [...],\n      \"blob\": \"...\"\n    }\n  ]\n}\n</code></pre>"},{"location":"content_pipeline/#43-server-implementierung","title":"4.3 Server-Implementierung","text":"<pre><code>Status ContentManager::importBatch(const json&amp; batch_spec) {\n    rocksdb::WriteBatch batch;\n    std::vector&lt;std::pair&lt;std::string, std::vector&lt;float&gt;&gt;&gt; embeddings_to_add;\n\n    for (const auto&amp; item : batch_spec[\"batch\"]) {\n        // Content + Chunks in WriteBatch speichern\n        ContentMeta meta = ContentMeta::fromJson(item[\"content\"]);\n        batch.Put(\"content:\" + meta.id, meta.toJson().dump());\n\n        for (const auto&amp; chunk_json : item[\"chunks\"]) {\n            ChunkMeta chunk = ChunkMeta::fromJson(chunk_json);\n            batch.Put(\"chunk:\" + chunk.id, chunk.toJson().dump());\n\n            if (!chunk.embedding.empty()) {\n                embeddings_to_add.push_back({chunk.id, chunk.embedding});\n            }\n        }\n    }\n\n    // Atomare DB-Write\n    auto db_status = storage_-&gt;getRaw()-&gt;Write(rocksdb::WriteOptions(), &amp;batch);\n    if (!db_status.ok()) {\n        return Status::Error(\"Batch write failed: \" + db_status.ToString());\n    }\n\n    // VectorIndex: Bulk-Add\n    vector_index_-&gt;addVectorsBatch(embeddings_to_add);\n\n    return Status::OK();\n}\n</code></pre>"},{"location":"content_pipeline/#5-error-handling","title":"5. Error Handling","text":""},{"location":"content_pipeline/#51-fehler-kategorien","title":"5.1 Fehler-Kategorien","text":"Fehler HTTP-Code Ursache Recovery <code>Invalid Schema</code> 400 Fehlende Pflichtfelder (<code>content</code>, <code>chunks</code>) Client: Schema validieren <code>Duplicate Content</code> 409 <code>hash_sha256</code> bereits vorhanden Client: Dedup-Check vor Upload <code>Embedding Dimension Mismatch</code> 400 Embedding hat falsche Dimension Client: Modell-Version pr\u00fcfen <code>Storage Error</code> 500 RocksDB Write fehlgeschlagen Server: Retry mit Backoff <code>VectorIndex Error</code> 500 HNSW-Build fehlgeschlagen Server: Rebuild Index"},{"location":"content_pipeline/#52-status-objekt","title":"5.2 Status-Objekt","text":"<p>Alle ContentManager-Methoden geben <code>Status</code> zur\u00fcck:</p> <pre><code>struct Status {\n    bool ok = true;\n    std::string message;\n\n    static Status OK() { return {}; }\n    static Status Error(std::string msg) { return Status{false, std::move(msg)}; }\n};\n</code></pre> <p>Beispiel-Nutzung:</p> <pre><code>auto status = content_manager-&gt;importContent(spec, blob);\nif (!status.ok) {\n    THEMIS_ERROR(\"Import failed: {}\", status.message);\n    // Logging, Retry-Logik, Client-Notification\n}\n</code></pre>"},{"location":"content_pipeline/#53-deduplication","title":"5.3 Deduplication","text":"<p>Hash-basierte Dedup verhindert doppelte Speicherung:</p> <pre><code>Status ContentManager::importContent(const json&amp; spec, const std::optional&lt;std::string&gt;&amp; blob) {\n    ContentMeta meta = ContentMeta::fromJson(spec[\"content\"]);\n\n    // Dedup-Check via SecondaryIndex (hash_sha256)\n    auto existing = secondary_index_-&gt;get(\"hash_sha256\", meta.hash_sha256);\n    if (existing.has_value()) {\n        return Status{\n            .ok = true,\n            .message = \"Duplicate content (hash: \" + meta.hash_sha256 + \"), skipping import\"\n        };\n    }\n\n    // ... normal import\n}\n</code></pre>"},{"location":"content_pipeline/#6-graph-konstruktion","title":"6. Graph-Konstruktion","text":""},{"location":"content_pipeline/#61-edge-typen","title":"6.1 Edge-Typen","text":"<p>THEMIS konstruiert automatisch Edges f\u00fcr verschiedene Beziehungen:</p> Edge-Typ Bedeutung Beispiel <code>parent</code> Chunk geh\u00f6rt zu Content <code>chunk:uuid</code> \u2192 <code>content:uuid</code> <code>next</code> Sequentieller Nachfolger <code>chunk:1</code> \u2192 <code>chunk:2</code> <code>prev</code> Sequentieller Vorg\u00e4nger <code>chunk:2</code> \u2192 <code>chunk:1</code> <code>contains</code> Hierarchie (Assembly \u2192 Part) <code>content:assembly</code> \u2192 <code>content:part</code> <code>sibling</code> Gleiche Hierarchie-Ebene <code>chunk:part1</code> \u2192 <code>chunk:part2</code> <code>member_of</code> Geodaten: Feature geh\u00f6rt zu Region <code>chunk:poi</code> \u2192 <code>chunk:region</code> <code>spatially_near</code> Geodaten: R\u00e4umliche Nachbarschaft <code>chunk:poi1</code> \u2192 <code>chunk:poi2</code> (z.B. &lt; 1 km)"},{"location":"content_pipeline/#62-automatische-edge-generierung","title":"6.2 Automatische Edge-Generierung","text":"<p>Text-Chunks:</p> <pre><code>// parent + next/prev Edges\nfor (size_t i = 0; i &lt; chunks.size(); ++i) {\n    graph_index_-&gt;addEdge(chunks[i].id, content_id, \"parent\", 1.0);\n\n    if (i &gt; 0) {\n        graph_index_-&gt;addEdge(chunks[i].id, chunks[i-1].id, \"prev\", 1.0);\n    }\n    if (i &lt; chunks.size() - 1) {\n        graph_index_-&gt;addEdge(chunks[i].id, chunks[i+1].id, \"next\", 1.0);\n    }\n}\n</code></pre> <p>CAD-Assembly:</p> <pre><code>// contains + sibling Edges\nfor (const auto&amp; part_id : assembly_parts) {\n    graph_index_-&gt;addEdge(assembly_id, part_id, \"contains\", 1.0);\n\n    for (const auto&amp; sibling_id : assembly_parts) {\n        if (part_id != sibling_id) {\n            graph_index_-&gt;addEdge(part_id, sibling_id, \"sibling\", 0.5);\n        }\n    }\n}\n</code></pre> <p>Geodaten:</p> <pre><code>// member_of + spatially_near Edges\nfor (const auto&amp; poi : pois) {\n    std::string region = findRegion(poi.lat, poi.lon); // Spatial Join\n    graph_index_-&gt;addEdge(poi.id, region, \"member_of\", 1.0);\n\n    auto nearby = findNearbyPOIs(poi.lat, poi.lon, 1000.0); // 1 km Radius\n    for (const auto&amp; neighbor : nearby) {\n        double distance = haversineDistance(poi, neighbor);\n        double weight = 1.0 / (1.0 + distance); // N\u00e4her = h\u00f6heres Gewicht\n        graph_index_-&gt;addEdge(poi.id, neighbor.id, \"spatially_near\", weight);\n    }\n}\n</code></pre>"},{"location":"content_pipeline/#63-graph-expansion-rag","title":"6.3 Graph-Expansion (RAG)","text":"<p>Suche mit Kontext-Expansion:</p> <pre><code>std::vector&lt;std::pair&lt;std::string, float&gt;&gt; ContentManager::searchWithExpansion(\n    const std::string&amp; query_text,\n    int k,\n    int expansion_hops\n) {\n    // 1. Vektor-Suche: Top-K Chunks\n    auto embedding = generateQueryEmbedding(query_text);\n    auto top_k_chunks = vector_index_-&gt;search(embedding, k);\n\n    // 2. Graph-Expansion: Nachbarn via BFS\n    std::set&lt;std::string&gt; expanded_chunks;\n    for (const auto&amp; [chunk_id, score] : top_k_chunks) {\n        expanded_chunks.insert(chunk_id);\n\n        // BFS: expansion_hops Schritte\n        auto neighbors = graph_index_-&gt;bfs(chunk_id, expansion_hops, {\"next\", \"prev\", \"parent\", \"sibling\"});\n        for (const auto&amp; neighbor : neighbors) {\n            expanded_chunks.insert(neighbor);\n        }\n    }\n\n    // 3. Ergebnisse ranken (Original-Score beibehalten)\n    std::vector&lt;std::pair&lt;std::string, float&gt;&gt; results;\n    for (const auto&amp; chunk_id : expanded_chunks) {\n        auto it = std::find_if(top_k_chunks.begin(), top_k_chunks.end(),\n            [&amp;](const auto&amp; p) { return p.first == chunk_id; });\n\n        float score = (it != top_k_chunks.end()) ? it-&gt;second : 0.5; // Nachbarn mit reduziertem Score\n        results.push_back({chunk_id, score});\n    }\n\n    // 4. Nach Score sortieren\n    std::sort(results.begin(), results.end(),\n        [](const auto&amp; a, const auto&amp; b) { return a.second &gt; b.second; });\n\n    return results;\n}\n</code></pre>"},{"location":"content_pipeline/#7-embedding-strategien","title":"7. Embedding-Strategien","text":""},{"location":"content_pipeline/#71-embedding-modelle-pro-modalitat","title":"7.1 Embedding-Modelle pro Modalit\u00e4t","text":"Modalit\u00e4t Modell Dimension Beschreibung Text Sentence-Transformers (<code>all-MiniLM-L6-v2</code>) 768D Semantische Textsuche Bilder CLIP (<code>openai/clip-vit-base-patch32</code>) 512D Multi-modale (Bild + Text) Embeddings Geodaten Geo2Vec (Custom) 128D [lon, lat] \u2192 Vektor CAD PartNet / GraphSAINT (Custom) 256D Geometry + BOM \u2192 Vektor Audio Wav2Vec2 (<code>facebook/wav2vec2-base</code>) 768D Akustische Features Tabellen TaBERT / TAPAS (Custom) 768D Schema + Rows \u2192 Vektor"},{"location":"content_pipeline/#72-externe-embedding-services","title":"7.2 Externe Embedding-Services","text":"<p>Embeddings werden via HTTP-APIs generiert:</p> <p>Text-Embedding:</p> <pre><code>POST http://localhost:5000/embed\nContent-Type: application/json\n\n{\n  \"text\": \"This is a sample document.\"\n}\n\nResponse:\n{\n  \"embedding\": [0.123, -0.456, ..., 0.789],  // 768D\n  \"model\": \"all-MiniLM-L6-v2\"\n}\n</code></pre> <p>Batch-Embedding:</p> <pre><code>POST http://localhost:5000/embed/batch\nContent-Type: application/json\n\n{\n  \"texts\": [\"Doc 1\", \"Doc 2\", ..., \"Doc 100\"]\n}\n\nResponse:\n{\n  \"embeddings\": [\n    [0.1, 0.2, ...],\n    [0.3, 0.4, ...],\n    ...\n  ]\n}\n</code></pre>"},{"location":"content_pipeline/#73-hybrid-search","title":"7.3 Hybrid-Search","text":"<p>Kombination von Vektor- und Attributsuche:</p> <pre><code>std::vector&lt;std::pair&lt;std::string, float&gt;&gt; ContentManager::hybridSearch(\n    const std::string&amp; query_text,\n    const json&amp; filters,\n    int k\n) {\n    // 1. Vektor-Suche\n    auto embedding = generateQueryEmbedding(query_text);\n    auto vector_results = vector_index_-&gt;search(embedding, k * 2); // Oversampling\n\n    // 2. Filter auf Metadaten (SecondaryIndex)\n    std::vector&lt;std::pair&lt;std::string, float&gt;&gt; filtered_results;\n    for (const auto&amp; [chunk_id, score] : vector_results) {\n        auto chunk = getChunk(chunk_id);\n        if (!chunk.has_value()) continue;\n\n        // Filter anwenden\n        bool matches = true;\n        if (filters.contains(\"category\")) {\n            auto content = getContentMeta(chunk-&gt;content_id);\n            if (content-&gt;category != filters[\"category\"].get&lt;ContentCategory&gt;()) {\n                matches = false;\n            }\n        }\n        if (filters.contains(\"tags\")) {\n            auto content = getContentMeta(chunk-&gt;content_id);\n            auto required_tags = filters[\"tags\"].get&lt;std::vector&lt;std::string&gt;&gt;();\n            for (const auto&amp; tag : required_tags) {\n                if (std::find(content-&gt;tags.begin(), content-&gt;tags.end(), tag) == content-&gt;tags.end()) {\n                    matches = false;\n                    break;\n                }\n            }\n        }\n\n        if (matches) {\n            filtered_results.push_back({chunk_id, score});\n        }\n    }\n\n    // 3. Top-K zur\u00fcckgeben\n    filtered_results.resize(std::min(k, static_cast&lt;int&gt;(filtered_results.size())));\n    return filtered_results;\n}\n</code></pre>"},{"location":"content_pipeline/#8-http-api","title":"8. HTTP API","text":""},{"location":"content_pipeline/#81-endpoints","title":"8.1 Endpoints","text":"Endpoint Methode Beschreibung <code>/content/import</code> POST Import vorverarbeiteter Inhalte (Schema oben) <code>/content/:id</code> GET Content-Metadaten abrufen <code>/content/:id/blob</code> GET Original-Blob herunterladen <code>/content/:id/chunks</code> GET Alle Chunks eines Contents (sortiert) <code>/content/search</code> POST Semantische Suche (Query-Text + Filters) <code>/content/:id</code> DELETE Content + Chunks + Edges l\u00f6schen"},{"location":"content_pipeline/#82-beispiele","title":"8.2 Beispiele","text":"<p>Import:</p> <pre><code>POST /content/import\nContent-Type: application/json\n\n{\n  \"content\": {\n    \"id\": \"doc-123\",\n    \"mime_type\": \"text/plain\",\n    \"category\": \"TEXT\",\n    \"original_filename\": \"readme.txt\",\n    \"size_bytes\": 512,\n    \"hash_sha256\": \"abc...\",\n    \"created_at\": 1672531200,\n    \"tags\": [\"docs\"]\n  },\n  \"chunks\": [\n    {\n      \"id\": \"chunk-1\",\n      \"content_id\": \"doc-123\",\n      \"seq_num\": 0,\n      \"chunk_type\": \"text\",\n      \"text\": \"Introduction...\",\n      \"embedding\": [0.1, 0.2, ...]\n    }\n  ],\n  \"edges\": [\n    {\n      \"from\": \"chunk-1\",\n      \"to\": \"doc-123\",\n      \"type\": \"parent\"\n    }\n  ]\n}\n\nResponse:\n{\n  \"ok\": true,\n  \"content_id\": \"doc-123\",\n  \"chunks_created\": 1,\n  \"edges_created\": 1\n}\n</code></pre> <p>Suche:</p> <pre><code>POST /content/search\nContent-Type: application/json\n\n{\n  \"query\": \"machine learning tutorial\",\n  \"k\": 10,\n  \"filters\": {\n    \"category\": \"TEXT\",\n    \"tags\": [\"ai\"]\n  },\n  \"expansion_hops\": 1\n}\n\nResponse:\n{\n  \"results\": [\n    {\n      \"chunk_id\": \"chunk-42\",\n      \"content_id\": \"doc-ml-intro\",\n      \"score\": 0.87,\n      \"text\": \"Introduction to machine learning...\",\n      \"metadata\": {\"filename\": \"ml_intro.md\"}\n    },\n    ...\n  ]\n}\n</code></pre>"},{"location":"content_pipeline/#9-best-practices","title":"9. Best Practices","text":""},{"location":"content_pipeline/#91-chunking-richtlinien","title":"9.1 Chunking-Richtlinien","text":"<ul> <li>Text: 200\u2013400 Tokens (besserer Retrieval/Ranking-Tradeoff), 50 Tokens Overlap</li> <li>Audio/Video: 2\u201310 Sekunden pro Segment (annehmbare Granularit\u00e4t)</li> <li>Tabellen: 100\u2013500 Rows pro Batch (Balance zwischen Kontext und Performance)</li> <li>Geodaten: Ein Chunk pro Feature (GeoJSON), Spatial Aggregation bei Millionen Features</li> </ul>"},{"location":"content_pipeline/#92-embedding-optimierung","title":"9.2 Embedding-Optimierung","text":"<ul> <li>Batch-Processing: 100\u2013500 Embeddings pro Request (10x schneller als einzeln)</li> <li>GPU-Beschleunigung: Sentence-Transformers mit CUDA (5\u201310x Speedup)</li> <li>Embedding-Cache: Hash \u2192 Embedding speichern (Dedup vermeidet Re-Computation)</li> </ul>"},{"location":"content_pipeline/#93-storage-optimierung","title":"9.3 Storage-Optimierung","text":"<ul> <li>Inline vs. External Blobs:</li> <li>&lt; 1 MB: RocksDB (schneller Zugriff)</li> <li>&gt; 1 MB: Filesystem oder S3 (Blob-Ref in RocksDB)</li> <li>Kompression: Zstd f\u00fcr gro\u00dfe Blobs (3:1 Ratio bei Text, 1.5:1 bei Bin\u00e4r)</li> <li>TTL: Alte Inhalte automatisch l\u00f6schen (siehe <code>docs/base_entity.md</code>)</li> </ul>"},{"location":"content_pipeline/#94-modalitats-spezifische-guidelines","title":"9.4 Modalit\u00e4ts-spezifische Guidelines","text":"<p>Bilder:</p> <ul> <li>EXIF-Daten extrahieren (GPS, DateTime, Camera Model)</li> <li>OCR nur bei Bedarf (teuer!)</li> <li>Object Detection optional (YOLO, Detectron2)</li> <li>Captioning mit BLIP/GIT f\u00fcr Textsuche</li> </ul> <p>Geodaten:</p> <ul> <li>Normalisierung auf WGS84 (EPSG:4326) vor Import</li> <li>Bounding Box pre-compute f\u00fcr schnelle Spatial Queries</li> <li>Spatial Joins f\u00fcr <code>member_of</code> Edges (Punkt-in-Polygon-Tests)</li> </ul> <p>CAD:</p> <ul> <li>BOM-Extraktion via Open CASCADE oder STEP-Parser</li> <li>Geometrie-Hashing f\u00fcr Duplikaterkennung (Topology-Hash)</li> <li>Assembly-Hierarchie als <code>contains</code> Edges abbilden</li> </ul> <p>Tabellen:</p> <ul> <li>Schema-Inferenz (Datentypen, Prim\u00e4rschl\u00fcssel)</li> <li>Foreign-Key-Erkennung \u2192 <code>references</code> Edges</li> <li>Spalten-Normalisierung (z.B. Dates \u2192 ISO8601)</li> </ul>"},{"location":"content_pipeline/#10-performance-benchmarks","title":"10. Performance &amp; Benchmarks","text":""},{"location":"content_pipeline/#101-ingestion-throughput","title":"10.1 Ingestion-Throughput","text":"<p>Baseline (Sequentiell):</p> <ul> <li>Text (1 MB): ~2 s (Tokenization + Embedding)</li> <li>Image (5 MB): ~5 s (EXIF + CLIP-Embedding)</li> <li>Geodaten (10k Features): ~10 s (Parsing + Spatial Embeddings)</li> </ul> <p>Mit Batching:</p> <ul> <li>Text Batch (100 Docs): ~10 s (10x Speedup via Batch-Embedding)</li> <li>Image Batch (50 Images): ~15 s (3x Speedup via GPU-Batch)</li> </ul>"},{"location":"content_pipeline/#102-search-latenz","title":"10.2 Search-Latenz","text":"<ul> <li>Vektor-Suche (HNSW): 10\u201350 ms (1M Vektoren, k=10)</li> <li>Hybrid-Search (Vektor + Filter): 50\u2013100 ms (Filter auf 100k Entities)</li> <li>Graph-Expansion (1 Hop): +20 ms (BFS auf 100k Edges)</li> </ul>"},{"location":"content_pipeline/#103-storage-groe","title":"10.3 Storage-Gr\u00f6\u00dfe","text":"<ul> <li>RocksDB Overhead: ~30% (Metadata, Indexes)</li> <li>VectorIndex (HNSW): ~1.5x der Embedding-Gr\u00f6\u00dfe (Links + Metadata)</li> <li>GraphIndex: ~40 Bytes pro Edge (From + To + Type + Weight)</li> </ul> <p>Beispiel: 1 Million Text-Chunks (768D Embeddings)</p> <ul> <li>RocksDB (Metadata): ~500 MB</li> <li>VectorIndex (Embeddings): 1M * 768 * 4 Bytes * 1.5 = ~4.5 GB</li> <li>GraphIndex (2 Edges/Chunk): 2M * 40 Bytes = ~80 MB</li> <li>Total: ~5 GB</li> </ul>"},{"location":"content_pipeline/#11-testing","title":"11. Testing","text":""},{"location":"content_pipeline/#111-unit-tests-pro-processor","title":"11.1 Unit-Tests (pro Processor)","text":"<pre><code>TEST(TextProcessorTest, ExtractsTextFromPlainText) {\n    TextProcessor processor;\n    std::string blob = \"Hello, world!\";\n    ContentType type = {.mime_type=\"text/plain\", .category=ContentCategory::TEXT};\n\n    auto result = processor.extract(blob, type);\n\n    ASSERT_TRUE(result.ok);\n    EXPECT_EQ(result.text, \"Hello, world!\");\n}\n\nTEST(ImageProcessorTest, ExtractsEXIF) {\n    ImageProcessor processor;\n    std::string blob = loadTestImage(\"test_photo.jpg\");\n    ContentType type = {.mime_type=\"image/jpeg\", .category=ContentCategory::IMAGE};\n\n    auto result = processor.extract(blob, type);\n\n    ASSERT_TRUE(result.ok);\n    EXPECT_TRUE(result.metadata.contains(\"exif\"));\n    EXPECT_EQ(result.metadata[\"exif\"][\"Make\"], \"Canon\");\n}\n</code></pre>"},{"location":"content_pipeline/#112-integration-tests","title":"11.2 Integration-Tests","text":"<pre><code>TEST(ContentManagerTest, ImportTextDocumentEndToEnd) {\n    auto storage = std::make_shared&lt;RocksDBWrapper&gt;(\"./test_db\");\n    auto vector_index = std::make_shared&lt;VectorIndexManager&gt;(storage, 768);\n    auto graph_index = std::make_shared&lt;GraphIndexManager&gt;(storage);\n    auto secondary_index = std::make_shared&lt;SecondaryIndexManager&gt;(storage);\n\n    ContentManager manager(storage, vector_index, graph_index, secondary_index);\n\n    json spec = {\n        {\"content\", {\n            {\"id\", \"test-doc\"},\n            {\"mime_type\", \"text/plain\"},\n            {\"category\", \"TEXT\"},\n            {\"original_filename\", \"test.txt\"},\n            {\"size_bytes\", 100},\n            {\"hash_sha256\", \"hash123\"},\n            {\"created_at\", 1672531200}\n        }},\n        {\"chunks\", json::array({\n            {{\"id\", \"chunk-1\"}, {\"content_id\", \"test-doc\"}, {\"seq_num\", 0}, {\"chunk_type\", \"text\"}, {\"text\", \"Hello\"}, {\"embedding\", std::vector&lt;float&gt;(768, 0.1)}}\n        })},\n        {\"edges\", json::array({\n            {{\"from\", \"chunk-1\"}, {\"to\", \"test-doc\"}, {\"type\", \"parent\"}}\n        })}\n    };\n\n    auto status = manager.importContent(spec, std::nullopt);\n\n    ASSERT_TRUE(status.ok);\n\n    // Verify metadata stored\n    auto meta = manager.getContentMeta(\"test-doc\");\n    ASSERT_TRUE(meta.has_value());\n    EXPECT_EQ(meta-&gt;mime_type, \"text/plain\");\n\n    // Verify chunks stored\n    auto chunks = manager.getContentChunks(\"test-doc\");\n    EXPECT_EQ(chunks.size(), 1);\n\n    // Verify graph edges\n    auto neighbors = graph_index-&gt;getOutNeighbors(\"chunk-1\");\n    EXPECT_EQ(neighbors.size(), 1); // Has 'parent' edge\n}\n</code></pre>"},{"location":"content_pipeline/#113-performance-benchmarks","title":"11.3 Performance-Benchmarks","text":"<pre><code>static void BM_ImportLargeDocument(benchmark::State&amp; state) {\n    ContentManager manager(/* ... */);\n\n    std::string large_text(10 * 1024 * 1024, 'A'); // 10 MB\n    json spec = createTestSpec(large_text, 512, 50); // 512 Tokens/Chunk, 50 Overlap\n\n    for (auto _ : state) {\n        manager.importContent(spec, std::nullopt);\n    }\n}\nBENCHMARK(BM_ImportLargeDocument);\n\nstatic void BM_HybridSearch(benchmark::State&amp; state) {\n    ContentManager manager(/* ... */);\n    // ... populate with 100k documents\n\n    for (auto _ : state) {\n        manager.hybridSearch(\"machine learning\", {{\"category\", \"TEXT\"}}, 10);\n    }\n}\nBENCHMARK(BM_HybridSearch);\n</code></pre>"},{"location":"content_pipeline/#12-roadmap","title":"12. Roadmap","text":""},{"location":"content_pipeline/#mvp-10-aktuell","title":"MVP 1.0 (Aktuell)","text":"<ul> <li>[x] ContentTypeRegistry + ContentCategory</li> <li>[x] TextProcessor (Extraction, Chunking, Embedding via Mock)</li> <li>[x] ContentManager::importContent() (kanonisches Schema)</li> <li>[x] HTTP Endpoint: POST /content/import</li> <li>[x] BasicTests (Unit + Integration)</li> </ul>"},{"location":"content_pipeline/#mvp-20-geplant","title":"MVP 2.0 (Geplant)","text":"<ul> <li>[ ] ImageProcessor (EXIF + CLIP-Embedding via external service)</li> <li>[ ] GeoProcessor (GeoJSON + Geo2Vec)</li> <li>[ ] CADProcessor (STEP + PartNet-Embedding)</li> <li>[ ] Batch-Import (POST /content/import/batch)</li> <li>[ ] Hybrid-Search (Vektor + Filter)</li> <li>[ ] Graph-Expansion (BFS mit <code>next</code>, <code>prev</code>, <code>contains</code>)</li> </ul>"},{"location":"content_pipeline/#future-post-mvp","title":"Future (Post-MVP)","text":"<ul> <li>[ ] AudioProcessor (ID3 + Wav2Vec2 + Whisper ASR)</li> <li>[ ] StructuredProcessor (CSV/Parquet + TaBERT)</li> <li>[ ] Async-Ingestion (Job-Queue mit Status-Tracking)</li> <li>[ ] External Blob-Storage (S3-Anbindung)</li> <li>[ ] Multi-Hop Graph-Reasoning (z.B. \"Show CAD parts from same supplier\")</li> <li>[ ] Federated Search (Multi-Tenant mit Access Control)</li> </ul>"},{"location":"content_pipeline/#13-fazit","title":"13. Fazit","text":"<p>Die Content Pipeline bietet eine skalierbare, erweiterbare Architektur f\u00fcr heterogene Datentypen. Durch die Trennung von generischen Operationen (Hashing, Graph-Erstellung) und typ-spezifischer Verarbeitung (via Processors) bleibt das System wartbar und einfach erweiterbar.</p> <p>Key Benefits:</p> <ul> <li>Einheitliche API: Ein Import-Endpoint f\u00fcr alle Datentypen</li> <li>Wiederverwendbare Komponenten: Chunking, Graph-Erstellung, Deduplication</li> <li>Typ-Sicherheit: ContentTypeRegistry verhindert falsche Verarbeitung</li> <li>Produktivit\u00e4t: Neue Datentypen in &lt; 1 Tag integrierbar (nur Processor implementieren)</li> <li>RAG-Ready: Graph-Expansion f\u00fcr kontextuelle Suche out-of-the-box</li> <li>Performance: Batching, GPU-Embeddings, HNSW-Index f\u00fcr Millionen Vektoren</li> </ul> <p>Weiterf\u00fchrende Dokumentation:</p> <ul> <li>Content Architecture - Design-Details der Prozessor-Architektur</li> <li>Ingestion Guidelines - Modalit\u00e4ts-spezifische Vorverarbeitungs-Empfehlungen</li> <li>Vector Index - HNSW-Algorithmus und Tuning-Parameter</li> <li>Graph Index - BFS/DFS-Traversierung und Edge-Typen</li> <li>AQL Syntax - Hybrid-Queries mit <code>VECTOR_KNN()</code> und <code>GRAPH_EXPAND()</code></li> </ul>"},{"location":"cursor_pagination/","title":"Cursor-Based Pagination in Themis","text":""},{"location":"cursor_pagination/#overview","title":"Overview","text":"<p>Themis unterst\u00fctzt Cursor-basierte Pagination f\u00fcr AQL-Queries. Dabei wird auf Index-Ebene ein effizienter Startpunkt gesetzt (Start-after/Start-before), statt gro\u00dfe Offsets zu \u00fcberspringen.</p>"},{"location":"cursor_pagination/#how-it-works-engine","title":"How it works (Engine)","text":"<ul> <li>ORDER BY \u00fcber eine Range-indexierte Spalte aktiviert einen indexbasierten Scan in Sortierreihenfolge.</li> <li>Der Cursor enth\u00e4lt den Primary Key der zuletzt gelieferten Entity. Der Server l\u00e4dt die Entity und extrahiert den Wert der Sortierspalte, um einen Anchor (value, pk) zu bilden.</li> <li>Asc (ASC): Start strictly after (value, pk) \u2013 Eintr\u00e4ge mit demselben Sortwert und h\u00f6herem PK kommen danach.</li> <li>Desc (DESC): Start strictly before (value, pk) \u2013 Eintr\u00e4ge mit demselben Sortwert und niedrigerem PK kommen davor.</li> <li>F\u00fcr die Erkennung von <code>has_more</code> wird <code>LIMIT</code> intern als <code>count + 1</code> an die Engine \u00fcbergeben und im HTTP-Pfad wieder auf <code>count</code> beschnitten.</li> </ul> <p>Diese Logik vermeidet das O(N)-Skipping gro\u00dfer Offsets und skaliert stabil \u00fcber gro\u00dfe Datenmengen.</p>"},{"location":"cursor_pagination/#http-api","title":"HTTP API","text":""},{"location":"cursor_pagination/#request-parameters","title":"Request Parameters","text":"<p>To enable cursor-based pagination, include the following parameters in your AQL query request:</p> <pre><code>{\n  \"query\": \"FOR user IN users SORT user.name ASC LIMIT 10 RETURN user\",\n  \"use_cursor\": true,\n  \"cursor\": \"optional_cursor_token_from_previous_response\"\n}\n</code></pre> <p>Parameters: - <code>use_cursor</code> (boolean): Set to <code>true</code> to enable cursor pagination - <code>cursor</code> (string, optional): Token from previous response's <code>next_cursor</code> field to continue pagination</p>"},{"location":"cursor_pagination/#response-format","title":"Response Format","text":"<p>When <code>use_cursor</code> is enabled, the response format changes from the standard format to:</p> <pre><code>{\n  \"items\": [ /* array of result entities */ ],\n  \"has_more\": true,\n  \"next_cursor\": \"base64_encoded_cursor_token\",\n  \"batch_size\": 10\n}\n</code></pre> <p>Response Fields: - <code>items</code>: Array of result entities (same format as standard <code>entities</code> field) - <code>has_more</code>: Boolean indicating if more results are available - <code>next_cursor</code>: Cursor token to use for fetching the next page (only present if <code>has_more</code> is true) - <code>batch_size</code>: Number of items in the current batch</p>"},{"location":"cursor_pagination/#standard-response-format-without-cursor","title":"Standard Response Format (without cursor)","text":"<p>Without <code>use_cursor</code>, the response uses the traditional format:</p> <pre><code>{\n  \"table\": \"users\",\n  \"count\": 10,\n  \"entities\": [ /* array of result entities */ ]\n}\n</code></pre>"},{"location":"cursor_pagination/#example-usage","title":"Example Usage","text":""},{"location":"cursor_pagination/#first-page","title":"First Page","text":"<pre><code>curl -X POST http://localhost:8080/query/aql \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"FOR user IN users SORT user.name ASC LIMIT 10 RETURN user\",\n    \"use_cursor\": true\n  }'\n</code></pre> <p>Response:</p> <pre><code>{\n  \"items\": [\n    {\"_key\": \"alice\", \"name\": \"Alice\", \"age\": \"25\"},\n    {\"_key\": \"bob\", \"name\": \"Bob\", \"age\": \"30\"},\n    ...\n  ],\n  \"has_more\": true,\n  \"next_cursor\": \"eyJwayI6ImJvYiIsImNvbGxlY3Rpb24iOiJ1c2VycyIsInZlcnNpb24iOjF9\",\n  \"batch_size\": 10\n}\n</code></pre>"},{"location":"cursor_pagination/#subsequent-pages","title":"Subsequent Pages","text":"<p>Use the <code>next_cursor</code> from the previous response:</p> <pre><code>curl -X POST http://localhost:8080/query/aql \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"FOR user IN users SORT user.name ASC LIMIT 10 RETURN user\",\n    \"use_cursor\": true,\n    \"cursor\": \"eyJwayI6ImJvYiIsImNvbGxlY3Rpb24iOiJ1c2VycyIsInZlcnNpb24iOjF9\"\n  }'\n</code></pre>"},{"location":"cursor_pagination/#last-page","title":"Last Page","text":"<p>When there are no more results, <code>has_more</code> will be <code>false</code> and <code>next_cursor</code> will not be present:</p> <pre><code>{\n  \"items\": [\n    {\"_key\": \"zack\", \"name\": \"Zack\", \"age\": \"28\"}\n  ],\n  \"has_more\": false,\n  \"batch_size\": 1\n}\n</code></pre>"},{"location":"cursor_pagination/#cursor-format","title":"Cursor Format","text":"<p>Cursors are Base64-encoded JSON objects containing: - <code>pk</code>: Primary key of the last item in the current page - <code>collection</code>: Name of the collection being queried - <code>version</code>: Cursor format version (for future compatibility)</p> <p>Example decoded cursor:</p> <pre><code>{\n  \"pk\": \"users:bob\",\n  \"collection\": \"users\",\n  \"version\": 1\n}\n</code></pre>"},{"location":"cursor_pagination/#edge-cases-semantics","title":"Edge Cases &amp; Semantics","text":"<ul> <li>Ties (gleicher Sortwert): Reihenfolge ist deterministisch durch PK-Tiebreaker. Cursor-Anker verwendet (value, pk), dadurch keine Duplikate/\u00dcberspr\u00fcnge zwischen Seiten.</li> <li>DESC-Reihenfolge: Start-before-Verhalten spiegelt die absteigende Sortierung korrekt wider, <code>has_more</code> wird via <code>count+1</code> erkannt.</li> <li>Kombination mit Filtern: Cursor-Position respektiert die aktive Filtermenge; Seiten sind konsistent mit den Filterbedingungen.</li> <li>Ung\u00fcltiger Cursor: Der Server antwortet mit HTTP 400 (Bad Request) und einer Fehlernachricht.</li> </ul>"},{"location":"cursor_pagination/#notes-limitations","title":"Notes &amp; Limitations","text":"<ul> <li>F\u00fcr Cursor-Pagination ist eine sortierende Spalte mit Range-Index empfohlen, damit der indexbasierte Scan greift.</li> <li>Ohne ORDER BY kann <code>use_cursor</code> verwendet werden, jedoch ist die Ordnung dann implizit nach PK; f\u00fcr reproduzierbares Paging wird eine Sortierung empfohlen.</li> </ul>"},{"location":"cursor_pagination/#error-handling","title":"Error Handling","text":""},{"location":"cursor_pagination/#invalid-cursor","title":"Invalid Cursor","text":"<p>If an invalid or expired cursor token is provided, the server returns a 400 Bad Request:</p> <pre><code>{\n  \"error\": \"Invalid or expired cursor\"\n}\n</code></pre>"},{"location":"cursor_pagination/#collection-mismatch","title":"Collection Mismatch","text":"<p>If the cursor was generated for a different collection, the server returns a 400 Bad Request:</p> <pre><code>{\n  \"error\": \"Cursor collection mismatch (expected: users, got: products)\"\n}\n</code></pre>"},{"location":"cursor_pagination/#best-practices","title":"Best Practices","text":"<ol> <li>Always check <code>has_more</code>: Don't assume there are more results based on batch size alone</li> <li>Store cursors short-term: Cursors are stateless but may become invalid if underlying data changes significantly</li> <li>Use consistent queries: The same query should be used across pagination requests (same SORT, FILTER, etc.)</li> <li>Handle errors gracefully: If a cursor becomes invalid, restart pagination from the beginning</li> <li>Combine with LIMIT: Use reasonable LIMIT values to control page size (recommended: 10-100 items)</li> </ol>"},{"location":"cursor_pagination/#comparison-with-offset-pagination","title":"Comparison with Offset Pagination","text":"Aspect Cursor-Based Offset-Based Performance O(1) resume O(N) skip Consistency Stable across pages May skip/duplicate if data changes Stateless Yes (token-based) Yes Use Case Large datasets, real-time data Small datasets, random access Current Support \u2705 Implemented \u2705 Implemented"},{"location":"cursor_pagination/#see-also","title":"See Also","text":"<ul> <li>AQL Syntax Guide</li> <li>AQL EXPLAIN/PROFILE</li> <li>HTTP API Reference</li> </ul>"},{"location":"deployment/","title":"THEMIS Deployment Guide","text":""},{"location":"deployment/#table-of-contents","title":"Table of Contents","text":"<ol> <li>System Requirements</li> <li>Installation Methods</li> <li>Configuration</li> <li>Production Deployment</li> <li>Monitoring &amp; Observability</li> <li>Backup &amp; Recovery</li> <li>Performance Tuning</li> <li>Security</li> <li>Troubleshooting</li> </ol>"},{"location":"deployment/#system-requirements","title":"System Requirements","text":""},{"location":"deployment/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>CPU: 4 cores (x86_64 or ARM64)</li> <li>RAM: 2 GB (1 GB for RocksDB, 1 GB for system/buffers)</li> <li>Disk: 20 GB SSD (NVMe recommended)</li> <li>OS: Windows 10/11, Linux (Ubuntu 20.04+, RHEL 8+), macOS 12+</li> <li>Network: 1 Gbps (for distributed deployments)</li> </ul>"},{"location":"deployment/#recommended-requirements","title":"Recommended Requirements","text":"<ul> <li>CPU: 8+ cores (Intel Xeon, AMD EPYC, or Apple Silicon M-series)</li> <li>RAM: 8 GB (4 GB block cache, 1 GB memtable, 3 GB system)</li> <li>Disk: 100 GB+ NVMe SSD (read: 3000 MB/s, write: 1500 MB/s)</li> <li>OS: Linux (kernel 5.10+) for production workloads</li> <li>Network: 10 Gbps (low-latency network for replication)</li> </ul>"},{"location":"deployment/#installation-methods","title":"Installation Methods","text":""},{"location":"deployment/#method-1-binary-release-recommended-for-production","title":"Method 1: Binary Release (Recommended for Production)","text":"<pre><code># Download latest release\nwget https://github.com/&lt;org&gt;/vccdb/releases/download/v1.0.0/vccdb-linux-x64.tar.gz\n\n# Extract\ntar -xzf vccdb-linux-x64.tar.gz\ncd vccdb\n\n# Verify installation\n./themis_server --version\n# Output: THEMIS v1.0.0 (build: 2025-10-28, commit: abc1234)\n</code></pre>"},{"location":"deployment/#method-2-docker-recommended-for-containers","title":"Method 2: Docker (Recommended for Containers)","text":"<pre><code># Pull image\ndocker pull vccdb/vccdb:latest\n\n# Run with persistent storage\ndocker run -d \\\n  --name vccdb \\\n  -p 8765:8765 \\\n  -v $(pwd)/data:/data \\\n  -v $(pwd)/config.json:/etc/vccdb/config.json \\\n  vccdb/vccdb:latest\n\n# Check logs\ndocker logs -f vccdb\n</code></pre>"},{"location":"deployment/#method-3-build-from-source-development","title":"Method 3: Build from Source (Development)","text":"<pre><code># Windows (PowerShell)\ngit clone https://github.com/&lt;org&gt;/vccdb.git\ncd vccdb\n.\\setup.ps1      # Install vcpkg dependencies\n.\\build.ps1      # Build Release binaries\n</code></pre> <pre><code># Linux/macOS (Bash)\ngit clone https://github.com/&lt;org&gt;/vccdb.git\ncd vccdb\n./setup.sh       # Install dependencies\n./build.sh       # Build Release binaries\n</code></pre>"},{"location":"deployment/#configuration","title":"Configuration","text":""},{"location":"deployment/#basic-configuration-configjson","title":"Basic Configuration (<code>config.json</code>)","text":"<pre><code>{\n  \"storage\": {\n    \"rocksdb_path\": \"/var/lib/vccdb/data\",\n    \"memtable_size_mb\": 256,\n    \"block_cache_size_mb\": 1024,\n    \"max_open_files\": 10000,\n    \"enable_statistics\": true,\n    \"compression\": {\n      \"default\": \"lz4\",\n      \"bottommost\": \"zstd\"\n    }\n  },\n  \"server\": {\n    \"host\": \"0.0.0.0\",\n    \"port\": 8765,\n    \"worker_threads\": 8,\n    \"request_timeout_ms\": 30000,\n    \"max_request_size_mb\": 10\n  },\n  \"logging\": {\n    \"level\": \"info\",\n    \"file\": \"/var/log/vccdb/server.log\",\n    \"rotation_size_mb\": 100,\n    \"max_files\": 10\n  },\n  \"vector_index\": {\n    \"engine\": \"hnsw\",\n    \"hnsw_m\": 16,\n    \"hnsw_ef_construction\": 200,\n    \"use_gpu\": false\n  }\n}\n</code></pre>"},{"location":"deployment/#environment-variables","title":"Environment Variables","text":"<p>Override config values with environment variables:</p> <pre><code>export THEMIS_SERVER_PORT=9000\nexport THEMIS_STORAGE_PATH=/mnt/nvme/vccdb\nexport THEMIS_LOG_LEVEL=debug\nexport THEMIS_WORKER_THREADS=16\n\n./themis_server --config config.json\n# Port 9000, custom storage path, debug logging, 16 threads\n</code></pre>"},{"location":"deployment/#configuration-validation","title":"Configuration Validation","text":"<pre><code># Validate config before starting server\n./themis_server --config config.json --validate\n\n# Output:\n# \u2713 Config file valid\n# \u2713 Storage path accessible: /var/lib/vccdb/data\n# \u2713 Port 8765 available\n# \u2713 Memory limits: memtable (256 MB) + block_cache (1024 MB) = 1280 MB\n# \u2713 Worker threads: 8 (optimal for 8-core CPU)\n</code></pre>"},{"location":"deployment/#runtime-configuration-hot-reload","title":"Runtime Configuration (Hot-Reload)","text":"<p>THEMIS supports hot-reload for specific configuration values without requiring a server restart.</p>"},{"location":"deployment/#supported-hot-reload-settings","title":"Supported Hot-Reload Settings","text":"<p>The following settings can be updated at runtime via <code>POST /config</code>:</p> <ol> <li>Logging Configuration</li> <li><code>logging.level</code>: \"trace\", \"debug\", \"info\", \"warn\", \"error\"</li> <li> <p><code>logging.format</code>: \"text\" (human-readable), \"json\" (structured logs for aggregation)</p> </li> <li> <p>Request Timeout</p> </li> <li> <p><code>request_timeout_ms</code>: 1000-300000 (1 second to 5 minutes)</p> </li> <li> <p>Feature Flags (Beta features)</p> </li> <li><code>features.semantic_cache</code>: Enable/disable semantic query caching</li> <li><code>features.llm_store</code>: Enable/disable LLM interaction storage</li> <li><code>features.cdc</code>: Enable/disable Change Data Capture streaming</li> <li> <p><code>features.timeseries</code>: Enable/disable time-series data store</p> </li> <li> <p>CDC Retention Policy (Logging only - requires manual cleanup)</p> </li> <li><code>cdc_retention_hours</code>: 1-8760 (1 hour to 1 year)</li> </ol>"},{"location":"deployment/#hot-reload-examples","title":"Hot-Reload Examples","text":"<p>Example 1: Enable JSON Logging</p> <pre><code>curl -X POST http://localhost:8765/config \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"logging\": {\n      \"level\": \"info\",\n      \"format\": \"json\"\n    }\n  }'\n\n# Response: Updated config with all current settings\n# Server logs now output structured JSON\n</code></pre> <p>Example 2: Update Request Timeout</p> <pre><code>curl -X POST http://localhost:8765/config \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"request_timeout_ms\": 60000\n  }'\n\n# Timeout increased to 60 seconds for long-running queries\n</code></pre> <p>Example 3: Enable CDC Feature</p> <pre><code>curl -X POST http://localhost:8765/config \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"features\": {\n      \"cdc\": true\n    }\n  }'\n\n# CDC streaming endpoints now accessible: /changefeed/stream\n</code></pre> <p>Example 4: Multiple Settings at Once</p> <pre><code>curl -X POST http://localhost:8765/config \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"logging\": {\n      \"level\": \"debug\",\n      \"format\": \"json\"\n    },\n    \"request_timeout_ms\": 45000,\n    \"features\": {\n      \"semantic_cache\": true,\n      \"cdc\": true\n    }\n  }'\n</code></pre>"},{"location":"deployment/#limitations","title":"Limitations","text":"<p>Cannot be changed at runtime (requires restart):</p> <ul> <li><code>server.port</code>: HTTP server port</li> <li><code>server.threads</code>: Number of worker threads (thread pool is fixed at startup)</li> <li><code>rocksdb.*</code>: All RocksDB storage settings (memtable size, block cache, compression, etc.)</li> <li><code>vector.dimension</code>: Vector index dimensionality</li> <li>Data directory paths</li> </ul> <p>Validation Rules:</p> <ul> <li><code>request_timeout_ms</code>: Must be between 1000 and 300000 (1s-5min)</li> <li><code>cdc_retention_hours</code>: Must be between 1 and 8760 (1h-1yr)</li> <li>Feature flags: Boolean values only</li> </ul>"},{"location":"deployment/#verify-current-configuration","title":"Verify Current Configuration","text":"<pre><code># GET current config\ncurl http://localhost:8765/config | jq .\n\n# Output includes all settings (read-only + hot-reload capable)\n{\n  \"server\": {\n    \"port\": 8765,\n    \"threads\": 8,\n    \"request_timeout_ms\": 30000\n  },\n  \"features\": {\n    \"semantic_cache\": false,\n    \"llm_store\": false,\n    \"cdc\": true,\n    \"timeseries\": false\n  },\n  \"rocksdb\": {\n    \"db_path\": \"/var/lib/vccdb/data\",\n    \"memtable_size_mb\": 256,\n    ...\n  }\n}\n</code></pre>"},{"location":"deployment/#production-deployment","title":"Production Deployment","text":""},{"location":"deployment/#systemd-service-linux","title":"Systemd Service (Linux)","text":"<p>Create <code>/etc/systemd/system/vccdb.service</code>:</p> <pre><code>[Unit]\nDescription=THEMIS Multi-Model Database Server\nAfter=network.target\n\n[Service]\nType=simple\nUser=vccdb\nGroup=vccdb\nWorkingDirectory=/opt/vccdb\nExecStart=/opt/vccdb/themis_server --config /etc/vccdb/config.json\nRestart=on-failure\nRestartSec=10\n\n# Security hardening\nNoNewPrivileges=true\nPrivateTmp=true\nProtectSystem=strict\nProtectHome=true\nReadWritePaths=/var/lib/vccdb /var/log/vccdb\n\n# Resource limits\nLimitNOFILE=65536\nMemoryMax=8G\nCPUQuota=800%\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <pre><code># Enable and start service\nsudo systemctl daemon-reload\nsudo systemctl enable vccdb\nsudo systemctl start vccdb\n\n# Check status\nsudo systemctl status vccdb\nsudo journalctl -u vccdb -f\n</code></pre>"},{"location":"deployment/#docker-compose-container-orchestration","title":"Docker Compose (Container Orchestration)","text":"<p>Hinweis zu Ports: - Der mitgelieferte <code>docker-compose.yml</code> im Repository nutzt standardm\u00e4\u00dfig Port <code>8080</code> (Mapping <code>8080:8080</code>). - In den Beispielen dieses Guides wird Port <code>8765</code> verwendet. Passe den Port in Compose entsprechend an (oder setze <code>THEMIS_PORT</code>).</p> <p>Create <code>docker-compose.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  vccdb:\n    image: vccdb/vccdb:latest\n    container_name: vccdb\n    ports:\n  - \"8765:8765\"  # ggf. zu \"8080:8080\" anpassen, wenn Image/Entrypoint 8080 nutzt\n    volumes:\n      - vccdb-data:/data\n      - ./config.json:/etc/vccdb/config.json:ro\n    environment:\n      - THEMIS_LOG_LEVEL=info\n      - THEMIS_WORKER_THREADS=8\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8765/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n    deploy:\n      resources:\n        limits:\n          cpus: '8'\n          memory: 8G\n        reservations:\n          cpus: '4'\n          memory: 4G\n\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro\n      - prometheus-data:/prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--storage.tsdb.retention.time=30d'\n\n  grafana:\n    image: grafana/grafana:latest\n    ports:\n      - \"3000:3000\"\n    volumes:\n      - grafana-data:/var/lib/grafana\n      - ./grafana-dashboards:/etc/grafana/provisioning/dashboards:ro\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=admin\n      - GF_INSTALL_PLUGINS=grafana-piechart-panel\n\nvolumes:\n  vccdb-data:\n  prometheus-data:\n  grafana-data:\n</code></pre> <pre><code># Start stack\ndocker-compose up -d\n\n# View logs\ndocker-compose logs -f vccdb\n\n# Scale (if using load balancer)\ndocker-compose up -d --scale vccdb=3\n</code></pre>"},{"location":"deployment/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>Create <code>k8s/deployment.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: vccdb-config\ndata:\n  config.json: |\n    {\n      \"storage\": {\n        \"rocksdb_path\": \"/data/vccdb\",\n        \"memtable_size_mb\": 512,\n        \"block_cache_size_mb\": 2048\n      },\n      \"server\": {\n        \"host\": \"0.0.0.0\",\n        \"port\": 8765,\n        \"worker_threads\": 16\n      }\n    }\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: vccdb-data\nspec:\n  accessModes:\n    - ReadWriteOnce\n  storageClassName: fast-ssd\n  resources:\n    requests:\n      storage: 100Gi\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: vccdb\n  labels:\n    app: vccdb\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: vccdb\n  template:\n    metadata:\n      labels:\n        app: vccdb\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"8765\"\n        prometheus.io/path: \"/metrics\"\n    spec:\n      containers:\n      - name: vccdb\n        image: vccdb/vccdb:latest\n        ports:\n        - containerPort: 8765\n          name: http\n        volumeMounts:\n        - name: data\n          mountPath: /data\n        - name: config\n          mountPath: /etc/vccdb\n          readOnly: true\n        resources:\n          requests:\n            cpu: 4000m\n            memory: 8Gi\n          limits:\n            cpu: 8000m\n            memory: 16Gi\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8765\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 8765\n          initialDelaySeconds: 5\n          periodSeconds: 5\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: vccdb-data\n      - name: config\n        configMap:\n          name: vccdb-config\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: vccdb\n  labels:\n    app: vccdb\nspec:\n  type: ClusterIP\n  ports:\n  - port: 8765\n    targetPort: 8765\n    protocol: TCP\n    name: http\n  selector:\n    app: vccdb\n</code></pre> <pre><code># Deploy to Kubernetes\nkubectl apply -f k8s/deployment.yaml\n\n# Check status\nkubectl get pods -l app=vccdb\nkubectl logs -l app=vccdb -f\n\n# Expose externally (LoadBalancer)\nkubectl expose deployment vccdb --type=LoadBalancer --port=8765\n</code></pre>"},{"location":"deployment/#monitoring-observability","title":"Monitoring &amp; Observability","text":""},{"location":"deployment/#reverse-proxy-und-ssekeep-alive-hinweise","title":"Reverse Proxy und SSE/Keep-Alive Hinweise","text":"<p>Server\u2011Sent Events (SSE) nutzen eine langlebige HTTP/1.1\u2011Verbindung mit kontinuierlichen Datenfl\u00fcssen. F\u00fcr stabile Streams sollten Reverse Proxies und Load Balancer speziell konfiguriert werden:</p> <ul> <li>HTTP/1.1 erzwingen und Keep\u2011Alive aktiv halten</li> <li>Timeouts gro\u00dfz\u00fcgig setzen (Lese\u2011/Idle\u2011Timeout \u2265 60s)</li> <li>Pufferung und Komprimierung f\u00fcr SSE deaktivieren</li> <li>Sticky Sessions/Session Affinity aktivieren, wenn mehrere Backend\u2011Instanzen genutzt werden</li> </ul> <p>Beispiele:</p> <p>1) Nginx</p> <pre><code>location /changefeed/stream {\n  proxy_http_version 1.1;\n  proxy_set_header Connection \"\";           # Keep-Alive nicht explizit schlie\u00dfen\n  proxy_set_header Cache-Control no-cache;\n  proxy_buffering off;                       # wichtig f\u00fcr SSE\n  gzip off;                                  # keine Komprimierung f\u00fcr SSE\n  chunked_transfer_encoding on;\n  proxy_read_timeout 120s;                   # ausreichend hoch\n  proxy_send_timeout 120s;\n}\n</code></pre> <p>2) HAProxy</p> <pre><code>frontend http\n  bind *:80\n  default_backend app\n\nbackend app\n  option http-keep-alive\n  option http-server-close          # optional je nach Setup\n  timeout server  120s\n  timeout client  120s\n  timeout http-keep-alive 120s\n  http-response set-header Cache-Control no-cache\n</code></pre> <p>3) Windows/IIS (Beispielauszug web.config)</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;configuration&gt;\n  &lt;system.webServer&gt;\n    &lt;httpProtocol&gt;\n      &lt;customHeaders&gt;\n        &lt;add name=\"Cache-Control\" value=\"no-cache\" /&gt;\n      &lt;/customHeaders&gt;\n    &lt;/httpProtocol&gt;\n    &lt;serverRuntime frequentHitThreshold=\"1\" frequentHitTimePeriod=\"00:00:10\" /&gt;\n    &lt;httpCompression directory=\"%SystemDrive%\\\\inetpub\\\\temp\\\\IIS Temporary Compressed Files\"&gt;\n      &lt;dynamicTypes&gt;\n        &lt;add enabled=\"false\" mimeType=\"text/event-stream\" /&gt;\n      &lt;/dynamicTypes&gt;\n    &lt;/httpCompression&gt;\n    &lt;handlers&gt;\n      &lt;add name=\"SSE\" path=\"changefeed/stream\" verb=\"GET\" modules=\"IsapiModule\" scriptProcessor=\"%windir%\\\\system32\\\\inetsrv\\\\asp.dll\" resourceType=\"Unspecified\" requireAccess=\"Read\" /&gt;\n    &lt;/handlers&gt;\n  &lt;/system.webServer&gt;\n&lt;/configuration&gt;\n</code></pre> <p>Zus\u00e4tzlich in der Anwendungspool\u2011Konfiguration Idle\u2011Timeout \u2265 2 Minuten setzen und ggf. Request Filtering Limits (z. B. responseBufferLimit) erh\u00f6hen/abschalten.</p> <p>Hinweis: Detaillierte Betriebsaspekte zum CDC\u2011Stream siehe <code>docs/change_data_capture.md</code>.</p>"},{"location":"deployment/#prometheus-configuration","title":"Prometheus Configuration","text":"<p>Create <code>prometheus.yml</code>:</p> <pre><code>global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: 'vccdb'\n    static_configs:\n      - targets: ['vccdb:8765']\n    metrics_path: /metrics\n</code></pre> <p>Zus\u00e4tzliche, themis-spezifische Metriken (Auszug): - <code>themis_index_rebuild_count</code>, <code>themis_index_rebuild_duration_ms_total</code>, <code>themis_index_rebuild_entities_processed_total</code> - <code>themis_index_cursor_anchor_hits_total</code>, <code>themis_index_range_scan_steps_total</code> Siehe auch: <code>docs/index_stats_maintenance.md</code>.</p>"},{"location":"deployment/#cdc-quick-start-ops","title":"CDC Quick Start (Ops)","text":"<p>1) Feature aktivieren (config/config.json):</p> <pre><code>{\n  \"features\": { \"cdc\": true }\n}\n</code></pre> <p>2) Endpoint pr\u00fcfen:</p> <pre><code>curl \"http://localhost:8765/changefeed?from_seq=0&amp;limit=1\"\n</code></pre> <p>3) Reverse Proxy f\u00fcr SSE konfigurieren, falls <code>/changefeed/stream</code> genutzt wird (siehe Hinweise oben) und Details in <code>docs/change_data_capture.md</code>.</p>"},{"location":"deployment/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>Key metrics to monitor:</p> <p>Server Metrics: - <code>vccdb_requests_total</code> (counter): Total requests - <code>vccdb_errors_total</code> (counter): Total errors - <code>vccdb_qps</code> (gauge): Queries per second - <code>process_uptime_seconds</code> (gauge): Server uptime</p> <p>RocksDB Metrics: - <code>rocksdb_block_cache_usage_bytes</code> / <code>rocksdb_block_cache_capacity_bytes</code>: Cache utilization - <code>rocksdb_estimate_num_keys</code>: Total entities in database - <code>rocksdb_pending_compaction_bytes</code>: Compaction backlog - <code>rocksdb_memtable_size_bytes</code>: Write buffer usage - <code>rocksdb_files_level{level=\"L0...L6\"}</code>: SST files per level</p> <p>Query Metrics: - Request latency (p50, p95, p99) - Index hit rate - Full scan fallback rate</p>"},{"location":"deployment/#alerting-rules","title":"Alerting Rules","text":"<p>Create <code>alerts.yml</code>:</p> <pre><code>groups:\n  - name: vccdb_alerts\n    interval: 30s\n    rules:\n      - alert: THEMISHighErrorRate\n        expr: rate(vccdb_errors_total[5m]) &gt; 10\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High error rate detected\"\n          description: \"Error rate is {{ $value }} errors/sec\"\n\n      - alert: THEMISLowCacheHitRate\n        expr: |\n          rocksdb_block_cache_hit / \n          (rocksdb_block_cache_hit + rocksdb_block_cache_miss) &lt; 0.8\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Low block cache hit rate\"\n          description: \"Cache hit rate is {{ $value | humanizePercentage }}\"\n\n      - alert: THEMISHighCompactionBacklog\n        expr: rocksdb_pending_compaction_bytes &gt; 10737418240  # 10 GB\n        for: 15m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High compaction backlog\"\n          description: \"Pending compaction: {{ $value | humanize1024 }}B\"\n\n      - alert: THEMISDown\n        expr: up{job=\"themis\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"THEMIS server is down\"\n          description: \"THEMIS instance {{ $labels.instance }} is unreachable\"\n</code></pre>"},{"location":"deployment/#backup-recovery","title":"Backup &amp; Recovery","text":""},{"location":"deployment/#snapshot-backup-rocksdb-checkpoint","title":"Snapshot Backup (RocksDB Checkpoint)","text":"<pre><code># Create snapshot\ncurl -X POST http://localhost:8765/admin/snapshot \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"path\":\"/backups/vccdb-snapshot-2025-10-28\"}'\n\n# Verify snapshot\nls -lh /backups/vccdb-snapshot-2025-10-28/\n# Output: CURRENT, MANIFEST, *.sst files\n\n# Restore from snapshot\n./themis_server --restore /backups/vccdb-snapshot-2025-10-28 \\\n               --target /var/lib/vccdb/data\n</code></pre>"},{"location":"deployment/#continuous-backup-wal-archival","title":"Continuous Backup (WAL Archival)","text":"<pre><code>{\n  \"storage\": {\n    \"wal_archive_path\": \"/backups/wal\",\n    \"wal_ttl_seconds\": 86400,  // Keep WAL for 24 hours\n    \"enable_wal_archival\": true\n  }\n}\n</code></pre> <pre><code># Backup script (cron job: 0 */6 * * *)\n#!/bin/bash\nBACKUP_DIR=\"/backups/$(date +%Y%m%d-%H%M%S)\"\ncp -r /var/lib/vccdb/data \"$BACKUP_DIR\"\ntar -czf \"$BACKUP_DIR.tar.gz\" \"$BACKUP_DIR\"\nrm -rf \"$BACKUP_DIR\"\n\n# Retention: keep last 7 days\nfind /backups -name \"*.tar.gz\" -mtime +7 -delete\n</code></pre>"},{"location":"deployment/#disaster-recovery-procedure","title":"Disaster Recovery Procedure","text":"<pre><code># 1. Stop server\nsudo systemctl stop vccdb\n\n# 2. Restore data directory\ntar -xzf /backups/20251028-120000.tar.gz -C /var/lib/vccdb/\n\n# 3. Verify data integrity\n./themis_server --config config.json --verify\n\n# 4. Restart server\nsudo systemctl start vccdb\n\n# 5. Verify health\ncurl http://localhost:8765/health\ncurl http://localhost:8765/stats | jq .storage.rocksdb.estimate_num_keys\n</code></pre>"},{"location":"deployment/#performance-tuning","title":"Performance Tuning","text":""},{"location":"deployment/#rocksdb-tuning-for-workload-types","title":"RocksDB Tuning for Workload Types","text":"<p>Write-Heavy (High Ingestion Rate):</p> <pre><code>{\n  \"storage\": {\n    \"memtable_size_mb\": 512,\n    \"max_write_buffer_number\": 4,\n    \"min_write_buffer_number_to_merge\": 2,\n    \"level0_file_num_compaction_trigger\": 4,\n    \"level0_slowdown_writes_trigger\": 20,\n    \"level0_stop_writes_trigger\": 36,\n    \"compression\": \"lz4\"\n  }\n}\n</code></pre> <p>Read-Heavy (Analytics Workload):</p> <pre><code>{\n  \"storage\": {\n    \"memtable_size_mb\": 128,\n    \"block_cache_size_mb\": 4096,\n    \"enable_bloom_filters\": true,\n    \"bloom_bits_per_key\": 10,\n    \"compression\": \"zstd\"\n  }\n}\n</code></pre> <p>Balanced (Mixed Workload):</p> <pre><code>{\n  \"storage\": {\n    \"memtable_size_mb\": 256,\n    \"block_cache_size_mb\": 2048,\n    \"compression\": {\n      \"default\": \"lz4\",\n      \"bottommost\": \"zstd\"\n    }\n  }\n}\n</code></pre>"},{"location":"deployment/#query-engine-tuning","title":"Query Engine Tuning","text":"<p>Edit <code>src/query/query_engine.cpp</code>:</p> <pre><code>// Low-latency tuning (reduce parallelization overhead)\nconstexpr size_t PARALLEL_THRESHOLD = 50;   // Start parallel at 50 entities\nconstexpr size_t BATCH_SIZE = 25;           // Smaller batches\n\n// High-throughput tuning (maximize CPU utilization)\nconstexpr size_t PARALLEL_THRESHOLD = 200;  // Less overhead\nconstexpr size_t BATCH_SIZE = 100;          // Larger batches\n</code></pre>"},{"location":"deployment/#network-tuning-linux","title":"Network Tuning (Linux)","text":"<pre><code># Increase TCP buffer sizes\nsudo sysctl -w net.core.rmem_max=16777216\nsudo sysctl -w net.core.wmem_max=16777216\nsudo sysctl -w net.ipv4.tcp_rmem=\"4096 87380 16777216\"\nsudo sysctl -w net.ipv4.tcp_wmem=\"4096 65536 16777216\"\n\n# Enable TCP Fast Open\nsudo sysctl -w net.ipv4.tcp_fastopen=3\n\n# Increase connection queue\nsudo sysctl -w net.core.somaxconn=4096\n</code></pre>"},{"location":"deployment/#security","title":"Security","text":""},{"location":"deployment/#authentication-api-key","title":"Authentication (API Key)","text":"<pre><code>{\n  \"server\": {\n    \"enable_auth\": true,\n    \"api_keys\": [\n      {\"key\": \"sk-prod-abc123...\", \"role\": \"admin\"},\n      {\"key\": \"sk-readonly-xyz789...\", \"role\": \"readonly\"}\n    ]\n  }\n}\n</code></pre> <pre><code># Authenticated request\ncurl -H \"Authorization: Bearer sk-prod-abc123...\" \\\n     http://localhost:8765/entities/users:alice\n</code></pre>"},{"location":"deployment/#tlsssl-encryption","title":"TLS/SSL Encryption","text":"<pre><code>{\n  \"server\": {\n    \"enable_tls\": true,\n    \"tls_cert\": \"/etc/vccdb/certs/server.crt\",\n    \"tls_key\": \"/etc/vccdb/certs/server.key\",\n    \"tls_ca\": \"/etc/vccdb/certs/ca.crt\"\n  }\n}\n</code></pre> <pre><code># Generate self-signed certificate (testing only)\nopenssl req -x509 -newkey rsa:4096 -keyout server.key -out server.crt \\\n        -days 365 -nodes -subj \"/CN=localhost\"\n\n# HTTPS request\ncurl --cacert ca.crt https://localhost:8765/health\n</code></pre>"},{"location":"deployment/#firewall-configuration","title":"Firewall Configuration","text":"<pre><code># Allow THEMIS port (Linux - ufw)\nsudo ufw allow 8765/tcp\nsudo ufw enable\n\n# Allow from specific IP only\nsudo ufw allow from 10.0.1.0/24 to any port 8765\n\n# Windows Firewall\nnetsh advfirewall firewall add rule name=\"THEMIS Server\" dir=in action=allow protocol=TCP localport=8765\n</code></pre>"},{"location":"deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/#common-issues","title":"Common Issues","text":"<p>Issue 1: Server fails to start - \"Database not open\"</p> <pre><code># Check storage path permissions\nls -ld /var/lib/vccdb/data\n# Fix: sudo chown -R vccdb:vccdb /var/lib/vccdb/data\n\n# Check disk space\ndf -h /var/lib/vccdb\n# Fix: Clean up old data or resize volume\n</code></pre> <p>Issue 2: High memory usage</p> <pre><code># Check RocksDB memory usage\ncurl http://localhost:8765/stats | jq '.storage.rocksdb | {\n  block_cache: .block_cache_usage_bytes,\n  memtable: .memtable_size_bytes,\n  total_mem_tables: .cur_size_all_mem_tables_bytes\n}'\n\n# Fix: Reduce block_cache_size_mb or memtable_size_mb in config.json\n</code></pre> <p>Issue 3: Slow queries</p> <pre><code># Check index usage\ncurl -X POST http://localhost:8765/query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"table\":\"users\",\"predicates\":[{\"column\":\"city\",\"value\":\"Berlin\"}],\"explain\":true}'\n\n# Output: {\"plan\": {\"mode\": \"full_scan_fallback\"}}\n# Fix: Create index on 'city' column\ncurl -X POST http://localhost:8765/index/create \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"table\":\"users\",\"column\":\"city\"}'\n</code></pre> <p>Issue 4: Compaction backlog</p> <pre><code># Check compaction stats\ncurl http://localhost:8765/stats | jq '.storage.rocksdb | {\n  pending: .estimate_pending_compaction_bytes,\n  running: .num_running_compactions\n}'\n\n# Fix: Increase compaction threads\n# config.json: \"max_background_compactions\": 8\n</code></pre>"},{"location":"deployment/#debug-logging","title":"Debug Logging","text":"<p>Enable debug logging:</p> <pre><code>{\n  \"logging\": {\n    \"level\": \"debug\",\n    \"file\": \"/var/log/vccdb/debug.log\"\n  }\n}\n</code></pre> <pre><code># Tail debug log\ntail -f /var/log/vccdb/debug.log\n\n# Filter specific component\ngrep \"QueryEngine\" /var/log/vccdb/debug.log\ngrep \"RocksDBWrapper\" /var/log/vccdb/debug.log\n</code></pre>"},{"location":"deployment/#performance-profiling","title":"Performance Profiling","text":"<pre><code># CPU profiling (Linux - perf)\nsudo perf record -F 99 -p $(pgrep themis_server) -g -- sleep 60\nsudo perf report\n\n# Memory profiling (valgrind)\nvalgrind --tool=massif ./themis_server --config config.json\nms_print massif.out.12345\n\n# Network profiling (tcpdump)\nsudo tcpdump -i any port 8765 -w vccdb-traffic.pcap\nwireshark vccdb-traffic.pcap\n</code></pre>"},{"location":"deployment/#migration-guide","title":"Migration Guide","text":""},{"location":"deployment/#from-standalone-to-docker","title":"From Standalone to Docker","text":"<pre><code># 1. Stop standalone server\nsudo systemctl stop vccdb\n\n# 2. Copy data directory\nsudo cp -r /var/lib/vccdb/data ./docker-data/\n\n# 3. Start Docker container\ndocker run -d \\\n  --name vccdb \\\n  -p 8765:8765 \\\n  -v $(pwd)/docker-data:/data \\\n  vccdb/vccdb:latest\n\n# 4. Verify data\ncurl http://localhost:8765/stats | jq .storage.rocksdb.estimate_num_keys\n</code></pre>"},{"location":"deployment/#from-v0x-to-v10","title":"From v0.x to v1.0","text":"<pre><code># 1. Backup current data\n./themis_server --backup /backups/pre-upgrade-$(date +%Y%m%d)\n\n# 2. Download v1.0 binary\nwget https://github.com/&lt;org&gt;/vccdb/releases/download/v1.0.0/vccdb-linux-x64.tar.gz\ntar -xzf vccdb-linux-x64.tar.gz\n\n# 3. Run migration tool\n./vccdb-migrate --from /var/lib/vccdb/data \\\n                --to /var/lib/vccdb/data-v1 \\\n                --version 0.9 --target 1.0\n\n# 4. Update config.json (new format)\n# See: https://github.com/&lt;org&gt;/vccdb/wiki/v1.0-Migration-Guide\n\n# 5. Start v1.0 server\n./themis_server --config config-v1.json\n</code></pre>"},{"location":"deployment/#support","title":"Support","text":"<ul> <li>Documentation: https://docs.vccdb.io</li> <li>GitHub Issues: https://github.com//vccdb/issues <li>Community Chat: https://discord.gg/vccdb</li> <li>Email: support@vccdb.io</li>"},{"location":"encryption_deployment/","title":"Themis Column-Level Encryption - Production Deployment Guide","text":"<p>Version: 1.0 Last Updated: 30. Oktober 2025 Target Audience: DevOps Engineers, Security Engineers, Database Administrators</p>"},{"location":"encryption_deployment/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Prerequisites</li> <li>Architecture</li> <li>HashiCorp Vault Setup</li> <li>Key Management Strategy</li> <li>Application Configuration</li> <li>Migration from Plaintext</li> <li>Key Rotation Procedures</li> <li>Monitoring &amp; Alerting</li> <li>Disaster Recovery</li> <li>Security Best Practices</li> <li>Troubleshooting</li> <li>Performance Tuning</li> </ol>"},{"location":"encryption_deployment/#overview","title":"Overview","text":"<p>Themis implements column-level encryption using AES-256-GCM to protect sensitive data at rest. This guide covers deploying the encryption system in production with HashiCorp Vault as the key management backend.</p>"},{"location":"encryption_deployment/#key-features","title":"Key Features","text":"<ul> <li>\u2705 AES-256-GCM encryption (NIST-approved)</li> <li>\u2705 Authenticated encryption (integrity + confidentiality)</li> <li>\u2705 Hardware acceleration (AES-NI auto-detected)</li> <li>\u2705 Key versioning for zero-downtime rotation</li> <li>\u2705 Vault integration for enterprise key management</li> <li>\u2705 Transparent field-level encryption (minimal code changes)</li> </ul>"},{"location":"encryption_deployment/#compliance-coverage","title":"Compliance Coverage","text":"Regulation Requirement Themis Implementation GDPR Data encryption at rest \u2705 AES-256-GCM HIPAA PHI encryption \u2705 Separate key for medical data PCI DSS Cardholder data protection \u2705 Field-level encryption SOC 2 Key management controls \u2705 Vault integration + audit logs CCPA Consumer data protection \u2705 Right to be forgotten support"},{"location":"encryption_deployment/#prerequisites","title":"Prerequisites","text":""},{"location":"encryption_deployment/#infrastructure-requirements","title":"Infrastructure Requirements","text":""},{"location":"encryption_deployment/#hashicorp-vault","title":"HashiCorp Vault","text":"<ul> <li>Version: Vault 1.15+ recommended</li> <li>Deployment: HA cluster (3+ nodes) for production</li> <li>Storage Backend: Consul (recommended) or Raft integrated storage</li> <li>TLS: Required for production (mutual TLS recommended)</li> </ul>"},{"location":"encryption_deployment/#application-servers","title":"Application Servers","text":"<ul> <li>CPU: AES-NI support (Intel/AMD x86-64)</li> <li>Check: <code>grep -E 'aes|sse4_2' /proc/cpuinfo</code> (Linux)</li> <li>Check: <code>sysctl -a | grep machdep.cpu.features</code> (macOS)</li> <li>Memory: +512MB heap for key cache</li> <li>Network: Low-latency connection to Vault (&lt;5ms RTT recommended)</li> </ul>"},{"location":"encryption_deployment/#database","title":"Database","text":"<ul> <li>RocksDB: Storage for encrypted data</li> <li>Disk: SSD recommended for encrypted blob performance</li> <li>Space: Plan for 20-30% overhead vs plaintext</li> </ul>"},{"location":"encryption_deployment/#software-dependencies","title":"Software Dependencies","text":"<pre><code># Required libraries (installed via vcpkg)\ncurl &gt;= 8.0\nopenssl &gt;= 3.0\nnlohmann-json &gt;= 3.11\nrocksdb &gt;= 8.0\n</code></pre>"},{"location":"encryption_deployment/#access-requirements","title":"Access Requirements","text":"<ul> <li>Vault Admin Access: For initial setup and key creation</li> <li>Application Service Account: Vault token or AppRole authentication</li> <li>Network Access: Application \u2192 Vault (port 8200, TLS)</li> </ul>"},{"location":"encryption_deployment/#architecture","title":"Architecture","text":""},{"location":"encryption_deployment/#component-diagram","title":"Component Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Application Layer                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502  \u2502   User      \u2502\u2500\u2500\u2500\u2500\u25b6\u2502 EncryptedField&lt;T&gt;\u2502              \u2502\n\u2502  \u2502   Customer  \u2502     \u2502   - email        \u2502              \u2502\n\u2502  \u2502   Document  \u2502     \u2502   - ssn          \u2502              \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502   - credit_score \u2502              \u2502\n\u2502                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502                                 \u2502                        \u2502\n\u2502                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502                      \u2502  FieldEncryption  \u2502              \u2502\n\u2502                      \u2502  (AES-256-GCM)    \u2502              \u2502\n\u2502                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2502                                 \u2502                        \u2502\n\u2502                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u2502\n\u2502                      \u2502  VaultKeyProvider \u2502              \u2502\n\u2502                      \u2502  - Key caching    \u2502              \u2502\n\u2502                      \u2502  - Token refresh  \u2502              \u2502\n\u2502                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502 HTTPS/TLS\n                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                      \u2502   HashiCorp Vault        \u2502\n                      \u2502   KV Secrets Engine v2   \u2502\n                      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n                      \u2502  Keys:                   \u2502\n                      \u2502   - user_pii (v1, v2)   \u2502\n                      \u2502   - user_sensitive (v1) \u2502\n                      \u2502   - customer_financial  \u2502\n                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n                      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                      \u2502   Vault Storage          \u2502\n                      \u2502   (Consul/Raft)          \u2502\n                      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"encryption_deployment/#data-flow","title":"Data Flow","text":"<p>Write Path (Encryption):</p> <pre><code>1. User.email = \"alice@example.com\"\n2. EncryptedField.encrypt(\"alice@example.com\", \"user_pii\")\n3. VaultKeyProvider.getKey(\"user_pii\") \u2192 [Check cache]\n4. If cache miss: HTTP GET /v1/themis/data/keys/user_pii\n5. Vault returns: {data: {key: \"&lt;base64&gt;\", version: 2}}\n6. Cache key for 1 hour\n7. FieldEncryption.encrypt(plaintext, key) \u2192 AES-256-GCM\n8. Generate random IV (96 bits)\n9. Encrypt + generate auth tag (128 bits)\n10. Return: \"user_pii:2:IV:ciphertext:tag\" (base64)\n11. Store in RocksDB as JSON: {\"email\": \"user_pii:2:...\"}\n</code></pre> <p>Read Path (Decryption):</p> <pre><code>1. Fetch from RocksDB: {\"email\": \"user_pii:2:IV:ciphertext:tag\"}\n2. EncryptedField.fromBase64(\"user_pii:2:...\")\n3. Parse: key_id=\"user_pii\", version=2, IV, ciphertext, tag\n4. VaultKeyProvider.getKey(\"user_pii\", version=2) \u2192 [Check cache]\n5. If cache miss: HTTP GET /v1/themis/data/keys/user_pii?version=2\n6. FieldEncryption.decrypt(ciphertext, key, IV, tag)\n7. Verify authentication tag (prevents tampering)\n8. Decrypt using AES-256-GCM\n9. Return plaintext: \"alice@example.com\"\n</code></pre>"},{"location":"encryption_deployment/#hashicorp-vault-setup","title":"HashiCorp Vault Setup","text":""},{"location":"encryption_deployment/#step-1-deploy-vault-cluster","title":"Step 1: Deploy Vault Cluster","text":""},{"location":"encryption_deployment/#production-ha-setup-recommended","title":"Production HA Setup (Recommended)","text":"<pre><code># Using Docker Compose for quick setup\n# For production, use Kubernetes/Nomad or systemd\n\ncat &gt; docker-compose.yml &lt;&lt;EOF\nversion: '3.8'\nservices:\n  vault1:\n    image: hashicorp/vault:1.15\n    container_name: vault-1\n    ports:\n      - \"8200:8200\"\n    environment:\n      VAULT_ADDR: 'https://0.0.0.0:8200'\n      VAULT_API_ADDR: 'https://vault-1:8200'\n    volumes:\n      - ./vault/config:/vault/config:ro\n      - ./vault/data:/vault/data\n      - ./vault/logs:/vault/logs\n    cap_add:\n      - IPC_LOCK\n    command: server\n\n  vault2:\n    image: hashicorp/vault:1.15\n    container_name: vault-2\n    ports:\n      - \"8201:8200\"\n    environment:\n      VAULT_ADDR: 'https://0.0.0.0:8200'\n      VAULT_API_ADDR: 'https://vault-2:8200'\n    volumes:\n      - ./vault/config:/vault/config:ro\n      - ./vault/data2:/vault/data\n      - ./vault/logs2:/vault/logs\n    cap_add:\n      - IPC_LOCK\n    command: server\n\n  vault3:\n    image: hashicorp/vault:1.15\n    container_name: vault-3\n    ports:\n      - \"8202:8200\"\n    environment:\n      VAULT_ADDR: 'https://0.0.0.0:8200'\n      VAULT_API_ADDR: 'https://vault-3:8200'\n    volumes:\n      - ./vault/config:/vault/config:ro\n      - ./vault/data3:/vault/data\n      - ./vault/logs3:/vault/logs\n    cap_add:\n      - IPC_LOCK\n    command: server\n\n  consul:\n    image: hashicorp/consul:1.16\n    container_name: consul\n    ports:\n      - \"8500:8500\"\n    command: agent -server -ui -bootstrap-expect=1 -client=0.0.0.0\nEOF\n\n# Vault configuration\nmkdir -p vault/config\ncat &gt; vault/config/vault.hcl &lt;&lt;EOF\nstorage \"consul\" {\n  address = \"consul:8500\"\n  path    = \"vault/\"\n}\n\nlistener \"tcp\" {\n  address     = \"0.0.0.0:8200\"\n  tls_cert_file = \"/vault/config/tls/vault.crt\"\n  tls_key_file  = \"/vault/config/tls/vault.key\"\n}\n\napi_addr = \"https://vault-1:8200\"\ncluster_addr = \"https://vault-1:8201\"\nui = true\n\n# Performance tuning\nmax_lease_ttl = \"87600h\"  # 10 years\ndefault_lease_ttl = \"87600h\"\n\n# Enable Prometheus metrics\ntelemetry {\n  prometheus_retention_time = \"24h\"\n  disable_hostname = true\n}\nEOF\n\ndocker-compose up -d\n</code></pre>"},{"location":"encryption_deployment/#generate-tls-certificates","title":"Generate TLS Certificates","text":"<pre><code># Create CA\nopenssl req -x509 -newkey rsa:4096 -keyout vault/config/tls/ca-key.pem \\\n  -out vault/config/tls/ca.pem -days 3650 -nodes \\\n  -subj \"/C=US/ST=CA/L=SF/O=Themis/CN=Vault CA\"\n\n# Create Vault certificate\nopenssl req -newkey rsa:4096 -keyout vault/config/tls/vault.key \\\n  -out vault/config/tls/vault.csr -nodes \\\n  -subj \"/C=US/ST=CA/L=SF/O=Themis/CN=vault.example.com\"\n\nopenssl x509 -req -in vault/config/tls/vault.csr \\\n  -CA vault/config/tls/ca.pem -CAkey vault/config/tls/ca-key.pem \\\n  -CAcreateserial -out vault/config/tls/vault.crt -days 825 \\\n  -extensions v3_req -extfile &lt;(cat &lt;&lt;EOF\n[v3_req]\nsubjectAltName = @alt_names\n[alt_names]\nDNS.1 = vault.example.com\nDNS.2 = localhost\nIP.1 = 127.0.0.1\nEOF\n)\n</code></pre>"},{"location":"encryption_deployment/#step-2-initialize-vault","title":"Step 2: Initialize Vault","text":"<pre><code>export VAULT_ADDR='https://vault.example.com:8200'\nexport VAULT_CACERT='/path/to/ca.pem'\n\n# Initialize (DO THIS ONCE)\nvault operator init -key-shares=5 -key-threshold=3 &gt; vault-init.txt\n\n# CRITICAL: Store unseal keys and root token securely!\n# Distribute unseal keys to different trusted personnel\n\n# Unseal all 3 nodes (requires 3 of 5 keys)\nvault operator unseal &lt;key1&gt;\nvault operator unseal &lt;key2&gt;\nvault operator unseal &lt;key3&gt;\n\n# Login with root token\nvault login &lt;root-token&gt;\n</code></pre>"},{"location":"encryption_deployment/#step-3-enable-kv-secrets-engine","title":"Step 3: Enable KV Secrets Engine","text":"<pre><code># Enable KV v2 secrets engine\nvault secrets enable -version=2 -path=themis kv\n\n# Verify\nvault secrets list\n# Should show:\n# themis/    kv    n/a       n/a     n/a        n/a   28h24m30s   n/a\n</code></pre>"},{"location":"encryption_deployment/#step-4-create-encryption-keys","title":"Step 4: Create Encryption Keys","text":"<pre><code># Helper script to generate encryption keys\ncat &gt; create-encryption-key.sh &lt;&lt;'EOF'\n#!/bin/bash\nset -e\n\nKEY_ID=$1\nDESCRIPTION=$2\n\nif [ -z \"$KEY_ID\" ]; then\n  echo \"Usage: $0 &lt;key_id&gt; [description]\"\n  exit 1\nfi\n\n# Generate 256-bit random key\nKEY=$(openssl rand -base64 32)\n\n# Store in Vault\nvault kv put themis/keys/$KEY_ID \\\n  key=\"$KEY\" \\\n  algorithm=\"AES-256-GCM\" \\\n  version=1 \\\n  description=\"$DESCRIPTION\" \\\n  created_at=\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"\n\necho \"\u2705 Created key: $KEY_ID\"\nvault kv get themis/keys/$KEY_ID\nEOF\n\nchmod +x create-encryption-key.sh\n\n# Create keys for different data categories\n./create-encryption-key.sh user_pii \"General user PII (email, phone, address)\"\n./create-encryption-key.sh user_sensitive \"High-sensitivity user data (SSN, medical records)\"\n./create-encryption-key.sh customer_financial \"Financial data (credit scores, income)\"\n./create-encryption-key.sh payment_info \"Payment card data (PCI DSS)\"\n</code></pre>"},{"location":"encryption_deployment/#step-5-create-application-policy","title":"Step 5: Create Application Policy","text":"<pre><code># Policy for Themis application\ncat &gt; themis-policy.hcl &lt;&lt;EOF\n# Read access to encryption keys\npath \"themis/data/keys/*\" {\n  capabilities = [\"read\", \"list\"]\n}\n\n# Read key metadata (for rotation monitoring)\npath \"themis/metadata/keys/*\" {\n  capabilities = [\"read\", \"list\"]\n}\n\n# Deny write/delete (keys managed by admins only)\npath \"themis/data/keys/*\" {\n  capabilities = [\"deny\"]\n  denied_parameters = {\n    \"*\" = []\n  }\n}\nEOF\n\nvault policy write themis-app themis-policy.hcl\n\n# Verify\nvault policy read themis-app\n</code></pre>"},{"location":"encryption_deployment/#step-6-configure-approle-authentication","title":"Step 6: Configure AppRole Authentication","text":"<pre><code># Enable AppRole auth\nvault auth enable approle\n\n# Create role for Themis application\nvault write auth/approle/role/themis-app \\\n  token_ttl=1h \\\n  token_max_ttl=4h \\\n  token_policies=\"themis-app\" \\\n  secret_id_ttl=0 \\\n  secret_id_num_uses=0\n\n# Get role ID\nvault read auth/approle/role/themis-app/role-id\n# role_id: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n\n# Generate secret ID\nvault write -f auth/approle/role/themis-app/secret-id\n# secret_id: yyyyyyyy-yyyy-yyyy-yyyy-yyyyyyyyyyyy\n\n# Store role_id and secret_id securely (e.g., Kubernetes secrets)\n</code></pre>"},{"location":"encryption_deployment/#key-management-strategy","title":"Key Management Strategy","text":""},{"location":"encryption_deployment/#key-categorization","title":"Key Categorization","text":"<p>Organize keys by data sensitivity and rotation frequency:</p> Key ID Purpose Data Examples Rotation Frequency Compliance <code>user_pii</code> General PII Email, phone, address 12 months GDPR, CCPA <code>user_sensitive</code> High-sensitivity PII SSN, passport, medical ID 6 months HIPAA, GDPR <code>customer_financial</code> Financial data Credit score, income 6 months PCI DSS, SOC 2 <code>payment_info</code> Payment cards Card number, CVV 3 months PCI DSS <code>healthcare_phi</code> Protected health info Diagnoses, prescriptions 6 months HIPAA"},{"location":"encryption_deployment/#key-versioning-scheme","title":"Key Versioning Scheme","text":"<pre><code>Key Format: &lt;key_id&gt;:&lt;version&gt;:&lt;iv&gt;:&lt;ciphertext&gt;:&lt;tag&gt;\nExample:    user_pii:2:ghQO6IvYuVdlrXna:qh6kXp9P6dPJlceX4hMes4U=:H9/fjZNKYg==\n\nVersion Lifecycle:\n  v1: ACTIVE    \u2192 Encrypts new data, decrypts old data\n  v2: ROTATING  \u2192 Dual-write phase (v1 deprecated, v2 active)\n  v1: DEPRECATED\u2192 Decrypts old data only (no new encryptions)\n  v1: DELETED   \u2192 After grace period (90 days), physically deleted\n</code></pre>"},{"location":"encryption_deployment/#key-rotation-schedule","title":"Key Rotation Schedule","text":"<pre><code># Automated rotation cron job (run monthly)\ncat &gt; /etc/cron.monthly/rotate-encryption-keys.sh &lt;&lt;'EOF'\n#!/bin/bash\nset -e\n\nVAULT_ADDR=\"https://vault.example.com:8200\"\nVAULT_TOKEN=\"&lt;service-account-token&gt;\"\n\n# Rotate keys older than 6 months\nfor KEY_ID in user_sensitive customer_financial healthcare_phi; do\n  CURRENT_VERSION=$(vault kv get -format=json themis/keys/$KEY_ID | jq -r '.data.metadata.version')\n  NEW_VERSION=$((CURRENT_VERSION + 1))\n\n  NEW_KEY=$(openssl rand -base64 32)\n\n  vault kv put themis/keys/$KEY_ID \\\n    key=\"$NEW_KEY\" \\\n    algorithm=\"AES-256-GCM\" \\\n    version=$NEW_VERSION \\\n    created_at=\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\" \\\n    rotated_from_version=$CURRENT_VERSION\n\n  echo \"\u2705 Rotated $KEY_ID: v$CURRENT_VERSION \u2192 v$NEW_VERSION\"\n\n  # Trigger application re-encryption job\n  curl -X POST https://themis-api.example.com/admin/re-encrypt \\\n    -H \"Authorization: Bearer $ADMIN_TOKEN\" \\\n    -d \"{\\\"key_id\\\": \\\"$KEY_ID\\\", \\\"target_version\\\": $NEW_VERSION}\"\ndone\nEOF\n\nchmod +x /etc/cron.monthly/rotate-encryption-keys.sh\n</code></pre>"},{"location":"encryption_deployment/#application-configuration","title":"Application Configuration","text":""},{"location":"encryption_deployment/#vaultkeyprovider-configuration","title":"VaultKeyProvider Configuration","text":"<pre><code>// config/encryption.hpp\n#include \"security/vault_key_provider.h\"\n\nthemis::VaultKeyProvider::Config getVaultConfig() {\n    themis::VaultKeyProvider::Config config;\n\n    // Vault connection\n    config.vault_addr = std::getenv(\"VAULT_ADDR\") ?: \"https://vault.example.com:8200\";\n    config.vault_token = std::getenv(\"VAULT_TOKEN\") ?: \"\";  // From AppRole login\n    config.kv_mount_path = \"themis\";\n    config.kv_version = \"v2\";\n\n    // TLS configuration\n    config.verify_ssl = true;\n    config.ca_cert_path = \"/etc/ssl/certs/vault-ca.pem\";\n\n    // Performance tuning\n    config.cache_ttl_seconds = 3600;      // 1 hour cache\n    config.cache_capacity = 1000;         // Max 1000 cached keys\n    config.request_timeout_ms = 5000;     // 5 second timeout\n\n    // Connection pooling (if using custom HTTP client)\n    config.max_connections = 10;\n    config.keepalive = true;\n\n    return config;\n}\n\n// Initialize in application startup\nvoid initializeEncryption() {\n    auto vault_config = getVaultConfig();\n    auto key_provider = std::make_shared&lt;themis::VaultKeyProvider&gt;(vault_config);\n    auto encryption = std::make_shared&lt;themis::FieldEncryption&gt;(key_provider);\n\n    // Set global encryption for all field types\n    themis::EncryptedField&lt;std::string&gt;::setFieldEncryption(encryption);\n    themis::EncryptedField&lt;int64_t&gt;::setFieldEncryption(encryption);\n    themis::EncryptedField&lt;double&gt;::setFieldEncryption(encryption);\n\n    // Warm up cache with frequently used keys\n    key_provider-&gt;getKey(\"user_pii\");\n    key_provider-&gt;getKey(\"user_sensitive\");\n    key_provider-&gt;getKey(\"customer_financial\");\n}\n</code></pre>"},{"location":"encryption_deployment/#environment-variables","title":"Environment Variables","text":"<pre><code># Production environment (.env file)\nVAULT_ADDR=https://vault.example.com:8200\nVAULT_TOKEN=&lt;from-approle-login&gt;\nVAULT_CACERT=/etc/ssl/certs/vault-ca.pem\nVAULT_NAMESPACE=themis  # For Vault Enterprise\n\n# Optional: Override defaults\nENCRYPTION_CACHE_TTL=3600\nENCRYPTION_CACHE_SIZE=1000\nENCRYPTION_KEY_MOUNT=themis\n</code></pre>"},{"location":"encryption_deployment/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<pre><code># kubernetes/deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: themis-api\n  namespace: production\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: themis-api\n  template:\n    metadata:\n      labels:\n        app: themis-api\n    spec:\n      serviceAccountName: themis-app\n      containers:\n      - name: themis-api\n        image: themis:latest\n        env:\n        - name: VAULT_ADDR\n          value: \"https://vault.vault.svc.cluster.local:8200\"\n        - name: VAULT_TOKEN\n          valueFrom:\n            secretKeyRef:\n              name: vault-token\n              key: token\n        - name: VAULT_CACERT\n          value: \"/vault/tls/ca.crt\"\n        volumeMounts:\n        - name: vault-tls\n          mountPath: /vault/tls\n          readOnly: true\n        resources:\n          requests:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n          limits:\n            memory: \"4Gi\"\n            cpu: \"2000m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 10\n          periodSeconds: 5\n      volumes:\n      - name: vault-tls\n        secret:\n          secretName: vault-ca-cert\n\n---\n# Vault token secret (from AppRole login)\napiVersion: v1\nkind: Secret\nmetadata:\n  name: vault-token\n  namespace: production\ntype: Opaque\ndata:\n  token: &lt;base64-encoded-vault-token&gt;\n</code></pre>"},{"location":"encryption_deployment/#migration-from-plaintext","title":"Migration from Plaintext","text":""},{"location":"encryption_deployment/#phase-1-assessment-week-1","title":"Phase 1: Assessment (Week 1)","text":"<pre><code>-- Identify columns to encrypt\nSELECT \n  table_name,\n  column_name,\n  data_type,\n  COUNT(*) as row_count,\n  SUM(LENGTH(column_name)) as total_bytes\nFROM information_schema.columns\nWHERE column_name IN ('email', 'ssn', 'phone', 'credit_card')\nGROUP BY table_name, column_name;\n\n-- Estimate migration time\n-- Rule of thumb: 10,000 rows/second on modern hardware\n</code></pre>"},{"location":"encryption_deployment/#phase-2-schema-changes-week-2","title":"Phase 2: Schema Changes (Week 2)","text":"<pre><code>// Add encrypted columns alongside plaintext (dual-write phase)\nstruct User {\n    std::string id;\n    std::string username;\n\n    // OLD: Plaintext (deprecated)\n    std::string email_plaintext;\n    std::string ssn_plaintext;\n\n    // NEW: Encrypted\n    EncryptedField&lt;std::string&gt; email;\n    EncryptedField&lt;std::string&gt; ssn;\n\n    // Migration flag\n    bool is_encrypted = false;\n};\n</code></pre>"},{"location":"encryption_deployment/#phase-3-dual-write-migration-week-3-4","title":"Phase 3: Dual-Write Migration (Week 3-4)","text":"<pre><code>// Write to both plaintext and encrypted columns\nvoid saveUser(const User&amp; user) {\n    // Write plaintext (for backward compatibility)\n    db-&gt;put(\"user:\" + user.id + \":email_plain\", user.email_plaintext);\n\n    // Write encrypted\n    user.email.encrypt(user.email_plaintext, \"user_pii\");\n    auto encrypted_blob = user.email.toBase64();\n    db-&gt;put(\"user:\" + user.id + \":email_enc\", encrypted_blob);\n\n    // Mark as encrypted\n    db-&gt;put(\"user:\" + user.id + \":encrypted\", \"true\");\n}\n\n// Background migration job\nvoid migrateUserData() {\n    auto all_users = db-&gt;scan(\"user:\");\n\n    for (const auto&amp; [key, value] : all_users) {\n        std::string user_id = extractUserId(key);\n\n        // Skip if already encrypted\n        auto encrypted_flag = db-&gt;get(\"user:\" + user_id + \":encrypted\");\n        if (encrypted_flag == \"true\") continue;\n\n        // Migrate plaintext to encrypted\n        auto email_plain = db-&gt;get(\"user:\" + user_id + \":email_plain\");\n        if (!email_plain.empty()) {\n            EncryptedField&lt;std::string&gt; email_enc;\n            email_enc.encrypt(email_plain, \"user_pii\");\n            db-&gt;put(\"user:\" + user_id + \":email_enc\", email_enc.toBase64());\n        }\n\n        db-&gt;put(\"user:\" + user_id + \":encrypted\", \"true\");\n\n        // Log progress\n        std::cout &lt;&lt; \"Migrated user: \" &lt;&lt; user_id &lt;&lt; std::endl;\n    }\n}\n</code></pre>"},{"location":"encryption_deployment/#phase-4-switch-reads-week-5","title":"Phase 4: Switch Reads (Week 5)","text":"<pre><code>// Preferentially read from encrypted columns\nstd::string getUserEmail(const std::string&amp; user_id) {\n    // Try encrypted first\n    auto encrypted_data = db-&gt;get(\"user:\" + user_id + \":email_enc\");\n    if (!encrypted_data.empty()) {\n        auto email_field = EncryptedField&lt;std::string&gt;::fromBase64(encrypted_data);\n        return email_field.decrypt();\n    }\n\n    // Fallback to plaintext (for unmigrated users)\n    return db-&gt;get(\"user:\" + user_id + \":email_plain\");\n}\n</code></pre>"},{"location":"encryption_deployment/#phase-5-cleanup-week-6","title":"Phase 5: Cleanup (Week 6+)","text":"<pre><code>// After 100% migration confirmed, delete plaintext columns\nvoid cleanupPlaintextData() {\n    auto all_users = db-&gt;scan(\"user:\");\n\n    for (const auto&amp; [key, value] : all_users) {\n        if (key.find(\":email_plain\") != std::string::npos ||\n            key.find(\":ssn_plain\") != std::string::npos) {\n\n            std::string user_id = extractUserId(key);\n\n            // Verify encrypted version exists\n            auto encrypted_flag = db-&gt;get(\"user:\" + user_id + \":encrypted\");\n            if (encrypted_flag == \"true\") {\n                // Safe to delete plaintext\n                db-&gt;del(key);\n                std::cout &lt;&lt; \"Deleted plaintext: \" &lt;&lt; key &lt;&lt; std::endl;\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"encryption_deployment/#key-rotation-procedures","title":"Key Rotation Procedures","text":""},{"location":"encryption_deployment/#manual-rotation-process","title":"Manual Rotation Process","text":"<pre><code>#!/bin/bash\n# rotate-key.sh - Manual key rotation script\n\nset -e\n\nKEY_ID=$1\nif [ -z \"$KEY_ID\" ]; then\n  echo \"Usage: $0 &lt;key_id&gt;\"\n  exit 1\nfi\n\necho \"\ud83d\udd04 Starting key rotation for: $KEY_ID\"\n\n# Step 1: Get current version\nCURRENT=$(vault kv get -format=json themis/keys/$KEY_ID | jq -r '.data.metadata.version')\nNEW_VERSION=$((CURRENT + 1))\n\necho \"\ud83d\udcca Current version: $CURRENT\"\necho \"\ud83d\udcca New version: $NEW_VERSION\"\n\n# Step 2: Generate new key\nNEW_KEY=$(openssl rand -base64 32)\n\n# Step 3: Store new version in Vault\nvault kv put themis/keys/$KEY_ID \\\n  key=\"$NEW_KEY\" \\\n  algorithm=\"AES-256-GCM\" \\\n  version=$NEW_VERSION \\\n  created_at=\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\" \\\n  rotated_from=$CURRENT \\\n  rotation_reason=\"Scheduled rotation\"\n\necho \"\u2705 New key version created in Vault\"\n\n# Step 4: Trigger application cache invalidation\ncurl -X POST https://themis-api.example.com/admin/cache/invalidate \\\n  -H \"Authorization: Bearer $ADMIN_TOKEN\" \\\n  -d \"{\\\"key_id\\\": \\\"$KEY_ID\\\"}\"\n\necho \"\u2705 Application caches invalidated\"\n\n# Step 5: Start background re-encryption\ncurl -X POST https://themis-api.example.com/admin/re-encrypt \\\n  -H \"Authorization: Bearer $ADMIN_TOKEN\" \\\n  -d \"{\n    \\\"key_id\\\": \\\"$KEY_ID\\\",\n    \\\"source_version\\\": $CURRENT,\n    \\\"target_version\\\": $NEW_VERSION,\n    \\\"batch_size\\\": 1000\n  }\"\n\necho \"\u2705 Re-encryption job started\"\necho \"\ud83c\udf89 Key rotation completed!\"\n</code></pre>"},{"location":"encryption_deployment/#re-encryption-job-implementation","title":"Re-Encryption Job Implementation","text":"<pre><code>// Background job to re-encrypt data with new key version\nclass ReEncryptionJob {\npublic:\n    struct Config {\n        std::string key_id;\n        uint32_t source_version;\n        uint32_t target_version;\n        size_t batch_size = 1000;\n        size_t parallelism = 4;\n    };\n\n    ReEncryptionJob(\n        std::shared_ptr&lt;RocksDBWrapper&gt; db,\n        std::shared_ptr&lt;FieldEncryption&gt; encryption,\n        const Config&amp; config\n    ) : db_(db), encryption_(encryption), config_(config) {}\n\n    void run() {\n        std::cout &lt;&lt; \"\ud83d\udd04 Starting re-encryption: \" &lt;&lt; config_.key_id \n                  &lt;&lt; \" v\" &lt;&lt; config_.source_version \n                  &lt;&lt; \" \u2192 v\" &lt;&lt; config_.target_version &lt;&lt; std::endl;\n\n        auto start = std::chrono::steady_clock::now();\n        size_t total_count = 0;\n        size_t success_count = 0;\n\n        // Scan all encrypted fields\n        auto it = db_-&gt;newIterator();\n        for (it-&gt;SeekToFirst(); it-&gt;Valid(); it-&gt;Next()) {\n            std::string key = it-&gt;key().ToString();\n            std::string value = it-&gt;value().ToString();\n\n            try {\n                // Parse encrypted blob\n                json j = json::parse(value);\n\n                for (auto&amp; [field_name, field_value] : j.items()) {\n                    if (!field_value.is_string()) continue;\n\n                    std::string blob_str = field_value.get&lt;std::string&gt;();\n\n                    // Check if this field uses the key being rotated\n                    if (blob_str.find(config_.key_id + \":\") == 0) {\n                        auto blob = EncryptedBlob::fromBase64(blob_str);\n\n                        if (blob.key_version == config_.source_version) {\n                            // Decrypt with old key\n                            std::string plaintext = encryption_-&gt;decryptToString(blob);\n\n                            // Re-encrypt with new key\n                            EncryptedField&lt;std::string&gt; new_field;\n                            new_field.encrypt(plaintext, config_.key_id);\n\n                            // Update JSON\n                            j[field_name] = new_field.toBase64();\n\n                            success_count++;\n                        }\n                    }\n                }\n\n                // Write updated record\n                db_-&gt;put(key, j.dump());\n                total_count++;\n\n                if (total_count % 1000 == 0) {\n                    std::cout &lt;&lt; \"Progress: \" &lt;&lt; total_count &lt;&lt; \" records processed, \"\n                              &lt;&lt; success_count &lt;&lt; \" fields re-encrypted\" &lt;&lt; std::endl;\n                }\n\n            } catch (const std::exception&amp; e) {\n                std::cerr &lt;&lt; \"Error processing key \" &lt;&lt; key &lt;&lt; \": \" &lt;&lt; e.what() &lt;&lt; std::endl;\n            }\n        }\n\n        auto end = std::chrono::steady_clock::now();\n        auto duration = std::chrono::duration_cast&lt;std::chrono::seconds&gt;(end - start).count();\n\n        std::cout &lt;&lt; \"\u2705 Re-encryption completed:\" &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"   Records processed: \" &lt;&lt; total_count &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"   Fields re-encrypted: \" &lt;&lt; success_count &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"   Duration: \" &lt;&lt; duration &lt;&lt; \"s\" &lt;&lt; std::endl;\n        std::cout &lt;&lt; \"   Throughput: \" &lt;&lt; (total_count / duration) &lt;&lt; \" records/sec\" &lt;&lt; std::endl;\n    }\n\nprivate:\n    std::shared_ptr&lt;RocksDBWrapper&gt; db_;\n    std::shared_ptr&lt;FieldEncryption&gt; encryption_;\n    Config config_;\n};\n</code></pre>"},{"location":"encryption_deployment/#monitoring-alerting","title":"Monitoring &amp; Alerting","text":""},{"location":"encryption_deployment/#key-metrics","title":"Key Metrics","text":""},{"location":"encryption_deployment/#application-metrics","title":"Application Metrics","text":"<pre><code>// Prometheus metrics (pseudocode)\nclass EncryptionMetrics {\npublic:\n    // Counters\n    prometheus::Counter encryption_operations;\n    prometheus::Counter decryption_operations;\n    prometheus::Counter encryption_errors;\n    prometheus::Counter decryption_errors;\n\n    // Histograms\n    prometheus::Histogram encryption_duration_ms;\n    prometheus::Histogram decryption_duration_ms;\n    prometheus::Histogram vault_request_duration_ms;\n\n    // Gauges\n    prometheus::Gauge key_cache_size;\n    prometheus::Gauge key_cache_hit_rate;\n    prometheus::Gauge active_key_versions;\n};\n\n// Record metrics\nvoid FieldEncryption::encrypt(const std::string&amp; plaintext, const std::string&amp; key_id) {\n    auto start = std::chrono::steady_clock::now();\n\n    try {\n        // ... encryption logic ...\n\n        metrics_.encryption_operations.Inc();\n\n        auto duration = std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(\n            std::chrono::steady_clock::now() - start\n        ).count();\n        metrics_.encryption_duration_ms.Observe(duration);\n\n    } catch (const std::exception&amp; e) {\n        metrics_.encryption_errors.Inc();\n        throw;\n    }\n}\n</code></pre>"},{"location":"encryption_deployment/#grafana-dashboard","title":"Grafana Dashboard","text":"<pre><code>{\n  \"dashboard\": {\n    \"title\": \"Themis Encryption Metrics\",\n    \"panels\": [\n      {\n        \"title\": \"Encryption Operations/sec\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(themis_encryption_operations_total[5m])\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Decryption Latency (p95)\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.95, themis_decryption_duration_ms)\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Cache Hit Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"themis_key_cache_hit_rate\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Vault Request Errors\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(themis_vault_request_errors_total[5m])\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"encryption_deployment/#alerting-rules","title":"Alerting Rules","text":"<pre><code># prometheus/alerts.yml\ngroups:\n- name: encryption\n  rules:\n\n  # Alert if encryption failure rate &gt; 1%\n  - alert: HighEncryptionErrorRate\n    expr: |\n      rate(themis_encryption_errors_total[5m]) / \n      rate(themis_encryption_operations_total[5m]) &gt; 0.01\n    for: 5m\n    labels:\n      severity: critical\n    annotations:\n      summary: \"High encryption error rate detected\"\n      description: \"Encryption error rate is {{ $value | humanizePercentage }}\"\n\n  # Alert if cache hit rate drops below 80%\n  - alert: LowCacheHitRate\n    expr: themis_key_cache_hit_rate &lt; 0.8\n    for: 10m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Low key cache hit rate\"\n      description: \"Cache hit rate is {{ $value | humanizePercentage }}\"\n\n  # Alert if Vault requests are slow\n  - alert: SlowVaultRequests\n    expr: |\n      histogram_quantile(0.95, \n        rate(themis_vault_request_duration_ms_bucket[5m])\n      ) &gt; 100\n    for: 5m\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Slow Vault API requests\"\n      description: \"P95 latency is {{ $value }}ms\"\n\n  # Alert if a key rotation is overdue\n  - alert: KeyRotationOverdue\n    expr: |\n      (time() - themis_key_last_rotation_timestamp) / 86400 &gt; 180\n    for: 1d\n    labels:\n      severity: warning\n    annotations:\n      summary: \"Key rotation overdue\"\n      description: \"Key {{ $labels.key_id }} has not been rotated in {{ $value }} days\"\n</code></pre>"},{"location":"encryption_deployment/#disaster-recovery","title":"Disaster Recovery","text":""},{"location":"encryption_deployment/#backup-procedures","title":"Backup Procedures","text":"<pre><code>#!/bin/bash\n# backup-vault.sh - Automated Vault backup\n\nBACKUP_DIR=\"/backups/vault/$(date +%Y%m%d)\"\nmkdir -p $BACKUP_DIR\n\n# Take Consul snapshot (Vault storage backend)\nconsul snapshot save $BACKUP_DIR/consul-snapshot.snap\n\n# Export all encryption keys (encrypted with GPG)\nvault kv get -format=json themis/keys | \\\n  gpg --encrypt --recipient backup@example.com &gt; \\\n  $BACKUP_DIR/encryption-keys.json.gpg\n\n# Backup Vault unseal keys (should be in separate secure location)\n# These should already be distributed to key custodians\n\n# Upload to S3 with server-side encryption\naws s3 cp $BACKUP_DIR s3://vault-backups/$(date +%Y%m%d)/ \\\n  --recursive \\\n  --sse AES256\n\necho \"\u2705 Vault backup completed: $BACKUP_DIR\"\n</code></pre>"},{"location":"encryption_deployment/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"encryption_deployment/#scenario-1-lost-vault-token","title":"Scenario 1: Lost Vault Token","text":"<pre><code># Generate new token from AppRole\nROLE_ID=\"&lt;stored-role-id&gt;\"\nSECRET_ID=$(vault write -f auth/approle/role/themis-app/secret-id | \\\n  grep 'secret_id ' | awk '{print $2}')\n\nNEW_TOKEN=$(vault write auth/approle/login \\\n  role_id=$ROLE_ID \\\n  secret_id=$SECRET_ID | \\\n  grep 'token ' | awk '{print $2}')\n\n# Update application configuration\nkubectl set env deployment/themis-api VAULT_TOKEN=$NEW_TOKEN\n</code></pre>"},{"location":"encryption_deployment/#scenario-2-vault-cluster-failure","title":"Scenario 2: Vault Cluster Failure","text":"<pre><code># Restore from backup\nconsul snapshot restore /backups/vault/20251030/consul-snapshot.snap\n\n# Unseal all Vault nodes\nfor NODE in vault-1 vault-2 vault-3; do\n  vault operator unseal -address=https://$NODE:8200 &lt;unseal-key-1&gt;\n  vault operator unseal -address=https://$NODE:8200 &lt;unseal-key-2&gt;\n  vault operator unseal -address=https://$NODE:8200 &lt;unseal-key-3&gt;\ndone\n\n# Verify key recovery\nvault kv get themis/keys/user_pii\n</code></pre>"},{"location":"encryption_deployment/#scenario-3-corrupted-encryption-key","title":"Scenario 3: Corrupted Encryption Key","text":"<pre><code># If a key becomes corrupted, restore from backup\ngpg --decrypt /backups/vault/20251030/encryption-keys.json.gpg | \\\n  jq '.data.keys.user_pii' | \\\n  vault kv put themis/keys/user_pii -\n\n# Verify\nvault kv get themis/keys/user_pii\n</code></pre>"},{"location":"encryption_deployment/#security-best-practices","title":"Security Best Practices","text":""},{"location":"encryption_deployment/#1-key-storage","title":"1. Key Storage","text":"<p>\u2705 DO: - Store keys in HashiCorp Vault with encryption at rest - Use hardware security modules (HSM) for Vault master key - Implement key versioning for rotation - Distribute unseal keys to 3+ trusted individuals - Audit all key access via Vault audit logs</p> <p>\u274c DON'T: - Store keys in environment variables or config files - Commit keys to version control - Share keys via email/Slack - Use single-version keys (prevents rotation)</p>"},{"location":"encryption_deployment/#2-access-control","title":"2. Access Control","text":"<pre><code># Principle of least privilege\npath \"themis/data/keys/user_pii\" {\n  capabilities = [\"read\"]\n\n  # Allow only from specific IP range\n  allowed_parameters = {\n    \"cidr_list\" = [\"10.0.0.0/8\"]\n  }\n}\n\n# Separate admin policy for key rotation\npath \"themis/data/keys/*\" {\n  capabilities = [\"create\", \"update\", \"delete\"]\n\n  # Require MFA for destructive operations\n  mfa_methods = [\"totp\"]\n}\n</code></pre>"},{"location":"encryption_deployment/#3-network-security","title":"3. Network Security","text":"<ul> <li>TLS 1.3 for all Vault communications</li> <li>Mutual TLS (mTLS) in production</li> <li>Network policies to restrict Vault access</li> <li>Private subnets for Vault cluster</li> </ul>"},{"location":"encryption_deployment/#4-audit-logging","title":"4. Audit Logging","text":"<pre><code># vault/config/audit.hcl\naudit {\n  type = \"file\"\n\n  options = {\n    file_path = \"/vault/logs/audit.log\"\n    log_raw = false  # Don't log sensitive data\n    hmac_accessor = true\n    mode = \"0600\"\n    format = \"json\"\n  }\n}\n</code></pre>"},{"location":"encryption_deployment/#5-monitoring","title":"5. Monitoring","text":"<ul> <li>Alert on failed authentication attempts</li> <li>Monitor key access patterns for anomalies</li> <li>Track cache hit rates (should be &gt;80%)</li> <li>Set up dead man's switch for unseal keys</li> </ul>"},{"location":"encryption_deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"encryption_deployment/#issue-slow-encryption-performance","title":"Issue: Slow Encryption Performance","text":"<p>Symptoms: - Encryption operations &gt;10ms - High CPU usage - Low throughput</p> <p>Diagnosis:</p> <pre><code># Check if AES-NI is enabled\nlscpu | grep aes\n# Should show \"aes\" in flags\n\n# Check OpenSSL version\nopenssl version\n# Should be 3.0+\n\n# Profile encryption calls\nperf record -g ./themis_demo_encryption\nperf report\n</code></pre> <p>Solutions: 1. Verify AES-NI hardware support 2. Update OpenSSL to latest version 3. Increase key cache size 4. Use connection pooling for Vault requests</p>"},{"location":"encryption_deployment/#issue-vault-connection-timeouts","title":"Issue: Vault Connection Timeouts","text":"<p>Symptoms: - <code>CURL error: Timeout was reached</code> - Intermittent decryption failures</p> <p>Diagnosis:</p> <pre><code># Test Vault connectivity\ntime curl -k https://vault.example.com:8200/v1/sys/health\n\n# Check network latency\nping -c 10 vault.example.com\n\n# Review Vault server logs\nvault audit log | grep themis\n</code></pre> <p>Solutions: 1. Increase <code>request_timeout_ms</code> in config 2. Deploy Vault closer to application (same datacenter) 3. Enable HTTP/2 keep-alive 4. Scale Vault cluster horizontally</p>"},{"location":"encryption_deployment/#issue-cache-thrashing","title":"Issue: Cache Thrashing","text":"<p>Symptoms: - Cache hit rate &lt;50% - Frequent Vault API calls - Increased latency</p> <p>Diagnosis:</p> <pre><code>// Enable debug logging\nauto stats = vault_provider-&gt;getCacheStats();\nstd::cout &lt;&lt; \"Hit rate: \" &lt;&lt; stats.hit_rate &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"Total requests: \" &lt;&lt; stats.total_requests &lt;&lt; std::endl;\nstd::cout &lt;&lt; \"Cache size: \" &lt;&lt; stats.cache_size &lt;&lt; std::endl;\n</code></pre> <p>Solutions: 1. Increase <code>cache_capacity</code> (default: 1000) 2. Increase <code>cache_ttl_seconds</code> (default: 3600) 3. Pre-warm cache on application startup 4. Review key access patterns (consolidate similar keys)</p>"},{"location":"encryption_deployment/#performance-tuning","title":"Performance Tuning","text":""},{"location":"encryption_deployment/#benchmark-results","title":"Benchmark Results","text":"<p>Hardware: Intel Xeon 8375C (AES-NI), 16GB RAM, NVMe SSD</p> Operation Throughput Latency (p50) Latency (p95) Encrypt (cached key) 256,000 ops/sec 0.004 ms 0.008 ms Decrypt (cached key) 200,000 ops/sec 0.005 ms 0.010 ms Vault key fetch (cold) 20 ops/sec 50 ms 100 ms DB write (encrypted) 1,300 ops/sec 0.75 ms 2 ms"},{"location":"encryption_deployment/#optimization-checklist","title":"Optimization Checklist","text":"<ul> <li>[x] Enable AES-NI hardware acceleration</li> <li>[x] Cache keys in memory (1h TTL)</li> <li>[x] Use connection pooling for Vault</li> <li>[x] Batch operations where possible</li> <li>[x] Pre-warm cache on startup</li> <li>[ ] Implement circuit breaker for Vault failures</li> <li>[ ] Use Vault agent for local caching</li> <li>[ ] Deploy Vault replicas in each datacenter</li> </ul>"},{"location":"encryption_deployment/#appendix","title":"Appendix","text":""},{"location":"encryption_deployment/#a-key-rotation-checklist","title":"A. Key Rotation Checklist","text":"<pre><code>\u25a1 Generate new key version in Vault\n\u25a1 Invalidate application key caches\n\u25a1 Start background re-encryption job\n\u25a1 Monitor re-encryption progress\n\u25a1 Verify 100% migration to new version\n\u25a1 Mark old key version as DEPRECATED\n\u25a1 Wait 90-day grace period\n\u25a1 Delete old key version from Vault\n\u25a1 Update audit logs\n</code></pre>"},{"location":"encryption_deployment/#b-emergency-contacts","title":"B. Emergency Contacts","text":"Role Name Contact Responsibility Security Lead Alice Johnson alice@example.com Key management approval DevOps Lead Bob Smith bob@example.com Vault infrastructure On-Call Engineer oncall@example.com 24/7 incident response"},{"location":"encryption_deployment/#c-compliance-matrix","title":"C. Compliance Matrix","text":"Requirement Implementation Evidence GDPR Art. 32 AES-256-GCM encryption Vault audit logs HIPAA \u00a7164.312(a)(2)(iv) Key versioning + rotation Rotation schedule PCI DSS 3.4 Cryptographic key management Vault policies SOC 2 CC6.1 Access controls Vault AppRole logs <p>Document Version: 1.0 Last Review: 30. Oktober 2025 Next Review: 30. Januar 2026 Owner: Security Engineering Team</p>"},{"location":"encryption_strategy/","title":"Verschl\u00fcsselungsstrategie f\u00fcr ThemisDB (E2E On-Premise)","text":""},{"location":"encryption_strategy/#executive-summary","title":"Executive Summary","text":"<p>Ziel: End-to-End-Verschl\u00fcsselung f\u00fcr sensible Daten in ThemisDB mit on-premise PKI-basiertem Key-Management unter Nutzung des VCC-PKI-Systems (<code>c:\\vcc\\pki</code>) und VCC-User-Systems (<code>c:\\vcc\\user</code>).</p> <p>Kernprinzipien: - \ud83d\udd13 Metadaten sichtbar: Indexstrukturen, PKs, Timestamps, Kategorien bleiben unverschl\u00fcsselt f\u00fcr Query-Performance - \ud83d\udd10 Daten verschl\u00fcsselt: Graph-Properties, Relational-Fields, Content-Blobs, Vector-Embeddings verschl\u00fcsselt at-rest - \ud83d\udd11 PKI-basiert: Integration mit VCC-PKI f\u00fcr Zertifikat-basierte Schl\u00fcsselableitung - \ud83d\udc64 User-Context: Per-User-Verschl\u00fcsselung via VCC-User-System (JWT-Propagation) - \ud83d\udeab Zero-Knowledge: Ohne korrekten Schl\u00fcssel keine Datenrekonstruktion m\u00f6glich</p>"},{"location":"encryption_strategy/#1-architektur-ubersicht","title":"1. Architektur-\u00dcbersicht","text":""},{"location":"encryption_strategy/#11-threat-model","title":"1.1 Threat Model","text":"<p>Was wird gesch\u00fctzt: - Graph: Edge-Properties (z.B. <code>weight</code>, <code>metadata</code>, benutzerdefinierte Felder) - Relational: Sensitive Spalten (z.B. <code>email</code>, <code>phone</code>, <code>address</code>, Custom-Fields) - Content: Bin\u00e4rblobs (PDF, DOCX, Bilder mit EXIF, Audio mit Metadaten) - Vector: Embeddings (768-dim float32, rekonstruierbar \u2192 Originaldokument)</p> <p>Was NICHT verschl\u00fcsselt wird (Performance/Query): - Primary Keys, Foreign Keys - Index-Keys (SecondaryIndex, CompositeIndex) - Timestamps (<code>created_at</code>, <code>modified_at</code>) - Kategorien, Tags, MIME-Types - Vector-Dimensionen (f\u00fcr Index-Initialisierung) - Graph-Topologie (Knoten-IDs, Kanten-Richtung, Label)</p> <p>Angriffszenarien: 1. \u274c Disk-Theft: Festplatte gestohlen \u2192 verschl\u00fcsselte Daten unlesbar 2. \u274c Backup-Leak: Backup-Datei im Netz \u2192 ohne Schl\u00fcssel nutzlos 3. \u274c Insider-Threat: DB-Admin ohne User-Key kann Daten nicht lesen 4. \u274c Memory-Dump: Angreifer kann nur kurzlebige In-Memory-Schl\u00fcssel extrahieren</p>"},{"location":"encryption_strategy/#2-pki-integration-vcc-pki","title":"2. PKI-Integration (VCC-PKI)","text":""},{"location":"encryption_strategy/#21-vcc-pki-system-cvccpki","title":"2.1 VCC-PKI System (<code>c:\\vcc\\pki</code>)","text":"<p>Vorhandene Infrastruktur: - Root CA: 10 Jahre G\u00fcltigkeit, 4096-bit RSA - Intermediate CA: 5 Jahre, signiert Service-Zertifikate - Service Certificates: Pro Service (veritas, covina, clara, themis) - REST API: <code>https://localhost:8443/api/v1</code> (FastAPI) - mTLS: Client-Zertifikat-basierte Authentifizierung (geplant)</p> <p>Nutzung f\u00fcr ThemisDB:</p> <pre><code>Root CA (VCC Root CA)\n \u2514\u2500\u2500 Intermediate CA (VCC Intermediate CA)\n      \u251c\u2500\u2500 Service Cert: themis-db.vcc.local\n      \u2514\u2500\u2500 Data Encryption Key (DEK) Wrapping Cert\n</code></pre>"},{"location":"encryption_strategy/#22-key-hierarchie","title":"2.2 Key-Hierarchie","text":"<p>3-Tier Key-Architektur:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502 verschl\u00fcsselt\n               \u25bc\n\u2502  DEK (Data Encryption Key)              \u2502\n\u2502  - AES-256-GCM Master-Key               \u2502\n\u2502  - Pro Datenbank/Tenant                 \u2502\n\u2502  - Gespeichert verschl\u00fcsselt in DB      \u2502\n\u2502  - Rotierbar ohne Daten-Re-Encryption   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502  - Aus JWT-Token + DEK abgeleitet       \u2502\n\u2502  - HKDF mit User-ID als Context         \u2502\n\u2502  - Ephemeral (nur In-Memory)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502 verschl\u00fcsselt\n               \u25bc\n        [Sensitive Data]\n</code></pre> <p>Key-Derivation:</p> <pre><code>// 1. KEK aus PKI-Zertifikat (einmalig beim Start)\nKEK = HKDF-SHA256(\n    info=\"KEK for ThemisDB instance\"\n)\n\n// 2. DEK laden/erstellen (beim DB-Init)\nencrypted_DEK = storage-&gt;get(\"config:dek_encrypted\")\nif (!encrypted_DEK) {\n    DEK = random_bytes(32)  // AES-256\n    encrypted_DEK = AES-GCM-encrypt(DEK, KEK, nonce=random(12))\n    storage-&gt;put(\"config:dek_encrypted\", encrypted_DEK)\n} else {\n    DEK = AES-GCM-decrypt(encrypted_DEK, KEK)\n}\n\n// 3. User-spezifischer Field-Key (bei jedem Request)\nuser_id = extract_from_jwt(request.headers[\"Authorization\"])\nfield_key = HKDF-SHA256(\n    DEK,\n    salt=user_id,\n    info=\"field-encryption:\" + field_name\n)\n---\n## 3. User-Context-Integration (VCC-User)\n\n### 3.1 VCC-User System (`c:\\vcc\\user`)\n\n**Identity Propagation:**\n- **Keycloak**: OIDC Identity Provider mit AD-F\u00f6deration\n- **JWT-Token**: Durchg\u00e4ngige Propagation durch alle Services\n- **Zero-Trust**: Jeder Service validiert JWT unabh\u00e4ngig\n\n**JWT-Claims f\u00fcr ThemisDB:**\n```json\n{\n  \"sub\": \"user123\",\n  \"email\": \"alice@vcc.local\",\n  \"groups\": [\"data_scientists\", \"hr_team\"],\n  \"roles\": [\"data_reader\", \"pii_access\"],\n  \"iss\": \"https://keycloak.vcc.local/realms/vcc\",\n  \"exp\": 1730000000\n}\n</code></pre>"},{"location":"encryption_strategy/#32-access-control-basierte-verschlusselung","title":"3.2 Access-Control-basierte Verschl\u00fcsselung","text":"<p>Idee: Verschiedene User-Gruppen haben verschiedene Verschl\u00fcsselungskontext \u2192 Multi-User-Encryption</p> <p>Beispiel:</p> <pre><code>// In ThemisDB HTTP-Handler\nstd::string jwt_token = request.get_header(\"Authorization\");\nauto claims = jwt_validator_.parse_and_validate(jwt_token);\nstd::string user_id = claims[\"sub\"];\nstd::vector&lt;std::string&gt; groups = claims[\"groups\"];\n\n// Ableitung eines gruppenspezifischen Schl\u00fcssels\nstd::string encryption_context = user_id; // oder group[0] f\u00fcr Gruppenschl\u00fcssel\nauto field_key = key_provider_-&gt;deriveUserKey(dek_, encryption_context, field_name);\n\n// Verschl\u00fcsseln mit User-Context\nEncryptedBlob blob = field_encryption_-&gt;encrypt(sensitive_data, field_key);\n</code></pre> <p>Vorteil: - \ud83d\udc64 User-Isolation: User A kann Daten von User B nicht entschl\u00fcsseln - \ud83d\udc65 Gruppenschl\u00fcssel: HR-Gruppe verschl\u00fcsselt mit <code>group=hr_team</code> \u2192 alle HR-Mitglieder k\u00f6nnen lesen - \ud83d\udd04 Key-Rotation: Bei User-Austritt \u2192 Keys ung\u00fcltig ohne Daten-Re-Encryption</p>"},{"location":"encryption_strategy/#4-datenmodell-spezifische-verschlusselung","title":"4. Datenmodell-spezifische Verschl\u00fcsselung","text":""},{"location":"encryption_strategy/#41-graph-property-graph","title":"4.1 Graph (Property Graph)","text":"<p>Was verschl\u00fcsseln:</p> <pre><code>// BaseEntity f\u00fcr Graph-Edge\n{\n  \"pk\": \"graph:edge:alice-&gt;bob\",           // PLAIN (Index)\n  \"from\": \"alice\",                          // PLAIN (Topologie)\n  \"to\": \"bob\",                              // PLAIN (Topologie)\n  \"label\": \"KNOWS\",                         // PLAIN (Query)\n  \"created_at\": 1730000000,                 // PLAIN (Index)\n  \"weight\": 0.95,                           // \ud83d\udd10 ENCRYPTED\n  \"metadata\": {                             // \ud83d\udd10 ENCRYPTED (ganzes Objekt)\n    \"since\": \"2020-01-01\",\n    \"context\": \"university\"\n  }\n}\n</code></pre> <p>Implementierung:</p> <pre><code>// In GraphIndexManager::addEdge()\nBaseEntity::FieldMap fields;\nfields[\"pk\"] = edge.getPrimaryKey();\nfields[\"from\"] = edge.getFieldAsString(\"from\");\nfields[\"to\"] = edge.getFieldAsString(\"to\");\nfields[\"label\"] = edge.getFieldAsString(\"label\");\nfields[\"created_at\"] = edge.getFieldAsInt(\"created_at\");\n\n// Sensitive Felder verschl\u00fcsseln\nif (auto weight = edge.getField(\"weight\")) {\n    std::string user_key = deriveUserKey(jwt_context, \"edge.weight\");\n    auto encrypted = field_enc_-&gt;encrypt(serializeValue(*weight), user_key);\n    fields[\"weight_encrypted\"] = encrypted.toBase64();\n}\nif (auto meta = edge.getField(\"metadata\")) {\n    std::string user_key = deriveUserKey(jwt_context, \"edge.metadata\");\n    auto encrypted = field_enc_-&gt;encrypt(serializeValue(*meta), user_key);\n    fields[\"metadata_encrypted\"] = encrypted.toBase64();\n}\n\nBaseEntity encrypted_edge = BaseEntity::fromFields(pk, fields);\nstorage_-&gt;put(key, encrypted_edge.serialize());\n</code></pre>"},{"location":"encryption_strategy/#42-relational-baseentity-fields","title":"4.2 Relational (BaseEntity Fields)","text":"<p>Schema-basierte Verschl\u00fcsselung:</p> <pre><code>{\n  \"schema\": {\n    \"users\": {\n      \"fields\": {\n        \"id\": { \"type\": \"string\", \"encrypted\": false, \"indexed\": true },\n        \"email\": { \"type\": \"string\", \"encrypted\": true, \"indexed\": false },\n        \"name\": { \"type\": \"string\", \"encrypted\": false, \"indexed\": true },\n        \"ssn\": { \"type\": \"string\", \"encrypted\": true, \"indexed\": false },\n        \"salary\": { \"type\": \"int64\", \"encrypted\": true, \"indexed\": false }\n      }\n    }\n  }\n}\n</code></pre> <p>Automatische Verschl\u00fcsselung:</p> <pre><code>// In QueryEngine beim INSERT\nauto schema = loadSchema(\"users\");\nfor (const auto&amp; [field, config] : schema.fields) {\n    if (config.encrypted) {\n        auto value = entity.getField(field);\n        auto user_key = deriveUserKey(jwt, \"users.\" + field);\n        auto enc = field_enc_-&gt;encrypt(serializeValue(*value), user_key);\n        entity.setField(field + \"_encrypted\", enc.toBase64());\n        entity.setField(field, std::monostate{}); // clear plaintext\n    }\n}\n</code></pre>"},{"location":"encryption_strategy/#43-content-binarblobs","title":"4.3 Content (Bin\u00e4rblobs)","text":"<p>Chunk-Level-Verschl\u00fcsselung:</p> <pre><code>// In ContentManager::importContent()\nif (config.encrypt_blobs &amp;&amp; blob.has_value()) {\n    std::string user_key = deriveUserKey(jwt, \"content.blob:\" + meta.id);\n    auto encrypted = field_enc_-&gt;encrypt(*blob, user_key);\n\n    // Meta-Flag setzen\n    meta.encrypted = true;\n    meta.encryption_type = \"aes-256-gcm\";\n    meta.encryption_context = jwt_claims[\"sub\"]; // oder group\n\n    storage_-&gt;put(\"content_blob:\" + meta.id, encrypted.toBase64());\n}\n\n// In ContentManager::getContentBlob()\nif (meta.encrypted) {\n    // User-Context validieren\n    if (jwt_claims[\"sub\"] != meta.encryption_context &amp;&amp; \n        !hasGroupAccess(jwt_claims, meta.encryption_context)) {\n        throw UnauthorizedException(\"No access to encrypted content\");\n    }\n\n    auto user_key = deriveUserKey(jwt, \"content.blob:\" + meta.id);\n    auto decrypted = field_enc_-&gt;decrypt(encrypted_blob, user_key);\n    return decrypted;\n}\n</code></pre>"},{"location":"encryption_strategy/#44-vector-embeddings","title":"4.4 Vector (Embeddings)","text":"<p>Trade-off: Verschl\u00fcsselung vs. Nearest-Neighbor-Search</p> <p>Problem: - ANN-Search (HNSW) ben\u00f6tigt float32-Vektoren im Klartext - Verschl\u00fcsselte Vektoren \u2192 keine Distanz-Berechnung m\u00f6glich</p> <p>L\u00f6sungen:</p>"},{"location":"encryption_strategy/#option-a-keine-vektor-verschlusselung-default","title":"Option A: Keine Vektor-Verschl\u00fcsselung (Default)","text":"<pre><code>// Vektoren bleiben unverschl\u00fcsselt f\u00fcr ANN\n// Zugriff nur \u00fcber authorizierte API-Calls\n// Audit-Logging aller Vector-Queries\n</code></pre> <p>Vorteil: \u2705 Volle ANN-Performance Nachteil: \u26a0\ufe0f Vektoren at-rest rekonstruierbar</p>"},{"location":"encryption_strategy/#option-b-encrypt-then-search-metadata-only","title":"Option B: Encrypt-then-Search (Metadata-only)","text":"<pre><code>// Nur Vektor-Metadaten verschl\u00fcsseln\nBaseEntity vector_entity;\nvector_entity.setField(\"pk\", pk);                    // PLAIN\nvector_entity.setField(\"embedding\", embedding);      // PLAIN (f\u00fcr HNSW)\nvector_entity.setField(\"source_text_encrypted\", enc_text);  // \ud83d\udd10 ENCRYPTED\nvector_entity.setField(\"metadata_encrypted\", enc_meta);     // \ud83d\udd10 ENCRYPTED\n</code></pre> <p>Vorteil: \u2705 ANN funktioniert, Quelltext gesch\u00fctzt Nachteil: \u26a0\ufe0f Embedding selbst im Klartext</p>"},{"location":"encryption_strategy/#option-c-homomorphic-encryption-future","title":"Option C: Homomorphic Encryption (Future)","text":"<pre><code>// Fully Homomorphic Encryption (FHE) f\u00fcr Distanz-Berechnung\n// Aktuell nicht produktionsreif (100-1000x Slowdown)\n</code></pre> <p>Empfehlung: Start mit Option B (Metadata-Verschl\u00fcsselung), sp\u00e4ter Option C evaluieren</p>"},{"location":"encryption_strategy/#5-implementierungsplan","title":"5. Implementierungsplan","text":""},{"location":"encryption_strategy/#51-phase-1-pki-integration-week-1","title":"5.1 Phase 1: PKI-Integration (Week 1)","text":"<p>Tasks: 1. \u2705 Bereits vorhanden: <code>FieldEncryption</code>, <code>KeyProvider</code>, <code>EncryptedBlob</code> 2. \u274c Neuer <code>PKIKeyProvider</code>:    <code>cpp    class PKIKeyProvider : public KeyProvider {    public:        PKIKeyProvider(std::string cert_path, std::string key_path);        std::vector&lt;uint8_t&gt; getKey(const std::string&amp; key_id, uint32_t version) override;    private:        std::vector&lt;uint8_t&gt; kek_;  // aus Zertifikat        std::vector&lt;uint8_t&gt; dek_;  // aus verschl\u00fcsseltem DB-Key    };</code></p> <ol> <li>\u274c VCC-PKI REST-Client:    <code>cpp    class VCCPKIClient {    public:        // Zertifikat von PKI-Server holen        Certificate requestServiceCertificate(std::string service_id);        void verifyCertificateChain(Certificate cert);    };</code></li> </ol>"},{"location":"encryption_strategy/#52-phase-2-user-context-week-2","title":"5.2 Phase 2: User-Context (Week 2)","text":"<p>Tasks: 1. \u274c JWT-Validator f\u00fcr Keycloak-Token:    <code>cpp    class JWTValidator {    public:        nlohmann::json parseAndValidate(const std::string&amp; token);    private:        std::string jwks_url_;  // Keycloak JWKS-Endpoint    };</code></p> <ol> <li>\u274c User-Key-Derivation:    <code>cpp    std::vector&lt;uint8_t&gt; deriveUserKey(        const std::vector&lt;uint8_t&gt;&amp; dek,        const std::string&amp; user_id,        const std::string&amp; field_name    ) {        return HKDF(dek, user_id, \"field:\" + field_name);    }</code></li> </ol>"},{"location":"encryption_strategy/#53-phase-3-storage-layer-integration-week-3","title":"5.3 Phase 3: Storage-Layer-Integration (Week 3)","text":"<p>Tasks: 1. \u274c GraphIndexManager: Verschl\u00fcssele <code>weight</code>, <code>metadata</code> 2. \u274c ContentManager: Verschl\u00fcssele Blobs (bereits vorbereitet mit <code>meta.encrypted</code>) 3. \u274c VectorIndexManager: Verschl\u00fcssele Vektor-Metadaten (Option B) 4. \u274c QueryEngine: Schema-basierte Auto-Verschl\u00fcsselung</p>"},{"location":"encryption_strategy/#54-phase-4-testing-audit-week-4","title":"5.4 Phase 4: Testing &amp; Audit (Week 4)","text":"<p>Tests: - Unit-Tests: Encrypt/Decrypt-Roundtrip f\u00fcr alle Datentypen - Integration: Multi-User-Szenarien (User A kann Daten von User B nicht lesen) - Performance: Overhead-Messung (Encrypt: ~0.5ms/KB, Decrypt: ~0.5ms/KB) - Security: Pen-Test mit gestohlenem Backup ohne Keys</p>"},{"location":"encryption_strategy/#6-konfiguration","title":"6. Konfiguration","text":""},{"location":"encryption_strategy/#61-db-config-configencryption-in-rocksdb","title":"6.1 DB-Config (<code>config:encryption</code> in RocksDB)","text":"<pre><code>{\n  \"enabled\": true,\n  \"algorithm\": \"aes-256-gcm\",\n  \"key_provider\": \"pki\",\n  \"pki\": {\n    \"server_url\": \"https://localhost:8443/api/v1\",\n    \"service_id\": \"themis-db\",\n    \"cert_path\": \"/etc/themis/certs/themis-db.pem\",\n    \"key_path\": \"/etc/themis/certs/themis-db-key.pem\"\n  },\n  \"user_context\": {\n    \"enabled\": true,\n    \"jwt_issuer\": \"https://keycloak.vcc.local/realms/vcc\",\n    \"jwks_url\": \"https://keycloak.vcc.local/realms/vcc/protocol/openid-connect/certs\"\n  },\n  \"encrypt_fields\": {\n    \"graph_edge_properties\": true,\n    \"content_blobs\": true,\n    \"vector_metadata\": true,\n    \"relational_sensitive\": true\n  }\n}\n</code></pre>"},{"location":"encryption_strategy/#62-schema-definition-per-collectionobject","title":"6.2 Schema-Definition (per Collection/Object)","text":"<pre><code>{\n  \"collections\": {\n    \"users\": {\n      \"encryption\": {\n        \"enabled\": true,\n        \"fields\": [\"email\", \"phone\", \"ssn\", \"address\"],\n        \"context_type\": \"user\"  // per-user oder \"group\"\n      }\n    },\n    \"documents\": {\n      \"encryption\": {\n        \"enabled\": true,\n        \"fields\": [\"content_blob\"],\n        \"context_type\": \"group\",\n        \"allowed_groups\": [\"legal_team\", \"executives\"]\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"encryption_strategy/#7-security-best-practices","title":"7. Security Best-Practices","text":""},{"location":"encryption_strategy/#71-key-management","title":"7.1 Key-Management","text":"<p>\u2705 DO: - KEK aus PKI-Zertifikat ableiten (Hardware-backed wenn m\u00f6glich) - DEK verschl\u00fcsselt in DB speichern - User-Keys nur in-memory halten (ephemeral) - Key-Rotation alle 90 Tage (DEK), Zertifikat-Erneuerung j\u00e4hrlich</p> <p>\u274c DON'T: - Keys im Klartext in Config-Dateien - Hardcoded Keys im Source-Code - DEK unverschl\u00fcsselt in Environment Variables</p>"},{"location":"encryption_strategy/#72-audit-logging","title":"7.2 Audit-Logging","text":"<p>Encrypt-then-Sign f\u00fcr sensible Logs (SAGA, AUDIT):</p> <ul> <li>Canonical JSON erzeugen (stabile Key-Order, UTF-8)</li> <li>Mit t\u00e4glichem LEK (Log Encryption Key) via AES-256-GCM verschl\u00fcsseln</li> <li>Hash \u00fcber den Ciphertext bilden (SHA-256)</li> <li>PKI-Signatur \u00fcber den Ciphertext-Hash (VCC-PKI)</li> <li>Persistieren: Ciphertext + iv + tag + lek_id + Signatur + Zert-Metadaten</li> <li>Optional redaktierte Kurzform in stdout/file loggen (kein Klartext)</li> </ul> <p>Konfiguration siehe Governance (<code>config/governance.yaml</code>): - <code>saga_signing.encrypt_then_sign: true</code> - <code>saga_signing.categories.encrypt_before_sign: [SAGA, AUDIT]</code> - <code>log_encryption.encrypt_categories: [SAGA, AUDIT]</code> - <code>log_encryption.aad_fields: [log_id, category, timestamp]</code></p> <p>LEK-Handling (t\u00e4glich rotierend): 1) KEK aus PKI-Zertifikat per HKDF \u2192 KEK(date) 2) Zuf\u00e4lliger 256-bit LEK generiert \u2192 LEK(date) 3) LEK verschl\u00fcsselt mit KEK(date) in RocksDB abgelegt</p> <p>Log jede Verschl\u00fcsselungs-/Entschl\u00fcsselungs-Operation:</p> <pre><code>{\n  \"timestamp\": \"2025-10-31T10:00:00Z\",\n  \"operation\": \"decrypt\",\n  \"user_id\": \"user123\",\n  \"field\": \"content.blob:abc123\",\n  \"success\": true,\n  \"ip\": \"192.168.1.50\"\n}\n</code></pre>"},{"location":"encryption_strategy/#73-zero-knowledge-compliance","title":"7.3 Zero-Knowledge-Compliance","text":"<p>Verification:</p> <pre><code># Backup ohne Keys erstellen\nrocksdb_dump --db=/data/themis &gt; backup.sst\n\n# Ohne DEK: Daten unlesbar\nstrings backup.sst | grep \"alice@example.com\"  # \u2192 Gibberish\n\n# Mit DEK: Daten lesbar\nthemis-decrypt --dek-file=dek.bin --input=backup.sst | grep \"alice@\"  # \u2192 alice@example.com\n</code></pre>"},{"location":"encryption_strategy/#8-zusammenfassung","title":"8. Zusammenfassung","text":"Feature Status Technologie Nutzen PKI-Integration \u274c TODO VCC-PKI (c:\\vcc\\pki) Zertifikat-basierte KEK User-Context \u274c TODO VCC-User JWT (c:\\vcc\\user) Per-User-Verschl\u00fcsselung Graph-Encryption \u274c TODO AES-256-GCM Edge-Properties gesch\u00fctzt Content-Encryption \ud83d\udfe1 PARTIAL AES-256-GCM Blob-Verschl\u00fcsselung vorbereitet Vector-Metadata-Enc \u274c TODO AES-256-GCM Quelltext gesch\u00fctzt, ANN nutzbar Schema-based Auto-Enc \u274c TODO Config-driven Deklarative Verschl\u00fcsselung Audit-Logging \u274c TODO Encrypt-then-Sign (AES-256-GCM + PKI) Compliance &amp; Forensics <p>N\u00e4chste Schritte: 1. Implementiere <code>PKIKeyProvider</code> mit VCC-PKI REST-Client 2. Integriere JWT-Validator f\u00fcr Keycloak-Token 3. Erweitere <code>GraphIndexManager</code>, <code>ContentManager</code>, <code>VectorIndexManager</code> 4. Teste Multi-User-Szenarien mit verschiedenen JWT-Claims 5. Performance-Benchmarks mit verschl\u00fcsselten Daten</p>"},{"location":"glossary/","title":"Glossar","text":"<ul> <li>AQL: Abfragesprache von ThemisDB (\u00e4hnlich JSON-basiert)</li> <li>Entity: Knoten-Element (Dokument) im Graph-/Dokumentenmodell</li> <li>Edge: Beziehung zwischen Entities</li> <li>MVCC: Multi-Version Concurrency Control (Nebenl\u00e4ufigkeitskontrolle)</li> <li>WAL: Write-Ahead Log von RocksDB</li> <li>TSStore: Zeitreihen-Speicherkomponente von ThemisDB</li> <li>HNSW: Graph-basierter Algorithmus f\u00fcr Vektor-NN-Suche</li> <li>PII: Personally Identifiable Information (personenbeziehbare Daten)</li> <li>OpenAPI: Spezifikation der HTTP-REST-APIs</li> </ul>"},{"location":"gnn_embeddings/","title":"GNN Embeddings","text":"<p>Status: \u2705 COMPLETE Version: 1.0 Date: 31. Oktober 2025 Tests: 13/13 Passing  </p>"},{"location":"gnn_embeddings/#overview","title":"Overview","text":"<p>The GNN (Graph Neural Network) Embeddings module provides graph embedding generation for nodes, edges, and entire graphs. It enables machine learning workflows like node classification, link prediction, and graph similarity search by converting graph structures into dense vector representations.</p>"},{"location":"gnn_embeddings/#architecture","title":"Architecture","text":"<pre><code>GNNEmbeddingManager\n\u251c\u2500 Feature Extraction (from BaseEntity fields)\n\u251c\u2500 Embedding Computation (feature-based MVP, extensible to GNN models)\n\u251c\u2500 Storage Layer (RocksDB + VectorIndexManager)\n\u251c\u2500 Similarity Search (HNSW-based KNN)\n\u2514\u2500 Model Registry (multiple embedding models per graph)\n</code></pre> <p>Components: - PropertyGraphManager: Provides graph structure (nodes, edges, labels, types) - VectorIndexManager: Stores embeddings for similarity search (HNSW index) - RocksDBWrapper: Persists embeddings for retrieval - BaseEntity: Flexible entity storage with type-safe field access</p>"},{"location":"gnn_embeddings/#features","title":"Features","text":""},{"location":"gnn_embeddings/#1-node-embeddings","title":"1. Node Embeddings","text":"<p>Generate embeddings for all nodes with a specific label:</p> <pre><code>GNNEmbeddingManager gem(db, pgm, vim);\n\n// Register model\ngem.registerModel(\"my_model\", \"GraphSAGE\", 128);\n\n// Generate embeddings for all \"Person\" nodes\nauto st = gem.generateNodeEmbeddings(\"graph1\", \"Person\", \"my_model\");\n\n// Update single node embedding\nauto st2 = gem.updateNodeEmbedding(\"person123\", \"graph1\", \"my_model\");\n\n// Retrieve embedding\nauto [st3, embInfo] = gem.getNodeEmbedding(\"person123\", \"graph1\", \"my_model\");\nstd::vector&lt;float&gt; embedding = embInfo.embedding;  // 128-dim vector\n</code></pre> <p>Use Cases: - Node classification (predict node labels) - Clustering (group similar nodes) - Anomaly detection (find outliers)</p>"},{"location":"gnn_embeddings/#2-edge-embeddings","title":"2. Edge Embeddings","text":"<p>Generate embeddings for relationships:</p> <pre><code>// Generate embeddings for all \"KNOWS\" edges\nauto st = gem.generateEdgeEmbeddings(\"graph1\", \"KNOWS\", \"my_model\");\n\n// Update single edge\nauto st2 = gem.updateEdgeEmbedding(\"edge456\", \"graph1\", \"my_model\");\n\n// Retrieve\nauto [st3, embInfo] = gem.getEdgeEmbedding(\"edge456\", \"graph1\", \"my_model\");\n</code></pre> <p>Use Cases: - Link prediction (predict missing edges) - Relationship classification - Edge importance scoring</p>"},{"location":"gnn_embeddings/#3-graph-level-embeddings","title":"3. Graph-Level Embeddings","text":"<p>Aggregate node embeddings to represent entire graphs:</p> <pre><code>// Mean pooling\nauto [st, graphEmb] = gem.generateGraphEmbedding(\"graph1\", \"my_model\", \"mean\");\n\n// Sum pooling\nauto [st2, graphEmbSum] = gem.generateGraphEmbedding(\"graph1\", \"my_model\", \"sum\");\n\n// Max pooling\nauto [st3, graphEmbMax] = gem.generateGraphEmbedding(\"graph1\", \"my_model\", \"max\");\n</code></pre> <p>Aggregation Methods: - <code>mean</code>: Average of all node embeddings (good for balanced graphs) - <code>sum</code>: Sum of embeddings (sensitive to graph size) - <code>max</code>: Element-wise maximum (captures extreme features)</p> <p>Use Cases: - Graph classification (classify entire graphs) - Graph similarity (compare graphs) - Graph clustering</p>"},{"location":"gnn_embeddings/#4-similarity-search","title":"4. Similarity Search","text":"<p>Find similar nodes or edges using vector similarity:</p> <pre><code>// Find 10 similar nodes to person123\nauto [st, similar] = gem.findSimilarNodes(\"person123\", \"graph1\", 10, \"my_model\");\n\nfor (const auto&amp; res : similar) {\n    std::cout &lt;&lt; \"Node: \" &lt;&lt; res.entity_id \n              &lt;&lt; \" Similarity: \" &lt;&lt; res.similarity &lt;&lt; \"\\n\";\n}\n\n// Find similar edges\nauto [st2, simEdges] = gem.findSimilarEdges(\"edge456\", \"graph1\", 5, \"my_model\");\n</code></pre> <p>Similarity Metric: Cosine similarity (1 - L2 distance from HNSW)</p> <p>Use Cases: - Recommendation (find similar users/items) - Duplicate detection - Entity resolution</p>"},{"location":"gnn_embeddings/#5-model-management","title":"5. Model Management","text":"<p>Support multiple embedding models per graph:</p> <pre><code>// Register models with different dimensions\ngem.registerModel(\"small_model\", \"GraphSAGE\", 64);\ngem.registerModel(\"large_model\", \"GraphSAGE\", 256);\n\n// List all models\nauto [st, models] = gem.listModels();\n// models = [\"small_model\", \"large_model\"]\n\n// Get model info\nauto [st2, info] = gem.getModelInfo(\"large_model\");\n// info.embedding_dim = 256\n// info.type = \"GraphSAGE\"\n</code></pre> <p>Model Types: - <code>feature_based</code>: Simple feature aggregation (current MVP) - <code>GraphSAGE</code>: Inductive graph learning (future) - <code>GAT</code>: Graph Attention Networks (future) - <code>GCN</code>: Graph Convolutional Networks (future)</p>"},{"location":"gnn_embeddings/#6-batch-operations","title":"6. Batch Operations","text":"<p>Efficient processing of multiple entities:</p> <pre><code>std::vector&lt;std::string&gt; node_pks = {\"person1\", \"person2\", \"person3\"};\n\n// Process in batches of 32\nauto st = gem.generateNodeEmbeddingsBatch(node_pks, \"graph1\", \"my_model\", 32);\n\n// Edge batching\nstd::vector&lt;std::string&gt; edge_ids = {...};\nauto st2 = gem.generateEdgeEmbeddingsBatch(edge_ids, \"graph1\", \"my_model\", 32);\n</code></pre> <p>Benefits: - Reduced database roundtrips - Better memory locality - Progress monitoring</p>"},{"location":"gnn_embeddings/#7-statistics-monitoring","title":"7. Statistics &amp; Monitoring","text":"<p>Track embedding generation:</p> <pre><code>auto [st, stats] = gem.getStats();\n\nstd::cout &lt;&lt; \"Total node embeddings: \" &lt;&lt; stats.total_node_embeddings &lt;&lt; \"\\n\";\nstd::cout &lt;&lt; \"Total edge embeddings: \" &lt;&lt; stats.total_edge_embeddings &lt;&lt; \"\\n\";\n\nfor (const auto&amp; [model, count] : stats.embeddings_per_model) {\n    std::cout &lt;&lt; \"Model \" &lt;&lt; model &lt;&lt; \": \" &lt;&lt; count &lt;&lt; \" embeddings\\n\";\n}\n</code></pre>"},{"location":"gnn_embeddings/#implementation-details","title":"Implementation Details","text":""},{"location":"gnn_embeddings/#feature-extraction","title":"Feature Extraction","text":"<p>Current MVP extracts numeric features from BaseEntity fields:</p> <pre><code>std::vector&lt;float&gt; extractFeatures_(\n    const BaseEntity&amp; entity,\n    const std::vector&lt;std::string&gt;&amp; feature_fields\n) {\n    std::vector&lt;float&gt; features;\n\n    for (const auto&amp; field : feature_fields) {\n        auto intVal = entity.getFieldAsInt(field);\n        if (intVal.has_value()) {\n            features.push_back(static_cast&lt;float&gt;(*intVal));\n            continue;\n        }\n\n        auto doubleVal = entity.getFieldAsDouble(field);\n        if (doubleVal.has_value()) {\n            features.push_back(static_cast&lt;float&gt;(*doubleVal));\n        }\n    }\n\n    return features;\n}\n</code></pre> <p>Default Fields (if none specified): - <code>age</code>, <code>score</code>, <code>rating</code>, <code>count</code>, <code>value</code></p> <p>Future: Support categorical encoding, text embeddings (Sentence-BERT), image features</p>"},{"location":"gnn_embeddings/#embedding-computation-mvp","title":"Embedding Computation (MVP)","text":"<p>Simple normalized feature aggregation:</p> <pre><code>std::vector&lt;float&gt; computeEmbedding_(\n    const std::vector&lt;float&gt;&amp; features,\n    int target_dim\n) {\n    // 1. Copy/pad features to target dimension\n    std::vector&lt;float&gt; embedding(target_dim, 0.0f);\n    std::copy(features.begin(), \n              features.begin() + std::min(features.size(), target_dim),\n              embedding.begin());\n\n    // 2. L2 normalization\n    float norm = std::sqrt(std::inner_product(\n        embedding.begin(), embedding.end(), \n        embedding.begin(), 0.0f));\n\n    if (norm &gt; 0.0f) {\n        for (float&amp; val : embedding) {\n            val /= norm;\n        }\n    }\n\n    return embedding;\n}\n</code></pre> <p>Future GNN Integration: - Load pretrained GNN models (PyTorch C++ API) - Online GNN training (incremental updates) - Neighbor aggregation (GraphSAGE, GAT)</p>"},{"location":"gnn_embeddings/#storage-architecture","title":"Storage Architecture","text":"<p>Dual storage for efficiency:</p> <pre><code>// 1. Store in RocksDB (for retrieval)\nstd::string embKey = \"gnn_emb:node:graph1:model:person123\";\ndb_.put(embKey, embEntity.serialize());\n\n// 2. Add to vector index (for similarity search)\nvim_.addEntity(embEntity, \"embedding\");\n</code></pre> <p>Key Schema: - Node: <code>gnn_emb:node:&lt;graph_id&gt;:&lt;model_name&gt;:&lt;node_pk&gt;</code> - Edge: <code>gnn_emb:edge:&lt;graph_id&gt;:&lt;model_name&gt;:&lt;edge_id&gt;</code></p> <p>Metadata: - <code>entity_id</code>: Original node/edge ID - <code>entity_type</code>: \"node\" or \"edge\" - <code>graph_id</code>: Multi-graph isolation - <code>model_name</code>: Model used for generation - <code>timestamp</code>: Creation/update time - <code>embedding</code>: Dense vector (std::vector)"},{"location":"gnn_embeddings/#multi-graph-isolation","title":"Multi-Graph Isolation","text":"<p>Embeddings are isolated per graph:</p> <pre><code>// Graph 1: person123 embedding\ngem.updateNodeEmbedding(\"person123\", \"graph1\", \"model\");\n\n// Graph 2: person123 embedding (different entity!)\ngem.updateNodeEmbedding(\"person123\", \"graph2\", \"model\");\n\n// Similarity search only within same graph\nauto [st, similar] = gem.findSimilarNodes(\"person123\", \"graph1\", 10, \"model\");\n// Result: Only nodes from graph1, never from graph2\n</code></pre> <p>Implementation: Graph ID is part of embedding key + similarity search filters</p>"},{"location":"gnn_embeddings/#api-reference","title":"API Reference","text":""},{"location":"gnn_embeddings/#constructor","title":"Constructor","text":"<pre><code>GNNEmbeddingManager(\n    RocksDBWrapper&amp; db,\n    PropertyGraphManager&amp; pgm,\n    VectorIndexManager&amp; vim\n);\n</code></pre>"},{"location":"gnn_embeddings/#node-embedding-methods","title":"Node Embedding Methods","text":"<pre><code>// Generate embeddings for all nodes with label\nStatus generateNodeEmbeddings(\n    std::string_view graph_id,\n    std::string_view label,\n    std::string_view model_name,\n    const std::vector&lt;std::string&gt;&amp; feature_fields = {}\n);\n\n// Update/create single node embedding\nStatus updateNodeEmbedding(\n    std::string_view node_pk,\n    std::string_view graph_id,\n    std::string_view model_name,\n    const std::vector&lt;std::string&gt;&amp; feature_fields = {}\n);\n\n// Retrieve node embedding\nstd::pair&lt;Status, EmbeddingInfo&gt; getNodeEmbedding(\n    std::string_view node_pk,\n    std::string_view graph_id,\n    std::string_view model_name\n) const;\n\n// Find similar nodes\nstd::pair&lt;Status, std::vector&lt;SimilarityResult&gt;&gt; findSimilarNodes(\n    std::string_view node_pk,\n    std::string_view graph_id,\n    int k,\n    std::string_view model_name\n) const;\n</code></pre>"},{"location":"gnn_embeddings/#edge-embedding-methods","title":"Edge Embedding Methods","text":"<pre><code>Status generateEdgeEmbeddings(...);\nStatus updateEdgeEmbedding(...);\nstd::pair&lt;Status, EmbeddingInfo&gt; getEdgeEmbedding(...) const;\nstd::pair&lt;Status, std::vector&lt;SimilarityResult&gt;&gt; findSimilarEdges(...) const;\n</code></pre>"},{"location":"gnn_embeddings/#graph-level-methods","title":"Graph-Level Methods","text":"<pre><code>std::pair&lt;Status, std::vector&lt;float&gt;&gt; generateGraphEmbedding(\n    std::string_view graph_id,\n    std::string_view model_name,\n    std::string_view aggregation_method  // \"mean\", \"sum\", \"max\"\n);\n</code></pre>"},{"location":"gnn_embeddings/#model-management","title":"Model Management","text":"<pre><code>Status registerModel(\n    std::string_view model_name,\n    std::string_view model_type,\n    int embedding_dim,\n    std::string_view config = \"\"\n);\n\nstd::pair&lt;Status, std::vector&lt;std::string&gt;&gt; listModels() const;\n\nstd::pair&lt;Status, ModelInfo&gt; getModelInfo(\n    std::string_view model_name\n) const;\n</code></pre>"},{"location":"gnn_embeddings/#batch-operations","title":"Batch Operations","text":"<pre><code>Status generateNodeEmbeddingsBatch(\n    const std::vector&lt;std::string&gt;&amp; node_pks,\n    std::string_view graph_id,\n    std::string_view model_name,\n    size_t batch_size = 32\n);\n\nStatus generateEdgeEmbeddingsBatch(...);\n</code></pre>"},{"location":"gnn_embeddings/#statistics","title":"Statistics","text":"<pre><code>struct EmbeddingStats {\n    int total_node_embeddings = 0;\n    int total_edge_embeddings = 0;\n    std::map&lt;std::string, int&gt; embeddings_per_model;\n    std::map&lt;std::string, int&gt; embeddings_per_graph;\n};\n\nstd::pair&lt;Status, EmbeddingStats&gt; getStats() const;\n</code></pre>"},{"location":"gnn_embeddings/#testing","title":"Testing","text":"<p>Test Suite: <code>test_gnn_embeddings.cpp</code> Test Count: 13 tests Pass Rate: 100%  </p> <p>Test Coverage: 1. \u2705 RegisterModel - Model registration and listing 2. \u2705 GenerateNodeEmbeddings - Batch generation by label 3. \u2705 UpdateNodeEmbedding - Single node update 4. \u2705 GenerateEdgeEmbeddings - Batch generation by type 5. \u2705 FindSimilarNodes - KNN similarity search 6. \u2705 FindSimilarEdges - Edge similarity 7. \u2705 GenerateGraphEmbedding - Graph-level aggregation 8. \u2705 BatchOperations - Batch processing 9. \u2705 GetStats - Statistics collection 10. \u2705 MultiGraphIsolation - Graph isolation 11. \u2705 FeatureExtraction - Multiple field types 12. \u2705 MultiModelSupport - Multiple models 13. \u2705 ErrorHandling - Error cases</p> <p>Run Tests:</p> <pre><code>.\\build\\Release\\themis_tests.exe --gtest_filter=\"GNNEmbeddingTest.*\"\n</code></pre>"},{"location":"gnn_embeddings/#performance","title":"Performance","text":"<p>Embedding Generation (64-dim): - Node embedding (feature extraction + normalization): ~0.5ms - Edge embedding: ~0.5ms - Batch processing (32 nodes): ~16ms</p> <p>Similarity Search (HNSW): - KNN search (k=10): ~1-5ms - Depends on index size (logarithmic scaling)</p> <p>Storage: - Embedding size: ~256 bytes (64-dim float + metadata) - 1M embeddings: ~256 MB</p>"},{"location":"gnn_embeddings/#migration-guide","title":"Migration Guide","text":""},{"location":"gnn_embeddings/#from-no-embeddings-gnn-embeddings","title":"From No Embeddings \u2192 GNN Embeddings","text":"<pre><code>// 1. Initialize GNN manager\nGNNEmbeddingManager gem(db, pgm, vim);\n\n// 2. Register model\ngem.registerModel(\"my_model\", \"feature_based\", 128);\n\n// 3. Generate embeddings for existing nodes\nauto [st, labels] = pgm.listLabels(\"my_graph\");\nfor (const auto&amp; label : labels) {\n    gem.generateNodeEmbeddings(\"my_graph\", label, \"my_model\");\n}\n\n// 4. Use similarity search\nauto [st2, similar] = gem.findSimilarNodes(\"node123\", \"my_graph\", 10, \"my_model\");\n</code></pre>"},{"location":"gnn_embeddings/#from-feature-vectors-gnn-models","title":"From Feature Vectors \u2192 GNN Models","text":"<pre><code>// MVP: Feature-based embeddings\ngem.registerModel(\"features\", \"feature_based\", 64);\ngem.updateNodeEmbedding(\"node1\", \"g1\", \"features\");\n\n// Future: Real GNN model\ngem.registerModel(\"graphsage\", \"GraphSAGE\", 128, R\"({\n    \"layers\": 2,\n    \"aggregator\": \"mean\",\n    \"pretrained_path\": \"/models/my_gnn.pt\"\n})\");\ngem.updateNodeEmbedding(\"node1\", \"g1\", \"graphsage\");\n</code></pre>"},{"location":"gnn_embeddings/#future-enhancements","title":"Future Enhancements","text":""},{"location":"gnn_embeddings/#1-real-gnn-models","title":"1. Real GNN Models","text":"<ul> <li>PyTorch C++ API integration</li> <li>GraphSAGE, GAT, GCN support</li> <li>Multi-hop neighbor aggregation</li> <li>Online training</li> </ul>"},{"location":"gnn_embeddings/#2-advanced-features","title":"2. Advanced Features","text":"<ul> <li>Categorical feature encoding (one-hot, embeddings)</li> <li>Text feature extraction (Sentence-BERT)</li> <li>Image feature extraction (ResNet, CLIP)</li> <li>Temporal features (time-aware embeddings)</li> </ul>"},{"location":"gnn_embeddings/#3-performance","title":"3. Performance","text":"<ul> <li>GPU acceleration (CUDA)</li> <li>Distributed training</li> <li>Incremental updates (avoid full recomputation)</li> <li>Embedding caching</li> </ul>"},{"location":"gnn_embeddings/#4-ml-integration","title":"4. ML Integration","text":"<ul> <li>Scikit-learn compatible API</li> <li>Feature store integration (Task 9)</li> <li>AutoML for hyperparameter tuning</li> </ul>"},{"location":"gnn_embeddings/#related-features","title":"Related Features","text":"<ul> <li>Task 1: Recursive Path Queries (context for GNN training)</li> <li>Task 2: Temporal Graphs (time-aware embeddings)</li> <li>Task 3: Property Graph Model (multi-label nodes)</li> <li>Task 9: ML Feature Store (embedding storage &amp; serving)</li> </ul>"},{"location":"gnn_embeddings/#summary","title":"Summary","text":"<p>The GNN Embeddings module provides production-ready graph embedding generation with: - \u2705 13/13 tests passing - \u2705 Node, edge, graph-level embeddings - \u2705 Multi-model support - \u2705 Similarity search (HNSW) - \u2705 Multi-graph isolation - \u2705 Batch operations - \u2705 Extensible architecture (future GNN models)</p> <p>Next Steps: Task 5 (Semantic Query Cache) builds on similarity search for caching frequent queries.</p>"},{"location":"governance_usage/","title":"Governance Policy Engine - Usage Examples","text":"<p>This document demonstrates how to use the YAML-based governance policy engine in Themis.</p>"},{"location":"governance_usage/#overview","title":"Overview","text":"<p>The Governance Policy Engine provides: - Classification-based data protection (offen, vs-nfd, geheim, streng-geheim) - Fine-grained access control (ANN, export, cache) - Retention policies per classification - Encrypt-then-Sign log handling - Observe/Enforce modes for gradual rollout</p>"},{"location":"governance_usage/#configuration","title":"Configuration","text":"<p>Governance policies are defined in <code>config/governance.yaml</code>:</p> <pre><code>vs_classification:\n  offen:\n    encryption_required: false\n    ann_allowed: true\n    export_allowed: true\n    cache_allowed: true\n    redaction_level: \"none\"\n    retention_days: 365\n    log_encryption: false\n\n  geheim:\n    encryption_required: true\n    ann_allowed: false  # ANN disabled; exact search only\n    export_allowed: false\n    cache_allowed: false\n    redaction_level: \"strict\"\n    retention_days: 3650  # 10 years\n    log_encryption: true\n\nenforcement:\n  resource_mapping:\n    \"/admin/*\": \"vs-nfd\"\n    \"/admin/status\": \"vs-nfd\"  # explizit gemappt\n    \"/vector/search\": \"offen\"\n\n  default_mode: \"enforce\"\n</code></pre>"},{"location":"governance_usage/#konfig-dateipfade-suchreihenfolge","title":"Konfig-Dateipfade (Suchreihenfolge)","text":"<p>Der Server l\u00e4dt <code>governance.yaml</code> aus den folgenden Pfaden (erste gefundene Datei gewinnt):</p> <ol> <li><code>config/governance.yaml</code> (aus Repo-Root gestartet)</li> <li><code>../config/governance.yaml</code> (selten, falls CWD <code>build/</code> ist)</li> <li><code>../../config/governance.yaml</code> (CTest/IDE: CWD ist h\u00e4ufig <code>build/&lt;Config&gt;</code> wie <code>build/Release</code>)</li> <li><code>./governance.yaml</code> (Fallback im aktuellen Verzeichnis)</li> </ol> <p>Hinweis: Diese Reihenfolge stellt sicher, dass CTest-L\u00e4ufe aus <code>build/&lt;Config&gt;</code> die zentrale Konfiguration unter <code>config/</code> finden.</p>"},{"location":"governance_usage/#http-headers","title":"HTTP Headers","text":""},{"location":"governance_usage/#request-headers","title":"Request Headers","text":"<p>Clients can specify governance requirements via HTTP headers:</p> <ul> <li><code>X-Classification</code>: Data classification level (offen, vs-nfd, geheim, streng-geheim)</li> <li><code>X-Governance-Mode</code>: Enforcement mode (enforce, observe)</li> <li><code>X-Encrypt-Logs</code>: Force log encryption (true, false, auto)</li> <li><code>X-Redaction-Level</code>: Redaction profile (none, standard, strict)</li> </ul>"},{"location":"governance_usage/#response-headers","title":"Response Headers","text":"<p>Server returns applied policy decisions:</p> <ul> <li><code>X-Themis-Policy</code>: Compact policy summary</li> <li><code>X-Themis-Integrity</code>: Signature status (signed-ciphertext:policy-only)</li> <li><code>X-Themis-ANN</code>: ANN availability (allowed, disabled)</li> <li><code>X-Themis-Content-Enc</code>: Content encryption requirement (required, optional)</li> <li><code>X-Themis-Export</code>: Export permission (allowed, forbidden)</li> <li><code>X-Themis-Cache</code>: Cache permission (allowed, disabled)</li> <li><code>X-Themis-Retention-Days</code>: Data retention period</li> </ul> <p>Im Observe-Modus k\u00f6nnen zus\u00e4tzlich Warnhinweise erscheinen:</p> <ul> <li><code>X-Themis-Policy-Warn</code>: z. B. <code>ann_disabled_but_observed</code> oder <code>content_encryption_required_but_observed</code></li> </ul>"},{"location":"governance_usage/#usage-examples","title":"Usage Examples","text":""},{"location":"governance_usage/#example-1-public-data-offen","title":"Example 1: Public Data (offen)","text":"<p>Request:</p> <pre><code>POST /vector/search\nX-Classification: offen\nContent-Type: application/json\n\n{\n  \"vector\": [0.1, 0.2, ...],\n  \"k\": 10\n}\n</code></pre> <p>Response:</p> <pre><code>HTTP/1.1 200 OK\nX-Themis-Policy: classification=offen;mode=enforce;encrypt_logs=false;redaction=none\nX-Themis-ANN: allowed\nX-Themis-Content-Enc: optional\nX-Themis-Export: allowed\nX-Themis-Cache: allowed\nX-Themis-Retention-Days: 365\n\n{\n  \"results\": [...]\n}\n</code></pre>"},{"location":"governance_usage/#example-2-secret-data-geheim-enforce-mode","title":"Example 2: Secret Data (geheim) - Enforce Mode","text":"<p>Request:</p> <pre><code>POST /vector/search\nX-Classification: geheim\nX-Governance-Mode: enforce\nContent-Type: application/json\n\n{\n  \"vector\": [0.1, 0.2, ...],\n  \"k\": 10\n}\n</code></pre> <p>Response:</p> <pre><code>HTTP/1.1 403 Forbidden\nX-Themis-Policy: classification=geheim;mode=enforce;encrypt_logs=true;redaction=strict\nX-Themis-ANN: disabled\n\n{\n  \"error\": true,\n  \"message\": \"Approximate vector search (ANN) is disabled for classification 'geheim'\"\n}\n</code></pre>"},{"location":"governance_usage/#example-3-secret-data-geheim-observe-mode","title":"Example 3: Secret Data (geheim) - Observe Mode","text":"<p>Request:</p> <pre><code>POST /vector/search\nX-Classification: geheim\nX-Governance-Mode: observe\nContent-Type: application/json\n\n{\n  \"vector\": [0.1, 0.2, ...],\n  \"k\": 10\n}\n</code></pre> <p>Response:</p> <pre><code>HTTP/1.1 200 OK\nX-Themis-Policy: classification=geheim;mode=observe;encrypt_logs=true;redaction=strict\nX-Themis-ANN: disabled\nX-Themis-Policy-Warn: ann_disabled_but_observed\nX-Themis-Export: forbidden\nX-Themis-Cache: disabled\nX-Themis-Retention-Days: 3650\n\n{\n  \"results\": [...]\n}\n</code></pre>"},{"location":"governance_usage/#example-4-content-import-with-encryption-requirement","title":"Example 4: Content Import with Encryption Requirement","text":"<p>Request:</p> <pre><code>POST /content/import\nX-Classification: streng-geheim\nX-Governance-Mode: enforce\nContent-Type: application/json\n\n{\n  \"content\": {\n    \"id\": \"doc123\",\n    \"mime_type\": \"application/pdf\",\n    \"encrypted\": false\n  },\n  \"blob\": \"base64encodeddata...\"\n}\n</code></pre> <p>Response:</p> <pre><code>HTTP/1.1 422 Unprocessable Entity\nX-Themis-Policy: classification=streng-geheim;mode=enforce;encrypt_logs=true;redaction=strict\n\n{\n  \"error\": true,\n  \"message\": \"Content encryption required for classification 'streng-geheim'\"\n}\n</code></pre>"},{"location":"governance_usage/#example-5-default-classification-from-resource-mapping","title":"Example 5: Default Classification from Resource Mapping","text":"<p>Request:</p> <pre><code>GET /admin/backup\n</code></pre> <p>Response:</p> <pre><code>HTTP/1.1 200 OK\nX-Themis-Policy: classification=vs-nfd;mode=enforce;encrypt_logs=true;redaction=standard\nX-Themis-Retention-Days: 1825\n\n{\n  \"status\": \"ok\"\n}\n</code></pre>"},{"location":"governance_usage/#classification-profiles","title":"Classification Profiles","text":""},{"location":"governance_usage/#offen-public","title":"offen (Public)","text":"<ul> <li>No encryption required</li> <li>ANN allowed</li> <li>Export/cache allowed</li> <li>1 year retention</li> </ul>"},{"location":"governance_usage/#vs-nfd-restricted","title":"vs-nfd (Restricted)","text":"<ul> <li>Encryption required</li> <li>ANN allowed</li> <li>Export/cache allowed</li> <li>5 years retention</li> </ul>"},{"location":"governance_usage/#geheim-secret","title":"geheim (Secret)","text":"<ul> <li>Encryption required</li> <li>ANN disabled (exact search only)</li> <li>Export/cache forbidden</li> <li>10 years retention</li> </ul>"},{"location":"governance_usage/#streng-geheim-top-secret","title":"streng-geheim (Top Secret)","text":"<ul> <li>Encryption required</li> <li>ANN disabled</li> <li>Export/cache forbidden</li> <li>20 years retention</li> </ul>"},{"location":"governance_usage/#gradual-rollout-with-observe-mode","title":"Gradual Rollout with Observe Mode","text":"<p>Use <code>X-Governance-Mode: observe</code> to test policies without enforcement:</p> <ol> <li>Deploy with <code>default_mode: observe</code> in <code>governance.yaml</code></li> <li>Monitor <code>X-Themis-Policy-Warn</code> headers in production</li> <li>Identify and fix policy violations</li> <li>Switch to <code>default_mode: enforce</code></li> </ol>"},{"location":"governance_usage/#policy-customization","title":"Policy Customization","text":"<p>Edit <code>config/governance.yaml</code> to customize: - Classification levels and their properties - Resource-to-classification mappings - Default enforcement mode - Retention periods - SAGA signing and log encryption settings</p> <p>Changes take effect after server restart (hot-reload planned for future).</p>"},{"location":"governance_usage/#integration-with-encryption","title":"Integration with Encryption","text":"<p>The governance engine works with the encryption strategy: - <code>encryption_required: true</code> \u2192 Data-at-rest encryption mandatory - <code>log_encryption: true</code> \u2192 SAGA/Audit logs encrypted before PKI signing (Encrypt-then-Sign) - Classification determines key hierarchy and access controls</p>"},{"location":"governance_usage/#compliance-frameworks","title":"Compliance Frameworks","text":"<p>Supported frameworks (configurable in <code>governance.yaml</code>): - GDPR (EU General Data Protection Regulation) - VSA (German Federal Classification System) - BSI-C5 (German Cloud Security Standard)</p>"},{"location":"governance_usage/#api-reference","title":"API Reference","text":""},{"location":"governance_usage/#get-tsconfig","title":"GET /ts/config","text":"<p>Returns current time-series compression configuration.</p>"},{"location":"governance_usage/#put-tsconfig","title":"PUT /ts/config","text":"<p>Updates time-series compression settings.</p>"},{"location":"governance_usage/#all-endpoints","title":"All Endpoints","text":"<p>All endpoints respect governance headers and return policy decisions in response headers.</p>"},{"location":"governance_usage/#testing","title":"Testing","text":"<p>Test policy enforcement with curl:</p> <pre><code># Test ANN restriction (enforce)\ncurl -X POST http://localhost:8080/vector/search \\\n  -H \"X-Classification: geheim\" \\\n  -H \"X-Governance-Mode: enforce\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"vector\": [0.1, 0.2], \"k\": 10}'\n# Expected: 403 Forbidden\n\n# Test ANN restriction (observe)\ncurl -X POST http://localhost:8080/vector/search \\\n  -H \"X-Classification: geheim\" \\\n  -H \"X-Governance-Mode: observe\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"vector\": [0.1, 0.2], \"k\": 10}'\n# Expected: 200 OK with X-Themis-Policy-Warn header\n</code></pre>"},{"location":"governance_usage/#gezielte-testlaufe-ctest","title":"Gezielte Testl\u00e4ufe (CTest)","text":"<p>Unter Windows PowerShell lassen sich gezielt nur Governance- oder Time-Series-Tests ausf\u00fchren. Beispiele (aus <code>build/</code>):</p> <pre><code># Alle Governance-Tests (mehrere Suites via Regex)\nctest -C Release -R \"StatsApiTest|MetricsApiTest|HttpRangeIndexTest|HttpGovernanceTest\" --output-on-failure\n\n# Nur drei spezifische Governance-F\u00e4lle\nctest -C Release -R \"HttpGovernanceTest.Classification_VsNfd_RequiresEncryption|HttpGovernanceTest.ResourceMapping_AppliesClassification|HttpGovernanceTest.RetentionDays_ReturnsPolicy\" --output-on-failure\n\n# Alle Time-Series-bezogenen Suites\nctest -C Release -R \"^HttpTimeSeriesTest\\.|^TSStoreTest\\.|^GorillaCodecTest\\.|^ContinuousAggTest\\.\" --output-on-failure\n</code></pre> <p>Tipps: - Verwende Anker (<code>^</code>) und das Escapen des Punkts (<code>\\.</code>) f\u00fcr exakte Pr\u00e4fix-Matches. - In PowerShell sind doppelte Anf\u00fchrungszeichen empfohlen, damit Regex-Sonderzeichen korrekt \u00fcbergeben werden.</p>"},{"location":"governance_usage/#future-enhancements","title":"Future Enhancements","text":"<p>Planned features: - Hot-reload of <code>governance.yaml</code> without restart - Per-user classification overrides (via JWT claims) - Audit trail for policy violations - Automated compliance reports - Field-level encryption based on classification</p>"},{"location":"hnsw_persistence/","title":"HNSW Persistenz &amp; Warmstart","text":"<p>Diese Seite beschreibt die Persistierung und Wiederherstellung von HNSW-Vektorindizes f\u00fcr schnellere Warmstarts und robustes Recovery.</p>"},{"location":"hnsw_persistence/#motivation","title":"Motivation","text":"<ul> <li>Problem: HNSW-Index wird bei jedem Neustart aus RocksDB neu aufgebaut (langsam bei &gt;100k Vektoren)</li> <li>L\u00f6sung: Index auf Disk speichern (<code>saveIndex</code>) und beim Start laden (<code>loadIndex</code>)</li> <li>Benefit: Warmstart &lt;10s statt mehrerer Minuten; kein Datenverlust</li> </ul>"},{"location":"hnsw_persistence/#lifecycle","title":"Lifecycle","text":"<pre><code>init(objectName, dim, metric, ..., savePath)\n  \u251c\u2500&gt; Falls savePath/meta.txt existiert: loadIndex(savePath)\n  \u2514\u2500&gt; Sonst: leerer HNSW-Index\n\n[Runtime: addEntity, searchKnn, ...]\n\nsetAutoSavePath(path, autoSave=true)\n  \u2514\u2500&gt; Aktiviert automatisches Speichern bei shutdown()\n\nshutdown()\n  \u2514\u2500&gt; Falls autoSave: saveIndex(savePath)\n</code></pre>"},{"location":"hnsw_persistence/#api","title":"API","text":""},{"location":"hnsw_persistence/#1-init-mit-save-path","title":"1) Init mit Save-Path","text":"<pre><code>VectorIndexManager vix(db);\nvix.init(\"chunks\", 768, VectorIndexManager::Metric::COSINE, \n         /*M*/16, /*efC*/200, /*ef*/64, \n         /*savePath=*/\"./data/hnsw_chunks\");\n// Falls ./data/hnsw_chunks/meta.txt vorhanden \u2192 l\u00e4dt Index automatisch\n</code></pre>"},{"location":"hnsw_persistence/#2-automatisches-speichern-aktivieren","title":"2) Automatisches Speichern aktivieren","text":"<pre><code>vix.setAutoSavePath(\"./data/hnsw_chunks\", /*autoSave*/true);\n// Bei shutdown() wird Index gespeichert\n</code></pre>"},{"location":"hnsw_persistence/#3-manuelles-speichern","title":"3) Manuelles Speichern","text":"<pre><code>auto status = vix.saveIndex(\"./data/hnsw_chunks\");\nif (!status.ok) {\n    THEMIS_ERROR(\"Failed to save index: {}\", status.message);\n}\n</code></pre>"},{"location":"hnsw_persistence/#4-manuelles-laden","title":"4) Manuelles Laden","text":"<pre><code>auto status = vix.loadIndex(\"./data/hnsw_chunks\");\nif (!status.ok) {\n    THEMIS_WARN(\"Failed to load index, rebuilding from storage\");\n    vix.rebuildFromStorage();\n}\n</code></pre>"},{"location":"hnsw_persistence/#persistenz-format","title":"Persistenz-Format","text":"<p>Verzeichnisstruktur:</p> <pre><code>data/hnsw_chunks/\n  \u251c\u2500 index.bin      # HNSW Graph-Struktur (hnswlib-Format)\n  \u251c\u2500 meta.txt       # Metadaten (Dimension, Metric, M, efC)\n  \u2514\u2500 mapping.txt    # PK-Mapping (Zeile i = PK f\u00fcr Label i)\n</code></pre>"},{"location":"hnsw_persistence/#metatxt","title":"meta.txt","text":"<pre><code>dim=768\nmetric=1\nM=16\nefConstruction=200\ncount=50000\n</code></pre>"},{"location":"hnsw_persistence/#mappingtxt","title":"mapping.txt","text":"<pre><code>chunk_doc123_0\nchunk_doc123_1\nchunk_doc456_0\n...\n</code></pre>"},{"location":"hnsw_persistence/#workflow-startup-mit-warmstart","title":"Workflow: Startup mit Warmstart","text":"<pre><code>// main_server.cpp\nauto vix = std::make_shared&lt;VectorIndexManager&gt;(db);\n\n// Setze Pfad vor init (optional)\nvix-&gt;setAutoSavePath(\"./data/hnsw_index\");\n\n// Init l\u00e4dt automatisch, falls vorhanden\nvix-&gt;init(\"chunks\", 768, VectorIndexManager::Metric::COSINE, 16, 200, 64);\n\n// Nach Init pr\u00fcfen\nif (vix-&gt;getVectorCount() &gt; 0) {\n    THEMIS_INFO(\"Warmstart: {} vectors loaded\", vix-&gt;getVectorCount());\n} else {\n    THEMIS_INFO(\"Cold start: rebuilding index from storage\");\n    vix-&gt;rebuildFromStorage();\n}\n\n// Laufzeit: addEntity/searchKnn\n\n// Bei Shutdown\nvix-&gt;shutdown(); // Speichert automatisch, falls autoSave aktiviert\n</code></pre>"},{"location":"hnsw_persistence/#performance","title":"Performance","text":""},{"location":"hnsw_persistence/#cold-start-rebuild-from-rocksdb","title":"Cold Start (rebuild from RocksDB)","text":"Vektoren Dim Rebuild-Zeit Speichernutzung 10k 768 ~2s ~50 MB 100k 768 ~30s ~500 MB 1M 768 ~8min ~5 GB"},{"location":"hnsw_persistence/#warmstart-loadindex","title":"Warmstart (loadIndex)","text":"Vektoren Dim Load-Zeit Disk-Gr\u00f6\u00dfe 10k 768 &lt;1s ~20 MB 100k 768 ~3s ~200 MB 1M 768 ~25s ~2 GB <p>Empfehlung: Ab &gt;50k Vektoren immer Persistenz nutzen.</p>"},{"location":"hnsw_persistence/#konfiguration","title":"Konfiguration","text":"<p>In <code>config/vector_index.json</code> (optional):</p> <pre><code>{\n  \"save_path\": \"./data/hnsw_index\",\n  \"auto_save\": true,\n  \"save_interval_sec\": 300\n}\n</code></pre> <p>Falls <code>save_interval_sec</code> gesetzt: periodisches Auto-Save im Hintergrund (geplant).</p>"},{"location":"hnsw_persistence/#fehlerbehandlung","title":"Fehlerbehandlung","text":""},{"location":"hnsw_persistence/#korrupte-index-datei","title":"Korrupte Index-Datei","text":"<p>Falls <code>loadIndex</code> fehlschl\u00e4gt:</p> <pre><code>auto status = vix-&gt;loadIndex(path);\nif (!status.ok) {\n    THEMIS_WARN(\"Corrupted index, rebuilding: {}\", status.message);\n    std::filesystem::remove_all(path); // Optional: alte Dateien l\u00f6schen\n    vix-&gt;rebuildFromStorage();\n    vix-&gt;saveIndex(path); // Neu speichern\n}\n</code></pre>"},{"location":"hnsw_persistence/#disk-space-fehler","title":"Disk-Space-Fehler","text":"<p>Bei <code>saveIndex</code>:</p> <pre><code>auto status = vix-&gt;saveIndex(path);\nif (!status.ok &amp;&amp; status.message.find(\"No space\") != std::string::npos) {\n    THEMIS_ERROR(\"Disk full, cannot save index\");\n    // Alarm ausl\u00f6sen, alte Backups l\u00f6schen, etc.\n}\n</code></pre>"},{"location":"hnsw_persistence/#backup-recovery","title":"Backup &amp; Recovery","text":""},{"location":"hnsw_persistence/#backup","title":"Backup","text":"<pre><code># Index-Verzeichnis sichern\ntar -czf hnsw_index_backup_$(date +%Y%m%d).tar.gz ./data/hnsw_index/\n\n# Optional: mit RocksDB-Checkpoint kombinieren\n</code></pre>"},{"location":"hnsw_persistence/#recovery","title":"Recovery","text":"<pre><code># Index wiederherstellen\ntar -xzf hnsw_index_backup_20251102.tar.gz -C ./data/\n\n# Server starten \u2192 l\u00e4dt Index automatisch\n./themis_server\n</code></pre>"},{"location":"hnsw_persistence/#rebuild-strategien","title":"Rebuild-Strategien","text":""},{"location":"hnsw_persistence/#1-vollstandiger-rebuild","title":"1) Vollst\u00e4ndiger Rebuild","text":"<pre><code>vix-&gt;rebuildFromStorage(); // Scannt alle Vektoren aus RocksDB\nvix-&gt;saveIndex(path);\n</code></pre>"},{"location":"hnsw_persistence/#2-inkrementelles-update","title":"2) Inkrementelles Update","text":"<p>Nach Bulk-Import:</p> <pre><code>// ... Batch-Insert von 10k Vektoren via WriteBatch\n\n// Index ist in-memory aktualisiert; speichere\nvix-&gt;saveIndex(path);\n</code></pre>"},{"location":"hnsw_persistence/#3-scheduled-rebuild","title":"3) Scheduled Rebuild","text":"<pre><code>// Cronjob oder Timer\nstd::thread([&amp;vix, path]() {\n    while (running) {\n        std::this_thread::sleep_for(std::chrono::hours(6));\n        vix-&gt;rebuildFromStorage();\n        vix-&gt;saveIndex(path);\n    }\n}).detach();\n</code></pre>"},{"location":"hnsw_persistence/#tests","title":"Tests","text":"<p>Unit-Tests: <code>tests/test_vector_index_persistence.cpp</code> (geplant)</p> <pre><code>TEST(VectorPersistence, SaveLoadCycle) {\n    // 1) Init + Insert 1000 Vektoren\n    // 2) saveIndex\n    // 3) Neuer VectorIndexManager\n    // 4) loadIndex\n    // 5) Query \u2192 pr\u00fcfe gleiche Top-k-IDs\n}\n</code></pre>"},{"location":"hnsw_persistence/#runbook","title":"Runbook","text":""},{"location":"hnsw_persistence/#problem-index-nicht-geladen","title":"Problem: Index nicht geladen","text":"<p>Symptom: <code>getVectorCount() == 0</code> nach Init, obwohl RocksDB Daten enth\u00e4lt.</p> <p>L\u00f6sung:</p> <ol> <li>Pr\u00fcfe <code>savePath</code>-Existenz: <code>ls -lh ./data/hnsw_index/</code></li> <li>Logs pr\u00fcfen: <code>grep \"VectorIndexManager::init\" server.log</code></li> <li>Falls <code>meta.txt</code> fehlt/korrupt \u2192 manueller Rebuild:</li> </ol> <pre><code>vix-&gt;rebuildFromStorage();\nvix-&gt;saveIndex(\"./data/hnsw_index\");\n</code></pre>"},{"location":"hnsw_persistence/#problem-langsame-queries-nach-load","title":"Problem: Langsame Queries nach Load","text":"<p>Symptom: KNN-Suche dauert &gt;500ms (sollte &lt;50ms sein).</p> <p>M\u00f6gliche Ursachen:</p> <ul> <li>efSearch zu niedrig \u2192 erh\u00f6hen:</li> </ul> <pre><code>vix-&gt;setEfSearch(128); // statt 64\n</code></pre> <ul> <li>Index nicht korrekt geladen \u2192 Rebuild erzwingen</li> </ul>"},{"location":"hnsw_persistence/#metriken","title":"Metriken","text":"<p>Prometheus <code>/metrics</code>:</p> <ul> <li><code>themis_vector_index_save_duration_seconds</code> \u2014 Histogram f\u00fcr saveIndex-Dauer</li> <li><code>themis_vector_index_load_duration_seconds</code> \u2014 Histogram f\u00fcr loadIndex-Dauer</li> <li><code>themis_vector_index_size_bytes</code> \u2014 Disk-Gr\u00f6\u00dfe des Index</li> <li><code>themis_vector_index_rebuild_total</code> \u2014 Counter f\u00fcr Rebuilds</li> </ul> <p>(Implementierung geplant)</p>"},{"location":"hnsw_persistence/#referenzen","title":"Referenzen","text":"<ul> <li>Vector Operations</li> <li>Indexes</li> <li>Performance &amp; Benchmarks</li> <li>Operations Runbook</li> </ul>"},{"location":"index_stats_maintenance/","title":"Index-Statistiken &amp; Wartung","text":"<p>Dieses Dokument erkl\u00e4rt die Statistik- und Wartungsfunktionen f\u00fcr Indizes.</p>"},{"location":"index_stats_maintenance/#indexstats","title":"IndexStats","text":"<pre><code>struct IndexStats {\n    std::string type;                 // \"regular\", \"composite\", \"range\", \"sparse\", \"geo\", \"ttl\", \"fulltext\"\n    std::string table;                // Tablename\n    std::string column;               // Spaltenname bzw. \"col1+col2\" f\u00fcr Composite\n    size_t entry_count = 0;           // Anzahl Index-Eintr\u00e4ge\n    size_t estimated_size_bytes = 0;  // grobe Sch\u00e4tzung\n    bool unique = false;              // Unique-Constraint\n    std::string additional_info;      // Typ-spezifisch (z. B. Composite-Spaltenliste, \"sorted\", \"inverted_index\", TTL)\n};\n</code></pre> <ul> <li>Composite: <code>additional_info</code> enth\u00e4lt die Spaltenliste (z. B. <code>\"customer_id, status\"</code>).</li> <li>Range: <code>additional_info = \"sorted\"</code></li> <li>Fulltext: <code>additional_info = \"inverted_index\"</code></li> <li>TTL: <code>additional_info = \"ttl_seconds=&lt;N&gt;\"</code></li> </ul> <p>Abruf der Statistiken:</p> <pre><code>SecondaryIndexManager idx(db);\n\nauto s = idx.getIndexStats(\"users\", \"email\");\nauto all = idx.getAllIndexStats(\"users\");\n</code></pre> <p>Zus\u00e4tzlich stehen Metriken und erweiterte Rebuild-Funktionen zur Verf\u00fcgung (siehe unten).</p>"},{"location":"index_stats_maintenance/#rebuild-eines-index","title":"Rebuild eines Index","text":"<p>Rebuild l\u00f6scht alle bestehenden Indexeintr\u00e4ge eines Indexes und baut sie aus den Entities neu auf.</p> <pre><code>idx.rebuildIndex(\"users\", \"email\");        // Single-Column\nidx.rebuildIndex(\"orders\", \"customer_id+status\"); // Composite\n</code></pre> <p>Wann sinnvoll? - Nach manuellen Eingriffen (inkonsistente Index-Keys) - Nach Bugfixes im Index-Aufbau</p> <p>Implementierungsdetails: - Entities werden unter Prefix <code>\"&lt;table&gt;:\"</code> gescannt (gem\u00e4\u00df <code>KeySchema::makeRelationalKey</code>). - Pro Entity wird der passende Index-Key neu erzeugt und gespeichert.</p>"},{"location":"index_stats_maintenance/#reindex-der-gesamten-tabelle","title":"Reindex der gesamten Tabelle","text":"<pre><code>idx.reindexTable(\"users\");\n</code></pre> <ul> <li>Sucht alle Meta-Keys (<code>idxmeta:</code>, <code>ridxmeta:</code>, <code>sidxmeta:</code>, <code>gidxmeta:</code>, <code>ttlidxmeta:</code>, <code>ftidxmeta:</code>) f\u00fcr die Tabelle und f\u00fchrt <code>rebuildIndex</code> je Spalte aus.</li> </ul>"},{"location":"index_stats_maintenance/#ttl-cleanup","title":"TTL-Cleanup","text":"<pre><code>auto [st, removed] = idx.cleanupExpiredEntities(\"sessions\", \"last_seen\");\n</code></pre> <ul> <li>L\u00f6scht abgelaufene Entities und zugeh\u00f6rige Indexeintr\u00e4ge atomar.</li> <li>Muss regelm\u00e4\u00dfig aufgerufen werden (Timer/Cron).</li> </ul>"},{"location":"index_stats_maintenance/#rebuild-metriken-query-metriken","title":"Rebuild-Metriken &amp; Query-Metriken","text":"<p>Header: <code>index/secondary_index.h</code></p> <pre><code>auto&amp; rbm = idx.getRebuildMetrics();\nauto&amp; qm  = idx.getQueryMetrics();\n\n// Counter auslesen (z. B. f\u00fcr Prometheus Exporter)\nuint64_t rebuilds   = rbm.rebuild_count.load();\nuint64_t durationMs = rbm.rebuild_duration_ms.load();\nuint64_t processed  = rbm.rebuild_entities_processed.load();\n\nuint64_t cursorAnchors = qm.cursor_anchor_hits_total.load();\nuint64_t rangeSteps    = qm.range_scan_steps_total.load();\n</code></pre> <p>Empfohlene Prometheus-Namen:</p> <ul> <li><code>themis_index_rebuild_count</code></li> <li><code>themis_index_rebuild_duration_ms_total</code></li> <li><code>themis_index_rebuild_entities_processed_total</code></li> <li><code>themis_index_cursor_anchor_hits_total</code></li> <li><code>themis_index_range_scan_steps_total</code></li> </ul> <p>Diese Z\u00e4hler k\u00f6nnen im HTTP-/Metrics-Endpunkt exponiert werden.</p>"},{"location":"index_stats_maintenance/#rebuild-mit-progress-callback","title":"Rebuild mit Progress-Callback","text":"<p>F\u00fcr lange Rebuilds kann ein Fortschritts-Callback registriert werden, der den Fortschritt meldet und Abbruch erlaubt:</p> <pre><code>size_t calls = 0;\nidx.rebuildIndex(\"users\", \"email\", [&amp;](size_t done, size_t total){\n  ++calls;\n  // Logging oder UI-Update\n  return true; // false \u2192 Rebuild abbrechen\n});\n</code></pre> <p>Siehe auch Testf\u00e4lle in <code>tests/test_index_stats.cpp</code> (Callback wird aufgerufen und kann abbrechen).</p>"},{"location":"index_stats_maintenance/#performance-hinweise","title":"Performance-Hinweise","text":"<ul> <li><code>estimated_size_bytes</code> ist eine einfache, konservative Sch\u00e4tzung (Entry-Anzahl * Durchschnittsgr\u00f6\u00dfe). F\u00fcr exakte Gr\u00f6\u00dfen Messungen auf Key-Ranges durchf\u00fchren.</li> <li><code>rebuildIndex</code> und <code>reindexTable</code> sind IO-intensiv. F\u00fcr gro\u00dfe Tabellen ggf. in Wartungsfenstern planen.</li> <li>Optionaler Fortschritts-Callback kann erg\u00e4nzt werden (siehe \"Ausblick\").</li> </ul> <p>Zus\u00e4tzlich: - Range-Scans mit <code>scanKeysRangeAnchored</code> minimieren Duplikate bei Pagination (Server-Side Cursor). - Geo- und Fulltext-Indizes k\u00f6nnen w\u00e4hrend Rebuilds ausgelassen oder separat reindiziert werden, falls teuer.</p>"},{"location":"index_stats_maintenance/#ausblick-progress-callback-optional","title":"Ausblick: Progress-Callback (optional)","text":"<p>Geplante API-Idee:</p> <pre><code>void rebuildIndex(\n    const std::string&amp; table,\n    const std::string&amp; column,\n    std::function&lt;bool(size_t done, size_t total)&gt; progress // return false -&gt; abbrechen\n);\n</code></pre> <p>Verwendung:</p> <pre><code>idx.rebuildIndex(\"users\", \"email\", [](size_t done, size_t total){\n  if (done % 10000 == 0) { /* log */ }\n  return true; // weiter\n});\n</code></pre>"},{"location":"indexes/","title":"Indexe \u2013 \u00dcberblick und Verwendung","text":"<p>Dieser Leitfaden beschreibt die in THEMIS verf\u00fcgbaren Indexe (Sekund\u00e4r-, Range-, Geo-, TTL-, Fulltext-, Graph- und Vektorindizes), ihre Key-Schemata und die korrekte Verwendung im Code.</p>"},{"location":"indexes/#key-schemata-prafixe","title":"Key-Schemata (Pr\u00e4fixe)","text":"<ul> <li>Equality (Single): <code>idx:&lt;table&gt;:&lt;column&gt;:&lt;value&gt;:&lt;PK&gt;</code></li> <li>Equality (Composite): <code>idx:&lt;table&gt;:&lt;col1+col2&gt;:&lt;val1&gt;:&lt;val2&gt;:&lt;PK&gt;</code></li> <li>Range (lexikografisch): <code>ridx:&lt;table&gt;:&lt;column&gt;:&lt;value&gt;:&lt;PK&gt;</code></li> <li>Sparse: <code>sidx:&lt;table&gt;:&lt;column&gt;:&lt;value&gt;:&lt;PK&gt;</code></li> <li>Geo (Geohash/Morton): <code>gidx:&lt;table&gt;:&lt;column&gt;:&lt;geohash&gt;:&lt;PK&gt;</code></li> <li>TTL (Expiry): <code>ttlidx:&lt;table&gt;:&lt;column&gt;:&lt;timestamp&gt;:&lt;PK&gt;</code></li> <li>Fulltext (invertiert): <code>ftidx:&lt;table&gt;:&lt;column&gt;:&lt;token&gt;:&lt;PK&gt;</code></li> <li>Graph (Adjazenz, logisch):</li> <li>Out: <code>graph:out:&lt;from_pk&gt;:&lt;edge_id&gt; -&gt; &lt;to_pk&gt;</code></li> <li>In:  <code>graph:in:&lt;to_pk&gt;:&lt;edge_id&gt;   -&gt; &lt;from_pk&gt;</code></li> <li>Vector (per Entity gespeichert): <code>objectName:&lt;PK&gt;</code> mit Feld <code>embedding</code></li> </ul> <p>Hinweise - Composite-Indizes verwenden das gleiche Pr\u00e4fix wie Single-Column (<code>idx:</code>); die Spaltennamen werden im <code>column</code>-Teil durch <code>+</code> getrennt. - Geo-Indizes erwarten Felder <code>&lt;column&gt;_lat</code> und <code>&lt;column&gt;_lon</code> als Strings (z. B. <code>\"52.5\"</code>, <code>\"13.4\"</code>). - TTL-Indizes speichern Expire-Timestamps in Sekunden; die tats\u00e4chliche L\u00f6schung erfolgt \u00fcber einen Cleanup-Lauf. - Fulltext-Tokenizer: simples Whitespace/Punktuation-Splitting, Lowercasing, AND-Logik bei Suche.  - Range-Scans sind lexikografisch (String-Encoding!). F\u00fcr numerische Ordnung ggf. Zero-Padding oder Canonical-Encoding verwenden.  - VectorIndex nutzt HNSW (falls mit THEMIS_HNSW_ENABLED gebaut) oder Fallback (Brute-Force) mit in-memory Cache.</p>"},{"location":"indexes/#api-snippets-c","title":"API-Snippets (C++)","text":"<p>Vorbereitung:</p> <pre><code>#include \"index/secondary_index.h\"\n#include \"storage/base_entity.h\"\nusing themis::SecondaryIndexManager;\nusing themis::BaseEntity;\n</code></pre>"},{"location":"indexes/#equality-index-single-column","title":"Equality-Index (Single-Column)","text":"<pre><code>SecondaryIndexManager idx(db);\nidx.createIndex(\"users\", \"email\", /*unique=*/false);\n\nBaseEntity e(\"user42\");\ne.setField(\"email\", \"u42@example.com\");\nidx.put(\"users\", e);\n\nauto [st, keys] = idx.scanKeysEqual(\"users\", \"email\", \"u42@example.com\");\n</code></pre> <ul> <li>Unique-Constraint: <code>createIndex(table, column, /*unique=*/true)</code> verhindert doppelte Values.</li> </ul>"},{"location":"indexes/#composite-index","title":"Composite-Index","text":"<pre><code>idx.createCompositeIndex(\"orders\", {\"customer_id\", \"status\"}, /*unique=*/false);\n\nBaseEntity o(\"order1\");\no.setField(\"customer_id\", \"cust1\");\no.setField(\"status\", \"pending\");\nidx.put(\"orders\", o);\n\nauto [st, keys] = idx.scanKeysEqualComposite(\"orders\", {\"customer_id\",\"status\"}, {\"cust1\",\"pending\"});\n</code></pre> <p>Wichtig: Composite benutzt <code>idx:</code> mit <code>column = col1+col2</code> und <code>value = val1:val2</code> (intern percent-encodiert, falls n\u00f6tig).</p>"},{"location":"indexes/#range-index","title":"Range-Index","text":"<pre><code>idx.createRangeIndex(\"users\", \"age\");\n\nauto [st, keys] = idx.scanKeysRange(\n  \"users\", \"age\",\n  /*lower*/ std::make_optional(std::string(\"18\")),\n  /*upper*/ std::make_optional(std::string(\"65\")),\n  /*includeLower*/ true, /*includeUpper*/ false,\n  /*limit*/ 1000, /*reversed*/ false);\n</code></pre> <p>Range-Index ist unabh\u00e4ngig vom Equality-Index auf derselben Spalte.</p>"},{"location":"indexes/#cursor-anker-pagination","title":"Cursor-Anker (Pagination)","text":"<pre><code>auto [st, page1] = idx.scanKeysRangeAnchored(\n  \"users\", \"age\",\n  /*lower*/ std::nullopt, /*upper*/ std::nullopt,\n  /*inclL*/ true, /*inclU*/ true,\n  /*limit*/ 50, /*reversed*/ false,\n  /*anchor*/ std::nullopt\n);\n\n// N\u00e4chste Seite (weiter ab letztem (value, pk))\nauto last = page1.back(); // PK der letzten Zeile\n// den zuletzt gesehenen Wert (age) aus Entity lesen\nauto [stE, ents] = idx.scanEntitiesEqual(\"users\", \"pk\", last);\nstd::string lastAge = ents.empty()?\"\":ents[0].getString(\"age\");\nauto [st2, page2] = idx.scanKeysRangeAnchored(\n  \"users\", \"age\",\n  std::nullopt, std::nullopt,\n  true, true,\n  50, false,\n  std::make_optional(std::make_pair(lastAge, last))\n);\n</code></pre>"},{"location":"indexes/#sparse-index","title":"Sparse-Index","text":"<pre><code>idx.createSparseIndex(\"users\", \"nickname\", /*unique=*/false);\n</code></pre> <p>Leere/fehlende Felder werden nicht indexiert \u2013 spart Speicher.</p>"},{"location":"indexes/#geo-index","title":"Geo-Index","text":"<pre><code>idx.createGeoIndex(\"places\", \"coords\");\n\nBaseEntity p(\"p1\");\np.setField(\"coords_lat\", \"52.52\");\np.setField(\"coords_lon\", \"13.40\");\nidx.put(\"places\", p);\n\nauto [st1, inBox] = idx.scanGeoBox(\"places\", \"coords\", 52.0, 53.0, 13.0, 14.0);\nauto [st2, inRadius] = idx.scanGeoRadius(\"places\", \"coords\", 52.52, 13.40, 5.0 /*km*/);\n</code></pre>"},{"location":"indexes/#ttl-index","title":"TTL-Index","text":"<pre><code>idx.createTTLIndex(\"sessions\", \"last_seen\", /*ttl_seconds=*/3600);\n\n// Periodisch aufrufen (z. B. CRON/Timer)\nauto [st, removed] = idx.cleanupExpiredEntities(\"sessions\", \"last_seen\");\n</code></pre> <ul> <li>Beim Put wird ein Ablauf-Timestamp berechnet und als <code>ttlidx:</code>-Eintrag abgelegt.</li> <li><code>cleanupExpiredEntities</code> l\u00f6scht abgelaufene Entities und zugeh\u00f6rige Indizes atomar.</li> </ul>"},{"location":"indexes/#fulltext-index","title":"Fulltext-Index","text":"<pre><code>idx.createFulltextIndex(\"articles\", \"body\");\n\nBaseEntity a(\"a1\");\na.setField(\"body\", \"Fast search with inverted index.\");\nidx.put(\"articles\", a);\n\nauto [st, hits] = idx.scanFulltext(\"articles\", \"body\", \"fast inverted\");\n</code></pre> <p>Tokens werden whitespace-/punktuationsbasiert extrahiert; Suche nutzt AND-Logik \u00fcber alle Tokens.</p>"},{"location":"indexes/#graph-index-property-graph","title":"Graph-Index (Property Graph)","text":"<p>Header: <code>index/graph_index.h</code></p> <p>Funktionen:</p> <ul> <li><code>addEdge(edgeEntity)</code> / <code>deleteEdge(edgeId)</code> \u2013 atomar via WriteBatch/MVCC</li> <li><code>outNeighbors(pk)</code> / <code>inNeighbors(pk)</code> \u2013 Nachbarschaftsabfragen</li> <li>Traversierungen: <code>bfs</code>, <code>dijkstra</code>, <code>aStar</code></li> <li>Zeitliche Varianten: <code>bfsAtTime</code>, <code>dijkstraAtTime</code>, <code>getEdgesInTimeRange</code></li> </ul> <p>Edge-Entity-Felder: <code>id</code>, <code>_from</code>, <code>_to</code>, optional <code>_weight</code>, <code>valid_from</code>, <code>valid_to</code></p> <p>Beispiel:</p> <pre><code>GraphIndexManager gidx(db);\n\nBaseEntity e(\"edge-1\");\ne.setField(\"_from\", \"chunk-1\");\ne.setField(\"_to\", \"chunk-2\");\ne.setField(\"_weight\", \"1.0\");\ngidx.addEdge(e);\n\nauto [st, outs] = gidx.outNeighbors(\"chunk-1\");\n</code></pre> <p>Statistiken: <code>getTopologyNodeCount()</code>, <code>getTopologyEdgeCount()</code></p>"},{"location":"indexes/#vektorindex-knnann","title":"Vektorindex (KNN/ANN)","text":"<p>Header: <code>index/vector_index.h</code></p> <p>Konfiguration und Aufbau:</p> <pre><code>VectorIndexManager vix(db);\nvix.init(\"chunks\", /*dim=*/768, VectorIndexManager::Metric::COSINE, /*M*/16, /*efC*/200, /*ef*/64);\n\n// Entity mit Embedding hinzuf\u00fcgen\nBaseEntity c(\"chunk-1\");\nc.setVector(\"embedding\", std::vector&lt;float&gt;(768, 0.1f));\nvix.addEntity(c);\n\n// Suche\nstd::vector&lt;float&gt; q(768, 0.05f);\nauto [st, res] = vix.searchKnn(q, 10);\n</code></pre> <p>Hinweise:</p> <ul> <li>HNSW optional (compile flag <code>THEMIS_HNSW_ENABLED</code>), sonst Brute-Force Fallback</li> <li>Persistenz: <code>saveIndex/loadIndex</code> bzw. <code>setAutoSavePath</code> und <code>shutdown()</code></li> <li>Laufzeit-Tuning: <code>setEfSearch()</code> (Tradeoff Genauigkeit/Latenz)</li> </ul>"},{"location":"indexes/#fehler-und-kantenfalle","title":"Fehler- und Kantenf\u00e4lle","text":"<ul> <li>Leere oder fehlende Felder: werden von Sparse und TTL korrekt behandelt (Sparse: skip; TTL: kein Eintrag).</li> <li>Typkonflikte: Werte werden als Strings behandelt; sortierte Range-Scans sind lexikografisch (ggf. Vorverarbeitung/Zero-Padding nutzen).</li> <li>Geo: Ung\u00fcltige Zahlenwerte werden beim Rebuild/Put \u00fcbersprungen.</li> <li>Unique: Verst\u00f6\u00dfe liefern Status mit <code>ok=false</code>.</li> <li>Graph: Fehlende <code>_from</code>/<code>_to</code>-Felder f\u00fchren zu <code>Status::Error</code>.</li> <li>Vektor: Dimension muss konsistent zur Initialisierung sein; falsche Dimension \u21d2 <code>Status::Error</code>.</li> </ul>"},{"location":"memory_tuning/","title":"Speicherhierarchie-Optimierung &amp; RocksDB Tuning","text":"<p>Dieser Leitfaden beschreibt, wie du die Speicherhierarchie f\u00fcr THEMIS mit RocksDB effektiv konfigurierst.</p>"},{"location":"memory_tuning/#rocksdb-kompression","title":"RocksDB Kompression","text":""},{"location":"memory_tuning/#verfugbare-algorithmen","title":"Verf\u00fcgbare Algorithmen","text":"<p>THEMIS unterst\u00fctzt folgende Kompressionsalgorithmen (konfigurierbar via <code>compression_default</code> und <code>compression_bottommost</code>):</p> Algorithmus Kompressionsrate CPU-Overhead Write-Speed Read-Speed Empfehlung None 1.0x (keine) Minimal \u26a1 Sehr schnell \u26a1 Sehr schnell Nur f\u00fcr sehr schnelle SSDs mit viel Speicher LZ4 2-3x Niedrig \u26a1 Schnell \u26a1 Schnell \u2705 Empfohlen f\u00fcr Level 0-5 ZSTD 3-5x Mittel Mittel Schnell \u2705 Empfohlen f\u00fcr Level 6+ (bottommost) Snappy 2-2.5x Niedrig Schnell Schnell Alternative zu LZ4 Zlib 3-4x Hoch Langsam Mittel \u26a0\ufe0f Nicht empfohlen"},{"location":"memory_tuning/#benchmark-ergebnisse","title":"Benchmark-Ergebnisse","text":"<p>Test: 10.000 Entities \u00e0 ~2KB (gemischte JSON-Daten mit Text)</p> <pre><code>Compression         DB Size (MB)    Ratio    Write (MB/s)    Read (MB/s)\n------------------------------------------------------------------------------\nnone / none             ~45         1.0x        34.5           125.3\nlz4 / zstd              ~19         2.4x        33.8           118.4\nzstd / zstd             ~15         2.9x        32.3           112.7\nsnappy / zstd           ~19         2.3x        33.1           115.9\n</code></pre> <p>Empfehlung: <code>compression_default = \"lz4\"</code> + <code>compression_bottommost = \"zstd\"</code> f\u00fcr besten Trade-off zwischen Speicherplatz und Performance.</p>"},{"location":"memory_tuning/#konfiguration","title":"Konfiguration","text":"<pre><code>RocksDBWrapper::Config config;\nconfig.compression_default = \"lz4\";       // F\u00fcr Level 0-5\nconfig.compression_bottommost = \"zstd\";   // F\u00fcr Level 6+ (selten gelesen)\n</code></pre> <p>Bei der DB-Erstellung wird die Kompression automatisch aktiviert. Pr\u00fcfen mit:</p> <pre><code># OPTIONS-Datei inspizieren\ncat data/themis_server/OPTIONS-* | grep compression\n</code></pre>"},{"location":"memory_tuning/#ziele","title":"Ziele","text":"<ul> <li>WAL (Write-Ahead-Log) auf schnelle NVMe</li> <li>SSTables verteilt auf mehrere NVMe-Pfade (Hot/Cold m\u00f6glich)</li> <li>Gro\u00dfer Block-Cache im RAM, Index/Filter bevorzugt (High-Priority-Pool)</li> <li>Direkte I/O f\u00fcr Flush/Compaction optional, um OS-Cache zu umgehen</li> <li>Bloom-Filter und Partitioned-Filter f\u00fcr schnelle Point-Lookups</li> </ul>"},{"location":"memory_tuning/#relevante-konfiguration-rocksdbwrapperconfig","title":"Relevante Konfiguration (<code>RocksDBWrapper::Config</code>)","text":"<ul> <li>Verzeichnisse</li> <li><code>db_path</code>: Hauptpfad f\u00fcr DB</li> <li><code>wal_dir</code>: separates WAL-Verzeichnis (z. B. NVMe1) \u2014 leer = Standard unter <code>db_path</code></li> <li> <p><code>db_paths</code>: Liste aus <code>{ path, target_size_bytes }</code> (z. B. NVMe2, NVMe3)</p> </li> <li> <p>Kompression</p> </li> <li><code>compression_default</code>: Algorithmus f\u00fcr Level 0-5 (empfohlen: \"lz4\")</li> <li> <p><code>compression_bottommost</code>: Algorithmus f\u00fcr Level 6+ (empfohlen: \"zstd\")</p> </li> <li> <p>Caches/Filter</p> </li> <li><code>block_cache_size_mb</code>: Gr\u00f6\u00dfe des Block-Caches in MB</li> <li><code>cache_index_and_filter_blocks</code> (true)</li> <li><code>pin_l0_filter_and_index_blocks_in_cache</code> (true)</li> <li><code>partition_filters</code> (true)</li> <li><code>high_pri_pool_ratio</code> (0.5): Anteil f\u00fcr Index/Filter im Cache</li> <li> <p><code>bloom_bits_per_key</code> (10)</p> </li> <li> <p>Write Buffer / Compaction</p> </li> <li><code>memtable_size_mb</code> (z. B. 256)</li> <li><code>max_write_buffer_number</code> (3)</li> <li><code>min_write_buffer_number_to_merge</code> (1)</li> <li><code>use_universal_compaction</code> (false/true)</li> <li><code>dynamic_level_bytes</code> (true)</li> <li><code>target_file_size_base_mb</code> (64)</li> <li> <p><code>max_bytes_for_level_base_mb</code> (256)</p> </li> <li> <p>I/O</p> </li> <li><code>use_direct_reads</code> (false)</li> <li> <p><code>use_direct_io_for_flush_and_compaction</code> (false)</p> </li> <li> <p>WAL</p> </li> <li> <p><code>enable_wal</code> (true) \u2014 <code>write_options.sync</code></p> </li> <li> <p>Kompression (best-effort)</p> </li> <li>Default: LZ4 (Levels), ZSTD (Bottommost)</li> </ul>"},{"location":"memory_tuning/#beispielkonfiguration","title":"Beispielkonfiguration","text":"<pre><code>themis::RocksDBWrapper::Config cfg;\ncfg.db_path = \"D:/data/vccdb\";            // Hauptpfad\ncfg.wal_dir = \"E:/logs/vccdb_wal\";       // WAL auf separater NVMe\ncfg.db_paths = {\n    {\"D:/data/vccdb\",       500ull * 1024 * 1024 * 1024}, // 500 GB\n    {\"F:/data/vccdb_hot\",   500ull * 1024 * 1024 * 1024}  // 500 GB\n};\n\ncfg.memtable_size_mb = 512;\ncfg.block_cache_size_mb = 4096; // 4 GB Cache\ncfg.cache_index_and_filter_blocks = true;\ncfg.pin_l0_filter_and_index_blocks_in_cache = true;\ncfg.partition_filters = true;\ncfg.high_pri_pool_ratio = 0.5;\ncfg.bloom_bits_per_key = 10;\n\ncfg.max_write_buffer_number = 4;\ncfg.min_write_buffer_number_to_merge = 1;\ncfg.use_universal_compaction = false;\ncfg.dynamic_level_bytes = true;\ncfg.target_file_size_base_mb = 128;\ncfg.max_bytes_for_level_base_mb = 1024;\n\ncfg.use_direct_reads = false;\ncfg.use_direct_io_for_flush_and_compaction = true;\n</code></pre>"},{"location":"memory_tuning/#hinweise","title":"Hinweise","text":"<ul> <li>Direct I/O kann Performance verbessern, wenn der RocksDB-Block-Cache gro\u00df ist und OS-Cache thrashen w\u00fcrde. Testen!</li> <li><code>db_paths</code> verteilt neue SSTables \u00fcber Pfade entsprechend <code>target_size_bytes</code>.</li> <li>F\u00fcr GPU-ANN (Faiss-GPU) ist VRAM-Management separat (Task 6/Weiteres); hier nicht enthalten.</li> <li>Pr\u00fcfe <code>rocksdb.stats</code> (siehe <code>RocksDBWrapper::getStats</code>) nach Lasttests und passe Parameter an.</li> </ul> <pre><code>THEMIS_INFO(\"{}\", db.getStats());\n</code></pre>"},{"location":"memory_tuning/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Langsame Point-Lookups: <code>bloom_bits_per_key</code> erh\u00f6hen, <code>cache_index_and_filter_blocks</code> aktivieren.</li> <li>Hohe Latenzen beim Flush/Compaction: <code>use_direct_io_for_flush_and_compaction</code> testen; mehr Background-Jobs (<code>max_background_jobs</code>).</li> <li>RAM zu knapp: <code>block_cache_size_mb</code> reduzieren, <code>memtable_size_mb</code> anpassen. ```</li> </ul>"},{"location":"mvcc_design/","title":"MVCC Design f\u00fcr THEMIS","text":""},{"location":"mvcc_design/#implementierungsstatus-produktionsreif","title":"\u2705 IMPLEMENTIERUNGSSTATUS: PRODUKTIONSREIF","text":"<p>Stand: 2. November 2025</p> <p>MVCC ist implementiert (Snapshot-Isolation, Konflikterkennung). Die aktuell produktive Variante entspricht der in \u201eOption 1\u201c beschriebenen Engine-gest\u00fctzten L\u00f6sung. Details zum physischen Layout und zu WAL/Snapshots siehe \u201eRocksDB Storage\u201c.</p>"},{"location":"mvcc_design/#test-resultate","title":"Test-Resultate","text":"<ul> <li>Transaction Tests: 27/27 PASS (100%)</li> <li>MVCC Tests: 12/12 PASS (100%)</li> <li>Performance: Minimal Overhead gegen\u00fcber WriteBatch</li> <li>SingleEntity: MVCC ~3.4k/s vs WriteBatch ~3.1k/s</li> <li>Batch 100: WriteBatch ~27.8k/s</li> <li>Rollback: MVCC ~35.3k/s</li> <li>Snapshot Reads: ~44k/s</li> </ul>"},{"location":"mvcc_design/#ubersicht","title":"\u00dcbersicht","text":"<p>MVCC (Multi-Version Concurrency Control) erm\u00f6glicht parallele Transaktionen ohne Locks durch Versionierung aller Daten.</p>"},{"location":"mvcc_design/#implementierte-losung-engine-gestutzte-mvcc","title":"Implementierte L\u00f6sung: Engine-gest\u00fctzte MVCC","text":"<p>Kerneigenschaften:</p> <ul> <li>Snapshot Isolation: Konsistentes Sichtfenster pro Transaktion</li> <li>Conflict Detection: Write-Write-Konflikte werden erkannt</li> <li>Lock/Timeouts: konfigurierbar</li> <li>ACID-Garantien: Atomarit\u00e4t \u00fcber alle beteiligten Indizes</li> </ul>"},{"location":"mvcc_design/#architektur","title":"Architektur","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         TransactionManager                   \u2502\n\u2502  (High-Level Transaction API)                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      RocksDBWrapper::TransactionWrapper     \u2502\n\u2502  \u2022 get(key) - snapshot reads                \u2502\n\u2502  \u2022 put(key, value) - conflict detection     \u2502\n\u2502  \u2022 del(key) - transactional deletes         \u2502\n\u2502  \u2022 commit() - atomic persistence            \u2502\n\u2502  \u2022 rollback() - automatic cleanup           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          RocksDB TransactionDB              \u2502\n\u2502  \u2022 Pessimistic Locking                      \u2502\n\u2502  \u2022 Snapshot Isolation                       \u2502\n\u2502  \u2022 Write-Write Conflict Detection           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"mvcc_design/#indexe-mit-mvcc","title":"Indexe mit MVCC","text":"<p>Alle Index-Manager unterst\u00fctzen MVCC-Transaktionen:</p> <ul> <li>SecondaryIndexManager: Equality, Range, Sparse, Geo, TTL, Fulltext</li> <li>GraphIndexManager: Kanten und Adjazenz-Indizes</li> <li>VectorIndexManager: HNSW + Cache-Updates</li> </ul> <p>Alle Index-Operationen sind atomar mit der Haupttransaktion - Rollback entfernt alle \u00c4nderungen vollst\u00e4ndig.</p>"},{"location":"mvcc_design/#aktuelle-situation-vs-mvcc","title":"Aktuelle Situation vs. MVCC","text":""},{"location":"mvcc_design/#vor-mvcc-saga-pattern","title":"Vor MVCC (SAGA Pattern)","text":"<ul> <li>\u2705 Eventual Consistency durch Compensating Actions</li> <li>\u2705 Vector Cache Consistency</li> <li>\u274c Last-Write-Wins bei konkurrierenden Writes</li> <li>\u274c Keine Snapshot Isolation</li> <li>\u274c Write-Write Conflicts werden nicht erkannt</li> </ul>"},{"location":"mvcc_design/#mit-mvcc-implementiert","title":"Mit MVCC (Implementiert)","text":"<ul> <li>\u2705 Vollst\u00e4ndige Snapshot Isolation</li> <li>\u2705 Write-Write Conflict Detection</li> <li>\u2705 Concurrent Reads blockieren nie</li> <li>\u2705 Atomare Rollbacks (inkl. Indizes)</li> <li>\u2705 SAGA Pattern f\u00fcr Vector Cache (hybride L\u00f6sung)</li> <li>\u26a0\ufe0f  H\u00f6herer Speicherverbrauch durch RocksDB Locks</li> <li>\u26a0\ufe0f  Kein Point-in-Time Recovery (RocksDB Limitation)</li> </ul>"},{"location":"mvcc_design/#design-optionen-archiv","title":"Design-Optionen (Archiv)","text":"<p>Die urspr\u00fcnglich evaluierten Optionen sind unten dokumentiert. Option 1 (RocksDB TransactionDB) wurde implementiert.</p>"},{"location":"mvcc_design/#kernkomponenten-skizze","title":"Kernkomponenten (Skizze)","text":""},{"location":"mvcc_design/#1-engine-konfiguration-beispiel","title":"1. Engine-Konfiguration (Beispiel)","text":"<pre><code>// In RocksDBWrapper::open()\nrocksdb::TransactionDBOptions txn_db_options;\ntxn_db_options.transaction_lock_timeout = 1000;      // 1s Lock Timeout\ntxn_db_options.default_lock_timeout = 1000;          // 1s f\u00fcr alle Locks\n\nrocksdb::TransactionOptions txn_options;\ntxn_options.set_snapshot = true;                     // Automatisches Snapshot\ntxn_options.deadlock_detect = true;                  // Deadlock Prevention\n\nrocksdb::TransactionDB* txn_db;\nrocksdb::TransactionDB::Open(options, txn_db_options, db_path, &amp;txn_db);\n</code></pre>"},{"location":"mvcc_design/#2-transaktions-api-skizze","title":"2. Transaktions-API (Skizze)","text":"<pre><code>class TransactionWrapper {\npublic:\n    // Reads (mit Snapshot Isolation)\n    std::optional&lt;std::vector&lt;uint8_t&gt;&gt; get(const std::string&amp; key);\n\n    // Writes (mit Conflict Detection)\n    bool put(const std::string&amp; key, const std::vector&lt;uint8_t&gt;&amp; value);\n    bool del(const std::string&amp; key);\n\n    // Commit/Rollback\n    bool commit();     // false = Conflict detected\n    void rollback();   // Immer erfolgreich\n\n    // Snapshot Management\n    const rocksdb::Snapshot* getSnapshot() const;\n    bool isActive() const;\n};\n</code></pre>"},{"location":"mvcc_design/#3-conflict-detection-flow","title":"3. Conflict Detection Flow","text":"<pre><code>Thread A                    Thread B\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ntxn_a = begin()\n  snapshot_a = get_snapshot()\n                              txn_b = begin()\n                                snapshot_b = get_snapshot()\n\nput(\"user:1\", data_a)       put(\"user:1\", data_b)\n  \u2705 Lock acquired            \u23f3 Waiting for lock...\n\ncommit()                    \n  \u2705 Lock released\n  \u2705 Committed\n                              \u274c Conflict detected!\n                              \u274c Abort &amp; Rollback\n</code></pre>"},{"location":"mvcc_design/#4-index-integration","title":"4. Index-Integration","text":"<p>Alle Index-Operationen verwenden dieselbe MVCC-Transaktion:</p> <pre><code>// In TransactionManager::Transaction::putEntity()\nauto txn = mvcc_txn_;  // Shared MVCC transaction\n\n// Primary data\ntxn-&gt;put(entityKey, entityData);\n\n// Secondary indexes (atomisch mit primary data)\nsecIdx_.put(table, entity, *txn);  // MVCC variant\n\n// Graph indexes (atomisch)\ngraphIdx_.addEdge(edge, *txn);     // MVCC variant\n\n// Vector indexes (atomisch)\nvecIdx_.addEntity(entity, *txn);   // MVCC variant\n\n// Commit alles zusammen\ntxn-&gt;commit();  // Alles oder nichts\n</code></pre>"},{"location":"mvcc_design/#originales-design-archiv-nicht-implementiert","title":"Originales Design (Archiv - Nicht implementiert)","text":""},{"location":"mvcc_design/#option-23-custom-version-management","title":"Option 2/3: Custom Version Management","text":"<p>Die folgenden Designs wurden evaluiert aber nicht gew\u00e4hlt:</p> <pre><code>pending_writes_[pk] = new_version;\nreturn Status::OK();\n</code></pre> <p>}</p> <pre><code>\n### 4. Commit-Protokoll\n\n```cpp\nStatus Transaction::commit() {\n    // 1. Atomare Version-Nummer holen\n    uint64_t commit_version = global_version_counter_.fetch_add(1);\n\n    // 2. Write-Write Conflicts pr\u00fcfen\n    for (auto&amp; [pk, new_version] : pending_writes_) {\n        auto latest = db_.getLatestVersion(pk);\n        if (latest &amp;&amp; latest-&gt;version_start &gt; begin_version_) {\n            rollback();\n            return Status::Error(\"Serialization failure - retry transaction\");\n        }\n    }\n\n    // 3. Alte Versionen \"abschlie\u00dfen\"\n    WriteBatch batch;\n    for (auto&amp; [pk, new_version] : pending_writes_) {\n        auto old_version = db_.getLatestVersion(pk);\n        if (old_version) {\n            // Alte Version: version_end = commit_version\n            old_version-&gt;version_end = commit_version;\n            batch.put(makeVersionKey(pk, old_version-&gt;version_start), \n                     serialize(*old_version));\n        }\n\n        // Neue Version: version_start = commit_version\n        new_version.version_start = commit_version;\n        batch.put(makeVersionKey(pk, commit_version), \n                 serialize(new_version));\n    }\n\n    // 4. Atomarer Commit\n    return batch.commit();\n}\n</code></pre>"},{"location":"mvcc_design/#5-garbage-collection","title":"5. Garbage Collection","text":"<pre><code>class MVCCGarbageCollector {\n    // \u00c4lteste aktive Transaktion finden\n    uint64_t getOldestActiveTransaction() {\n        std::lock_guard lock(txn_mutex_);\n        uint64_t min_version = UINT64_MAX;\n        for (auto&amp; [txn_id, txn] : active_transactions_) {\n            min_version = std::min(min_version, txn-&gt;begin_version);\n        }\n        return min_version;\n    }\n\n    // Alte Versionen l\u00f6schen\n    void collectGarbage() {\n        uint64_t gc_horizon = getOldestActiveTransaction();\n\n        // Alle Versionen mit version_end &lt; gc_horizon k\u00f6nnen gel\u00f6scht werden\n        for (auto&amp; [pk, versions] : version_map_) {\n            versions.erase(\n                std::remove_if(versions.begin(), versions.end(),\n                    [gc_horizon](const VersionedEntity&amp; v) {\n                        return v.version_end &lt; gc_horizon;\n                    }),\n                versions.end()\n            );\n        }\n    }\n};\n</code></pre>"},{"location":"mvcc_design/#storage-hinweise","title":"Storage-Hinweise","text":"<p>Siehe erg\u00e4nzend: RocksDB Storage f\u00fcr WAL, Snapshots und Compaction sowie Schl\u00fcsselpr\u00e4fixe (entities, idx, ridx, graph, vector, changefeed, ts).</p> <pre><code>#include &lt;rocksdb/utilities/transaction_db.h&gt;\n\nclass MVCCWrapper {\n    rocksdb::TransactionDB* txn_db_;\n\n    // RocksDB TransactionDB bietet:\n    // - Built-in MVCC\n    // - Optimistic/Pessimistic Concurrency Control\n    // - Snapshot Isolation\n    // - Conflict Detection\n};\n</code></pre> <p>Hinweis: Engine-spezifische Tuning-Parameter (z. B. Lock-Timeouts, Snapshot-Handling) sollten anhand der Ziel-Workloads validiert werden.</p>"},{"location":"mvcc_design/#option-2-manuelle-mvcc-implementierung","title":"Option 2: Manuelle MVCC-Implementierung","text":"<p>Eigene Versionsverwaltung \u00fcber RocksDB Keys:</p> <pre><code>// Key-Format: entity:{table}:{pk}:v{version}\n// Beispiel:   entity:users:user_123:v0000000000000042\n\nclass ManualMVCC {\n    // Version-Range Scan\n    std::vector&lt;VersionedEntity&gt; getAllVersions(const std::string&amp; pk) {\n        std::string prefix = \"entity:\" + table + \":\" + pk + \":v\";\n        std::vector&lt;VersionedEntity&gt; versions;\n        db_.scanPrefix(prefix, [&amp;](auto key, auto value) {\n            versions.push_back(deserialize(value));\n            return true;\n        });\n        return versions;\n    }\n};\n</code></pre> <p>Vorteile: - \u2705 Volle Kontrolle - \u2705 Keine Breaking Changes - \u2705 Optimierbar f\u00fcr spezifische Workloads</p> <p>Nachteile: - \u274c Komplex zu implementieren - \u274c Mehr Fehlerquellen - \u274c GC muss selbst implementiert werden</p>"},{"location":"mvcc_design/#index-anpassungen","title":"Index-Anpassungen","text":""},{"location":"mvcc_design/#secondary-index-mit-mvcc","title":"Secondary Index mit MVCC","text":"<pre><code>// Aktuell: idx:users:age:25 -&gt; [\"user_123\", \"user_456\"]\n// MVCC:    idx:users:age:25:v42 -&gt; [\"user_123:v42\", \"user_456:v39\"]\n\nclass MVCCSecondaryIndex {\n    Status addToIndex(const BaseEntity&amp; entity, uint64_t version) {\n        // Index-Entry muss auch versioniert sein\n        std::string idx_key = makeIndexKey(field, value, version);\n        std::string pk_with_version = entity.getPrimaryKey() + \":v\" + \n                                      std::to_string(version);\n        // ...\n    }\n};\n</code></pre>"},{"location":"mvcc_design/#vector-index-mit-mvcc","title":"Vector Index mit MVCC","text":"<pre><code>class MVCCVectorIndex {\n    struct VersionedVector {\n        std::string pk;\n        uint64_t version;\n        std::vector&lt;float&gt; embedding;\n    };\n\n    // HNSW Index: Nur aktuelle Versionen\n    std::unordered_map&lt;uint64_t, std::vector&lt;VersionedVector&gt;&gt; version_snapshots_;\n\n    std::vector&lt;SearchResult&gt; search(\n        const std::vector&lt;float&gt;&amp; query,\n        uint64_t snapshot_version,\n        size_t k\n    ) {\n        // Filter: Nur Vektoren die in snapshot_version sichtbar sind\n        auto visible_vectors = getVisibleVectors(snapshot_version);\n        return hnsw_index_.search(query, k, visible_vectors);\n    }\n};\n</code></pre>"},{"location":"mvcc_design/#graph-index-mit-mvcc","title":"Graph Index mit MVCC","text":"<pre><code>class MVCCGraphIndex {\n    // Kanten versionieren\n    struct VersionedEdge {\n        std::string edge_id;\n        std::string from_node;\n        std::string to_node;\n        uint64_t version_start;\n        uint64_t version_end;\n    };\n\n    // Graph-Traversierung mit Snapshot\n    std::vector&lt;std::string&gt; traverse(\n        const std::string&amp; start_node,\n        uint64_t snapshot_version\n    ) {\n        // Nur Kanten verwenden, die in snapshot_version sichtbar sind\n        auto visible_edges = getVisibleEdges(snapshot_version);\n        return bfs(start_node, visible_edges);\n    }\n};\n</code></pre>"},{"location":"mvcc_design/#migration-plan","title":"Migration Plan","text":""},{"location":"mvcc_design/#phase-1-foundation-2-3-wochen","title":"Phase 1: Foundation (2-3 Wochen)","text":"<ol> <li>RocksDB TransactionDB Migration</li> <li><code>RocksDBWrapper</code> zu <code>TransactionDB</code> migrieren</li> <li>Snapshot-Management implementieren</li> <li> <p>Bestehende Tests anpassen</p> </li> <li> <p>TransactionManager Refactoring</p> </li> <li><code>begin()</code> gibt <code>rocksdb::Transaction*</code> zur\u00fcck</li> <li>Snapshot beim <code>begin()</code> erstellen</li> <li>Commit/Rollback \u00fcber TransactionDB</li> </ol>"},{"location":"mvcc_design/#phase-2-index-integration-2-3-wochen","title":"Phase 2: Index Integration (2-3 Wochen)","text":"<ol> <li>Secondary Index MVCC</li> <li>Index-Eintr\u00e4ge versionieren</li> <li>Range-Queries mit Snapshot</li> <li> <p>Visibility-Filter</p> </li> <li> <p>Vector Index MVCC</p> </li> <li>Version-aware HNSW</li> <li>Snapshot-basierte Suche</li> <li> <p>In-Memory Cache pro Version</p> </li> <li> <p>Graph Index MVCC</p> </li> <li>Versionierte Kanten</li> <li>Snapshot-Traversierung</li> <li>Temporal Graph Queries</li> </ol>"},{"location":"mvcc_design/#phase-3-advanced-features-1-2-wochen","title":"Phase 3: Advanced Features (1-2 Wochen)","text":"<ol> <li>Garbage Collection</li> <li>Background Thread</li> <li>Version-Pruning</li> <li> <p>Configurable Retention</p> </li> <li> <p>Performance Optimization</p> </li> <li>Version-Caching</li> <li>Optimistic Locking</li> <li>Batch Conflict Detection</li> </ol>"},{"location":"mvcc_design/#phase-4-testing-documentation-1-woche","title":"Phase 4: Testing &amp; Documentation (1 Woche)","text":"<ol> <li>Test Suite</li> <li>Concurrent Transaction Tests</li> <li>Conflict Detection Tests</li> <li> <p>Snapshot Isolation Tests</p> </li> <li> <p>Documentation</p> </li> <li>MVCC Architecture Guide</li> <li>Migration Guide</li> <li>Performance Tuning Guide</li> </ol>"},{"location":"mvcc_design/#benotigte-anderungen","title":"Ben\u00f6tigte \u00c4nderungen","text":""},{"location":"mvcc_design/#dateien-zu-erstellen","title":"Dateien zu erstellen:","text":"<ul> <li><code>include/transaction/mvcc_manager.h</code> - MVCC Coordination</li> <li><code>src/transaction/mvcc_manager.cpp</code></li> <li><code>include/storage/versioned_entity.h</code> - Version-aware Entity</li> <li><code>src/storage/versioned_entity.cpp</code></li> <li><code>include/transaction/garbage_collector.h</code> - GC</li> <li><code>src/transaction/garbage_collector.cpp</code></li> </ul>"},{"location":"mvcc_design/#dateien-zu-andern","title":"Dateien zu \u00e4ndern:","text":"<ul> <li><code>include/storage/rocksdb_wrapper.h</code> - TransactionDB statt DB</li> <li><code>src/storage/rocksdb_wrapper.cpp</code></li> <li><code>include/transaction/transaction_manager.h</code> - Snapshot Support</li> <li><code>src/transaction/transaction_manager.cpp</code></li> <li><code>include/index/secondary_index.h</code> - Versionierte Indizes</li> <li><code>src/index/secondary_index.cpp</code></li> <li><code>include/index/vector_index.h</code> - Snapshot-aware Search</li> <li><code>src/index/vector_index.cpp</code></li> <li><code>include/index/graph_index.h</code> - Temporal Graphs</li> <li><code>src/index/graph_index.cpp</code></li> </ul>"},{"location":"mvcc_design/#dependencies","title":"Dependencies:","text":"<pre><code>// vcpkg.json\n{\n  \"dependencies\": [\n    \"rocksdb[core,lz4,zlib,zstd,transactions]\"  // +transactions feature\n  ]\n}\n</code></pre>"},{"location":"mvcc_design/#performance-uberlegungen","title":"Performance-\u00dcberlegungen","text":""},{"location":"mvcc_design/#speicher-overhead","title":"Speicher-Overhead","text":"<ul> <li>Pro Version: ~100 Bytes Metadata + Entity-Gr\u00f6\u00dfe</li> <li>Beispiel: 1M Entities, 10 Versionen = ~1GB zus\u00e4tzlicher Speicher</li> <li>Mitigation: Aggressive GC, Configurable Retention</li> </ul>"},{"location":"mvcc_design/#write-amplification","title":"Write Amplification","text":"<ul> <li>Aktuell: 1 Write = 1 RocksDB Put</li> <li>MVCC: 1 Write = 2 Puts (alte Version update + neue Version insert)</li> <li>Mitigation: RocksDB Compaction optimieren</li> </ul>"},{"location":"mvcc_design/#read-performance","title":"Read Performance","text":"<ul> <li>Snapshot Reads: +5-10% Overhead (Version-Check)</li> <li>Range Queries: +10-20% Overhead (Visibility-Filter)</li> <li>Mitigation: Version-Cache, Bloom Filters</li> </ul>"},{"location":"mvcc_design/#alternativen","title":"Alternativen","text":""},{"location":"mvcc_design/#1-hybrid-saga-optimistic-locking","title":"1. Hybrid: SAGA + Optimistic Locking","text":"<ul> <li>SAGA Pattern behalten</li> <li>Nur Write-Write Conflict Detection hinzuf\u00fcgen</li> <li>Kein vollst\u00e4ndiges MVCC</li> <li>Aufwand: 1 Woche, Benefit: 70% von MVCC</li> </ul>"},{"location":"mvcc_design/#2-postgresql-style-mvcc","title":"2. PostgreSQL-Style MVCC","text":"<ul> <li>Tuple-Versionierung in-place</li> <li>Vacuum statt GC</li> <li>Aufwand: 4-6 Wochen, Benefit: Bessere Performance</li> </ul>"},{"location":"mvcc_design/#3-rocksdb-optimistictransactiondb","title":"3. RocksDB OptimisticTransactionDB","text":"<ul> <li>Leichtgewichtiger als TransactionDB</li> <li>Nur Conflict Detection, kein Locking</li> <li>Aufwand: 2-3 Wochen, Benefit: 80% von MVCC</li> </ul>"},{"location":"mvcc_design/#empfehlung","title":"Empfehlung","text":"<p>Start: Hybrid-Ansatz (SAGA + Optimistic Locking)</p> <ol> <li>Kurzfristig (1-2 Wochen):</li> <li>Write-Write Conflict Detection zu SAGA hinzuf\u00fcgen</li> <li>Version-Counter in TransactionManager</li> <li>Conflict-Check vor Commit</li> <li> <p>Ergebnis: 70% MVCC-Benefit, minimaler Aufwand</p> </li> <li> <p>Mittelfristig (1-2 Monate):</p> </li> <li>Migration zu RocksDB OptimisticTransactionDB</li> <li>Snapshot Isolation implementieren</li> <li>Index-Versionierung</li> <li> <p>Ergebnis: Vollst\u00e4ndiges MVCC</p> </li> <li> <p>Langfristig (3-6 Monate):</p> </li> <li>Garbage Collection optimieren</li> <li>Temporal Queries (Time-Travel)</li> <li>Performance Tuning</li> <li>Ergebnis: Production-ready MVCC</li> </ol>"},{"location":"mvcc_design/#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ol> <li>Proof of Concept: RocksDB TransactionDB Test (1 Tag)</li> <li>Benchmark: SAGA vs. Optimistic vs. Full MVCC (2 Tage)</li> <li>Entscheidung: Hybrid oder Full MVCC</li> <li>Implementation: Nach gew\u00e4hltem Ansatz</li> </ol>"},{"location":"mvcc_design/#ressourcen","title":"Ressourcen","text":"<ul> <li>RocksDB Transactions Wiki</li> <li>PostgreSQL MVCC Internals</li> <li>Cockroach MVCC Design</li> <li>Percolator Paper - Google's MVCC System</li> </ul>"},{"location":"operations_runbook/","title":"Operations Runbook","text":"<p>Dieses Runbook fasst die wichtigsten Betriebsaufgaben und Notfallma\u00dfnahmen f\u00fcr THEMIS zusammen. Es richtet sich an On-Call/Operations und beschreibt Checks, Standardprozeduren und Playbooks.</p>"},{"location":"operations_runbook/#1-quick-checks-60-sekunden","title":"1) Quick Checks (60 Sekunden)","text":"<ul> <li>Health: GET /health</li> <li>Version: GET /version (falls aktiviert) oder Server-Logs</li> <li>Metrics: GET /metrics (Prometheus Textformat)</li> <li>Stats: GET /stats (System-/Storage-Kurz\u00fcberblick, falls aktiviert)</li> <li>Config (laufend): GET /config</li> </ul> <p>Beispiele (Windows PowerShell):</p> <pre><code>Invoke-RestMethod http://localhost:8765/health\nInvoke-RestMethod http://localhost:8765/metrics | Out-String | Select-Object -First 50\nInvoke-RestMethod http://localhost:8765/config | ConvertTo-Json -Depth 5\n</code></pre> <p>Linux/macOS:</p> <pre><code>curl -fsS http://localhost:8765/health\ncurl -fsS http://localhost:8765/metrics | head -50\ncurl -fsS http://localhost:8765/config | jq .\n</code></pre>"},{"location":"operations_runbook/#2-startstoprestart","title":"2) Start/Stop/Restart","text":""},{"location":"operations_runbook/#systemd-linux","title":"Systemd (Linux)","text":"<pre><code>sudo systemctl status vccdb\nsudo systemctl restart vccdb\nsudo journalctl -u vccdb -f\n</code></pre>"},{"location":"operations_runbook/#docker-docker-compose","title":"Docker / Docker Compose","text":"<pre><code>docker ps | grep vccdb\ndocker logs -f vccdb\n# Restart\ndocker restart vccdb\n\n# Compose Stack\ndocker-compose ps\ndocker-compose logs -f vccdb\ndocker-compose restart vccdb\n</code></pre>"},{"location":"operations_runbook/#windows-powershell-standalone-binary","title":"Windows (PowerShell, Standalone Binary)","text":"<pre><code># Prozess pr\u00fcfen\nGet-Process themis_server -ErrorAction SilentlyContinue\n# Starten (aus Build/Release-Verzeichnis)\nStart-Process -FilePath \".\\build\\Release\\themis_server.exe\" -NoNewWindow\n# Stoppen\nGet-Process themis_server -ErrorAction SilentlyContinue | Stop-Process -Force\n</code></pre>"},{"location":"operations_runbook/#3-monitoring-alert-response","title":"3) Monitoring &amp; Alert Response","text":"<p>Wichtige Metriken (siehe auch docs/deployment.md):</p> <ul> <li>Server: vccdb_requests_total, vccdb_errors_total, vccdb_qps, process_uptime_seconds</li> <li>Latenz: vccdb_latency_bucket_microseconds{le=\"...\"}, vccdb_latency_sum_microseconds, vccdb_latency_count</li> <li>RocksDB: rocksdb_block_cache_usage_bytes, rocksdb_block_cache_capacity_bytes, rocksdb_pending_compaction_bytes, rocksdb_estimate_num_keys</li> <li>Index: themis_index_rebuild_count, themis_index_rebuild_duration_ms_total, themis_index_rebuild_entities_processed_total, themis_index_cursor_anchor_hits_total, themis_index_range_scan_steps_total</li> </ul> <p>Typische Alarme und Sofortma\u00dfnahmen:</p> <ul> <li>Hohe Fehlerquote (errors_total):</li> <li>Logs auf Exceptions pr\u00fcfen (Server-Logs, /metrics f\u00fcr spikes)</li> <li>Falls Konfig-\u00c4nderung urs\u00e4chlich: /config zur\u00fcckdrehen oder Neustart mit bekannter funktionierender config.json</li> <li>Hohe p95/p99 Latenz:</li> <li>Compaction-Backlog pr\u00fcfen (rocksdb_pending_compaction_bytes)</li> <li>Block Cache Nutzung vs. Kapazit\u00e4t pr\u00fcfen; ggf. Cache vergr\u00f6\u00dfern (Neustart erforderlich)</li> <li>Index-Hitrate/Range-Schritte pr\u00fcfen (range_scan_steps_total); Query-Filter/Indexierung optimieren</li> <li>Compaction-Backlog hoch:</li> <li>Wartungsfenster: <code>flush</code>/<code>compactRange</code> per Admin-Tool, IO-Budget freihalten, kurzzeitig Ingestion drosseln</li> <li>/metrics nicht erreichbar:</li> <li>Health pr\u00fcfen; Reverse Proxy/Firewall pr\u00fcfen; ggf. direkt auf die Instanz zugreifen</li> </ul>"},{"location":"operations_runbook/#4-konfiguration-im-betrieb-hot-reload","title":"4) Konfiguration im Betrieb (Hot-Reload)","text":"<p>Folgende Werte sind zur Laufzeit \u00e4nderbar (siehe docs/deployment.md \u2192 Runtime Configuration):</p> <ul> <li>logging.level (trace/debug/info/warn/error)</li> <li>logging.format (text/json)</li> <li>request_timeout_ms (1000\u2013300000)</li> <li>features (z. B. cdc, semantic_cache)</li> </ul> <p>Beispiel (Timeout auf 60s):</p> <pre><code>curl -X POST http://localhost:8765/config \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"request_timeout_ms\": 60000}'\n</code></pre> <p>Tracing an/aus (siehe docs/tracing.md):</p> <pre><code>{\n  \"tracing\": { \"enabled\": true, \"service_name\": \"themis\", \"otlp_endpoint\": \"http://localhost:4318\" }\n}\n</code></pre>"},{"location":"operations_runbook/#5-backup-restore","title":"5) Backup &amp; Restore","text":"<p>Siehe Details in docs/deployment.md \u2192 Backup &amp; Recovery.</p>"},{"location":"operations_runbook/#snapshot-checkpoint","title":"Snapshot (Checkpoint)","text":"<pre><code># Snapshot erstellen\ncurl -X POST http://localhost:8765/admin/snapshot \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"path\":\"/backups/themis-snap-$(date +%Y%m%d-%H%M%S)\"}'\n\n# Restore (Server stoppen, Daten zur\u00fcckspielen, verifizieren)\n./themis_server --restore /backups/themis-snap-YYYYMMDD-HHMMSS --target /var/lib/vccdb/data\n</code></pre>"},{"location":"operations_runbook/#wal-archivierung","title":"WAL-Archivierung","text":"<ul> <li>WAL-Archiv aktivieren (config.json), regelm\u00e4\u00dfige Rotation/Retention einplanen</li> </ul>"},{"location":"operations_runbook/#6-index-und-datenpflege-wartung","title":"6) Index- und Datenpflege (Wartung)","text":"<p>Dokumentation und API-Beispiele: <code>docs/indexes.md</code>, <code>docs/index_stats_maintenance.md</code>.</p> <ul> <li>Rebuild einzelner Indizes (bei Inkonsistenzen, Schema-\u00c4nderungen)</li> <li>Reindex ganzer Tabellen (geplant f\u00fcr Wartungsfenster)</li> <li>TTL-Cleanup regelm\u00e4\u00dfig ausf\u00fchren (Cron/Timer in Admin-Service)</li> </ul> <p>Hinweis: Die Rebuild-/Reindex-APIs existieren in der Serverbibliothek (C++). In Produktion idealerweise \u00fcber ein Admin-Tool oder Maintenance-Job nutzen. Beachte die Metriken <code>themis_index_rebuild_*</code> f\u00fcr Dauer/Progress.</p>"},{"location":"operations_runbook/#7-cdc-betrieb-change-data-capture","title":"7) CDC Betrieb (Change Data Capture)","text":"<p>Siehe <code>docs/change_data_capture.md</code>.</p> <ul> <li>Aktivieren \u00fcber Feature Flag in config.json</li> <li>Pull-Pattern: <code>GET /changefeed?from_seq=&lt;checkpoint&gt;&amp;limit=&lt;N&gt;</code></li> <li>Long-Poll: <code>long_poll_ms</code> zur Latenzreduktion</li> <li>Retention/Cleanup: Admin-Endpunkt (vorherige Sequenzen entfernen) gem\u00e4\u00df Doku</li> <li>Reverse Proxy f\u00fcr SSE-Stream <code>/changefeed/stream</code> korrekt konfigurieren (Keep-Alive, keine Pufferung)</li> </ul>"},{"location":"operations_runbook/#8-skalierung-performance","title":"8) Skalierung &amp; Performance","text":"<ul> <li>Threads: <code>server.worker_threads</code> (Neustart erforderlich)</li> <li>VectorIndex (ANN): <code>efSearch</code> zur Laufzeit erh\u00f6hen f\u00fcr Genauigkeit, trade-off Latenz</li> <li>RocksDB:</li> <li><code>block_cache_size_mb</code>, <code>memtable_size_mb</code> (Neustart erforderlich)</li> <li>Direct IO/Compaction-Optionen nur nach Tests \u00e4ndern</li> <li>Compose/K8s: Ressourcenlimits und Replikate anpassen; Load Balancer/Sticky Sessions bei SSE beachten</li> </ul>"},{"location":"operations_runbook/#9-troubleshooting-playbooks-kurzfassung","title":"9) Troubleshooting Playbooks (Kurzfassung)","text":"<ul> <li>API 5xx Spike</li> <li>Health OK? /health</li> <li>Logs auf Exceptions pr\u00fcfen</li> <li>Letzte Config-\u00c4nderungen r\u00fcckg\u00e4ngig machen (POST /config) oder Neustart</li> <li> <p>Bei Indexfehlern: betroffenen Index im Wartungsfenster rebuilden</p> </li> <li> <p>Abfragen sehr langsam</p> </li> <li>p95/p99 pr\u00fcfen, Range-Schritte hoch? \u2192 Index-Selektion/Pr\u00e4dikate pr\u00fcfen</li> <li>Compaction-Backlog hoch? \u2192 IO-Feuerwehr (Flush/Compaction), Ingestion drosseln</li> <li> <p>Vector-Suche: <code>efSearch</code> erh\u00f6hen, ggf. ANN-Persistenz laden (<code>saveIndex</code>/<code>loadIndex</code>)</p> </li> <li> <p>CDC Events fehlen</p> </li> <li>Feature aktiviert? Config pr\u00fcfen</li> <li>/changefeed liefert latest_sequence, checkpoint-Logik auf Consumer-Seite pr\u00fcfen</li> <li> <p>Reverse Proxy-Einstellungen f\u00fcr SSE pr\u00fcfen</p> </li> <li> <p>Graph-Anomalien (Kanten fehlen)</p> </li> <li>Topologie neu aufbauen (<code>GraphIndexManager::rebuildTopology()</code> im Maintenance-Tool)</li> </ul>"},{"location":"operations_runbook/#10-slosli-empfehlung","title":"10) SLO/SLI (Empfehlung)","text":"<ul> <li>Verf\u00fcgbarkeit (monthly): \u2265 99.9%</li> <li>p95 Latenz (Query): \u2264 200 ms (je Index/Workload variabel)</li> <li>Fehlerquote: &lt; 0.1% Requests</li> <li>Compaction Backlog: &lt; 5 GB \u00fcber 15 Minuten</li> </ul>"},{"location":"operations_runbook/#11-checklisten","title":"11) Checklisten","text":""},{"location":"operations_runbook/#releasedeployment-checklist","title":"Release/Deployment Checklist","text":"<ul> <li>[ ] Config validiert (<code>--validate</code>)</li> <li>[ ] Health/Metrics erreichbar</li> <li>[ ] Prometheus/Grafana up-to-date</li> <li>[ ] CDC Feature-Flags korrekt</li> <li>[ ] Backup-Policy aktiv</li> </ul>"},{"location":"operations_runbook/#incident-checklist","title":"Incident Checklist","text":"<ul> <li>[ ] Health/Errors/Latenz gepr\u00fcft</li> <li>[ ] Logs nach top Errors gefiltert</li> <li>[ ] Konfig-Drift ausgeschlossen (/config)</li> <li>[ ] Compaction/Storage-Lage gepr\u00fcft</li> <li>[ ] Eskalation/Kommunikation dokumentiert</li> </ul> <p>Weitere Details:  - Deployment &amp; Betrieb: <code>docs/deployment.md</code> - Tracing: <code>docs/tracing.md</code> - CDC: <code>docs/change_data_capture.md</code> - Indexe &amp; Wartung: <code>docs/indexes.md</code>, <code>docs/index_stats_maintenance.md</code></p>"},{"location":"path_constraints/","title":"Graph Traversal Path Constraints","text":"<p>Version: 1.0 Draft Datum: 28. Oktober 2025 Status: Konzept \u2013 Noch nicht implementiert</p>"},{"location":"path_constraints/#motivation","title":"Motivation","text":"<p>Aktuell werden FILTER-Ausdr\u00fccke in Traversals nur am letzten Level vor dem Enqueue angewendet (konservatives Pruning). Dies ist sicher, aber l\u00e4sst Optimierungspotenzial auf Zwischenebenen ungenutzt.</p> <p>Pfad-Constraints erm\u00f6glichen aggressiveres Pruning auf allen Tiefen, indem Pr\u00e4dikate entlang des gesamten Pfads gelten.</p>"},{"location":"path_constraints/#problem-naive-anwendung-ist-unsicher","title":"Problem: Naive Anwendung ist unsicher","text":""},{"location":"path_constraints/#beispiel-unsicheres-edge-pruning","title":"Beispiel: Unsicheres Edge-Pruning","text":"<p>Query:</p> <pre><code>FOR v IN 1..3 OUTBOUND 'user1' GRAPH 'social'\n  FILTER e.type == 'follows'\n  RETURN v\n</code></pre> <p>Naive (falsche) Interpretation: - \"Schneide alle Kanten ab, bei denen <code>e.type != 'follows'</code>\" - Problem: Bei depth=1 ist <code>e</code> die Kante von user1 \u2192 v1, aber bei depth=2 ist <code>e</code> die Kante zum aktuellen Knoten (v2), nicht die gesamte Pfadhistorie.</p> <p>Ergebnis: Zu viele Pfade abgeschnitten, die \u00fcber alternative Routen erreichbar w\u00e4ren.</p>"},{"location":"path_constraints/#losung-pfad-constraints-explizit-definieren","title":"L\u00f6sung: Pfad-Constraints explizit definieren","text":""},{"location":"path_constraints/#1-constraint-typen","title":"1. Constraint-Typen","text":""},{"location":"path_constraints/#11-last-edge-constraint-bereits-implementiert","title":"1.1 Last-Edge Constraint (bereits implementiert)","text":"<p>Semantik: FILTER gilt nur f\u00fcr die eingehende Kante zur aktuellen Zeile (depth).</p> <p>Syntax:</p> <pre><code>FILTER e.type == 'follows'  -- nur am letzten Level sicher\n</code></pre> <p>Anwendung: - Am letzten Level vor Enqueue pr\u00fcfen (\u2705 implementiert) - Auf Zwischenebenen: nicht prunen (w\u00fcrde Pfade abschneiden)</p>"},{"location":"path_constraints/#12-all-edges-constraint-pfad-weites-pradikat","title":"1.2 All-Edges Constraint (Pfad-weites Pr\u00e4dikat)","text":"<p>Semantik: FILTER gilt f\u00fcr alle Kanten entlang des Pfads von Start bis aktueller Zeile.</p> <p>Syntax (zuk\u00fcnftig):</p> <pre><code>FILTER PATH.ALL(e, e.type == 'follows')\n</code></pre> <p>Bedeutung: - Pr\u00fcfe bei jedem Expand: Ist die neue Kante ein <code>follows</code>? - Wenn nein: Pfad ist ung\u00fcltig \u2192 nicht enqueuen - Sicher auf allen Tiefen!</p> <p>Implementierung: - Beim Enqueue: Pr\u00fcfe <code>a.edgeId</code> gegen Constraint - Tracking: Optional Pfad-Historie (Liste der edgeIds) mitf\u00fchren, falls Constraints auf \"vorherige Kante\" pr\u00fcfen</p>"},{"location":"path_constraints/#13-any-edge-constraint","title":"1.3 Any-Edge Constraint","text":"<p>Semantik: Mindestens eine Kante entlang des Pfads erf\u00fcllt Pr\u00e4dikat.</p> <p>Syntax (zuk\u00fcnftig):</p> <pre><code>FILTER PATH.ANY(e, e.weight &gt; 10)\n</code></pre> <p>Implementierung: - Pfad-State: Boolean Flag <code>hasSeenHeavyEdge</code> - Beim Enqueue: Update Flag - Bei Result-Zeile: Pr\u00fcfe Flag</p>"},{"location":"path_constraints/#14-no-vertex-constraint-blockierte-knoten","title":"1.4 No-Vertex Constraint (Blockierte Knoten)","text":"<p>Semantik: Kein Vertex entlang des Pfads darf Pr\u00e4dikat verletzen.</p> <p>Syntax (zuk\u00fcnftig):</p> <pre><code>FILTER PATH.NONE(v, v.blocked == true)\n</code></pre> <p>Implementierung: - Beim Enqueue: Pr\u00fcfe neuen Vertex <code>nb</code> gegen Constraint - Wenn <code>nb.blocked == true</code>: Nicht enqueuen - Sicher auf allen Tiefen!</p>"},{"location":"path_constraints/#2-sichere-pruning-regeln","title":"2. Sichere Pruning-Regeln","text":"Constraint-Typ Anwendungstiefe Implementierung Last-Edge (e.field OP value) Nur letztes Level \u2705 Implementiert (evalSingleE) Last-Vertex (v.field OP value) Nur letztes Level \u2705 Implementiert (evalSingleV) PATH.ALL(e, ...) Alle Tiefen \ud83d\udd1c Geplant (Expand-Zeit-Check) PATH.NONE(v, ...) Alle Tiefen \ud83d\udd1c Geplant (Expand-Zeit-Check) PATH.ANY(e, ...) Alle Tiefen (State) \ud83d\udd1c Geplant (Flag-basiert)"},{"location":"path_constraints/#3-ast-erweiterungen-parser","title":"3. AST-Erweiterungen (Parser)","text":""},{"location":"path_constraints/#31-neue-expression-typen","title":"3.1 Neue Expression-Typen","text":"<pre><code>struct PathConstraintExpr : Expression {\n    enum class Type { All, Any, None };\n    Type type;\n    char varName;  // 'e' oder 'v'\n    std::unique_ptr&lt;Expression&gt; predicate;\n};\n</code></pre> <p>Parser-Syntax:</p> <pre><code>PATH.ALL(e, e.type == 'follows')\nPATH.NONE(v, v.blocked == true)\nPATH.ANY(e, e.weight &gt; 10)\n</code></pre>"},{"location":"path_constraints/#32-ast-classifier-filter-analyse","title":"3.2 AST-Classifier (Filter-Analyse)","text":"<pre><code>struct FilterClassification {\n    std::vector&lt;Expression*&gt; lastEdgeOnly;\n    std::vector&lt;Expression*&gt; lastVertexOnly;\n    std::vector&lt;Expression*&gt; pathAllEdge;\n    std::vector&lt;Expression*&gt; pathNoneVertex;\n    std::vector&lt;Expression*&gt; pathAnyEdge;\n    std::vector&lt;Expression*&gt; mixed;  // AND/OR kombiniert, keine einfache Klassifikation\n};\n\nFilterClassification classifyFilters(const std::vector&lt;std::unique_ptr&lt;FilterClause&gt;&gt;&amp; filters);\n</code></pre>"},{"location":"path_constraints/#4-bfs-anpassungen","title":"4. BFS-Anpassungen","text":""},{"location":"path_constraints/#41-expand-zeit-checks-pathallnone","title":"4.1 Expand-Zeit-Checks (PATH.ALL/NONE)","text":"<pre><code>auto enqueueOut = [&amp;](const std::vector&lt;AdjacencyInfo&gt;&amp; adj) {\n    for (const auto&amp; a : adj) {\n        // PATH.ALL(e, e.type == 'follows')\n        for (const auto&amp; pathAllE : pathAllEdgeConstraints) {\n            if (!evalEdgeConstraint(a.edgeId, pathAllE)) {\n                prunedAllDepths++;\n                continue;  // sicher auf allen Tiefen!\n            }\n        }\n\n        // PATH.NONE(v, v.blocked == true)\n        for (const auto&amp; pathNoneV : pathNoneVertexConstraints) {\n            if (evalVertexConstraint(a.targetPk, pathNoneV)) {\n                prunedAllDepths++;\n                continue;  // blockierter Vertex \u2192 skip\n            }\n        }\n\n        // Konservative Pr\u00fcfungen (nur letztes Level)\n        if (depth + 1 == t.maxDepth) {\n            // ... (wie bisher)\n        }\n\n        if (visited.insert(a.targetPk).second) {\n            parent[a.targetPk] = {node, a.edgeId};\n            qnodes.push({a.targetPk, depth + 1});\n            enqueuedPerDepth[depth + 1]++;\n        }\n    }\n};\n</code></pre>"},{"location":"path_constraints/#42-state-basierte-constraints-pathany","title":"4.2 State-basierte Constraints (PATH.ANY)","text":"<pre><code>struct PathState {\n    bool hasSeenHeavyEdge = false;\n    // weitere Flags je Constraint\n};\n\nstd::unordered_map&lt;std::string, PathState&gt; pathStates;\n\n// Beim Enqueue:\nPathState newState = pathStates[node];\nif (checkEdgeWeight(a.edgeId) &gt; 10) newState.hasSeenHeavyEdge = true;\npathStates[a.targetPk] = newState;\n\n// Bei Result-Zeile:\nif (pathAnyEdgeConstraints.hasHeavyEdge &amp;&amp; !pathStates[node].hasSeenHeavyEdge) {\n    pass = false;  // PATH.ANY nicht erf\u00fcllt\n}\n</code></pre>"},{"location":"path_constraints/#5-performance-implikationen","title":"5. Performance-Implikationen","text":""},{"location":"path_constraints/#vorteile","title":"Vorteile","text":"<ul> <li>Frontier-Reduktion: Aggressives Pruning auf allen Tiefen</li> <li>Fr\u00fchzeitiger Abbruch: Ung\u00fcltige Pfade werden sofort verworfen</li> <li>Weniger Entity-Loads: Nur validierte Pfade landen in Result-Set</li> </ul>"},{"location":"path_constraints/#kosten","title":"Kosten","text":"<ul> <li>Expand-Zeit-Overhead: Jede Kante wird gegen PATH.ALL/NONE gepr\u00fcft</li> <li>Memory: PathState f\u00fcr PATH.ANY (HashMap, kleine Keys)</li> </ul> <p>Faustregel: - Nutzen &gt; Kosten, wenn Constraints selektiv sind (z. B. nur 10% der Kanten sind <code>follows</code>)</p>"},{"location":"path_constraints/#6-implementierungs-roadmap","title":"6. Implementierungs-Roadmap","text":"<ol> <li>Phase 1: Parser-Erweiterung (PATH.ALL/NONE/ANY Syntax)</li> <li>Phase 2: AST-Classifier (Filter-Typen erkennen)</li> <li>Phase 3: BFS Expand-Zeit-Checks (PATH.ALL/NONE)</li> <li>Phase 4: State-Tracking (PATH.ANY)</li> <li>Phase 5: Metriken (<code>pruned_all_depths</code>, <code>path_state_size</code>)</li> <li>Phase 6: Tests &amp; Benchmarks (Vergleich mit/ohne Constraints)</li> </ol>"},{"location":"path_constraints/#7-beispiel-queries","title":"7. Beispiel-Queries","text":""},{"location":"path_constraints/#nur-follows-kanten-erlauben","title":"Nur follows-Kanten erlauben","text":"<pre><code>FOR v IN 1..3 OUTBOUND 'user1' GRAPH 'social'\n  FILTER PATH.ALL(e, e.type == 'follows')\n  RETURN v\n</code></pre> <p>Effekt: BFS expandiert nur \u00fcber <code>follows</code>-Kanten, alle anderen werden auf allen Tiefen gedroppt.</p>"},{"location":"path_constraints/#keine-blockierten-vertices-im-pfad","title":"Keine blockierten Vertices im Pfad","text":"<pre><code>FOR v IN 1..5 OUTBOUND 'user1' GRAPH 'social'\n  FILTER PATH.NONE(v, v.blocked == true)\n  RETURN v\n</code></pre> <p>Effekt: Pfade, die einen blockierten Vertex passieren, werden sofort verworfen.</p>"},{"location":"path_constraints/#mindestens-eine-starke-beziehung","title":"Mindestens eine starke Beziehung","text":"<pre><code>FOR v IN 1..4 OUTBOUND 'user1' GRAPH 'social'\n  FILTER PATH.ANY(e, e.weight &gt; 10)\n  RETURN v\n</code></pre> <p>Effekt: Nur Pfade mit mindestens einer starken Kante (weight &gt; 10) landen im Result.</p>"},{"location":"path_constraints/#zusammenfassung","title":"Zusammenfassung","text":"Aktuelle Implementierung Pfad-Constraints (geplant) Pruning nur am letzten Level Pruning auf allen Tiefen Unsicher f\u00fcr Zwischenebenen Sichere Semantik durch PATH.ALL/NONE Einfach (kein State) State-Tracking f\u00fcr PATH.ANY Konservativ (viele False Positives) Aggressiv (nur valide Pfade expandiert) <p>Empfehlung: - Phase 1-3 implementieren (PATH.ALL/NONE) f\u00fcr sofortigen Nutzen - Phase 4 (PATH.ANY) optional, falls Use-Cases existieren - Metriken sammeln: <code>pruned_all_depths</code> vs. <code>pruned_last_level</code> Vergleich</p> <p>Siehe auch: - AQL EXPLAIN &amp; PROFILE - BFS Pruning (aktuell)</p>"},{"location":"performance_benchmarks/","title":"Performance &amp; Benchmarks","text":"<p>Dieser Leitfaden konsolidiert die wichtigsten Performance-Themen und Microbenchmarks in ThemisDB: Kompression, Pagination, MVCC vs. WriteBatch, Index-Rebuilds und Vector-Suche. Er beschreibt Messmethodik, Interpretation und konkrete Tuning-Empfehlungen.</p>"},{"location":"performance_benchmarks/#ziele-und-erfolgsmetriken","title":"Ziele und Erfolgsmetriken","text":"<ul> <li>Schreibrate und -latenz unter realistischen Index-Setups</li> <li>Leselatenzen f\u00fcr typische Abfragepfade (Equal/Range/Cursor)</li> <li>Speicherbedarf und Write Amplification unter verschiedenen Kompressionsmodi</li> <li>Rebuild-/Reindex-Durchsatz und Fortschrittsmetriken</li> <li>Vector-Suche: Latenz vs. Genauigkeit (HNSW efSearch)</li> </ul>"},{"location":"performance_benchmarks/#methodik","title":"Methodik","text":"<ul> <li>Alle Microbenchmarks basieren auf Google Benchmark und laufen isoliert mit reproduzierbaren Seeds.</li> <li>Ergebnisse h\u00e4ngen stark von Hardware, OS, Compiler und Cache-Zustand ab; mehrere L\u00e4ufe und Mittelwerte bilden.</li> <li>Metriken \u00fcber Prometheus (/metrics) und RocksDB Properties erg\u00e4nzen (z. B. SST-Gr\u00f6\u00dfen, Compactions).</li> </ul>"},{"location":"performance_benchmarks/#benchmarks-ausfuhren-optional","title":"Benchmarks ausf\u00fchren (optional)","text":"<p>Hinweis: Beispiel f\u00fcr Windows PowerShell, Release-Build und aktivierte Benchmarks.</p> <pre><code># Im Build-Ordner (falls nicht vorhanden, erzeugen)\ncmake -S .. -B . -DCMAKE_BUILD_TYPE=Release -DTHEMIS_BUILD_BENCHMARKS=ON\ncmake --build . --config Release --parallel\n\n# Alle Benchmarks\n.\\Release\\themis_benchmarks.exe --benchmark_repetitions=3\n\n# Nur Pagination\n.\\Release\\themis_benchmarks.exe --benchmark_filter=BM_Pagination_.*\n\n# Nur CRUD/MVCC\n.\\Release\\themis_benchmarks.exe --benchmark_filter=CRUDFixture|MVCCFixture\n</code></pre> <p>Siehe auch: spezifische Seiten unten f\u00fcr Filter und Setups.</p>"},{"location":"performance_benchmarks/#kompression-none-vs-lz4-vs-zstd","title":"Kompression: none vs lz4 vs zstd","text":"<p>Quelle: <code>benchmarks/bench_compression.cpp</code>, Dokumentation: Kompressionsvalidierung &amp; Benchmarks</p> <p>Kernaussagen (aus Messungen): - Kleine Entities (\u2264 1 KB): lz4/zstd oft schneller als none (I/O-Reduktion &gt; CPU-Overhead) - Mittlere Gr\u00f6\u00dfen (~4 KB): \u00e4hnlich; zstd minimal besser bei hoher Kompressibilit\u00e4t - Gro\u00dfe Blobs (\u2265 16 KB): none schneller (CPU-Kosten der Kompression dominieren) - Reads (warm cache): none am schnellsten; in I/O-limitierten Szenarien kann Kompression dennoch helfen</p> <p>Empfohlene Hybrid-Konfiguration:</p> <pre><code>\"compression\": {\n  \"default\": \"lz4\",\n  \"bottommost\": \"zstd\"\n}\n</code></pre> <p>Write Amplification einsch\u00e4tzen und messen: - SST-Gr\u00f6\u00dfe reduziert Kompaktionsarbeit \u2192 geringere Write Amplification bei kompressiblen JSON - Exakt messen \u00fcber RocksDB <code>GetProperty(\"rocksdb.total-sst-files-size\")</code> vor/nach Workloads</p> <p>Weitere Details und Tabellen: siehe compression_benchmarks.md</p>"},{"location":"performance_benchmarks/#pagination-offset-vs-cursor-anchor","title":"Pagination: Offset vs Cursor (Anchor)","text":"<p>Quelle: <code>benchmarks/bench_query.cpp</code>, Dokumentation: Pagination Benchmarks</p> <ul> <li>Offset: Aufwand w\u00e4chst linear mit dem Offset (Index traversiert alle Eintr\u00e4ge bis zur Seite)</li> <li>Cursor/Anchor: konstante Arbeit pro Seite via start-after <code>(cursor_value, cursor_pk)</code> und <code>LIMIT count+1</code></li> <li>Praxisempfehlung: Cursor-Pagination f\u00fcr gro\u00dfe Datenmengen; siehe Cursor/Pagination f\u00fcr API/Beispiele</li> </ul> <p>Optional reproduzieren:</p> <pre><code>.\\Release\\themis_benchmarks.exe --benchmark_filter=BM_Pagination_.*\n</code></pre>"},{"location":"performance_benchmarks/#mvcc-vs-writebatch-und-crud-durchsatz","title":"MVCC vs WriteBatch und CRUD-Durchsatz","text":"<p>Quelle: <code>benchmarks/bench_mvcc.cpp</code>, <code>benchmarks/bench_crud.cpp</code></p> <ul> <li>MVCC (Transaction) bietet Snapshot-Isolation und komfortable Rollbacks; leichter Overhead vs. WriteBatch</li> <li>WriteBatch ist minimal schneller bei Bulk-Inserts, aber ohne Isolation/Locks</li> <li>Indexschwere Workloads (mehrere Sekund\u00e4rindizes) skalieren besser mit Batching (100+ pro Commit)</li> </ul> <p>Empfehlungen: - Einzel- und kleine Writes: MVCC f\u00fcr Korrektheit, besonders bei parallelen Reads - Bulk-Import: WriteBatch nutzen, WAL optional deaktivieren, danach <code>flush()</code> - Allgemein: Batches von 100\u20131000 Entities f\u00fcr Throughput optimieren</p>"},{"location":"performance_benchmarks/#index-rebuilds-und-reindex","title":"Index-Rebuilds und Reindex","text":"<p>Quelle: <code>benchmarks/bench_index_rebuild.cpp</code>, Dokumentation: Index-Statistiken &amp; Wartung</p> <ul> <li>Rebuild pro Index-Typ (Regular/Composite/Range/Sparse/Geo/TTL/Fulltext) separat messbar</li> <li>Gesamt-Reindex pro Tabelle ber\u00fccksichtigt alle Indizes; IO- und CPU-limitierte Phasen m\u00f6glich</li> <li>Fortschritt \u00fcber Prometheus-Metriken und interne Counters beobachten</li> </ul> <p>Wichtige Metriken (Auswahl): - <code>themis_index_rebuild_count</code>, <code>themis_index_rebuild_duration_ms_total</code> - <code>themis_index_rebuild_entities_processed_total</code> - <code>themis_index_cursor_anchor_hits_total</code>, <code>themis_index_range_scan_steps_total</code></p>"},{"location":"performance_benchmarks/#vector-suche-hnsw-tuning","title":"Vector-Suche (HNSW) Tuning","text":"<p>Voraussetzung: Build mit HNSW (<code>THEMIS_HNSW_ENABLED</code>). Konfiguration siehe Deployment: - <code>engine</code>: \"hnsw\" - <code>hnsw_m</code>: Nachbarschaftsgrad (Speicher/Genauigkeit) - <code>hnsw_ef_construction</code>: Aufbau-Qualit\u00e4t (Indexierzeit/Genauigkeit) - Laufzeit-Tuning: <code>setEfSearch(ef)</code> steigert Recall mit mehr Sucharbeit (h\u00f6here Latenz)</p> <p>Empfehlungen: - Startwerte: <code>m=16</code>, <code>ef_construction=200</code>, <code>efSearch=32\u2013128</code> je nach k und Datenbankgr\u00f6\u00dfe - Persistenz nutzen (<code>saveIndex</code>/<code>loadIndex</code>) f\u00fcr schnellere Warmstarts - Bei reiner CPU-Suche: Vektoren normalisieren, kleineren Dimensionalit\u00e4tsraum bevorzugen</p> <p>Benchmarks (implementiert in <code>benchmarks/bench_vector_search.cpp</code>): - BM_VectorSearch_efSearch(ef,k): Sweep \u00fcber <code>efSearch</code> f\u00fcr k-NN (Latenz vs. Suchaufwand) - BM_VectorInsert_Batch100(dim): Insert-Durchsatz in 100er Batches</p> <p>Optional ausf\u00fchren (PowerShell):</p> <pre><code>.\\Release\\themis_benchmarks.exe --benchmark_filter=BM_Vector(Search|Insert)_.*\n</code></pre>"},{"location":"performance_benchmarks/#best-practices-und-tuning-checkliste","title":"Best Practices und Tuning-Checkliste","text":"<ul> <li>Batching: Schreib- und Indexoperationen in Batches (100\u20131000) b\u00fcndeln</li> <li>Cursor-Pagination statt Offset f\u00fcr gro\u00dfe Offsets einsetzen</li> <li>Kompression hybrid (lz4 + zstd bottommost); gro\u00dfe Bin\u00e4rblobs ggf. ohne Kompression</li> <li>RocksDB-Tuning: Memtable/Block-Cache passend zur Workload, Hintergrundjobs ausreichend hoch</li> <li>Kalte vs. warme Messungen getrennt betrachten; OS-Cache explizit ber\u00fccksichtigen</li> <li>Rebuilds in Wartungsfenstern; Fortschritt/Metriken \u00fcberwachen</li> <li>Vector-Suche: <code>efSearch</code> dynamisch an SLOs anpassen (Latenz/Recall)</li> </ul>"},{"location":"performance_benchmarks/#referenzen","title":"Referenzen","text":"<ul> <li>compression_benchmarks.md</li> <li>search/pagination_benchmarks.md</li> <li>indexes.md</li> <li>index_stats_maintenance.md</li> <li>memory_tuning.md</li> </ul>"},{"location":"pii_detection_engines/","title":"PII Detection Engine Extensions","text":""},{"location":"pii_detection_engines/#overview","title":"Overview","text":"<p>The PII detection system uses a plugin architecture that allows multiple detection engines to work together:</p> <ol> <li>RegexDetectionEngine (default, always available)</li> <li>NERDetectionEngine (optional, requires external dependencies)</li> <li>EmbeddingDetectionEngine (optional, requires external dependencies)</li> </ol>"},{"location":"pii_detection_engines/#current-status","title":"Current Status","text":"<p>\u2705 Implemented: - Plugin architecture (<code>IPIIDetectionEngine</code> interface) - RegexDetectionEngine with YAML configuration - Engine factory and orchestration - Runtime reload with validation</p> <p>\u23f3 Ready for Implementation: - NERDetectionEngine (requires MITIE or ONNX Runtime) - EmbeddingDetectionEngine (requires fastText or word2vec)</p>"},{"location":"pii_detection_engines/#future-engine-ner-named-entity-recognition","title":"Future Engine: NER (Named Entity Recognition)","text":""},{"location":"pii_detection_engines/#dependencies","title":"Dependencies","text":"<p>Option 1: MITIE (Recommended for C++)</p> <pre><code>vcpkg install mitie\n</code></pre> <p>Option 2: ONNX Runtime (For pre-trained BERT/RoBERTa models)</p> <pre><code>vcpkg install onnxruntime\n</code></pre>"},{"location":"pii_detection_engines/#yaml-configuration","title":"YAML Configuration","text":"<pre><code>detection_engines:\n  - type: \"ner\"\n    enabled: true\n    settings:\n      model_path: \"models/pii_ner.dat\"  # MITIE model\n      # OR\n      model_path: \"models/bert_ner.onnx\"  # ONNX BERT model\n      model_type: \"mitie\"  # or \"onnx_bert\"\n      confidence_threshold: 0.85\n      batch_size: 32  # For ONNX models\n\n    entity_types:\n      - name: \"PERSON\"\n        pii_type: \"PERSON_NAME\"\n        redaction_mode: \"strict\"\n        enabled: true\n\n      - name: \"GPE\"  # Geo-Political Entity (locations)\n        pii_type: \"LOCATION\"\n        redaction_mode: \"partial\"\n        enabled: false\n\n      - name: \"ORG\"\n        pii_type: \"ORGANIZATION\"\n        redaction_mode: \"none\"\n        enabled: false\n</code></pre>"},{"location":"pii_detection_engines/#implementation-sketch","title":"Implementation Sketch","text":"<pre><code>class NERDetectionEngine : public IPIIDetectionEngine {\nprivate:\n    std::unique_ptr&lt;MitieNER&gt; ner_model_;  // or ONNXRuntime\n    std::unordered_map&lt;std::string, PIIType&gt; entity_mapping_;\n\npublic:\n    bool initialize(const nlohmann::json&amp; config) override {\n        std::string model_path = config[\"settings\"][\"model_path\"];\n        std::string model_type = config[\"settings\"][\"model_type\"];\n\n        if (model_type == \"mitie\") {\n            ner_model_ = std::make_unique&lt;MitieNER&gt;(model_path);\n        } else if (model_type == \"onnx_bert\") {\n            ner_model_ = std::make_unique&lt;OnnxBertNER&gt;(model_path);\n        }\n\n        // Map entity types to PII types\n        for (const auto&amp; entity : config[\"entity_types\"]) {\n            if (entity[\"enabled\"].get&lt;bool&gt;()) {\n                entity_mapping_[entity[\"name\"]] = \n                    PIITypeUtils::fromString(entity[\"pii_type\"]);\n            }\n        }\n\n        return ner_model_-&gt;isLoaded();\n    }\n\n    std::vector&lt;PIIFinding&gt; detectInText(const std::string&amp; text) const override {\n        auto entities = ner_model_-&gt;extract(text);\n        std::vector&lt;PIIFinding&gt; findings;\n\n        for (const auto&amp; entity : entities) {\n            auto it = entity_mapping_.find(entity.label);\n            if (it != entity_mapping_.end()) {\n                PIIFinding finding;\n                finding.type = it-&gt;second;\n                finding.value = entity.text;\n                finding.start_offset = entity.start;\n                finding.end_offset = entity.end;\n                finding.confidence = entity.score;\n                finding.pattern_name = entity.label;\n                finding.engine_name = \"ner\";\n                findings.push_back(finding);\n            }\n        }\n\n        return findings;\n    }\n};\n</code></pre>"},{"location":"pii_detection_engines/#training-custom-ner-models","title":"Training Custom NER Models","text":"<p>MITIE Training:</p> <pre><code># Prepare annotated data (CoNLL format)\n# Train MITIE model\nmitie-train ner_trainer pii_training_data.txt pii_ner.dat\n</code></pre> <p>ONNX Models: - Use pre-trained models from Hugging Face - Convert to ONNX format with <code>transformers</code> library - Example models:   - <code>dslim/bert-base-NER</code> (English)   - <code>dbmdz/bert-large-cased-finetuned-conll03-english</code>   - German: <code>deepset/gbert-base-germandpr</code></p>"},{"location":"pii_detection_engines/#future-engine-embeddings-semantic-similarity","title":"Future Engine: Embeddings (Semantic Similarity)","text":""},{"location":"pii_detection_engines/#dependencies_1","title":"Dependencies","text":"<p>fastText (Recommended)</p> <pre><code>vcpkg install fasttext\n</code></pre>"},{"location":"pii_detection_engines/#yaml-configuration_1","title":"YAML Configuration","text":"<pre><code>detection_engines:\n  - type: \"embedding\"\n    enabled: true\n    settings:\n      model_path: \"models/cc.de.300.bin\"  # fastText German model\n      model_type: \"fasttext\"\n      similarity_threshold: 0.80\n      context_window: 5  # Words before/after to consider\n\n    sensitive_keywords:\n      - keyword: \"gehalt\"\n        pii_type: \"SALARY\"\n        similarity_threshold: 0.85\n        redaction_mode: \"strict\"\n\n      - keyword: \"krankheit\"\n        pii_type: \"HEALTH_INFO\"\n        similarity_threshold: 0.85\n        redaction_mode: \"strict\"\n\n      - keyword: \"passwort\"\n        pii_type: \"CREDENTIAL\"\n        similarity_threshold: 0.90\n        redaction_mode: \"strict\"\n</code></pre>"},{"location":"pii_detection_engines/#implementation-sketch_1","title":"Implementation Sketch","text":"<pre><code>class EmbeddingDetectionEngine : public IPIIDetectionEngine {\nprivate:\n    std::unique_ptr&lt;fasttext::FastText&gt; model_;\n    std::vector&lt;SensitiveKeyword&gt; keywords_;\n\n    struct SensitiveKeyword {\n        std::string keyword;\n        PIIType type;\n        double threshold;\n        std::string redaction_mode;\n    };\n\npublic:\n    std::vector&lt;PIIFinding&gt; detectInText(const std::string&amp; text) const override {\n        auto words = tokenize(text);\n        std::vector&lt;PIIFinding&gt; findings;\n\n        for (size_t i = 0; i &lt; words.size(); ++i) {\n            auto word_vec = model_-&gt;getWordVector(words[i]);\n\n            for (const auto&amp; keyword : keywords_) {\n                auto keyword_vec = model_-&gt;getWordVector(keyword.keyword);\n                double similarity = cosineSimilarity(word_vec, keyword_vec);\n\n                if (similarity &gt;= keyword.threshold) {\n                    // Extract context window\n                    std::string context = extractContext(words, i, context_window_);\n\n                    PIIFinding finding;\n                    finding.type = keyword.type;\n                    finding.value = context;\n                    finding.confidence = similarity;\n                    finding.pattern_name = keyword.keyword;\n                    finding.engine_name = \"embedding\";\n                    findings.push_back(finding);\n                }\n            }\n        }\n\n        return findings;\n    }\n};\n</code></pre>"},{"location":"pii_detection_engines/#pre-trained-models","title":"Pre-trained Models","text":"<p>fastText: - Download: https://fasttext.cc/docs/en/crawl-vectors.html - German: <code>cc.de.300.bin</code> (6.7 GB) - English: <code>cc.en.300.bin</code> (5.8 GB)</p> <p>word2vec: - Google News: <code>GoogleNews-vectors-negative300.bin</code> - German: <code>german.model</code> (DeReWo)</p>"},{"location":"pii_detection_engines/#integration-steps","title":"Integration Steps","text":""},{"location":"pii_detection_engines/#1-add-dependencies-to-vcpkgjson","title":"1. Add Dependencies to vcpkg.json","text":"<pre><code>{\n  \"dependencies\": [\n    \"mitie\",        // For NER\n    \"onnxruntime\",  // For BERT-based NER\n    \"fasttext\"      // For embeddings\n  ],\n  \"overrides\": [\n    {\n      \"name\": \"mitie\",\n      \"version\": \"0.7\"\n    }\n  ]\n}\n</code></pre>"},{"location":"pii_detection_engines/#2-update-cmakeliststxt","title":"2. Update CMakeLists.txt","text":"<pre><code># Optional NER support\noption(ENABLE_PII_NER \"Enable NER-based PII detection\" OFF)\nif(ENABLE_PII_NER)\n    find_package(mitie CONFIG)\n    if(mitie_FOUND)\n        target_link_libraries(themis_core PRIVATE mitie::mitie)\n        target_compile_definitions(themis_core PRIVATE THEMIS_ENABLE_NER)\n    endif()\nendif()\n\n# Optional embedding support\noption(ENABLE_PII_EMBEDDING \"Enable embedding-based PII detection\" OFF)\nif(ENABLE_PII_EMBEDDING)\n    find_package(fastText CONFIG)\n    if(fastText_FOUND)\n        target_link_libraries(themis_core PRIVATE fastText::fastText)\n        target_compile_definitions(themis_core PRIVATE THEMIS_ENABLE_EMBEDDING)\n    endif()\nendif()\n</code></pre>"},{"location":"pii_detection_engines/#3-conditional-compilation","title":"3. Conditional Compilation","text":"<pre><code>// In pii_detection_engine_factory.cpp\nstd::unique_ptr&lt;IPIIDetectionEngine&gt; PIIDetectionEngineFactory::create(\n    const std::string&amp; engine_type) {\n\n    if (engine_type == \"regex\") {\n        return std::make_unique&lt;RegexDetectionEngine&gt;();\n    }\n\n#ifdef THEMIS_ENABLE_NER\n    if (engine_type == \"ner\") {\n        return std::make_unique&lt;NERDetectionEngine&gt;();\n    }\n#endif\n\n#ifdef THEMIS_ENABLE_EMBEDDING\n    if (engine_type == \"embedding\") {\n        return std::make_unique&lt;EmbeddingDetectionEngine&gt;();\n    }\n#endif\n\n    return nullptr;\n}\n</code></pre>"},{"location":"pii_detection_engines/#performance-considerations","title":"Performance Considerations","text":"Engine Speed Accuracy Memory Use Case Regex Very Fast Good (95%+) Low Structured PII (email, SSN, cards) NER Medium Excellent (98%+) Medium Names, locations, organizations Embedding Slow Variable High Context-based, semantic PII <p>Recommendation: - Default: Regex only (fast, low overhead) - Enhanced: Regex + NER (best balance) - Advanced: All three (highest accuracy, higher latency)</p>"},{"location":"pii_detection_engines/#testing-strategy","title":"Testing Strategy","text":"<pre><code>TEST(PIIDetectorTest, MultiEngineDetection) {\n    // Enable both regex and NER\n    PIIDetector detector(\"config/pii_patterns_with_ner.yaml\");\n\n    std::string text = \"Contact Max Mustermann at max@example.com\";\n    auto findings = detector.detectInText(text);\n\n    // Should find:\n    // 1. \"Max Mustermann\" via NER (PERSON_NAME)\n    // 2. \"max@example.com\" via Regex (EMAIL)\n    ASSERT_EQ(findings.size(), 2);\n\n    EXPECT_EQ(findings[0].engine_name, \"ner\");\n    EXPECT_EQ(findings[0].type, PIIType::PERSON_NAME);\n\n    EXPECT_EQ(findings[1].engine_name, \"regex\");\n    EXPECT_EQ(findings[1].type, PIIType::EMAIL);\n}\n</code></pre>"},{"location":"pii_detection_engines/#deployment","title":"Deployment","text":"<p>Production Checklist: 1. \u2705 Regex engine always enabled (safe default) 2. \u23f3 NER engine optional (enable for high-value data) 3. \u23f3 Embedding engine optional (enable for advanced use cases) 4. \u2705 YAML config with engine sections 5. \u2705 Fallback to embedded defaults 6. \u23f3 Model files deployed to <code>models/</code> directory 7. \u23f3 Memory limits configured (prevent OOM) 8. \u23f3 Performance monitoring (track detection latency)</p>"},{"location":"pii_detection_engines/#future-enhancements","title":"Future Enhancements","text":"<ul> <li>Multi-language Support: Load language-specific models per tenant</li> <li>Custom Training: API for training custom NER models on tenant data</li> <li>Explainability: Return detection reasoning (which words triggered)</li> <li>Confidence Calibration: Adjust thresholds based on false positive rates</li> <li>GPU Acceleration: Use CUDA for ONNX models in high-throughput scenarios</li> </ul>"},{"location":"pii_engine_signing/","title":"PII Detection Engine Signing","text":""},{"location":"pii_engine_signing/#overview","title":"Overview","text":"<p>All PII detection engines must be signed with PKI signatures before they can be loaded by the PIIDetector orchestrator. This ensures:</p> <ul> <li>Integrity: Engine configurations cannot be tampered with</li> <li>Authenticity: Only trusted entities can create detection engines</li> <li>Auditability: All signature verifications are logged</li> <li>Non-repudiation: Signer identity is cryptographically verified</li> </ul>"},{"location":"pii_engine_signing/#security-architecture","title":"Security Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  PII Detection Engine Loading Flow (with PKI Verification)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n1. Load YAML Config\n   \u2193\n2. Extract Engine Config + Signature\n   \u2193\n3. Compute Config Hash (SHA-256)\n   \u251c\u2500 Normalize to JSON (deterministic)\n   \u251c\u2500 Exclude signature block\n   \u2514\u2500 Hash with SHA-256\n   \u2193\n4. Verify PKI Signature\n   \u251c\u2500 Decode base64 signature\n   \u251c\u2500 Verify with public key\n   \u2514\u2500 Compare with computed hash\n   \u2193\n5. [PASS] Initialize Engine  OR  [FAIL] Reject + Log\n</code></pre>"},{"location":"pii_engine_signing/#quick-start","title":"Quick Start","text":""},{"location":"pii_engine_signing/#1-generate-test-keys-development-only","title":"1. Generate Test Keys (Development Only)","text":"<pre><code>cd tools\npython sign_pii_engine.py keygen --output-dir ../config/keys\n\n# Output:\n# [\u2713] Generated test key pair:\n#     Private key: ../config/keys/private_key.pem\n#     Public key: ../config/keys/public_key.pem\n# [!] WARNING: These are test keys. Use HSM for production!\n</code></pre>"},{"location":"pii_engine_signing/#2-sign-an-engine-configuration","title":"2. Sign an Engine Configuration","text":"<pre><code>python sign_pii_engine.py sign \\\n    --config ../config/pii_patterns.yaml \\\n    --engine regex \\\n    --key ../config/keys/private_key.pem \\\n    --output ../config/pii_patterns_signed.yaml \\\n    --signer \"VCC Security Team\"\n\n# Output:\n# [*] Found regex engine configuration\n# [*] Configuration hash (SHA-256): e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n# [*] Generated signature: BASE64_ENCODED_SIGNATURE...\n# [\u2713] Signed configuration written to ../config/pii_patterns_signed.yaml\n# [\u2713] Signature ID: pii-regex-engine-v1.0.0\n# [\u2713] Signed by: VCC Security Team\n# [\u2713] Signed at: 2025-11-01T12:34:56+00:00\n</code></pre>"},{"location":"pii_engine_signing/#3-use-signed-configuration-in-c","title":"3. Use Signed Configuration in C++","text":"<pre><code>#include \"utils/pii_detector.h\"\n#include \"utils/pki_client.h\"\n\n// Initialize PKI client with public key\nPKIConfig pki_config;\npki_config.public_key_path = \"config/keys/public_key.pem\";\nauto pki_client = std::make_shared&lt;VCCPKIClient&gt;(pki_config);\n\n// Create PII detector with PKI verification\nPIIDetector detector(\"config/pii_patterns_signed.yaml\", pki_client);\n\n// All engines are now verified with PKI signatures!\nauto findings = detector.detectInText(\"Contact alice@example.com\");\n</code></pre>"},{"location":"pii_engine_signing/#production-deployment","title":"Production Deployment","text":""},{"location":"pii_engine_signing/#hardware-security-module-hsm","title":"Hardware Security Module (HSM)","text":"<p>For production environments, private keys should be stored in an HSM:</p> <pre><code>// Production PKI client with HSM backing\nPKIConfig pki_config;\npki_config.use_hsm = true;\npki_config.hsm_slot = 0;\npki_config.hsm_pin = std::getenv(\"HSM_PIN\");\npki_config.public_key_id = \"VCC-PKI-001\";\n\nauto pki_client = std::make_shared&lt;VCCPKIClient&gt;(pki_config);\nPIIDetector detector(\"config/pii_patterns.yaml\", pki_client);\n</code></pre>"},{"location":"pii_engine_signing/#cicd-integration","title":"CI/CD Integration","text":"<p>Add signing to your deployment pipeline:</p> <pre><code># .github/workflows/deploy.yml\n- name: Sign PII Engine Configurations\n  run: |\n    python tools/sign_pii_engine.py sign \\\n      --config config/pii_patterns.yaml \\\n      --engine regex \\\n      --key ${{ secrets.PII_SIGNING_KEY }} \\\n      --output config/pii_patterns_signed.yaml \\\n      --signer \"VCC CI/CD Pipeline\"\n\n- name: Verify Signatures\n  run: |\n    python tools/verify_pii_signatures.py \\\n      --config config/pii_patterns_signed.yaml \\\n      --public-key config/keys/public_key.pem\n</code></pre>"},{"location":"pii_engine_signing/#signature-format","title":"Signature Format","text":""},{"location":"pii_engine_signing/#in-yaml-configuration","title":"In YAML Configuration","text":"<pre><code>detection_engines:\n  - type: \"regex\"\n    version: \"1.0.0\"\n    enabled: true\n\n    # PKI Signature Block\n    signature:\n      config_hash: \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\"\n      signature: \"BASE64_ENCODED_SIGNATURE\"\n      signature_id: \"pii-regex-engine-v1.0.0\"\n      cert_serial: \"VCC-PKI-001\"\n      signed_at: \"2025-11-01T12:34:56Z\"\n      signer: \"VCC Security Team\"\n\n    # Engine configuration (included in hash)\n    settings:\n      min_confidence: 0.75\n      # ...\n    patterns:\n      - name: EMAIL\n        # ...\n</code></pre>"},{"location":"pii_engine_signing/#signature-verification-in-c","title":"Signature Verification in C++","text":"<pre><code>// In PIIDetectionEngineFactory::createSigned()\n\n// 1. Extract signature from config\nauto sig_node = config[\"signature\"];\nPluginSignature signature;\nsignature.config_hash = sig_node[\"config_hash\"];\nsignature.signature = sig_node[\"signature\"];\nsignature.signature_id = sig_node[\"signature_id\"];\n// ...\n\n// 2. Compute hash of config (excluding signature)\nauto config_copy = config;\nconfig_copy.erase(\"signature\");\nstd::string computed_hash = PluginSignature::computeConfigHash(config_copy);\n\n// 3. Verify signature\nif (computed_hash != signature.config_hash) {\n    error_msg = \"Config hash mismatch\";\n    return nullptr;\n}\n\nif (!pki_client.verifyHash(signature.config_hash, signature.signature)) {\n    error_msg = \"PKI signature verification failed\";\n    return nullptr;\n}\n\n// 4. Create engine (signature is valid)\nauto engine = createUnsigned(engine_type);\nengine-&gt;initialize(config);\n</code></pre>"},{"location":"pii_engine_signing/#security-considerations","title":"Security Considerations","text":""},{"location":"pii_engine_signing/#threat-model","title":"Threat Model","text":"Threat Mitigation Tampered engine config Config hash mismatch detected, engine rejected Unsigned engine No signature block, engine rejected (unless fallback enabled) Expired signature Signature age check in global_settings.max_signature_age_days Untrusted signer Signer whitelist in global_settings.pki_verification.trusted_signers Key compromise Rotate keys, re-sign all engines, deploy new public key Replay attack Signature includes timestamp, old signatures rejected"},{"location":"pii_engine_signing/#key-rotation-procedure","title":"Key Rotation Procedure","text":"<ol> <li>Generate new key pair (keep old keys for transition period)</li> <li>Re-sign all engine configurations with new key</li> <li>Deploy signed configs + new public key to all instances</li> <li>Monitor logs for verification failures</li> <li>After transition period, revoke old keys</li> </ol>"},{"location":"pii_engine_signing/#audit-logging","title":"Audit Logging","text":"<p>All signature verification attempts are logged:</p> <pre><code>[INFO] PIIDetector: Verifying signature for engine 'regex' v1.0.0\n[INFO] PKI signature verification succeeded for 'pii-regex-engine-v1.0.0'\n[INFO] Engine 'regex' loaded successfully (signed by: VCC Security Team)\n</code></pre> <p>Failures trigger alerts:</p> <pre><code>[ERROR] PKI signature verification FAILED for engine 'regex'\n[ERROR] Config hash mismatch: expected e3b0c44..., computed a1b2c3...\n[ERROR] Falling back to embedded unsigned defaults\n</code></pre>"},{"location":"pii_engine_signing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"pii_engine_signing/#config-hash-mismatch-error","title":"\"Config hash mismatch\" Error","text":"<p>Cause: Engine configuration was modified after signing.</p> <p>Solution: Re-sign the configuration:</p> <pre><code>python tools/sign_pii_engine.py sign --config pii_patterns.yaml --engine regex --key private_key.pem --output pii_patterns_signed.yaml\n</code></pre>"},{"location":"pii_engine_signing/#pki-signature-verification-failed-error","title":"\"PKI signature verification failed\" Error","text":"<p>Cause: Signature doesn't match public key (wrong key, corrupted signature, etc.)</p> <p>Solution:  1. Verify public key matches private key used for signing 2. Check signature wasn't corrupted (base64 encoding issues) 3. Re-sign with correct key</p>"},{"location":"pii_engine_signing/#untrusted-signer-error","title":"\"Untrusted signer\" Error","text":"<p>Cause: Signer not in <code>trusted_signers</code> list.</p> <p>Solution: Add signer to <code>global_settings.pki_verification.trusted_signers</code> in YAML:</p> <pre><code>global_settings:\n  pki_verification:\n    trusted_signers:\n      - \"VCC Security Team\"\n      - \"Your New Signer\"  # Add here\n</code></pre>"},{"location":"pii_engine_signing/#fallback-to-unsigned-defaults","title":"Fallback to Unsigned Defaults","text":"<p>If all signed engines fail to load, the detector falls back to embedded unsigned regex patterns:</p> <pre><code>[WARN] All signed engines failed PKI verification\n[WARN] Falling back to embedded unsigned RegexDetectionEngine\n[INFO] Using 7 embedded regex patterns (EMAIL, PHONE, SSN, ...)\n</code></pre> <p>To disable fallback (enforce signature requirement):</p> <pre><code>global_settings:\n  pki_verification:\n    allow_embedded_fallback: false\n</code></pre>"},{"location":"pii_engine_signing/#advanced-usage","title":"Advanced Usage","text":""},{"location":"pii_engine_signing/#multiple-signers-chain-of-trust","title":"Multiple Signers (Chain of Trust)","text":"<p>For critical environments, require multiple signatures:</p> <pre><code>signature:\n  signatures:  # Array of signatures\n    - signer: \"VCC Security Team\"\n      signature: \"...\"\n      signed_at: \"2025-11-01T12:00:00Z\"\n\n    - signer: \"VCC Compliance Officer\"\n      signature: \"...\"\n      signed_at: \"2025-11-01T12:30:00Z\"\n</code></pre>"},{"location":"pii_engine_signing/#signature-revocation","title":"Signature Revocation","text":"<p>Maintain a revocation list:</p> <pre><code>global_settings:\n  pki_verification:\n    revoked_signatures:\n      - \"pii-regex-engine-v0.9.0\"  # Old version, revoked\n      - \"pii-ner-compromised-2024\"  # Compromised key\n</code></pre>"},{"location":"pii_engine_signing/#emergency-unsigned-mode","title":"Emergency Unsigned Mode","text":"<p>For disaster recovery, temporarily disable PKI verification:</p> <pre><code>// Emergency bypass (log extensively!)\nPIIDetector detector(\"config/pii_patterns.yaml\", nullptr);  // nullptr = no PKI client\nspdlog::critical(\"EMERGENCY: Running without PKI verification!\");\n</code></pre>"},{"location":"pii_engine_signing/#references","title":"References","text":"<ul> <li>PKI Client Implementation: <code>include/utils/pki_client.h</code></li> <li>Plugin Interface: <code>include/utils/pii_detection_engine.h</code></li> <li>Orchestrator: <code>include/utils/pii_detector.h</code></li> <li>YAML Configuration: <code>config/pii_patterns.yaml</code></li> </ul>"},{"location":"property_graph_model/","title":"Property Graph Model &amp; Multi-Graph Federation","text":"<p>Status: \u2705 Implemented &amp; Tested (13/13 tests passing) Feature: Property Graph Model with Node Labels, Relationship Types, and Multi-Graph Federation Date: 2025-01-15</p>"},{"location":"property_graph_model/#overview","title":"Overview","text":"<p>This feature extends Themis's graph capabilities with Property Graph Model semantics and Multi-Graph Federation. You can now:</p> <ul> <li>Assign multiple labels to nodes (e.g., <code>:Person</code>, <code>:Employee</code>)</li> <li>Define typed relationships (e.g., <code>FOLLOWS</code>, <code>LIKES</code>, <code>REPORTS_TO</code>)</li> <li>Manage multiple isolated graphs with cross-graph queries</li> <li>Perform federated pattern matching across graphs</li> </ul>"},{"location":"property_graph_model/#use-cases","title":"Use Cases","text":"<ul> <li>Social Networks: <code>:Person -[FOLLOWS]-&gt; :Person</code>, <code>:User -[LIKES]-&gt; :Post</code></li> <li>Knowledge Graphs: <code>:Entity -[RELATES_TO]-&gt; :Entity</code>, <code>:Concept -[IS_A]-&gt; :Category</code></li> <li>Enterprise Graphs: <code>:Employee -[REPORTS_TO]-&gt; :Manager</code>, <code>:Department -[CONTAINS]-&gt; :Team</code></li> <li>Multi-Tenant Systems: Separate graphs per tenant with cross-tenant analytics</li> </ul>"},{"location":"property_graph_model/#architecture","title":"Architecture","text":""},{"location":"property_graph_model/#key-schema-design","title":"Key Schema Design","text":"<pre><code># Nodes (with labels)\nnode:&lt;graph_id&gt;:&lt;pk&gt; -&gt; BaseEntity(id, name, _labels, ...)\n\n# Edges (with types)\nedge:&lt;graph_id&gt;:&lt;edge_id&gt; -&gt; BaseEntity(id, _from, _to, _type, ...)\n\n# Label Index (for fast label-based queries)\nlabel:&lt;graph_id&gt;:&lt;label&gt;:&lt;pk&gt; -&gt; (empty)\n\n# Type Index (for fast type-based queries)\ntype:&lt;graph_id&gt;:&lt;type&gt;:&lt;edge_id&gt; -&gt; (empty)\n\n# Graph Adjacency Indices (federated)\ngraph:out:&lt;graph_id&gt;:&lt;from_pk&gt;:&lt;edge_id&gt; -&gt; &lt;to_pk&gt;\ngraph:in:&lt;graph_id&gt;:&lt;to_pk&gt;:&lt;edge_id&gt; -&gt; &lt;from_pk&gt;\n</code></pre> <p>Design Principles: - Graph Isolation: <code>graph_id</code> prefix ensures complete isolation between graphs - Label Multiplicity: Nodes can have 0+ labels (stored as comma-separated string) - Type Singularity: Edges have exactly one type (or none) - Index Efficiency: Separate indices for labels/types enable O(N_label)/O(E_type) queries</p>"},{"location":"property_graph_model/#api-reference","title":"API Reference","text":""},{"location":"property_graph_model/#property-graph-manager","title":"Property Graph Manager","text":"<pre><code>#include \"index/property_graph.h\"\n\nPropertyGraphManager pgm(db);\n</code></pre>"},{"location":"property_graph_model/#node-label-operations","title":"Node Label Operations","text":""},{"location":"property_graph_model/#add-node-with-labels","title":"Add Node with Labels","text":"<pre><code>Status addNode(const BaseEntity&amp; node, std::string_view graph_id = \"default\");\n</code></pre> <p>Parameters: - <code>node</code>: BaseEntity with <code>_labels</code> field (comma-separated string) - <code>graph_id</code>: Graph identifier (default: \"default\")</p> <p>Returns: Status (ok/error)</p> <p>Example:</p> <pre><code>BaseEntity alice(\"alice\");\nalice.setField(\"id\", \"alice\");\nalice.setField(\"name\", \"Alice Smith\");\nalice.setField(\"age\", 30);\nalice.setField(\"_labels\", \"Person,Employee,Manager\");\n\nauto st = pgm.addNode(alice, \"corporate\");\n// Creates 3 label index entries:\n// - label:corporate:Person:alice\n// - label:corporate:Employee:alice\n// - label:corporate:Manager:alice\n</code></pre>"},{"location":"property_graph_model/#add-label-to-existing-node","title":"Add Label to Existing Node","text":"<pre><code>Status addNodeLabel(std::string_view pk, std::string_view label, \n                    std::string_view graph_id = \"default\");\n</code></pre> <p>Example:</p> <pre><code>auto st = pgm.addNodeLabel(\"alice\", \"Director\", \"corporate\");\n// Updates node: _labels = \"Person,Employee,Manager,Director\"\n// Creates index: label:corporate:Director:alice\n</code></pre>"},{"location":"property_graph_model/#remove-label-from-node","title":"Remove Label from Node","text":"<pre><code>Status removeNodeLabel(std::string_view pk, std::string_view label,\n                       std::string_view graph_id = \"default\");\n</code></pre> <p>Example:</p> <pre><code>auto st = pgm.removeNodeLabel(\"alice\", \"Employee\", \"corporate\");\n// Updates node: _labels = \"Person,Manager,Director\"\n// Deletes index: label:corporate:Employee:alice\n</code></pre>"},{"location":"property_graph_model/#query-nodes-by-label","title":"Query Nodes by Label","text":"<pre><code>std::pair&lt;Status, std::vector&lt;std::string&gt;&gt; \ngetNodesByLabel(std::string_view label, std::string_view graph_id = \"default\") const;\n</code></pre> <p>Returns: Vector of primary keys matching label</p> <p>Time Complexity: O(N_label) where N_label = nodes with label</p> <p>Example:</p> <pre><code>auto [st, people] = pgm.getNodesByLabel(\"Person\", \"corporate\");\n// Result: [\"alice\", \"bob\", \"charlie\", ...]\n</code></pre>"},{"location":"property_graph_model/#check-if-node-has-label","title":"Check if Node Has Label","text":"<pre><code>std::pair&lt;Status, bool&gt; \nhasNodeLabel(std::string_view pk, std::string_view label,\n             std::string_view graph_id = \"default\") const;\n</code></pre> <p>Example:</p> <pre><code>auto [st, hasLabel] = pgm.hasNodeLabel(\"alice\", \"Manager\", \"corporate\");\n// Result: true (alice is a Manager)\n</code></pre>"},{"location":"property_graph_model/#relationship-type-operations","title":"Relationship Type Operations","text":""},{"location":"property_graph_model/#add-edge-with-type","title":"Add Edge with Type","text":"<pre><code>Status addEdge(const BaseEntity&amp; edge, std::string_view graph_id = \"default\");\n</code></pre> <p>Parameters: - <code>edge</code>: BaseEntity with <code>_from</code>, <code>_to</code>, <code>_type</code> fields - <code>graph_id</code>: Graph identifier</p> <p>Example:</p> <pre><code>BaseEntity follows(\"follows_1\");\nfollows.setField(\"id\", \"follows_1\");\nfollows.setField(\"_from\", \"alice\");\nfollows.setField(\"_to\", \"bob\");\nfollows.setField(\"_type\", \"FOLLOWS\");\nfollows.setField(\"since\", 2020);\nfollows.setField(\"strength\", 0.8);\n\nauto st = pgm.addEdge(follows, \"social\");\n// Creates indices:\n// - edge:social:follows_1 -&gt; BaseEntity\n// - graph:out:social:alice:follows_1 -&gt; bob\n// - graph:in:social:bob:follows_1 -&gt; alice\n// - type:social:FOLLOWS:follows_1 -&gt; (empty)\n</code></pre>"},{"location":"property_graph_model/#query-edges-by-type","title":"Query Edges by Type","text":"<pre><code>struct EdgeInfo {\n    std::string edgeId;\n    std::string fromPk;\n    std::string toPk;\n    std::string type;\n    std::string graph_id;\n};\n\nstd::pair&lt;Status, std::vector&lt;EdgeInfo&gt;&gt;\ngetEdgesByType(std::string_view type, std::string_view graph_id = \"default\") const;\n</code></pre> <p>Returns: All edges with specified type</p> <p>Time Complexity: O(E_type) where E_type = edges with type</p> <p>Example:</p> <pre><code>auto [st, followsEdges] = pgm.getEdgesByType(\"FOLLOWS\", \"social\");\n// Result: [\n//   {edgeId: \"follows_1\", fromPk: \"alice\", toPk: \"bob\", type: \"FOLLOWS\"},\n//   {edgeId: \"follows_2\", fromPk: \"bob\", toPk: \"charlie\", type: \"FOLLOWS\"},\n//   ...\n// ]\n</code></pre>"},{"location":"property_graph_model/#query-typed-outgoing-edges-from-node","title":"Query Typed Outgoing Edges from Node","text":"<pre><code>std::pair&lt;Status, std::vector&lt;EdgeInfo&gt;&gt;\ngetTypedOutEdges(std::string_view fromPk, std::string_view type,\n                 std::string_view graph_id = \"default\") const;\n</code></pre> <p>Returns: Outgoing edges from node with specified type</p> <p>Time Complexity: O(d_type) where d_type = out-degree for type</p> <p>Example:</p> <pre><code>auto [st, aliceFollows] = pgm.getTypedOutEdges(\"alice\", \"FOLLOWS\", \"social\");\n// Result: All FOLLOWS edges originating from alice\n</code></pre>"},{"location":"property_graph_model/#multi-graph-federation","title":"Multi-Graph Federation","text":""},{"location":"property_graph_model/#list-all-graphs","title":"List All Graphs","text":"<pre><code>std::pair&lt;Status, std::vector&lt;std::string&gt;&gt; listGraphs() const;\n</code></pre> <p>Example:</p> <pre><code>auto [st, graphs] = pgm.listGraphs();\n// Result: [\"default\", \"social\", \"corporate\", \"knowledge\"]\n</code></pre>"},{"location":"property_graph_model/#get-graph-statistics","title":"Get Graph Statistics","text":"<pre><code>struct GraphStats {\n    std::string graph_id;\n    size_t node_count;\n    size_t edge_count;\n    size_t label_count;\n    size_t type_count;\n};\n\nstd::pair&lt;Status, GraphStats&gt; getGraphStats(std::string_view graph_id) const;\n</code></pre> <p>Example:</p> <pre><code>auto [st, stats] = pgm.getGraphStats(\"social\");\n// Result: {\n//   graph_id: \"social\",\n//   node_count: 1500,\n//   edge_count: 8200,\n//   label_count: 5,  // Person, Post, Comment, Tag, Group\n//   type_count: 7    // FOLLOWS, LIKES, COMMENTS, TAGGED, MEMBER_OF, ...\n// }\n</code></pre>"},{"location":"property_graph_model/#federated-pattern-matching","title":"Federated Pattern Matching","text":"<pre><code>struct FederationPattern {\n    std::string graph_id;\n    std::string label_or_type;  // Node label or edge type\n    std::string pattern_type;   // \"node\" or \"edge\"\n};\n\nstruct FederationResult {\n    std::vector&lt;NodeInfo&gt; nodes;\n    std::vector&lt;EdgeInfo&gt; edges;\n};\n\nstd::pair&lt;Status, FederationResult&gt;\nfederatedQuery(const std::vector&lt;FederationPattern&gt;&amp; patterns) const;\n</code></pre> <p>Example:</p> <pre><code>// Find all Person nodes in social graph and Employee nodes in corporate graph\n// Plus all FOLLOWS edges in social and REPORTS_TO edges in corporate\nstd::vector&lt;PropertyGraphManager::FederationPattern&gt; patterns = {\n    {\"social\", \"Person\", \"node\"},\n    {\"corporate\", \"Employee\", \"node\"},\n    {\"social\", \"FOLLOWS\", \"edge\"},\n    {\"corporate\", \"REPORTS_TO\", \"edge\"}\n};\n\nauto [st, result] = pgm.federatedQuery(patterns);\n// Result: {\n//   nodes: [NodeInfo{pk: \"alice\", labels: [\"Person\"], graph_id: \"social\"}, ...],\n//   edges: [EdgeInfo{edgeId: \"follows_1\", type: \"FOLLOWS\", ...}, ...]\n// }\n</code></pre>"},{"location":"property_graph_model/#batch-operations","title":"Batch Operations","text":""},{"location":"property_graph_model/#add-multiple-nodes-atomic","title":"Add Multiple Nodes (Atomic)","text":"<pre><code>Status addNodesBatch(const std::vector&lt;BaseEntity&gt;&amp; nodes,\n                     std::string_view graph_id = \"default\");\n</code></pre> <p>Example:</p> <pre><code>std::vector&lt;BaseEntity&gt; people;\nfor (int i = 0; i &lt; 1000; ++i) {\n    BaseEntity person(\"person_\" + std::to_string(i));\n    person.setField(\"id\", \"person_\" + std::to_string(i));\n    person.setField(\"_labels\", \"Person\");\n    people.push_back(person);\n}\n\nauto st = pgm.addNodesBatch(people, \"social\");\n// Atomic: All 1000 nodes + label indices added in one transaction\n</code></pre>"},{"location":"property_graph_model/#add-multiple-edges-atomic","title":"Add Multiple Edges (Atomic)","text":"<pre><code>Status addEdgesBatch(const std::vector&lt;BaseEntity&gt;&amp; edges,\n                     std::string_view graph_id = \"default\");\n</code></pre> <p>Example:</p> <pre><code>std::vector&lt;BaseEntity&gt; relationships;\nfor (int i = 0; i &lt; 100; ++i) {\n    BaseEntity follows(\"follows_\" + std::to_string(i));\n    follows.setField(\"id\", \"follows_\" + std::to_string(i));\n    follows.setField(\"_from\", \"person_\" + std::to_string(i));\n    follows.setField(\"_to\", \"person_\" + std::to_string(i + 1));\n    follows.setField(\"_type\", \"FOLLOWS\");\n    relationships.push_back(follows);\n}\n\nauto st = pgm.addEdgesBatch(relationships, \"social\");\n// Atomic: All 100 edges + type/adjacency indices added in one transaction\n</code></pre>"},{"location":"property_graph_model/#usage-examples","title":"Usage Examples","text":""},{"location":"property_graph_model/#example-1-social-network-graph","title":"Example 1: Social Network Graph","text":"<pre><code>PropertyGraphManager pgm(db);\n\n// Create Person nodes\nBaseEntity alice(\"alice\");\nalice.setField(\"id\", \"alice\");\nalice.setField(\"name\", \"Alice\");\nalice.setField(\"_labels\", \"Person,Influencer\");\npgm.addNode(alice, \"social\");\n\nBaseEntity bob(\"bob\");\nbob.setField(\"id\", \"bob\");\nbob.setField(\"name\", \"Bob\");\nbob.setField(\"_labels\", \"Person\");\npgm.addNode(bob, \"social\");\n\n// Create typed relationships\nBaseEntity follows(\"follows_1\");\nfollows.setField(\"id\", \"follows_1\");\nfollows.setField(\"_from\", \"alice\");\nfollows.setField(\"_to\", \"bob\");\nfollows.setField(\"_type\", \"FOLLOWS\");\nfollows.setField(\"since\", 2020);\npgm.addEdge(follows, \"social\");\n\nBaseEntity likes(\"likes_1\");\nlikes.setField(\"id\", \"likes_1\");\nlikes.setField(\"_from\", \"bob\");\nlikes.setField(\"_to\", \"alice\");\nlikes.setField(\"_type\", \"LIKES\");\npgm.addEdge(likes, \"social\");\n\n// Query: Find all Influencers\nauto [st1, influencers] = pgm.getNodesByLabel(\"Influencer\", \"social\");\n// Result: [\"alice\"]\n\n// Query: Find all FOLLOWS relationships\nauto [st2, followsEdges] = pgm.getEdgesByType(\"FOLLOWS\", \"social\");\n// Result: [{edgeId: \"follows_1\", fromPk: \"alice\", toPk: \"bob\", ...}]\n\n// Query: Who does alice follow?\nauto [st3, aliceFollows] = pgm.getTypedOutEdges(\"alice\", \"FOLLOWS\", \"social\");\n// Result: [{toPk: \"bob\", ...}]\n</code></pre>"},{"location":"property_graph_model/#example-2-enterprise-org-chart","title":"Example 2: Enterprise Org Chart","text":"<pre><code>// Corporate graph with Employee-Manager hierarchy\nBaseEntity emp1(\"emp1\");\nemp1.setField(\"id\", \"emp1\");\nemp1.setField(\"name\", \"John Doe\");\nemp1.setField(\"_labels\", \"Employee,Developer\");\npgm.addNode(emp1, \"corporate\");\n\nBaseEntity emp2(\"emp2\");\nemp2.setField(\"id\", \"emp2\");\nemp2.setField(\"name\", \"Jane Smith\");\nemp2.setField(\"_labels\", \"Employee,Manager\");\npgm.addNode(emp2, \"corporate\");\n\nBaseEntity reports(\"reports_1\");\nreports.setField(\"id\", \"reports_1\");\nreports.setField(\"_from\", \"emp1\");\nreports.setField(\"_to\", \"emp2\");\nreports.setField(\"_type\", \"REPORTS_TO\");\npgm.addEdge(reports, \"corporate\");\n\n// Query: Find all Managers\nauto [st, managers] = pgm.getNodesByLabel(\"Manager\", \"corporate\");\n// Result: [\"emp2\"]\n\n// Query: Find reporting structure\nauto [st2, reportingEdges] = pgm.getEdgesByType(\"REPORTS_TO\", \"corporate\");\n// Result: [{fromPk: \"emp1\", toPk: \"emp2\", type: \"REPORTS_TO\"}]\n</code></pre>"},{"location":"property_graph_model/#example-3-cross-graph-federation","title":"Example 3: Cross-Graph Federation","text":"<pre><code>// Setup social graph\nBaseEntity alice_social(\"alice\");\nalice_social.setField(\"id\", \"alice\");\nalice_social.setField(\"_labels\", \"Person\");\npgm.addNode(alice_social, \"social\");\n\n// Setup corporate graph\nBaseEntity alice_corp(\"alice\");\nalice_corp.setField(\"id\", \"alice\");\nalice_corp.setField(\"_labels\", \"Employee\");\npgm.addNode(alice_corp, \"corporate\");\n\n// Federated query: Find Person in social AND Employee in corporate\nstd::vector&lt;PropertyGraphManager::FederationPattern&gt; patterns = {\n    {\"social\", \"Person\", \"node\"},\n    {\"corporate\", \"Employee\", \"node\"}\n};\n\nauto [st, result] = pgm.federatedQuery(patterns);\n// Result combines data from both graphs:\n// nodes: [\n//   {pk: \"alice\", labels: [\"Person\"], graph_id: \"social\"},\n//   {pk: \"alice\", labels: [\"Employee\"], graph_id: \"corporate\"}\n// ]\n</code></pre>"},{"location":"property_graph_model/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"property_graph_model/#label-queries","title":"Label Queries","text":"<ul> <li>Time Complexity: O(N_label) where N_label = nodes with label</li> <li>Space Complexity: O(N_label \u00d7 L) where L = avg labels per node</li> <li>Index Structure: Prefix scan on <code>label:&lt;graph_id&gt;:&lt;label&gt;:*</code></li> </ul> <p>Optimization: - Labels stored as comma-separated string (trade-off: compact vs. array parsing) - Label index enables fast <code>getNodesByLabel()</code> queries - Multi-label nodes create multiple index entries (denormalized)</p>"},{"location":"property_graph_model/#type-queries","title":"Type Queries","text":"<ul> <li>Time Complexity: O(E_type) where E_type = edges with type</li> <li>Space Complexity: O(E_type)</li> <li>Index Structure: Prefix scan on <code>type:&lt;graph_id&gt;:&lt;type&gt;:*</code></li> </ul> <p>Optimization: - Type index enables fast <code>getEdgesByType()</code> queries - Typed traversal filters edges client-side (TODO: server-side filtering)</p>"},{"location":"property_graph_model/#multi-graph-operations","title":"Multi-Graph Operations","text":"<ul> <li>Graph Isolation: O(1) via <code>graph_id</code> prefix</li> <li>List Graphs: O(N) where N = total nodes (full scan to extract graph_ids)</li> <li>Graph Stats: O(N + E + L + T) for counts (prefix scans)</li> <li>Federation: O(P \u00d7 (N_p + E_p)) where P = patterns, N_p/E_p = matches per pattern</li> </ul> <p>Optimization Opportunities: - Maintain graph metadata index (graph registry) - Cache graph stats in memory - Parallel federation queries (concurrent pattern matching)</p>"},{"location":"property_graph_model/#cypher-like-query-examples","title":"Cypher-Like Query Examples","text":"<p>While Themis doesn't support Cypher syntax directly, here's how to express common patterns:</p>"},{"location":"property_graph_model/#pattern-match-pperson-return-p","title":"Pattern: <code>MATCH (p:Person) RETURN p</code>","text":"<pre><code>auto [st, people] = pgm.getNodesByLabel(\"Person\");\nfor (const auto&amp; pk : people) {\n    // Load full node entity if needed\n    std::string nodeKey = \"node:default:\" + pk;\n    auto blob = db.get(nodeKey);\n    BaseEntity person = BaseEntity::deserialize(pk, *blob);\n    // Use person data...\n}\n</code></pre>"},{"location":"property_graph_model/#pattern-match-rfollows-return-r","title":"Pattern: <code>MATCH ()-[r:FOLLOWS]-&gt;() RETURN r</code>","text":"<pre><code>auto [st, followsEdges] = pgm.getEdgesByType(\"FOLLOWS\");\nfor (const auto&amp; edge : followsEdges) {\n    // edge.fromPk, edge.toPk, edge.edgeId available\n}\n</code></pre>"},{"location":"property_graph_model/#pattern-match-aperson-rfollows-bperson-return-a-r-b","title":"Pattern: <code>MATCH (a:Person)-[r:FOLLOWS]-&gt;(b:Person) RETURN a, r, b</code>","text":"<pre><code>auto [st1, people] = pgm.getNodesByLabel(\"Person\");\nauto [st2, followsEdges] = pgm.getEdgesByType(\"FOLLOWS\");\n\n// Filter edges where both endpoints are Person\nfor (const auto&amp; edge : followsEdges) {\n    bool fromIsPerson = std::find(people.begin(), people.end(), edge.fromPk) != people.end();\n    bool toIsPerson = std::find(people.begin(), people.end(), edge.toPk) != people.end();\n\n    if (fromIsPerson &amp;&amp; toIsPerson) {\n        // Matching pattern: Person -[FOLLOWS]-&gt; Person\n    }\n}\n</code></pre>"},{"location":"property_graph_model/#pattern-match-a-follows-b-follows-c-return-a-c","title":"Pattern: <code>MATCH (a)-[:FOLLOWS]-&gt;(b)-[:FOLLOWS]-&gt;(c) RETURN a, c</code>","text":"<pre><code>// 2-hop traversal with type filtering\nauto [st, edges] = pgm.getTypedOutEdges(\"alice\", \"FOLLOWS\");\nfor (const auto&amp; edge1 : edges) {\n    std::string intermediate = edge1.toPk;\n    auto [st2, edges2] = pgm.getTypedOutEdges(intermediate, \"FOLLOWS\");\n    for (const auto&amp; edge2 : edges2) {\n        // alice -&gt; intermediate -&gt; edge2.toPk (2-hop path)\n    }\n}\n</code></pre>"},{"location":"property_graph_model/#migration-guide","title":"Migration Guide","text":""},{"location":"property_graph_model/#from-simple-graph-to-property-graph","title":"From Simple Graph to Property Graph","text":"<p>Before (Simple Graph):</p> <pre><code>GraphIndexManager graph(db);\n\nBaseEntity edge(\"e1\");\nedge.setField(\"_from\", \"alice\");\nedge.setField(\"_to\", \"bob\");\ngraph.addEdge(edge);\n\nauto [st, neighbors] = graph.outNeighbors(\"alice\");\n</code></pre> <p>After (Property Graph):</p> <pre><code>PropertyGraphManager pgm(db);\n\n// Add nodes with labels\nBaseEntity alice(\"alice\");\nalice.setField(\"id\", \"alice\");\nalice.setField(\"_labels\", \"Person\");\npgm.addNode(alice);\n\nBaseEntity bob(\"bob\");\nbob.setField(\"id\", \"bob\");\nbob.setField(\"_labels\", \"Person\");\npgm.addNode(bob);\n\n// Add edge with type\nBaseEntity edge(\"e1\");\nedge.setField(\"id\", \"e1\");\nedge.setField(\"_from\", \"alice\");\nedge.setField(\"_to\", \"bob\");\nedge.setField(\"_type\", \"FOLLOWS\");\npgm.addEdge(edge);\n\n// Query by label\nauto [st, people] = pgm.getNodesByLabel(\"Person\");\n\n// Query by type\nauto [st2, followsEdges] = pgm.getEdgesByType(\"FOLLOWS\");\n</code></pre> <p>Key Changes: 1. Nodes require explicit <code>addNode()</code> call (not just edges) 2. Nodes can have <code>_labels</code> field (comma-separated) 3. Edges can have <code>_type</code> field 4. New query methods: <code>getNodesByLabel()</code>, <code>getEdgesByType()</code> 5. Multi-graph support via <code>graph_id</code> parameter</p>"},{"location":"property_graph_model/#integration-with-existing-features","title":"Integration with Existing Features","text":""},{"location":"property_graph_model/#works-with-temporal-graphs","title":"Works With Temporal Graphs","text":"<pre><code>// Temporal edge with type\nBaseEntity edge(\"e1\");\nedge.setField(\"id\", \"e1\");\nedge.setField(\"_from\", \"alice\");\nedge.setField(\"_to\", \"bob\");\nedge.setField(\"_type\", \"FOLLOWS\");\nedge.setField(\"valid_from\", 1609459200000);  // 2021-01-01\nedge.setField(\"valid_to\", 1640995200000);    // 2022-01-01\npgm.addEdge(edge);\n\n// Query: FOLLOWS edges active in 2021\nauto [st, followsEdges] = pgm.getEdgesByType(\"FOLLOWS\");\n// Then filter by valid_from/valid_to (client-side)\n\n// TODO: Combine with getEdgesInTimeRange() for server-side filtering\n</code></pre>"},{"location":"property_graph_model/#works-with-recursive-path-queries","title":"Works With Recursive Path Queries","text":"<pre><code>// Recursive query with type filtering\nRecursivePathQuery rpq;\nrpq.start_node = \"alice\";\nrpq.end_node = \"charlie\";\nrpq.max_depth = 3;\n// Then filter path edges by type using getEdgesByType()\n\n// TODO: Add type parameter to executeRecursivePathQuery()\n</code></pre>"},{"location":"property_graph_model/#known-limitations","title":"Known Limitations","text":"<ol> <li>Labels as String: Labels stored as comma-separated string (not array)</li> <li>Workaround: Parse string manually or extend BaseEntity</li> <li>No Server-Side Type Filtering in Traversal: <code>getTypedOutEdges()</code> loads all edges then filters</li> <li>Future: Add type-aware BFS/Dijkstra</li> <li>No Property Constraints: Cannot enforce label/type schemas</li> <li>Future: Add schema validation</li> <li>Federation is Simplified: No complex joins (only union of patterns)</li> <li>Future: Add join operators (nested loop, hash join)</li> <li>No Cypher Parser: Manual API calls required</li> <li>Future: Cypher-to-API translator</li> </ol>"},{"location":"property_graph_model/#future-enhancements","title":"Future Enhancements","text":""},{"location":"property_graph_model/#1-array-based-labels","title":"1. Array-Based Labels","text":"<p>Problem: Comma-separated string requires parsing Solution: Extend BaseEntity to support <code>std::vector&lt;std::string&gt;</code></p> <pre><code>alice.setField(\"_labels\", std::vector&lt;std::string&gt;{\"Person\", \"Employee\"});\n</code></pre>"},{"location":"property_graph_model/#2-type-aware-graph-traversal","title":"2. Type-Aware Graph Traversal","text":"<p>Problem: BFS/Dijkstra don't filter by type Solution: Add type parameter to traversal algorithms</p> <pre><code>auto [st, path] = graph.dijkstra(\"alice\", \"bob\", \"FOLLOWS\");\n// Only traverse FOLLOWS edges\n</code></pre>"},{"location":"property_graph_model/#3-schema-validation","title":"3. Schema Validation","text":"<p>Problem: No enforcement of valid labels/types Solution: Add schema definition and validation</p> <pre><code>PropertyGraphSchema schema;\nschema.defineNodeLabel(\"Person\", {{\"name\", \"string\"}, {\"age\", \"int\"}});\nschema.defineEdgeType(\"FOLLOWS\", {{\"since\", \"int\"}});\npgm.setSchema(schema);\n\n// Validation on insert\npgm.addNode(invalidNode);  // Error: Missing required field 'name'\n</code></pre>"},{"location":"property_graph_model/#4-complex-federated-joins","title":"4. Complex Federated Joins","text":"<p>Problem: Only union of patterns supported Solution: Add join operators</p> <pre><code>FederatedJoinQuery fjq;\nfjq.addPattern(\"social\", \"Person\", \"node\");\nfjq.addPattern(\"corporate\", \"Employee\", \"node\");\nfjq.setJoinKey(\"id\");  // Join on node primary key\nauto [st, result] = pgm.federatedJoin(fjq);\n// Result: Person nodes that are also Employees\n</code></pre>"},{"location":"property_graph_model/#5-cypher-query-language","title":"5. Cypher Query Language","text":"<p>Problem: Manual API calls verbose Solution: Cypher-to-API translator</p> <pre><code>std::string cypher = \"MATCH (p:Person)-[r:FOLLOWS]-&gt;(f:Person) RETURN p, f\";\nauto [st, result] = pgm.executeCypher(cypher, \"social\");\n</code></pre>"},{"location":"property_graph_model/#changelog","title":"Changelog","text":"<ul> <li>2025-01-15: Initial implementation</li> <li>Added <code>PropertyGraphManager</code> class</li> <li>Implemented node labels (<code>_labels</code> field)</li> <li>Implemented relationship types (<code>_type</code> field)</li> <li>Added multi-graph federation (<code>graph_id</code> prefix)</li> <li>Created label/type indices</li> <li>Implemented federated pattern matching</li> <li>Added batch operations</li> <li>Created 13 comprehensive tests (all passing)</li> <li>Documentation created</li> </ul>"},{"location":"property_graph_model/#see-also","title":"See Also","text":"<ul> <li>Graph Index - Base graph adjacency index</li> <li>Temporal Graphs - Time-window queries</li> <li>Recursive Path Queries - Multi-hop traversal</li> <li>Base Entity - Flexible schema-less storage</li> </ul>"},{"location":"publishing/","title":"Publikation &amp; Ablage","text":"<p>Diese Seite beschreibt den Build der Dokumentation, die Ver\u00f6ffentlichung auf GitHub Pages und einen optionalen PDF-Export f\u00fcr Offline-Nutzung.</p>"},{"location":"publishing/#1-lokaler-docs-build","title":"1) Lokaler Docs-Build","text":"<p>Voraussetzungen: Python 3.x, <code>pip</code>, <code>mkdocs</code>, <code>mkdocs-material</code>.</p> <pre><code># Optional: Virtuelle Umgebung (empfohlen)\n# py -3 -m venv .venv ; .\\.venv\\Scripts\\Activate.ps1\n\npip install --upgrade pip\npip install mkdocs mkdocs-material\n\n# Aus dem Repo-Root\nmkdocs serve\n# Browser: http://127.0.0.1:8000\n\n# Produktion (statisches Site-Verzeichnis \"site/\")\nmkdocs build\n</code></pre>"},{"location":"publishing/#2-github-pages-deployment-ci","title":"2) GitHub Pages Deployment (CI)","text":"<p>Das Repo enth\u00e4lt einen Workflow unter <code>.github/workflows/docs.yml</code>, der bei Push auf <code>main</code> die Seite baut und per GitHub Pages ver\u00f6ffentlicht.</p> <ul> <li>Artefakt: <code>site/</code></li> <li>Ver\u00f6ffentlichung: <code>https://&lt;owner&gt;.github.io/&lt;repo&gt;/</code> (Repository Settings \u2192 Pages \u2192 Build &amp; Deployment: GitHub Actions)</li> </ul> <p>Falls dein Projektname/Org abweicht, passe optional <code>site_url</code> in <code>mkdocs.yml</code>.</p>"},{"location":"publishing/#3-pdf-export-optional","title":"3) PDF-Export (optional)","text":"<p>F\u00fcr einen einfachen PDF-Export gibt es mehrere Wege; zwei pragmatische Varianten:</p> <ul> <li>Browser-basiert: <code>mkdocs build</code> ausf\u00fchren und die Startseite <code>site/index.html</code> im Browser als PDF drucken (Hintergrundgrafiken aktivieren).</li> <li>Plugin-basiert: <code>mkdocs-with-pdf</code> oder <code>mkdocs-pdf-export-plugin</code> nutzen.</li> </ul> <p>Beispiel (lokal, ohne CI-Verpflichtung):</p> <pre><code>pip install mkdocs-with-pdf\n# Tempor\u00e4r im Build aufrufen\nmkdocs build --use-directory-urls\n# Danach PDF-Generierung (abh\u00e4ngig vom Plugin, siehe Plugin-Doku)\n</code></pre> <p>Hinweis: PDF-Plugins ben\u00f6tigen oft zus\u00e4tzliche Systembibliotheken (WeasyPrint/wkhtmltopdf). F\u00fcr Repro in CI lieber separat halten.</p>"},{"location":"publishing/#4-artefakt-ablage","title":"4) Artefakt-Ablage","text":"<ul> <li>Site-Build: <code>site/</code>-Ordner (statisch, kann als Release-Asset oder Pages-Artefakt genutzt werden)</li> <li>Optional: ZIP der Doku f\u00fcr Offline-Verteilung</li> </ul> <pre><code>Compress-Archive -Path .\\site\\* -DestinationPath .\\site.zip -Force\n</code></pre>"},{"location":"publishing/#5-troubleshooting","title":"5) Troubleshooting","text":"<ul> <li>404 in Navigation: Pr\u00fcfe <code>mkdocs.yml</code>-Pfade und ob Dateien existieren</li> <li>Lokaler Build schl\u00e4gt fehl: <code>mkdocs build --verbose</code> und auf fehlende Plugins achten</li> <li>Pages zeigt alte Version: Warte auf Actions-Finish, ggf. Browser-Cache leeren</li> </ul>"},{"location":"quality_assurance/","title":"Qualit\u00e4tssicherung (QA)","text":"<p>Diese Seite beschreibt die Teststrategie, Werkzeuge und Best Practices zur Sicherstellung der Softwarequalit\u00e4t in ThemisDB: Unit/Integration/E2E-Tests, CI/CD, Code Coverage, statische Analysen und Performance-Regressionstests.</p>"},{"location":"quality_assurance/#testpyramide-und-abdeckung","title":"Testpyramide und Abdeckung","text":"<ul> <li>Unit-Tests: Logiknah, schnell, unabh\u00e4ngig von I/O (z. B. Parser, Serializer, Hilfsfunktionen)</li> <li>Integrationstests: Zusammenspiel von Storage/Indexes/Query (z. B. <code>tests/test_*</code>)</li> <li>E2E-/API-Tests: HTTP-/OpenAPI-Endpunkte, CDC/SSE, Fehlerpfade, Berechtigungen</li> <li>Performance-Benchmarks: Google Benchmark (stabil, reproduzierbar), keine CI-Gates, aber Trends \u00fcberwachen</li> </ul> <p>Zielabdeckung: 70\u201380% auf kritischen Kernpfaden (Parser, Index, Query Engine, Storage-Wrapper).</p>"},{"location":"quality_assurance/#tests-ausfuhren","title":"Tests ausf\u00fchren","text":"<ul> <li>CTest/Executable (Windows PowerShell Beispiel):</li> </ul> <pre><code># Build (Release empfohlen f\u00fcr realistischere Ausf\u00fchrungszeiten)\ncmake -S . -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build --config Release --parallel\n\n# Tests\nctest --test-dir build --output-on-failure --parallel\n\n# Alternativ: direktes Binary (falls vorhanden)\n.\\build\\Release\\themis_tests.exe\n</code></pre>"},{"location":"quality_assurance/#struktur-und-namenskonventionen","title":"Struktur und Namenskonventionen","text":"<ul> <li>Testdateien in <code>tests/</code> mit Pr\u00e4fix <code>test_*.cpp</code></li> <li>Eine Testdatei pro Komponente/Subsystem</li> <li>Klarer Arrange-Act-Assert-Stil, aussagekr\u00e4ftige Namen, keine versteckten Sleeps/Timing-Hacks</li> </ul>"},{"location":"quality_assurance/#testdaten-strategie","title":"Testdaten-Strategie","text":"<ul> <li>Deterministische Seeds f\u00fcr Zufallsdaten in Tests und Benchmarks</li> <li>Kleine, repr\u00e4sentative Fixtures; gro\u00dfe Datens\u00e4tze nur in Benchmarks/Loadtests</li> <li>Cleanup von tempor\u00e4ren DB-Pfaden pro Test (z. B. unter <code>data/test_*</code>)</li> </ul>"},{"location":"quality_assurance/#cicd-empfehlungen-github-actions","title":"CI/CD-Empfehlungen (GitHub Actions)","text":"<ul> <li>Pipelines (Beispiele):</li> <li>build-and-test: MSVC (Windows) und Clang/GCC (Linux), Release + Debug</li> <li>static-analysis: clang-tidy, cppcheck (Nur-Warnungen, optional blockend f\u00fcr neue Issues)</li> <li>coverage: lcov/gcovr (Linux), Artefakte/Badges ver\u00f6ffentlichen</li> <li>package: Docker-Image bauen, SBOM generieren (Syft), Signatur (cosign) optional</li> <li>Caching: vcpkg/ccache (Linux) und MSVC Build Cache</li> <li>Artefakte: Testreports (JUnit), Coverage HTML, Binaries (Nightly)</li> </ul>"},{"location":"quality_assurance/#code-coverage","title":"Code Coverage","text":"<ul> <li>Linux: <code>-fprofile-arcs -ftest-coverage</code> bzw. <code>-fprofile-instr-generate -fcoverage-mapping</code></li> <li>Werkzeuge: gcovr/lcov; Ausschl\u00fcsse f\u00fcr generierten Code/3rd-Party</li> <li>Schwellenwerte: z. B. Zeilen \u2265 70%, Funktionen \u2265 75% (nicht hart blockend, aber Trend-basiert)</li> </ul>"},{"location":"quality_assurance/#statische-analysen-linters","title":"Statische Analysen &amp; Linters","text":"<ul> <li>clang-tidy: Modernize-, Performance-, Readability-Checks aktivieren</li> <li>cppcheck: Fehleranf\u00e4llige Muster, MISRA-\u00e4hnliche Regeln wo sinnvoll</li> <li>Formatierung: clang-format mit projektspezifischem Style; Pre-commit Hook empfohlen</li> </ul>"},{"location":"quality_assurance/#performance-regressionen","title":"Performance-Regressionen","text":"<ul> <li>Google Benchmark-Suite regelm\u00e4\u00dfig auf dedizierter Maschine ausf\u00fchren</li> <li>Relevante Filter: CRUD, MVCC, Pagination, Kompression, Vector-Suche</li> <li>Ver\u00e4nderungen dokumentieren (Changelog) und auff\u00e4llige Deltas untersuchen</li> </ul>"},{"location":"quality_assurance/#testbarkeit-architektur","title":"Testbarkeit &amp; Architektur","text":"<ul> <li>Abh\u00e4ngigkeiten injizieren (Interfaces), um I/O zu mocken</li> <li>Pure Functions bevorzugen, deterministische Uhrzeit/Zufall abstrahieren</li> <li>Kleine, fokussierte Klassen/Methoden, klare Verantwortlichkeiten</li> </ul>"},{"location":"quality_assurance/#review-checkliste-auszug","title":"Review-Checkliste (Auszug)","text":"<ul> <li>Korrektheit: Tests vorhanden (Happy Path + 1\u20132 Edge Cases)</li> <li>Robustheit: Fehlerpfade, Timeouts, Null/Empty-Handling</li> <li>Performance: Hot Paths, Allokationen, unn\u00f6tige Kopien, Paging/Batching</li> <li>Sicherheit: Input-Validierung, Logging von Secrets vermeiden</li> <li>Docs: \u00d6ffentliche APIs und Verhalten dokumentiert, Changelog aktualisiert</li> </ul>"},{"location":"quality_assurance/#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ul> <li>CI-Workflows hinzuf\u00fcgen (GitHub Actions) mit Build+Test, static-analysis, Coverage</li> <li>Abdeckungsl\u00fccken identifizieren (Reports) und kritische Bereiche priorisieren</li> <li>Optional: Nightly Performance-Benchmarks mit Trend-Dashboards</li> </ul>"},{"location":"query_engine_aql/","title":"Query Engine &amp; AQL \u2013 THEMIS","text":"<p>Version: 2.0 Status: Implementiert (MVP) Letzte Aktualisierung: 2. November 2025</p>"},{"location":"query_engine_aql/#uberblick","title":"\u00dcberblick","text":"<p>Das Query Engine &amp; AQL-System von THEMIS besteht aus mehreren Komponenten, die zusammen eine effiziente Ausf\u00fchrung von Multi-Modell-Queries erm\u00f6glichen:</p> <ol> <li>AQL (Advanced Query Language) \u2013 SQL-\u00e4hnliche deklarative Query-Sprache</li> <li>AQL Parser \u2013 Lexer &amp; Parser f\u00fcr AQL \u2192 AST</li> <li>AQL Translator \u2013 AST \u2192 Ausf\u00fchrungspl\u00e4ne (ConjunctiveQuery, JoinQuery, TraversalQuery)</li> <li>Query Optimizer \u2013 Kardinalit\u00e4tssch\u00e4tzung &amp; Index-Auswahl</li> <li>Query Engine \u2013 Ausf\u00fchrung mit Index-/Full-Scan-Support</li> </ol>"},{"location":"query_engine_aql/#1-aql-advanced-query-language","title":"1. AQL \u2013 Advanced Query Language","text":""},{"location":"query_engine_aql/#11-design-prinzipien","title":"1.1 Design-Prinzipien","text":"<ul> <li>\u2705 Einfach: SQL-\u00e4hnliche Syntax (FOR, FILTER, SORT, LIMIT, RETURN)</li> <li>\u2705 M\u00e4chtig: Multi-Modell-Support (Relational, Graph, Vector)</li> <li>\u2705 Optimierbar: Automatische Index-Auswahl via Optimizer</li> <li>\u2705 Erweiterbar: Schrittweise Features (LET, COLLECT, Joins)</li> </ul>"},{"location":"query_engine_aql/#12-grundstruktur","title":"1.2 Grundstruktur","text":"<pre><code>FOR variable IN collection\n  [LET var = expression [, ...]]\n  [FILTER condition]\n  [SORT expression [ASC|DESC] [, ...]]\n  [LIMIT offset, count]\n  [RETURN expression]\n</code></pre> <p>Execution-Reihenfolge: 1. <code>FOR</code> \u2013 Iteration \u00fcber Collection/Index 2. <code>FILTER</code> \u2013 Pr\u00e4dikat-Evaluation (mit Index-Nutzung) 3. <code>SORT</code> \u2013 Sortierung (mit Range-Index wenn m\u00f6glich) 4. <code>LIMIT</code> \u2013 Pagination/Offset 5. <code>RETURN</code> \u2013 Projektion</p>"},{"location":"query_engine_aql/#13-query-typen","title":"1.3 Query-Typen","text":"Typ FOR-Klauseln Features Beispiel Relational 1 FILTER, SORT, LIMIT, RETURN <code>FOR u IN users FILTER u.age &gt; 18</code> Join 2+ Multi-FOR, JOIN-Bedingungen <code>FOR u IN users FOR o IN orders FILTER o.user_id == u._key</code> Graph Traversal 1 (speziell) BFS, Depth-Limits, FILTER auf v/e <code>FOR v IN 1..3 OUTBOUND 'user1' GRAPH 'social'</code> Vector Search 1 NEAR(), k-NN <code>FOR doc IN articles NEAR(doc.embedding, @vec, 10)</code> Aggregation 1 COLLECT, AGGREGATE (SUM/AVG/etc.) <code>FOR sale IN sales COLLECT cat = sale.category AGGREGATE total = SUM(sale.amount)</code>"},{"location":"query_engine_aql/#2-aql-parser","title":"2. AQL Parser","text":""},{"location":"query_engine_aql/#21-komponenten","title":"2.1 Komponenten","text":"<pre><code>class AQLParser {\npublic:\n    struct ParseResult {\n        bool success;\n        std::string error_message;\n        std::shared_ptr&lt;Query&gt; ast;  // Root AST Node\n    };\n\n    ParseResult parse(std::string_view query);\n};\n</code></pre>"},{"location":"query_engine_aql/#22-ast-struktur","title":"2.2 AST-Struktur","text":"<p>Node-Typen:</p> <pre><code>enum class ASTNodeType {\n    // Query Nodes\n    Query,              // Root\n    ForNode,            // FOR variable IN collection\n    FilterNode,         // FILTER condition\n    SortNode,           // SORT expr [ASC|DESC]\n    LimitNode,          // LIMIT offset, count\n    ReturnNode,         // RETURN expression\n    LetNode,            // LET variable = expression\n    CollectNode,        // COLLECT ... AGGREGATE ...\n\n    // Expressions\n    BinaryOp,           // ==, !=, &gt;, &lt;, AND, OR, +, -, *, /\n    UnaryOp,            // NOT, -\n    FunctionCall,       // CONCAT, SUM, etc.\n    FieldAccess,        // doc.field\n    Literal,            // \"string\", 123, true, null\n    Variable,           // doc, user\n    ArrayLiteral,       // [1, 2, 3]\n    ObjectConstruct     // {name: doc.name, age: doc.age}\n};\n</code></pre> <p>Beispiel-AST:</p> <pre><code>FOR u IN users \nFILTER u.age &gt; 18 AND u.city == \"Berlin\"\nRETURN u.name\n</code></pre> <p>\u2192 AST:</p> <pre><code>{\n  \"type\": \"Query\",\n  \"children\": [\n    {\n      \"type\": \"ForNode\",\n      \"variable\": \"u\",\n      \"collection\": \"users\"\n    },\n    {\n      \"type\": \"FilterNode\",\n      \"condition\": {\n        \"type\": \"BinaryOp\",\n        \"operator\": \"AND\",\n        \"left\": {\n          \"type\": \"BinaryOp\",\n          \"operator\": \"&gt;\",\n          \"left\": {\"type\": \"FieldAccess\", \"variable\": \"u\", \"field\": \"age\"},\n          \"right\": {\"type\": \"Literal\", \"value\": 18}\n        },\n        \"right\": {\n          \"type\": \"BinaryOp\",\n          \"operator\": \"==\",\n          \"left\": {\"type\": \"FieldAccess\", \"variable\": \"u\", \"field\": \"city\"},\n          \"right\": {\"type\": \"Literal\", \"value\": \"Berlin\"}\n        }\n      }\n    },\n    {\n      \"type\": \"ReturnNode\",\n      \"expression\": {\"type\": \"FieldAccess\", \"variable\": \"u\", \"field\": \"name\"}\n    }\n  ]\n}\n</code></pre>"},{"location":"query_engine_aql/#23-operatoren","title":"2.3 Operatoren","text":"<p>Binary Operators:</p> <pre><code>enum class BinaryOperator {\n    // Comparison\n    Eq, Neq, Lt, Lte, Gt, Gte,      // ==, !=, &lt;, &lt;=, &gt;, &gt;=\n\n    // Logical\n    And, Or, Xor,                    // AND, OR, XOR\n\n    // Arithmetic\n    Add, Sub, Mul, Div, Mod,         // +, -, *, /, %\n\n    // Membership\n    In                               // IN\n};\n</code></pre> <p>Unary Operators:</p> <pre><code>enum class UnaryOperator {\n    Not,                // NOT\n    Minus,              // - (unary)\n    Plus                // + (unary)\n};\n</code></pre>"},{"location":"query_engine_aql/#3-aql-translator","title":"3. AQL Translator","text":""},{"location":"query_engine_aql/#31-ubersetzungsstrategien","title":"3.1 \u00dcbersetzungsstrategien","text":"<p>Der Translator wandelt AST in ausf\u00fchrbare Query-Pl\u00e4ne um:</p> <pre><code>class AQLTranslator {\npublic:\n    struct TranslationResult {\n        bool success;\n        std::string error_message;\n\n        // Single-FOR: Relational Query\n        ConjunctiveQuery query;\n\n        // Multi-FOR: Join Query\n        std::optional&lt;JoinQuery&gt; join;\n\n        // Graph: Traversal Query\n        std::optional&lt;TraversalQuery&gt; traversal;\n    };\n\n    TranslationResult translate(std::shared_ptr&lt;Query&gt; ast);\n};\n</code></pre>"},{"location":"query_engine_aql/#32-relational-query-translation","title":"3.2 Relational Query Translation","text":"<p>Eingabe:</p> <pre><code>FOR u IN users \nFILTER u.age &gt; 18 AND u.city == \"Berlin\"\nSORT u.created_at DESC\nLIMIT 10\nRETURN u\n</code></pre> <p>Ausgabe (ConjunctiveQuery):</p> <pre><code>ConjunctiveQuery {\n    table: \"users\",\n    predicates: [\n        {column: \"city\", op: Eq, value: \"Berlin\"}\n    ],\n    rangePredicates: [\n        {column: \"age\", lower: \"18\", includeLower: false, op: Gt}\n    ],\n    orderBy: {\n        column: \"created_at\",\n        desc: true,\n        limit: 10\n    }\n}\n</code></pre>"},{"location":"query_engine_aql/#33-join-query-translation","title":"3.3 Join Query Translation","text":"<p>Eingabe:</p> <pre><code>FOR u IN users\nFOR o IN orders\nFILTER o.user_id == u._key\nRETURN {user: u.name, order: o.id}\n</code></pre> <p>Ausgabe (JoinQuery):</p> <pre><code>JoinQuery {\n    for_nodes: [\n        {variable: \"u\", collection: \"users\"},\n        {variable: \"o\", collection: \"orders\"}\n    ],\n    filters: [\n        {op: Eq, left: \"o.user_id\", right: \"u._key\"}  // Join-Bedingung\n    ],\n    return_node: ObjectConstruct{...}\n}\n</code></pre>"},{"location":"query_engine_aql/#34-graph-traversal-translation","title":"3.4 Graph Traversal Translation","text":"<p>Eingabe:</p> <pre><code>FOR v, e, p IN 1..3 OUTBOUND 'user1' GRAPH 'social'\nFILTER v.age &gt; 18\nRETURN v\n</code></pre> <p>Ausgabe (TraversalQuery):</p> <pre><code>TraversalQuery {\n    variable: \"v\",\n    minDepth: 1,\n    maxDepth: 3,\n    direction: Outbound,\n    startVertex: \"user1\",\n    graphName: \"social\",\n    filters: [{column: \"age\", op: Gt, value: \"18\"}]\n}\n</code></pre>"},{"location":"query_engine_aql/#4-query-optimizer","title":"4. Query Optimizer","text":""},{"location":"query_engine_aql/#41-kardinalitatsschatzung","title":"4.1 Kardinalit\u00e4tssch\u00e4tzung","text":"<p>Der Optimizer sch\u00e4tzt Selektivit\u00e4ten von Pr\u00e4dikaten und ordnet sie optimal:</p> <pre><code>class QueryOptimizer {\npublic:\n    struct Estimation {\n        PredicateEq pred;\n        size_t estimatedCount;\n        bool capped;  // true wenn &gt;= maxProbe\n    };\n\n    struct Plan {\n        std::vector&lt;PredicateEq&gt; orderedPredicates;  // Sortiert nach Selektivit\u00e4t\n        std::vector&lt;Estimation&gt; details;\n    };\n\n    Plan chooseOrderForAndQuery(const ConjunctiveQuery&amp; q, size_t maxProbe = 1000);\n};\n</code></pre>"},{"location":"query_engine_aql/#42-optimierungs-strategie","title":"4.2 Optimierungs-Strategie","text":"<p>Beispiel:</p> <pre><code>FOR u IN users \nFILTER u.age &gt; 18 AND u.city == \"Berlin\"\n</code></pre> <p>Sch\u00e4tzung: - <code>city == \"Berlin\"</code>: ~100 Treffer (selektiv!) - <code>age &gt; 18</code>: ~5000 Treffer (weniger selektiv)</p> <p>Optimaler Plan: 1. Scan <code>city == \"Berlin\"</code> \u2192 100 Keys 2. F\u00fcr jeden Key: Check <code>age &gt; 18</code> \u2192 ~80 finale Treffer</p> <p>Vorteil: Nur 100 Entity-Loads statt 5000!</p>"},{"location":"query_engine_aql/#43-index-auswahl","title":"4.3 Index-Auswahl","text":"<p>Verf\u00fcgbare Strategien:</p> <pre><code>enum class QueryMode {\n    IndexOptimized,      // Optimizer-gesteuert (Kardinalit\u00e4tssch\u00e4tzung)\n    IndexParallel,       // Parallele Scans + AND-Merge (f\u00fcr kleine Datasets)\n    FullScanFallback,    // Sequential Scan (nur mit allow_full_scan=true)\n    IndexRangeAware      // Range-Index + Sortierung direkt\n};\n</code></pre> <p>Beispiel-Plan (EXPLAIN):</p> <pre><code>{\n  \"plan\": {\n    \"mode\": \"index_optimized\",\n    \"order\": [\n      {\"column\": \"city\", \"value\": \"Berlin\"},\n      {\"column\": \"age\", \"value\": \"18\"}\n    ],\n    \"estimates\": [\n      {\"column\": \"city\", \"value\": \"Berlin\", \"estimatedCount\": 100, \"capped\": false},\n      {\"column\": \"age\", \"value\": \"18\", \"estimatedCount\": 5000, \"capped\": false}\n    ]\n  }\n}\n</code></pre>"},{"location":"query_engine_aql/#5-query-engine","title":"5. Query Engine","text":""},{"location":"query_engine_aql/#51-ausfuhrungs-pipeline","title":"5.1 Ausf\u00fchrungs-Pipeline","text":"<pre><code>class QueryEngine {\npublic:\n    struct Status {\n        bool ok;\n        std::string message;\n    };\n\n    // Relational Query (Single-FOR)\n    std::pair&lt;Status, std::vector&lt;std::string&gt;&gt; \n    executeConjunctiveKeys(const ConjunctiveQuery&amp; q);\n\n    std::pair&lt;Status, std::vector&lt;BaseEntity&gt;&gt; \n    executeConjunctiveEntities(const ConjunctiveQuery&amp; q);\n\n    // Join Query (Multi-FOR)\n    std::pair&lt;Status, std::vector&lt;nlohmann::json&gt;&gt; \n    executeJoin(const JoinQuery&amp; join);\n\n    // Graph Traversal (BFS)\n    std::pair&lt;Status, std::vector&lt;BaseEntity&gt;&gt; \n    executeTraversal(const TraversalQuery&amp; trav);\n};\n</code></pre>"},{"location":"query_engine_aql/#52-relational-execution","title":"5.2 Relational Execution","text":"<p>Schritt-f\u00fcr-Schritt:</p> <ol> <li>Optimizer: Sch\u00e4tze Selektivit\u00e4ten \u2192 Sortiere Pr\u00e4dikate</li> <li>Index-Scan: Starte mit selektivstem Pr\u00e4dikat</li> <li>Filter-Chain: Wende weitere Pr\u00e4dikate an</li> <li>Sort/Limit: Nutze Range-Index wenn m\u00f6glich</li> <li>Return: Projiziere Felder</li> </ol> <p>Code-Flow (vereinfacht):</p> <pre><code>auto [status, keys] = idx.scanKeysEqual(\"users\", \"city\", \"Berlin\");  // 100 Keys\nstd::vector&lt;std::string&gt; filtered;\nfor (const auto&amp; key : keys) {\n    auto entity = loadEntity(key);\n    if (entity.getFieldAsInt(\"age\") &gt; 18) {  // Range-Filter\n        filtered.push_back(key);\n    }\n}\n// Sort/Limit...\n</code></pre>"},{"location":"query_engine_aql/#53-join-execution-nested-loop","title":"5.3 Join Execution (Nested-Loop)","text":"<p>Algorithmus:</p> <pre><code>std::vector&lt;nlohmann::json&gt; results;\nfor (const auto&amp; uKey : getUserKeys()) {\n    auto user = loadEntity(\"users\", uKey);\n    for (const auto&amp; oKey : getOrderKeys()) {\n        auto order = loadEntity(\"orders\", oKey);\n        if (order.getField(\"user_id\") == user.getField(\"_key\")) {  // Join-Bedingung\n            results.push_back({\n                {\"user\", user.getField(\"name\")},\n                {\"order\", order.getField(\"id\")}\n            });\n        }\n    }\n}\n</code></pre> <p>Performance-Hinweise: - \u26a0\ufe0f O(n\u00d7m) Komplexit\u00e4t (teuer bei gro\u00dfen Collections) - \ud83d\udca1 Nutze Indizes auf Join-Spalten (<code>user_id</code>) - \ud83d\udca1 Geplant: Hash-Join f\u00fcr gro\u00dfe Collections</p>"},{"location":"query_engine_aql/#54-graph-traversal-bfs","title":"5.4 Graph Traversal (BFS)","text":"<p>BFS-Algorithmus mit Pruning:</p> <pre><code>std::queue&lt;Node&gt; frontier;\nstd::unordered_set&lt;std::string&gt; visited;\nfrontier.push({startVertex, depth: 0});\n\nwhile (!frontier.empty()) {\n    auto node = frontier.front(); frontier.pop();\n    if (visited.count(node.pk)) continue;\n    visited.insert(node.pk);\n\n    if (node.depth &gt;= minDepth) {\n        auto entity = loadEntity(node.pk);\n        if (evalFilters(entity)) {  // v.age &gt; 18\n            results.push_back(entity);\n        }\n    }\n\n    if (node.depth &lt; maxDepth) {\n        auto neighbors = getNeighbors(node.pk, direction);\n        for (const auto&amp; nb : neighbors) {\n            if (node.depth + 1 == maxDepth) {\n                // Konservatives Pruning am letzten Level\n                auto e = loadEntity(nb.pk);\n                if (!evalFilters(e)) {\n                    pruned_last_level++;\n                    continue;\n                }\n            }\n            frontier.push({nb.pk, node.depth + 1});\n        }\n    }\n}\n</code></pre> <p>Metriken (siehe EXPLAIN): - <code>edges_expanded</code>: Anzahl inspizierter Kanten - <code>pruned_last_level</code>: Durch Filter gedroppt - <code>frontier_processed_per_depth</code>: BFS-Expansion pro Level</p>"},{"location":"query_engine_aql/#6-explain-profile","title":"6. EXPLAIN &amp; PROFILE","text":""},{"location":"query_engine_aql/#61-explain-usage","title":"6.1 EXPLAIN Usage","text":"<p>HTTP Request:</p> <pre><code>POST /query/aql\nContent-Type: application/json\n\n{\n  \"query\": \"FOR u IN users FILTER u.age &gt; 18 AND u.city == 'Berlin' RETURN u\",\n  \"explain\": true\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"query\": \"FOR u IN users FILTER u.age &gt; 18 AND u.city == 'Berlin' RETURN u\",\n  \"ast\": {...},\n  \"plan\": {\n    \"mode\": \"index_optimized\",\n    \"order\": [\n      {\"column\": \"city\", \"value\": \"Berlin\"},\n      {\"column\": \"age\", \"value\": \"18\"}\n    ],\n    \"estimates\": [\n      {\"column\": \"city\", \"value\": \"Berlin\", \"estimatedCount\": 100, \"capped\": false},\n      {\"column\": \"age\", \"value\": \"18\", \"estimatedCount\": 5000, \"capped\": false}\n    ]\n  }\n}\n</code></pre>"},{"location":"query_engine_aql/#62-traversal-metrics","title":"6.2 Traversal Metrics","text":"<p>Graph-Query:</p> <pre><code>FOR v IN 1..3 OUTBOUND 'user1' GRAPH 'social' \nFILTER v.age &gt; 30 \nRETURN v\n</code></pre> <p>Metrics:</p> <pre><code>{\n  \"metrics\": {\n    \"edges_expanded\": 156,\n    \"pruned_last_level\": 23,\n    \"filter_evaluations_total\": 89,\n    \"filter_short_circuits\": 12,\n    \"frontier_processed_per_depth\": {\n      \"0\": 1,\n      \"1\": 5,\n      \"2\": 18,\n      \"3\": 65\n    }\n  }\n}\n</code></pre> <p>Interpretation: - edges_expanded: 156 Kanten inspiziert (BFS-Kosten) - pruned_last_level: 23 Vertices am letzten Level gedroppt (Filter wirkt!) - filter_short_circuits: 12 AND-Short-Circuits (Effizienz)</p>"},{"location":"query_engine_aql/#63-cursor-pagination-metrics","title":"6.3 Cursor Pagination Metrics","text":"<p>Relational Query mit Cursor:</p> <pre><code>{\n  \"query\": \"FOR u IN users SORT u.created_at DESC LIMIT 10 RETURN u\",\n  \"use_cursor\": true\n}\n</code></pre> <p>Plan-Details:</p> <pre><code>{\n  \"plan\": {\n    \"mode\": \"index_rangeaware\",\n    \"cursor\": {\n      \"used\": true,\n      \"cursor_present\": false,\n      \"sort_column\": \"created_at\",\n      \"effective_limit\": 11,\n      \"anchor_set\": false,\n      \"requested_count\": 10\n    }\n  }\n}\n</code></pre> <p>Prometheus Metrics: - <code>vccdb_cursor_anchor_hits_total</code>: Cursor-Anker-Verwendungen - <code>vccdb_range_scan_steps_total</code>: Besuchte Index-Eintr\u00e4ge - <code>vccdb_page_fetch_time_ms_*</code>: Seitenerzeugung-Dauer</p>"},{"location":"query_engine_aql/#7-best-practices","title":"7. Best Practices","text":""},{"location":"query_engine_aql/#71-query-optimierung","title":"7.1 Query-Optimierung","text":"<pre><code>-- \u2705 RICHTIG: Selektive Filter zuerst\nFOR u IN users \nFILTER u.city == \"SmallTown\" AND u.age &gt; 18  -- city sehr selektiv!\nRETURN u\n\n-- \u274c FALSCH: Unselektive Filter zuerst\nFOR u IN users \nFILTER u.age &gt; 18 AND u.city == \"SmallTown\"  -- age wenig selektiv\nRETURN u\n</code></pre>"},{"location":"query_engine_aql/#72-index-nutzung","title":"7.2 Index-Nutzung","text":"<pre><code>-- \u2705 RICHTIG: Index auf age + city\nCREATE INDEX idx_users_age ON users(age)\nCREATE INDEX idx_users_city ON users(city)\n\nFOR u IN users \nFILTER u.age &gt; 18 AND u.city == \"Berlin\"  -- Beide Indizes genutzt!\nRETURN u\n\n-- \u274c FALSCH: Kein Index \u2192 Full Scan\nFOR u IN users \nFILTER u.random_field == \"value\"  -- Kein Index!\nRETURN u\n</code></pre>"},{"location":"query_engine_aql/#73-joins-minimieren","title":"7.3 Joins minimieren","text":"<pre><code>-- \u2705 RICHTIG: Filter vor Join\nFOR u IN users \nFILTER u.active == true           -- Reduziert u-Set!\nFOR o IN orders \nFILTER o.user_id == u._key\nRETURN {user: u.name, order: o.id}\n\n-- \u274c FALSCH: Kein Filter \u2192 Gro\u00dfer Cross-Product\nFOR u IN users \nFOR o IN orders \nFILTER o.user_id == u._key        -- Erst nach Cross-Product!\nRETURN {user: u.name, order: o.id}\n</code></pre>"},{"location":"query_engine_aql/#74-graph-traversals","title":"7.4 Graph-Traversals","text":"<pre><code>-- \u2705 RICHTIG: Depth begrenzen\nFOR v IN 1..3 OUTBOUND 'user1' GRAPH 'social'  -- Max 3 Hops\nFILTER v.age &gt; 30\nRETURN v\n\n-- \u274c FALSCH: Unbegrenzte Depth\nFOR v IN 1..10 OUTBOUND 'user1' GRAPH 'social'  -- Exponentielles Wachstum!\nRETURN v\n</code></pre>"},{"location":"query_engine_aql/#8-limitierungen-mvp","title":"8. Limitierungen (MVP)","text":""},{"location":"query_engine_aql/#81-aktuelle-einschrankungen","title":"8.1 Aktuelle Einschr\u00e4nkungen","text":"<ul> <li>\u274c OR-Support: Nur AND im Translator (OR in Arbeit)</li> <li>\u274c Feld-zu-Feld-Vergleiche: <code>u.city == o.city</code> nicht generisch (nur in Join-Bedingungen)</li> <li>\u274c Subqueries: Noch nicht implementiert</li> <li>\u274c Hash-Join: Nur Nested-Loop-Joins (O(n\u00d7m))</li> <li>\u274c Complex Functions: CONCAT, SUBSTRING in Entwicklung</li> </ul>"},{"location":"query_engine_aql/#82-geplante-erweiterungen","title":"8.2 Geplante Erweiterungen","text":"<ul> <li>[ ] OR-Support: Disjunktive Pr\u00e4dikate</li> <li>[ ] Hash-Join: F\u00fcr gro\u00dfe Collections</li> <li>[ ] Subqueries: Nested Queries</li> <li>[ ] Window Functions: ROW_NUMBER, RANK</li> <li>[ ] CTEs (WITH): Common Table Expressions</li> <li>[ ] UPSERT: INSERT ... ON CONFLICT UPDATE</li> </ul>"},{"location":"query_engine_aql/#referenzen","title":"Referenzen","text":"<ul> <li>AQL Syntax: aql_syntax.md</li> <li>EXPLAIN &amp; PROFILE: aql_explain_profile.md</li> <li>Parser: <code>include/query/aql_parser.h</code></li> <li>Translator: <code>include/query/aql_translator.h</code></li> <li>Optimizer: <code>include/query/query_optimizer.h</code></li> <li>Engine: <code>include/query/query_engine.h</code></li> <li>Cursor Pagination: cursor_pagination.md</li> <li>Indexes: indexes.md</li> </ul>"},{"location":"rbac_authorization/","title":"RBAC &amp; Authorization (MVP)","text":"<p>Diese Seite beschreibt die API-Token-basierte Zugriffskontrolle in ThemisDB. MVP-Version nutzt statische Token mit Scopes; sp\u00e4ter erweitert um ABAC (Ranger-inspiriert).</p>"},{"location":"rbac_authorization/#konzept","title":"Konzept","text":"<ul> <li>Token-basiert: API-Clients senden <code>Authorization: Bearer &lt;token&gt;</code> Header</li> <li>Scopes: Jeder Token hat einen Satz von Scopes (z. B. <code>admin</code>, <code>config:write</code>, <code>cdc:read</code>, <code>metrics:read</code>)</li> <li>Endpoint-Schutz: Sensitive Endpunkte pr\u00fcfen erforderliche Scopes</li> <li>Audit-Logs: Verweigerte Zugriffe werden geloggt</li> <li>Metriken: Prometheus-Z\u00e4hler f\u00fcr Autorisierungsergebnisse</li> </ul>"},{"location":"rbac_authorization/#scope-matrix","title":"Scope-Matrix","text":"Scope Berechtigungen <code>admin</code> Voller Zugriff auf alle Endpoints (Superuser) <code>config:read</code> GET /config <code>config:write</code> POST /config (Hot-Reload) <code>cdc:read</code> GET /changefeed/*, CDC Stats <code>cdc:admin</code> POST /changefeed/retention (Konfiguration) <code>metrics:read</code> GET /metrics (Prometheus) <code>data:read</code> GET /entities/, /query/, /graph/, /vector/ <code>data:write</code> PUT/DELETE /entities/*, POST /query/aql (schreibend)"},{"location":"rbac_authorization/#konfiguration","title":"Konfiguration","text":"<p>Token werden in <code>config/auth.json</code> definiert (oder via ENV-Variablen):</p> <pre><code>{\n  \"tokens\": [\n    {\n      \"token\": \"admin-secret-token-abc123\",\n      \"user_id\": \"admin\",\n      \"scopes\": [\"admin\", \"config:write\", \"config:read\", \"cdc:read\", \"cdc:admin\", \"metrics:read\", \"data:read\", \"data:write\"]\n    },\n    {\n      \"token\": \"readonly-token-def456\",\n      \"user_id\": \"monitoring\",\n      \"scopes\": [\"metrics:read\", \"cdc:read\", \"data:read\"]\n    }\n  ]\n}\n</code></pre> <p>Alternativ via Umgebungsvariablen (f\u00fcr Container):</p> <pre><code>THEMIS_AUTH_TOKENS='[{\"token\":\"abc123\",\"user_id\":\"admin\",\"scopes\":[\"admin\"]}]'\n</code></pre>"},{"location":"rbac_authorization/#api-nutzung","title":"API-Nutzung","text":"<p>Clients senden Token im Authorization-Header:</p> <pre><code># Erfolg (admin hat admin-Scope)\ncurl -H \"Authorization: Bearer admin-secret-token-abc123\" \\\n     http://localhost:8765/config\n\n# Verweigert (readonly hat keinen config:write-Scope)\ncurl -X POST -H \"Authorization: Bearer readonly-token-def456\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"logging\":{\"level\":\"debug\"}}' \\\n     http://localhost:8765/config\n# -&gt; 403 Forbidden\n</code></pre>"},{"location":"rbac_authorization/#geschutzte-endpunkte","title":"Gesch\u00fctzte Endpunkte","text":"<p>MVP-Version sch\u00fctzt folgende Endpunkte:</p> <ul> <li><code>POST /config</code> \u2192 Scope: <code>config:write</code></li> <li><code>GET /config</code> \u2192 Scope: <code>config:read</code></li> <li><code>GET /changefeed/*</code> \u2192 Scope: <code>cdc:read</code></li> <li><code>POST /changefeed/retention</code> \u2192 Scope: <code>cdc:admin</code></li> <li><code>GET /metrics</code> \u2192 Scope: <code>metrics:read</code> (optional, f\u00fcr private Deployments)</li> <li>Admin-Endpoints (z. B. <code>/admin/*</code>, falls vorhanden) \u2192 Scope: <code>admin</code></li> </ul> <p>Datenendpunkte (<code>/entities</code>, <code>/query</code>, <code>/graph</code>, <code>/vector</code>) sind zun\u00e4chst offen; optionale Aktivierung via Feature-Flag <code>require_data_auth</code>.</p>"},{"location":"rbac_authorization/#metriken","title":"Metriken","text":"<p>Prometheus <code>/metrics</code> enth\u00e4lt:</p> <ul> <li><code>themis_authz_success_total</code> \u2014 Erfolgreiche Autorisierungen (Label: <code>user_id</code>, <code>scope</code>)</li> <li><code>themis_authz_denied_total</code> \u2014 Verweigerte Zugriffe (Label: <code>user_id</code>, <code>scope</code>, <code>reason</code>)</li> <li><code>themis_authz_invalid_token_total</code> \u2014 Ung\u00fcltige/fehlende Token</li> </ul>"},{"location":"rbac_authorization/#audit-logs","title":"Audit-Logs","text":"<p>Bei verweigertem Zugriff wird ein WARN-Log geschrieben:</p> <pre><code>WARN: Authorization denied for user 'monitoring': Missing required scope: config:write\n</code></pre> <p>F\u00fcr vollst\u00e4ndige Audit-Trails k\u00f6nnen strukturierte Logs (JSON) aktiviert werden (<code>POST /config</code> \u2192 <code>logging.format = \"json\"</code>).</p>"},{"location":"rbac_authorization/#sicherheitshinweise","title":"Sicherheitshinweise","text":"<ul> <li>Token-Rotation: Aktuell statische Token; Rotation via Neustart oder <code>/config</code> Reload (geplant: Key-Rotation-API)</li> <li>TLS: In Produktion IMMER hinter TLS-Proxy (nginx/Caddy); Token sonst plain-text \u00fcbertragen</li> <li>Secrets-Management: Token nicht in Git committen; nutze Secrets-Manager (Vault, K8s Secrets)</li> <li>Least Privilege: Verteile minimale Scopes; Admin-Token nur f\u00fcr ops/debugging</li> </ul>"},{"location":"rbac_authorization/#roadmap-abac-policy-engine","title":"Roadmap: ABAC &amp; Policy-Engine","text":"<p>Mittelfristig (Sprint C/Q4):</p> <ul> <li>ABAC-Schema (resource, action, subject attributes)</li> <li>Policy-Store (RocksDB), Evaluator, Caching</li> <li>Apache Ranger-kompatible Konzepte (Policies, Deny-Overrides)</li> <li>Admin-UI f\u00fcr Policy-Verwaltung</li> </ul>"},{"location":"rbac_authorization/#beispiel-workflows","title":"Beispiel-Workflows","text":""},{"location":"rbac_authorization/#1-monitoring-setup","title":"1) Monitoring-Setup","text":"<p>Token mit <code>metrics:read</code> + <code>cdc:read</code>:</p> <pre><code>curl -H \"Authorization: Bearer readonly-token-def456\" \\\n     http://localhost:8765/metrics\n</code></pre>"},{"location":"rbac_authorization/#2-config-hot-reload","title":"2) Config Hot-Reload","text":"<p>Token mit <code>config:write</code>:</p> <pre><code>curl -X POST \\\n     -H \"Authorization: Bearer admin-secret-token-abc123\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"logging\":{\"level\":\"info\"},\"request_timeout_sec\":60}' \\\n     http://localhost:8765/config\n</code></pre>"},{"location":"rbac_authorization/#3-cdc-subscription","title":"3) CDC-Subscription","text":"<p>Token mit <code>cdc:read</code>:</p> <pre><code>curl -H \"Authorization: Bearer readonly-token-def456\" \\\n     \"http://localhost:8765/changefeed?from_seq=0&amp;limit=100\"\n</code></pre>"},{"location":"rbac_authorization/#testing","title":"Testing","text":"<p>Unit-Tests: <code>tests/test_auth_middleware.cpp</code></p> <pre><code># Build + Test\ncmake --build build --config Release\n.\\build\\Release\\themis_tests.exe --gtest_filter=AuthMiddlewareTest.*\n</code></pre>"},{"location":"rbac_authorization/#referenzen","title":"Referenzen","text":"<ul> <li>Security/Compliance Review</li> <li>Operations Runbook</li> <li>Deployment</li> </ul>"},{"location":"recursive_path_queries/","title":"Recursive Path Queries &amp; Multi-Hop Reasoning","text":"<p>Status: MVP Complete (31. Oktober 2025) Feature Set: Rekursive Pfadabfragen, Multi-Hop Traversal, Temporale Graph-Queries</p>"},{"location":"recursive_path_queries/#uberblick","title":"\u00dcberblick","text":"<p>Das Themis Query-Engine-Modul unterst\u00fctzt jetzt rekursive Pfadabfragen f\u00fcr Graph-Traversals mit variabler Tiefe und optionaler zeitlicher Filterung.</p>"},{"location":"recursive_path_queries/#hauptfunktionen","title":"Hauptfunktionen","text":"<ul> <li>Recursive Path Queries: Variable Tiefe ohne festes Limit (1..max_depth)</li> <li>Multi-Hop Traversal: Automatische Pfadfindung \u00fcber mehrere Knoten</li> <li>Temporal Graph Support: Zeitabh\u00e4ngige Kanten mit <code>valid_from</code>/<code>valid_to</code></li> <li>Shortest Path: Dijkstra-Algorithmus f\u00fcr k\u00fcrzeste Pfade</li> <li>Breadth-First Search: Alle erreichbaren Knoten bis zu einer bestimmten Tiefe</li> </ul>"},{"location":"recursive_path_queries/#api-referenz","title":"API-Referenz","text":""},{"location":"recursive_path_queries/#recursivepathquery-struktur","title":"RecursivePathQuery Struktur","text":"<pre><code>struct RecursivePathQuery {\n    std::string start_node;              // Start-Knoten (erforderlich)\n    std::string end_node;                // Ziel-Knoten (optional, leer = BFS)\n    std::string edge_type;               // Kanten-Typ-Filter (reserviert)\n    size_t max_depth = 5;                // Maximale Traversal-Tiefe\n    std::optional&lt;std::string&gt; valid_from;  // Zeitfenster Start (ms)\n    std::optional&lt;std::string&gt; valid_to;    // Zeitfenster Ende (ms)\n};\n</code></pre>"},{"location":"recursive_path_queries/#queryengine-methode","title":"QueryEngine Methode","text":"<pre><code>std::pair&lt;Status, std::vector&lt;std::vector&lt;std::string&gt;&gt;&gt; \nexecuteRecursivePathQuery(const RecursivePathQuery&amp; q) const;\n</code></pre> <p>R\u00fcckgabe: - <code>Status</code>: OK oder Fehlermeldung - <code>vector&lt;vector&lt;string&gt;&gt;</code>: Liste von Pfaden (jeder Pfad ist eine Sequenz von Knoten-IDs)</p>"},{"location":"recursive_path_queries/#verwendungsbeispiele","title":"Verwendungsbeispiele","text":""},{"location":"recursive_path_queries/#beispiel-1-kurzester-pfad-single-target","title":"Beispiel 1: K\u00fcrzester Pfad (Single Target)","text":"<pre><code>#include \"query/query_engine.h\"\n#include \"index/graph_index.h\"\n\n// Setup\nRocksDBWrapper db;\ndb.open(\"data/mydb\");\nSecondaryIndexManager secIdx(db);\nGraphIndexManager graphIdx(db);\nQueryEngine engine(db, secIdx, graphIdx);\n\n// Query: Finde k\u00fcrzesten Pfad von A nach D\nRecursivePathQuery q;\nq.start_node = \"A\";\nq.end_node = \"D\";\nq.max_depth = 10;\n\nauto [st, paths] = engine.executeRecursivePathQuery(q);\nif (st.ok &amp;&amp; !paths.empty()) {\n    // paths[0] = [\"A\", \"B\", \"C\", \"D\"]\n    for (const auto&amp; node : paths[0]) {\n        std::cout &lt;&lt; node &lt;&lt; \" -&gt; \";\n    }\n}\n</code></pre>"},{"location":"recursive_path_queries/#beispiel-2-bfs-alle-erreichbaren-knoten","title":"Beispiel 2: BFS - Alle erreichbaren Knoten","text":"<pre><code>// Query: Finde alle Knoten erreichbar von A (max Tiefe 3)\nRecursivePathQuery q;\nq.start_node = \"A\";\n// Kein end_node = BFS-Modus\nq.max_depth = 3;\n\nauto [st, paths] = engine.executeRecursivePathQuery(q);\nif (st.ok) {\n    std::cout &lt;&lt; \"Erreichbare Knoten: \" &lt;&lt; paths.size() &lt;&lt; std::endl;\n    for (const auto&amp; path : paths) {\n        std::cout &lt;&lt; \"  \" &lt;&lt; path.back() &lt;&lt; std::endl; // Ziel-Knoten\n    }\n}\n</code></pre>"},{"location":"recursive_path_queries/#beispiel-3-temporale-pfadabfrage","title":"Beispiel 3: Temporale Pfadabfrage","text":"<pre><code>// Query: Finde Pfad, der zur Zeit 1600ms g\u00fcltig war\nRecursivePathQuery q;\nq.start_node = \"A\";\nq.end_node = \"C\";\nq.max_depth = 5;\nq.valid_from = \"1600\";  // Zeitstempel in Millisekunden\n\nauto [st, paths] = engine.executeRecursivePathQuery(q);\n// Nur Kanten, die bei valid_from &lt;= 1600 &lt;= valid_to sind, werden traversiert\n</code></pre>"},{"location":"recursive_path_queries/#beispiel-4-zeitfenster-query","title":"Beispiel 4: Zeitfenster-Query","text":"<pre><code>// Query: Finde Pfad im Zeitfenster [1000, 2000]\nRecursivePathQuery q;\nq.start_node = \"A\";\nq.end_node = \"D\";\nq.max_depth = 10;\nq.valid_from = \"1000\";\nq.valid_to = \"2000\";\n\nauto [st, paths] = engine.executeRecursivePathQuery(q);\n// Verwendet Mittelpunkt des Zeitfensters (1500ms) als Query-Zeitstempel\n</code></pre>"},{"location":"recursive_path_queries/#graphen-schema","title":"Graphen-Schema","text":""},{"location":"recursive_path_queries/#knoten-entity","title":"Knoten-Entity","text":"<pre><code>BaseEntity node(\"nodes\", \"node_id\");\nnode.set(\"name\", \"Node Name\");\nnode.set(\"type\", \"Person\");\n// ... weitere Attribute\ndb.putEntity(node);\n</code></pre>"},{"location":"recursive_path_queries/#kanten-entity-standardgraph","title":"Kanten-Entity (Standardgraph)","text":"<pre><code>BaseEntity edge(\"edges\", \"edge_id\");\nedge.set(\"_from\", \"node_a\");  // Erforderlich\nedge.set(\"_to\", \"node_b\");    // Erforderlich\nedge.set(\"_weight\", 1.5);     // Optional f\u00fcr gewichtete Pfade\ndb.putEntity(edge);\ngraphIdx.addEdge(edge);\n</code></pre>"},{"location":"recursive_path_queries/#kanten-entity-temporaler-graph","title":"Kanten-Entity (Temporaler Graph)","text":"<pre><code>BaseEntity edge(\"edges\", \"edge_id\");\nedge.set(\"_from\", \"node_a\");\nedge.set(\"_to\", \"node_b\");\nedge.set(\"valid_from\", 1000);  // Millisekunden seit Epoch\nedge.set(\"valid_to\", 2000);    // Millisekunden seit Epoch\ndb.putEntity(edge);\ngraphIdx.addEdge(edge);\n</code></pre> <p>Zeitfenster-Semantik: - <code>valid_from</code> = null \u2192 g\u00fcltig seit Anbeginn der Zeit - <code>valid_to</code> = null \u2192 g\u00fcltig bis in alle Ewigkeit - Query-Zeitstempel <code>t</code> muss in <code>[valid_from, valid_to]</code> liegen</p>"},{"location":"recursive_path_queries/#interne-algorithmen","title":"Interne Algorithmen","text":""},{"location":"recursive_path_queries/#shortest-path-end_node-angegeben","title":"Shortest Path (end_node angegeben)","text":"<p>Verwendet Dijkstra-Algorithmus: - Zeit-Komplexit\u00e4t: O((V + E) log V) - Gewichtete Graphen unterst\u00fctzt (Feld <code>_weight</code>) - Temporal variant: <code>dijkstraAtTime()</code> filtert Kanten nach Zeitstempel</p>"},{"location":"recursive_path_queries/#bfs-kein-end_node","title":"BFS (kein end_node)","text":"<p>Verwendet Breadth-First Search: - Zeit-Komplexit\u00e4t: O(V + E) - Findet alle Knoten bis zu <code>max_depth</code> - Temporal variant: <code>bfsAtTime()</code> filtert Kanten nach Zeitstempel</p>"},{"location":"recursive_path_queries/#temporal-filtering","title":"Temporal Filtering","text":"<pre><code>TemporalFilter filter = TemporalFilter::at(timestamp_ms);\n\n// F\u00fcr jede Kante:\nbool isValid = filter.isValid(edge.valid_from, edge.valid_to);\n</code></pre>"},{"location":"recursive_path_queries/#performance-charakteristiken","title":"Performance-Charakteristiken","text":"Operation Time Complexity Space Complexity Notes Shortest Path (Dijkstra) O((V + E) log V) O(V) Mit Priority Queue BFS Traversal O(V + E) O(V) Breadth-First Temporal Filter Check O(1) O(1) Per Edge Path Reconstruction O(depth) O(depth) Linear in Tiefe <p>Skalierung: - In-Memory Graph Topology: O(1) Nachbarschaftsabfragen - RocksDB Fallback: O(log N) bei kalten Kanten - Empfohlenes Limit: max_depth &lt;= 10 f\u00fcr interaktive Queries</p>"},{"location":"recursive_path_queries/#tests","title":"Tests","text":""},{"location":"recursive_path_queries/#unit-tests-test_recursive_path_querycpp","title":"Unit-Tests (test_recursive_path_query.cpp)","text":"<ul> <li>\u2705 <code>SimplePathQuery</code>: K\u00fcrzester Pfad A \u2192 D in linearem Graph</li> <li>\u2705 <code>PathNotFound</code>: Kein Pfad in Gegenrichtung (gerichteter Graph)</li> <li>\u2705 <code>BFSReachableNodes</code>: BFS findet alle erreichbaren Knoten</li> <li>\u2705 <code>TemporalPathQuery_ValidTime</code>: Pfad zur Zeit 1600ms</li> <li>\u2705 <code>TemporalPathQuery_InvalidTime</code>: Kein Pfad zur Zeit 500ms</li> <li>\u2705 <code>MaxDepthLimit</code>: Respektiert max_depth Grenze</li> <li>\u2705 <code>EmptyStartNode</code>: Fehlerbehandlung f\u00fcr leeren Start</li> <li>\u2705 <code>NoGraphIndexManager</code>: Fehlerbehandlung ohne Graph-Index</li> </ul> <p>Test-Ausf\u00fchrung:</p> <pre><code>cd build\n.\\Release\\themis_tests.exe --gtest_filter=\"RecursivePathQueryTest.*\"\n</code></pre>"},{"location":"recursive_path_queries/#einschrankungen-todos","title":"Einschr\u00e4nkungen &amp; TODOs","text":""},{"location":"recursive_path_queries/#mvp-scope-aktuell","title":"MVP Scope (Aktuell)","text":"<ul> <li>\u2705 Single shortest path (Dijkstra)</li> <li>\u2705 BFS f\u00fcr erreichbare Knoten</li> <li>\u2705 Temporale Filterung (valid_from/valid_to)</li> <li>\u2705 Max-Tiefe-Limit</li> </ul>"},{"location":"recursive_path_queries/#zukunftige-erweiterungen","title":"Zuk\u00fcnftige Erweiterungen","text":"<ul> <li>[ ] All Paths Enumeration: Nicht nur k\u00fcrzester, sondern alle Pfade</li> <li>[ ] Path Constraints: Filter auf Kanten-Attributen (z.B. <code>edge_type</code>)</li> <li>[ ] Variable-Length Patterns: Cypher-Style <code>[:KNOWS*1..5]</code></li> <li>[ ] Recursive CTEs: SQL-\u00e4hnliche WITH RECURSIVE Syntax</li> <li>[ ] Weighted Temporal Paths: Kombination von Zeitfenster und Gewichtung</li> <li>[ ] Bidirectional Search: Schnellere Pfadsuche f\u00fcr gro\u00dfe Graphen</li> <li>[ ] Graph Projection: Virtuelle Subgraphen f\u00fcr spezielle Queries</li> </ul>"},{"location":"recursive_path_queries/#aql-integration-geplant","title":"AQL-Integration (Geplant)","text":""},{"location":"recursive_path_queries/#zukunftige-aql-syntax","title":"Zuk\u00fcnftige AQL-Syntax","text":"<pre><code>// K\u00fcrzester Pfad\nFOR v, e, p IN 1..5 OUTBOUND 'nodes/A' GRAPH 'my_graph'\n    FILTER p.vertices[*]._key == 'D'\n    LIMIT 1\n    RETURN p\n\n// Temporale Pfadabfrage\nFOR v, e, p IN 1..3 OUTBOUND 'nodes/A' GRAPH 'my_graph'\n    FILTER e.valid_from &lt;= @timestamp AND e.valid_to &gt;= @timestamp\n    FILTER p.vertices[-1]._key == 'D'\n    RETURN p\n\n// Alle erreichbaren Knoten\nFOR v IN 1..3 OUTBOUND 'nodes/A' GRAPH 'my_graph'\n    RETURN DISTINCT v\n</code></pre>"},{"location":"recursive_path_queries/#siehe-auch","title":"Siehe auch","text":"<ul> <li><code>docs/architecture.md</code> - System-Architektur-\u00dcbersicht</li> <li><code>include/index/graph_index.h</code> - Graph-Index API</li> <li><code>include/index/temporal_graph.h</code> - Temporal-Filter Design</li> <li><code>tests/test_graph_index.cpp</code> - Graph-Index Unit-Tests</li> <li><code>tests/test_temporal_graph.cpp</code> - Temporal-Graph Tests</li> </ul> <p>Letzte Aktualisierung: 31. Oktober 2025 Version: 1.0.0 (MVP) Status: \u2705 Production Ready</p>"},{"location":"roadmap/","title":"Roadmap","text":"<p>Diese Roadmap skizziert priorisierte Vorhaben f\u00fcr ThemisDB. Zeitpl\u00e4ne sind indikativ; \u00c4nderungen ergeben sich aus Feedback und Priorit\u00e4ten.</p>"},{"location":"roadmap/#kurzfristig-01-quartal","title":"Kurzfristig (0\u20131 Quartal)","text":"<ul> <li>RBAC/Policies f\u00fcr Admin- und Datenendpunkte (Scopes, API-Keys)</li> <li>VectorIndex: HNSW Persistenz/Recovery-H\u00e4rtung, Warmstart-Optimierungen</li> <li>CDC/SSE: Skalierung und Backpressure (Proxy/Ingress-Guidelines), Reconnect-Strategien</li> <li>Backup/Restore: Inkrementelle Backups und Automatisierung (systemd/K8s CronJobs)</li> <li>CI: clang-tidy/cppcheck Gates, Coverage-Reporting, Secrets-Scanning (gitleaks)</li> </ul>"},{"location":"roadmap/#mittelfristig-13-quartale","title":"Mittelfristig (1\u20133 Quartale)","text":"<ul> <li>Query Engine: Join-Optimierungen, Kostenmodell verfeinern, Statistiken/Histograms</li> <li>Indexe: Kompakte Fulltext-Indexierung, Geo-Verbesserungen, progressives Reindexing</li> <li>Sicherheit: Externe KMS-Integration (Vault/AWS KMS), Key-Rotation APIs</li> <li>Speicherformate: Binary-Format Spezifikation stabilisieren, Zero-Copy-Reads ausbauen</li> <li>Observability: Mehr Metriken (Abfrage-Latenzen pro Typ), Trace-Sampling Regeln</li> </ul>"},{"location":"roadmap/#langfristig-3-quartale","title":"Langfristig (3+ Quartale)","text":"<ul> <li>Verteilte Replikation (Leader/Follower), Konsistenzmodi, Leseskalierung</li> <li>Multi-Tenancy mit Quotas/Isolation</li> <li>GNN/Hybrid-Search Pipelines (Online/Offline) inkl. Feature Store Hooks</li> <li>Policy-Engine (ABAC) und Compliance-Vorlagen (GDPR/ISO)</li> </ul>"},{"location":"roadmap/#angenommene-risiken-und-gegenmanahmen","title":"Angenommene Risiken und Gegenma\u00dfnahmen","text":"<ul> <li>Performance-Regressionen: Regelm\u00e4\u00dfige Benchmarks, Budget f\u00fcr Optimierungssprints</li> <li>Sicherheit: Security Reviews pro Release, Pen-Tests bei gr\u00f6\u00dferen \u00c4nderungen</li> <li>Komplexit\u00e4t: Modulare Architektur, klare Verantwortlichkeiten, Dokumentation aktuell halten</li> </ul>"},{"location":"security_audit_checklist/","title":"Themis \u2013 Sicherheits-Audit Checkliste","text":"<p>Diese Checkliste unterst\u00fctzt ein wiederholbares Sicherheits-Audit f\u00fcr Themis-Server und Admin-Tools.</p>"},{"location":"security_audit_checklist/#1-architektur-threat-modeling","title":"1) Architektur &amp; Threat Modeling","text":"<ul> <li>Datenfl\u00fcsse und Vertrauensgrenzen dokumentiert (Client \u2194 Server \u2194 Storage)</li> <li>Angriffsfl\u00e4chen identifiziert (HTTP-API, Admin-Tools, Datei-Importe)</li> <li>Missbrauchsf\u00e4lle (Abuse Cases) erfasst (API-Scraping, DoS, unautorisierte Exporte)</li> </ul>"},{"location":"security_audit_checklist/#2-abhangigkeiten-vulnerability-scan","title":"2) Abh\u00e4ngigkeiten &amp; Vulnerability-Scan","text":"<ul> <li>.NET: <code>dotnet list package --vulnerable</code> in allen Tools</li> <li>C++/vcpkg: Versionen und CVEs pr\u00fcfen (vcpkg-Baseline aktuell, Release Notes)</li> <li>Container-Images (falls genutzt): Trivy/Grype Scan</li> <li>Repo-Scan: <code>security-scan.ps1</code> ausf\u00fchren (C/C++ Risky-APIs, Secret-Pattern, .NET Vulnerabilities)</li> </ul>"},{"location":"security_audit_checklist/#3-buildcompiler-hartung","title":"3) Build/Compiler-H\u00e4rtung","text":"<ul> <li>C++: Warnings auf Maximum, Sanitizer im CI-Testlauf (ASAN/UBSAN) aktivierbar</li> <li>Windows: ASLR/DEP standardm\u00e4\u00dfig aktiv, Code Signing f\u00fcr EXEs/Installer</li> <li>Release-Builds reproduzierbar (vcpkg Baseline, deterministische Flags)</li> </ul>"},{"location":"security_audit_checklist/#4-authentifizierung-autorisierung","title":"4) Authentifizierung &amp; Autorisierung","text":"<ul> <li>Admin-APIs nur f\u00fcr authentisierte Nutzer (Token/Bearer, mTLS oder Reverse Proxy Auth)</li> <li>Rollen/Rechte getrennt (View vs. Export vs. L\u00f6schfunktionen)</li> <li>Sensitive Aktionen (PII-Delete, Key-Rotation) auditierbar</li> </ul>"},{"location":"security_audit_checklist/#5-transport-sicherheit","title":"5) Transport-Sicherheit","text":"<ul> <li>TLS erzwingen (Reverse Proxy wie Nginx/Traefik vor Themis-Server)</li> <li>Sichere Cipher Suites, HSTS, TLS 1.2+</li> <li>Interne Admin-Tools: Kommunikation nur \u00fcber HTTPS</li> </ul>"},{"location":"security_audit_checklist/#6-input-validierung-serialisierung","title":"6) Input-Validierung &amp; Serialisierung","text":"<ul> <li>Strikte Schema-Validierung f\u00fcr JSON-Inputs</li> <li>Limitierung von Eingabegr\u00f6\u00dfen (Body Size, Felder)</li> <li>Schutz gegen Path Traversal, SSRF, Open Redirects (URL/Path-Validierung)</li> </ul>"},{"location":"security_audit_checklist/#7-ratenbegrenzung-ressourcen-schutz","title":"7) Ratenbegrenzung &amp; Ressourcen-Schutz","text":"<ul> <li>Rate Limiting / Backoff bei teuren Endpoints (Export, Query)</li> <li>Timeouts, maximale Parallelit\u00e4t, Queue-Limits</li> <li>DoS-Schutz auf Proxy-Ebene</li> </ul>"},{"location":"security_audit_checklist/#8-logging-audit","title":"8) Logging &amp; Audit","text":"<ul> <li>Security-relevante Events protokolliert (Login, Export, L\u00f6schungen, Rotation)</li> <li>Log-Integrit\u00e4t (WORM/zentral, manipulationssicher)</li> <li>PII-Logging minimieren, keine sensiblen Daten im Klartext</li> </ul>"},{"location":"security_audit_checklist/#9-secrets-konfiguration","title":"9) Secrets &amp; Konfiguration","text":"<ul> <li>Keine Secrets im Repo (API Keys, Zertifikate) \u2013 Geheimnis-Scan</li> <li>Konfiguration via Umgebung/gesch\u00fctzte Stores (Windows DPAPI/KeyVault)</li> <li>Rotationspl\u00e4ne und Notfall-Rollback definiert</li> </ul>"},{"location":"security_audit_checklist/#10-privacy-compliance","title":"10) Privacy &amp; Compliance","text":"<ul> <li>Data Minimization, Zweckbindung, L\u00f6schkonzepte (Art. 17)</li> <li>Export-/Reporting-Pfade DSGVO-konform (Berechtigungen, Pseudonymisierung)</li> <li>Auftragsverarbeitung und TOMs dokumentiert</li> </ul>"},{"location":"security_audit_checklist/#11-testen-review","title":"11) Testen &amp; Review","text":"<ul> <li>Security Code Review (C++/C#) gegen diese Checkliste</li> <li>Fuzzing-Kampagnen (Parser, Query, Import)</li> <li>Penetration-Test gegen die bereitgestellte Staging-Umgebung</li> </ul>"},{"location":"security_audit_checklist/#12-release-gates","title":"12) Release-Gates","text":"<ul> <li>Build/Lint/Tests PASS</li> <li>Vulnerability-Scan: keine kritischen offenen CVEs</li> <li>Signierte Artefakte (Code Signing), Hashes ver\u00f6ffentlicht</li> <li>Geheimnis-Scan ohne Treffer (oder Findings adressiert): <code>security-scan.ps1</code></li> </ul>"},{"location":"security_hardening_guide/","title":"Themis \u2013 Security Hardening Guide","text":"<p>Praxisleitfaden zur H\u00e4rtung von Themis-Server und Admin-Tools.</p>"},{"location":"security_hardening_guide/#server-hartung","title":"Server-H\u00e4rtung","text":"<ul> <li>Reverse Proxy vor Themis (TLS, Rate Limiting, Auth): Nginx/Traefik empfohlen</li> <li>TLS: TLS 1.2+, HSTS, sichere Cipher Suites, OCSP Stapling</li> <li>Accounts: Least-Privilege Service User, kein Admin-Kontext</li> <li>Firewall: Nur ben\u00f6tigte Ports (8765) freigeben, IP-Restriktionen erw\u00e4gen</li> <li>Logging: Security-Events zentralisieren; Log Rotation, WORM/ELK/Graylog</li> <li>Ressourcen: Request-Timeouts, Body-Size-Limits, Parallelit\u00e4tsgrenzen</li> <li>Build: Reproducible, vcpkg Baseline fixiert; ASAN/UBSAN im Testlauf</li> </ul>"},{"location":"security_hardening_guide/#admin-tools-wpf","title":"Admin-Tools (WPF)","text":"<ul> <li>Code Signing der EXEs und Installer (MSIX/WiX)</li> <li>Updates: Signierte Updates; Hash-Validierung bei Verteilung</li> <li>Netzwerk: Nur HTTPS-Endpoints verwenden; Zertifikatsvalidierung aktiv</li> <li>Konfiguration: Keine Secrets in Klartextdateien; Windows Credential Locker/DPAPI</li> <li>Telemetrie/Logs: Keine PII im Klartext; Minimalprinzip</li> </ul>"},{"location":"security_hardening_guide/#secrets-management","title":"Secrets-Management","text":"<ul> <li>Keinerlei Secrets im Repo halten; .gitignore beachten</li> <li>Nutzung von Secret Stores (Windows, Azure Key Vault, HashiCorp Vault)</li> <li>Rotationspl\u00e4ne definieren (LEK/KEK/DEK + App-Secrets)</li> </ul>"},{"location":"security_hardening_guide/#compliance-aspekte","title":"Compliance-Aspekte","text":"<ul> <li>DSGVO: Recht auf L\u00f6schung, Auskunft, Pseudonymisierung</li> <li>Auditierbarkeit: Export-/L\u00f6schaktionen protokollieren</li> <li>Aufbewahrung: Retention-Policies technisch durchsetzen</li> </ul>"},{"location":"security_hardening_guide/#checklisten-gates","title":"Checklisten &amp; Gates","text":"<ul> <li>Vor Release: <code>docs/security_audit_checklist.md</code> durchgehen</li> <li>Vulnerability-Scans ohne kritische Funde</li> <li>Signierte, versionierte Artefakte im <code>dist/</code>-Pfad</li> </ul>"},{"location":"semantic_cache/","title":"Semantic Query Cache# Semantic Cache (Sprint A - Task 1)","text":""},{"location":"semantic_cache/#overviewstatus-vollstandig-implementiert-30-oktober-2025","title":"OverviewStatus: \u2705 Vollst\u00e4ndig implementiert (30. Oktober 2025)","text":"<p>The Semantic Query Cache is an intelligent, LRU-based cache for query results that supports both exact string matching and semantic similarity matching. It uses feature-based embeddings to find similar queries and return cached results, significantly reducing redundant query execution.## \u00dcberblick</p>"},{"location":"semantic_cache/#key-featuresder-semantic-cache-reduziert-llm-kosten-um-40-60-durch-zwischenspeicherung-von-prompt-response-paaren-er-verwendet-sha256-hashing-fur-exaktes-matching-von-prompt-parameters-response","title":"Key FeaturesDer Semantic Cache reduziert LLM-Kosten um 40-60% durch Zwischenspeicherung von Prompt-Response-Paaren. Er verwendet SHA256-Hashing f\u00fcr exaktes Matching von <code>(prompt, parameters)</code> \u2192 <code>response</code>.","text":""},{"location":"semantic_cache/#1-multi-level-lookup-strategy-implementierung","title":"1. Multi-Level Lookup Strategy## Implementierung","text":"<pre><code>\nQuery \u2192 Exact Match \u2192 Semantic Match (KNN) \u2192 Cache Miss### Dateien\n\n```- **Header:** `include/cache/semantic_cache.h`\n\n- **Implementation:** `src/cache/semantic_cache.cpp`\n\n- **Exact Match**: Fast O(1) lookup by query string- **HTTP Handler:** `src/server/http_server.cpp` (handleCacheQuery, handleCachePut, handleCacheStats)\n\n- **Semantic Match**: KNN search in vector space (configurable threshold)\n\n- **Fallback**: Execute query if no match found### Architektur\n\n\n\n### 2. Intelligent Eviction```cpp\n\n- **LRU Eviction**: Removes least recently used entries when cache is fullclass SemanticCache {\n\n- **TTL Expiration**: Auto-removes expired entries (configurable TTL)    // Key: SHA256(prompt + JSON.stringify(params))\n\n- **Manual Eviction**: `evictLRU()` for explicit cleanup    // Value: {response, metadata, timestamp_ms, ttl_seconds}\n\n\n\n### 3. Query Embedding    bool put(prompt, params, response, metadata, ttl_seconds);\n\nFeature-based embedding with:    std::optional&lt;CacheEntry&gt; query(prompt, params);\n\n- **Tokenization**: Extracts tokens from query text    Stats getStats();  // hit_count, miss_count, hit_rate, avg_latency_ms\n\n- **Bigrams**: Captures query structure    uint64_t clearExpired();\n\n- **Keywords**: Identifies important terms (WHERE, JOIN, etc.)    bool clear();\n\n- **Feature Hashing**: Maps features to 128-dim vector};\n\n- **L2 Normalization**: Unit-length vectors for cosine similarity```\n\n\n\n### 4. Thread-Safe Operations### Storage\n\n- **Concurrent Reads**: Multiple threads can call `get()` simultaneously- **RocksDB Column Family:** Default CF (geplant: `semantic_cache` CF)\n\n- **Concurrent Writes**: Thread-safe `put()` with mutex protection- **Key Format:** SHA256 hash (32 bytes hex string)\n\n- **Deadlock-Free**: Careful lock ordering prevents resource deadlocks- **Value Format:** JSON `{response, metadata, timestamp_ms, ttl_seconds}`\n\n\n\n## Architecture### TTL-Mechanik\n\n- **Speicherung:** `timestamp_ms` (Erstellungszeit) + `ttl_seconds`\n\n### Storage- **Abfrage:** `isExpired()` pr\u00fcft `current_time &gt; (timestamp + TTL)`\n\n```- **Cleanup:** `clearExpired()` entfernt abgelaufene Eintr\u00e4ge via WriteBatch\n\nRocksDB Keys:- **No-Expiry:** `ttl_seconds = -1` \u2192 nie ablaufen\n\n  - qcache:exact:&lt;query&gt;    \u2192 CacheEntry (JSON)\n\n  - qcache:entry:&lt;query&gt;    \u2192 CacheEntry (JSON)### Metriken\n\n```cpp\n\nVectorIndexManager:struct Stats {\n\n  - Collection: \"query_cache\"    uint64_t hit_count;       // Cache hits\n\n  - Vectors: 128-dim float (L2 normalized)    uint64_t miss_count;      // Cache misses\n\n  - Index: HNSW for fast KNN search    double hit_rate;          // hit_count / (hit_count + miss_count)\n\n```    double avg_latency_ms;    // Durchschnittliche Lookup-Latenz\n\n    uint64_t total_entries;   // Anzahl Eintr\u00e4ge im Cache\n\n### Data Structures    uint64_t total_size_bytes;// Gesamtgr\u00f6\u00dfe in Bytes\n\n};\n\n#### CacheEntry```\n\n```cpp\n\nstruct CacheEntry {## HTTP API\n\n    std::string query;                  // Original query string\n\n    std::string result_json;            // Cached result (JSON)### POST /cache/put\n\n    std::vector&lt;float&gt; embedding;       // 128-dim query embedding**Request:**\n\n    std::chrono::system_clock::time_point created_at;```json\n\n    std::chrono::system_clock::time_point last_accessed;{\n\n    int hit_count;                      // Access frequency  \"prompt\": \"What is the capital of France?\",\n\n    size_t result_size;                 // Bytes  \"parameters\": {\"model\": \"gpt-4\", \"temperature\": 0.7},\n\n  \"response\": \"The capital of France is Paris.\",\n\n    bool isExpired(std::chrono::seconds ttl) const;  \"metadata\": {\"tokens\": 15, \"cost_usd\": 0.001},\n\n};  \"ttl_seconds\": 3600\n\n```}\n\n</code></pre>"},{"location":"semantic_cache/#lookupresult","title":"LookupResult","text":"<p>```cppResponse:</p> <p>struct LookupResult {```json</p> <pre><code>bool found;                         // Cache hit?{\n\nbool exact_match;                   // True if exact string match  \"success\": true,\n\nstd::string result_json;            // Cached result  \"message\": \"Response cached successfully\"\n\nfloat similarity;                   // Similarity score (0-1)}\n\nstd::string matched_query;          // Which query was matched```\n</code></pre> <p>};</p> <p>```### POST /cache/query</p> <p>Request:</p>"},{"location":"semantic_cache/#cachestatsjson","title":"CacheStats```json","text":"<p>```cpp{</p> <p>struct CacheStats {  \"prompt\": \"What is the capital of France?\",</p> <pre><code>size_t total_lookups;               // All get() calls  \"parameters\": {\"model\": \"gpt-4\", \"temperature\": 0.7}\n\nsize_t exact_hits;                  // Exact string matches}\n\nsize_t similarity_hits;             // Semantic matches```\n\nsize_t misses;                      // Cache misses\n\nsize_t evictions;                   // Entries evicted**Response (Hit):**\n\nsize_t current_entries;             // Entries in cache```json\n\nsize_t total_result_bytes;          // Memory usage{\n</code></pre> <p>};  \"found\": true,</p> <p>```  \"response\": \"The capital of France is Paris.\",</p> <p>\"metadata\": {\"tokens\": 15, \"cost_usd\": 0.001}</p>"},{"location":"semantic_cache/#usage","title":"Usage}","text":"<pre><code>\n### Basic Usage\n\n```cpp**Response (Miss):**\n\n#include \"query/semantic_cache.h\"```json\n\n{\n\n// Initialize cache  \"found\": false\n\nSemanticQueryCache::Config config;}\n\nconfig.max_entries = 1000;```\n\nconfig.similarity_threshold = 0.85f;\n\nconfig.ttl = std::chrono::hours(1);### GET /cache/stats\n\n**Response:**\n\nSemanticQueryCache cache(db, vim, config);```json\n\n{\n\n// Put query result  \"hit_count\": 42,\n\nstd::string query = \"FIND users WHERE age &gt; 30\";  \"miss_count\": 8,\n\nstd::string result = R\"({\"users\": [...]})\";  \"hit_rate\": 0.84,\n\ncache.put(query, result);  \"avg_latency_ms\": 1.2,\n\n  \"total_entries\": 100,\n\n// Get cached result  \"total_size_bytes\": 524288\n\nauto lookup = cache.get(query);}\n\nif (lookup.found) {```\n\n    if (lookup.exact_match) {\n\n        std::cout &lt;&lt; \"Exact match! Similarity: \" &lt;&lt; lookup.similarity &lt;&lt; \"\\n\";## Server-Logs (Validierung)\n\n    } else {\n\n        std::cout &lt;&lt; \"Similar query matched: \" &lt;&lt; lookup.matched_query ```\n\n                  &lt;&lt; \" (similarity: \" &lt;&lt; lookup.similarity &lt;&lt; \")\\n\";[2025-10-30 14:13:54] [themis] [info] Semantic Cache initialized (TTL: 3600s) using default CF\n\n    }[2025-10-30 14:13:54] [themis] [info]   POST /cache/query - Semantic cache lookup (beta)\n\n    std::cout &lt;&lt; \"Result: \" &lt;&lt; lookup.result_json &lt;&lt; \"\\n\";[2025-10-30 14:13:54] [themis] [info]   POST /cache/put   - Semantic cache put (beta)\n\n} else {[2025-10-30 14:13:54] [themis] [info]   GET  /cache/stats - Semantic cache stats (beta)\n\n    std::cout &lt;&lt; \"Cache miss - execute query\\n\";```\n\n}\n\n```## Performance-Ziele\n\n\n\n### Configuration| Metric | Ziel | Status |\n\n```cpp|--------|------|--------|\n\nSemanticQueryCache::Config config;| Cache Hit Rate | &gt;40% | \u2705 Implementiert |\n\nconfig.max_entries = 2000;              // Max cached queries| Lookup Latenz | &lt;5ms | \u2705 Gemessen via avg_latency_ms |\n\nconfig.similarity_threshold = 0.90f;    // Stricter matching (0-1)| TTL Genauigkeit | \u00b11s | \u2705 Millisekunden-Pr\u00e4zision |\n\nconfig.ttl = std::chrono::minutes(30);  // 30 min expiration| Cost Reduction | 40-60% | \u23f3 Workload-abh\u00e4ngig |\n\nconfig.enable_exact_match = true;       // Enable exact lookup\n\nconfig.enable_similarity_match = true;  // Enable semantic lookup## Anwendungsf\u00e4lle\n\n</code></pre> <ol> <li>LLM Response Caching: Identische Prompts \u2192 Wiederverwendung teurer LLM-Calls</li> </ol>"},{"location":"semantic_cache/#eviction2-rag-pipelines-embedding-lookup-caching-retrieval-results","title":"Eviction2. RAG Pipelines: Embedding-Lookup-Caching, Retrieval-Results","text":"<p>```cpp3. Chatbots: H\u00e4ufige Fragen \u2192 sofortige Antworten</p> <p>// Explicit LRU eviction (removes 10% of entries)4. A/B Testing: Verschiedene <code>parameters</code> \u2192 separate Cache-Keys</p> <p>cache.evictLRU(0.1);</p>"},{"location":"semantic_cache/#test-ergebnisse-30102025","title":"Test-Ergebnisse (30.10.2025)","text":"<p>// Remove expired entries</p> <p>cache.evictExpired();### Manuelle HTTP-Tests</p> <p>// Remove specific entry| Test | Ergebnis | Details |</p> <p>cache.remove(\"FIND users WHERE age &gt; 30\");|------|----------|---------|</p> <p>| PUT | \u2705 Success | <code>{\"success\": true, \"message\": \"Response cached successfully\"}</code> |</p> <p>// Clear entire cache| QUERY (Hit) | \u2705 Success | <code>{\"hit\": true, \"response\": \"Paris\", \"metadata\": {...}}</code> |</p> <p>cache.clear();| QUERY (Miss) | \u2705 Success | <code>{\"hit\": false}</code> |</p> <p>```| STATS | \u2705 Success | Hit Rate: 50%, Latency: 0.058ms |</p> <p>| Workload (20 queries) | \u2705 81.82% Hit Rate | Ziel &gt;40% \u00fcbertroffen! |</p>"},{"location":"semantic_cache/#statistics","title":"Statistics","text":"<p>```cpp### Performance-Metriken</p> <p>auto stats = cache.getStats();</p> <p>std::cout &lt;&lt; \"Total Lookups: \" &lt;&lt; stats.total_lookups &lt;&lt; \"\\n\";- Durchschnittliche Latenz: 0.058ms (Ziel: &lt;5ms) \u2705</p> <p>std::cout &lt;&lt; \"Exact Hits: \" &lt;&lt; stats.exact_hits &lt;&lt; \"\\n\";- Hit Rate unter Last: 81.82% (Ziel: &gt;40%) \u2705</p> <p>std::cout &lt;&lt; \"Similarity Hits: \" &lt;&lt; stats.similarity_hits &lt;&lt; \"\\n\";- Speichereffizienz: 23 Eintr\u00e4ge = 2.4KB \u2705</p> <p>std::cout &lt;&lt; \"Misses: \" &lt;&lt; stats.misses &lt;&lt; \"\\n\";</p> <p>std::cout &lt;&lt; \"Hit Rate: \" ## N\u00e4chste Schritte</p> <pre><code>      &lt;&lt; (100.0 * (stats.exact_hits + stats.similarity_hits) / stats.total_lookups)\n\n      &lt;&lt; \"%\\n\";- \u2705 Implementierung vollst\u00e4ndig\n</code></pre> <p>std::cout &lt;&lt; \"Current Entries: \" &lt;&lt; stats.current_entries &lt;&lt; \"\\n\";- \u2705 Integration Tests (manuell validiert)</p> <p>std::cout &lt;&lt; \"Total Memory: \" &lt;&lt; stats.total_result_bytes &lt;&lt; \" bytes\\n\";- \u2705 Load Testing (81.82% Hit Rate erreicht)</p> <p>```- \u23f3 Prometheus Metrics Export (cache_hit_rate, cache_latency)</p> <ul> <li>\u23f3 Dedicated Column Family (<code>semantic_cache</code> CF)</li> </ul>"},{"location":"semantic_cache/#implementation-details","title":"Implementation Details","text":""},{"location":"semantic_cache/#zusammenfassung","title":"Zusammenfassung","text":""},{"location":"semantic_cache/#query-embedding-algorithm","title":"Query Embedding Algorithm","text":"<p>```cppDer Semantic Cache ist produktionsbereit und bietet:</p> <p>std::vector computeQueryEmbedding_(std::string_view query) {- \u2705 Exakte Prompt+Parameter-Matching via SHA256 <pre><code>// 1. Tokenization (whitespace split, lowercase)- \u2705 Flexible TTL-Steuerung (pro Entry)\n\nstd::vector&lt;std::string&gt; tokens = tokenize(query);- \u2705 Umfassende Metriken (Hit-Rate, Latenz, Size)\n\n- \u2705 HTTP API f\u00fcr CRUD-Operationen\n\n// 2. Feature Extraction- \u2705 Thread-safe Implementierung\n\nstd::unordered_map&lt;std::string, int&gt; features;- \u2705 Graceful Expiry-Handling\n\n\n\n// Token features (TF-IDF-like)**Deployment:** Server startet mit aktiviertem Semantic Cache, Endpoints unter `/cache/*` verf\u00fcgbar.\n\nfor (const auto&amp; token : tokens) {\n    features[token]++;\n}\n\n// Bigram features (structure capture)\nfor (size_t i = 0; i + 1 &lt; tokens.size(); ++i) {\n    features[tokens[i] + \" \" + tokens[i+1]]++;\n}\n\n// Keyword features (semantic importance)\nstd::set&lt;std::string&gt; keywords = {\n    \"find\", \"where\", \"join\", \"group\", \"order\", \n    \"create\", \"update\", \"delete\", \"index\"\n};\nfor (const auto&amp; token : tokens) {\n    if (keywords.count(token)) {\n        features[\"KW:\" + token] += 5;  // Higher weight\n    }\n}\n\n// 3. Feature Hashing (128-dim)\nstd::vector&lt;float&gt; embedding(128, 0.0f);\nfor (const auto&amp; [feature, count] : features) {\n    size_t hash = std::hash&lt;std::string&gt;{}(feature);\n    size_t idx = hash % 128;\n    embedding[idx] += static_cast&lt;float&gt;(count);\n}\n\n// 4. L2 Normalization\nfloat norm = 0.0f;\nfor (float val : embedding) {\n    norm += val * val;\n}\nnorm = std::sqrt(norm);\nif (norm &gt; 0.0f) {\n    for (float&amp; val : embedding) {\n        val /= norm;\n    }\n}\n\nreturn embedding;\n</code></pre> <p>}</p> <pre><code>\n### Similarity Calculation\n```cpp\n// Cosine similarity via L2 distance\nfloat similarity = 1.0f - distance;  // distance from HNSW search\n\n// Example:\n// - distance=0.0 \u2192 similarity=1.0 (identical)\n// - distance=0.2 \u2192 similarity=0.8 (very similar)\n// - distance=0.5 \u2192 similarity=0.5 (somewhat similar)\n</code></pre>"},{"location":"semantic_cache/#lru-implementation","title":"LRU Implementation","text":"<pre><code>// Dual data structure for O(1) operations\nstd::list&lt;std::string&gt; lru_list_;                // Ordered by access time\nstd::unordered_map&lt;std::string, std::list&lt;std::string&gt;::iterator&gt; lru_map_;\n\n// Update LRU (move to front)\nvoid updateLRU_(std::string_view query) {\n    std::lock_guard&lt;std::mutex&gt; lock(lru_mutex_);\n\n    auto it = lru_map_.find(std::string(query));\n    if (it != lru_map_.end()) {\n        lru_list_.erase(it-&gt;second);  // Remove old position\n    }\n\n    lru_list_.push_front(std::string(query));  // Add to front\n    lru_map_[std::string(query)] = lru_list_.begin();\n}\n\n// Evict LRU entry (from back)\nStatus evictOne_() {\n    std::string lru_query;\n    {\n        std::lock_guard&lt;std::mutex&gt; lruLock(lru_mutex_);\n        if (lru_list_.empty()) return Status::OK();\n        lru_query = lru_list_.back();  // Least recently used\n    }\n    return removeInternal_(lru_query);  // Assumes stats_mutex_ held\n}\n</code></pre>"},{"location":"semantic_cache/#thread-safety","title":"Thread Safety","text":""},{"location":"semantic_cache/#mutex-architecture","title":"Mutex Architecture","text":"<pre><code>std::mutex stats_mutex_;  // Protects: cache state, stats, db operations\nstd::mutex lru_mutex_;    // Protects: LRU list/map\n</code></pre>"},{"location":"semantic_cache/#deadlock-prevention","title":"Deadlock Prevention","text":"<pre><code>// Pattern: Public methods acquire lock, call internal methods\nStatus remove(std::string_view query) {\n    std::lock_guard&lt;std::mutex&gt; lock(stats_mutex_);\n    return removeInternal_(query);  // Assumes lock held\n}\n\nStatus removeInternal_(std::string_view query) {\n    // No lock acquisition - caller holds stats_mutex_\n    // Safe to call from evictOne_(), evictExpired_(), get()\n}\n</code></pre>"},{"location":"semantic_cache/#performance","title":"Performance","text":""},{"location":"semantic_cache/#benchmarks-release-mode","title":"Benchmarks (Release Mode)","text":"<pre><code>Operation          Time      Notes\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nput()              ~3ms      Insert + compute embedding\nget() exact        ~1ms      Fast RocksDB lookup\nget() similarity   ~5ms      KNN search (HNSW)\nremove()          ~2ms      Delete + update LRU\nevictLRU()        ~20ms     For 100 entries (10% of 1000)\n</code></pre>"},{"location":"semantic_cache/#memory-usage","title":"Memory Usage","text":"<pre><code>Per Entry:\n  - CacheEntry: ~200 bytes (query + result + metadata)\n  - Embedding:  512 bytes (128-dim float)\n  - LRU:        ~100 bytes (list node + map entry)\n  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n  Total:        ~800 bytes per entry\n\n1000 entries: ~800 KB\n</code></pre>"},{"location":"semantic_cache/#scalability","title":"Scalability","text":"<ul> <li>Exact Match: O(1) - constant time</li> <li>Similarity Match: O(log n) - HNSW index</li> <li>LRU Update: O(1) - hash map + list</li> <li>Eviction: O(k) - k = number of entries to evict</li> </ul>"},{"location":"semantic_cache/#testing","title":"Testing","text":""},{"location":"semantic_cache/#test-suite-14-tests","title":"Test Suite (14 Tests)","text":"<pre><code># Run all semantic cache tests\n.\\build\\Release\\themis_tests.exe --gtest_filter=\"SemanticCacheTest.*\"\n\n# Expected output:\n[==========] Running 14 tests from 1 test suite.\n[  PASSED  ] 14 tests.\n</code></pre>"},{"location":"semantic_cache/#test-coverage","title":"Test Coverage","text":"<ul> <li>\u2705 PutAndGetExactMatch: Exact query match returns cached result</li> <li>\u2705 CacheMiss: Non-existent query returns not found</li> <li>\u2705 SimilarityMatch: Similar query matches (&gt;0.85 threshold)</li> <li>\u2705 DissimilarQueryMiss: Dissimilar query does not match</li> <li>\u2705 LRUEviction: Oldest entry evicted when cache is full</li> <li>\u2705 TTLExpiration: Expired entries auto-removed</li> <li>\u2705 ManualEviction: Explicit eviction works</li> <li>\u2705 RemoveEntry: Manual removal works</li> <li>\u2705 ClearCache: Clear all entries</li> <li>\u2705 HitRateCalculation: Stats calculation correct</li> <li>\u2705 ConfigUpdate: Dynamic config changes</li> <li>\u2705 EmptyInputRejection: Validates input</li> <li>\u2705 HitCountTracking: Tracks access frequency</li> <li>\u2705 ConcurrentAccess: Thread-safe reads (50 concurrent gets)</li> </ul>"},{"location":"semantic_cache/#integration-with-query-engine","title":"Integration with Query Engine","text":""},{"location":"semantic_cache/#example-integration","title":"Example Integration","text":"<pre><code>class QueryEngine {\n    SemanticQueryCache cache_;\n\npublic:\n    std::string executeQuery(const std::string&amp; query) {\n        // Try cache first\n        auto lookup = cache_.get(query);\n        if (lookup.found) {\n            if (lookup.exact_match) {\n                LOG_INFO(\"Cache hit (exact): \" &lt;&lt; query);\n            } else {\n                LOG_INFO(\"Cache hit (similar): \" &lt;&lt; lookup.matched_query \n                         &lt;&lt; \" (similarity: \" &lt;&lt; lookup.similarity &lt;&lt; \")\");\n            }\n            return lookup.result_json;\n        }\n\n        // Cache miss - execute query\n        LOG_INFO(\"Cache miss - executing: \" &lt;&lt; query);\n        std::string result = doExecuteQuery(query);\n\n        // Cache result for future\n        cache_.put(query, result);\n\n        return result;\n    }\n};\n</code></pre>"},{"location":"semantic_cache/#when-to-use-semantic-cache","title":"When to Use Semantic Cache","text":"<p>\u2705 Good Use Cases: - Frequent identical queries (e.g., dashboards, reports) - Similar queries with minor variations (e.g., different IDs) - Expensive queries with stable results (e.g., aggregations) - Read-heavy workloads (e.g., analytics)</p> <p>\u274c Poor Use Cases: - Rapidly changing data (results become stale) - Unique queries with no repetition - Write-heavy workloads (invalidation overhead) - Real-time data requirements (no staleness tolerance)</p>"},{"location":"semantic_cache/#configuration-best-practices","title":"Configuration Best Practices","text":""},{"location":"semantic_cache/#development","title":"Development","text":"<pre><code>config.max_entries = 100;               // Small cache\nconfig.similarity_threshold = 0.95f;    // Very strict matching\nconfig.ttl = std::chrono::minutes(5);   // Short TTL\n</code></pre>"},{"location":"semantic_cache/#production-read-heavy","title":"Production (Read-Heavy)","text":"<pre><code>config.max_entries = 10000;             // Large cache\nconfig.similarity_threshold = 0.85f;    // Balanced matching\nconfig.ttl = std::chrono::hours(1);     // Long TTL\n</code></pre>"},{"location":"semantic_cache/#production-write-heavy","title":"Production (Write-Heavy)","text":"<pre><code>config.max_entries = 1000;              // Medium cache\nconfig.similarity_threshold = 0.95f;    // Strict matching\nconfig.ttl = std::chrono::minutes(10);  // Short TTL\nconfig.enable_similarity_match = false; // Only exact match\n</code></pre>"},{"location":"semantic_cache/#future-enhancements","title":"Future Enhancements","text":""},{"location":"semantic_cache/#potential-improvements","title":"Potential Improvements","text":"<ol> <li>Learned Embeddings: Train query encoder with historical data</li> <li>Multi-Tier Cache: L1 (exact) \u2192 L2 (similarity) \u2192 L3 (disk)</li> <li>Invalidation Hooks: Auto-invalidate on data writes</li> <li>Adaptive Thresholds: Dynamic similarity threshold based on hit rate</li> <li>Compression: Compress cached results to reduce memory</li> <li>Distributed Cache: Multi-node cache with consistent hashing</li> </ol>"},{"location":"semantic_cache/#advanced-features","title":"Advanced Features","text":"<ul> <li>Query Rewriting: Normalize queries before caching (e.g., remove whitespace)</li> <li>Result Merging: Combine partial results from similar queries</li> <li>Cost-Based Caching: Cache expensive queries, skip cheap ones</li> <li>Prefetching: Predict and pre-cache likely queries</li> </ul>"},{"location":"semantic_cache/#troubleshooting","title":"Troubleshooting","text":""},{"location":"semantic_cache/#low-hit-rate","title":"Low Hit Rate","text":"<pre><code>Problem: Hit rate &lt;10%\nDiagnosis:\n  - Check similarity_threshold (too strict?)\n  - Check TTL (too short?)\n  - Check query patterns (too diverse?)\nSolution:\n  - Lower threshold to 0.80\n  - Increase TTL to 2 hours\n  - Enable similarity_match\n</code></pre>"},{"location":"semantic_cache/#high-memory-usage","title":"High Memory Usage","text":"<pre><code>Problem: Cache uses &gt;1GB RAM\nDiagnosis:\n  - Check max_entries (too high?)\n  - Check result sizes (large results?)\nSolution:\n  - Lower max_entries to 5000\n  - Compress results before caching\n  - Implement result size limit\n</code></pre>"},{"location":"semantic_cache/#deadlocks","title":"Deadlocks","text":"<pre><code>Problem: Resource deadlock errors\nDiagnosis:\n  - Nested mutex acquisition\n  - Incorrect use of remove() vs removeInternal_()\nSolution:\n  - Use removeInternal_() when stats_mutex_ is held\n  - Use scope-based locking for temporary locks\n  - Never call public methods from internal methods\n</code></pre>"},{"location":"semantic_cache/#summary","title":"Summary","text":"<p>The Semantic Query Cache provides: - \u2705 Fast Lookups: ~1ms exact, ~5ms similarity - \u2705 Intelligent Matching: Feature-based embeddings - \u2705 Automatic Eviction: LRU + TTL - \u2705 Thread-Safe: Concurrent reads/writes - \u2705 Production-Ready: 14/14 tests passing</p> <p>Status: \u2705 COMPLETE (Task 5/9) Tests: 14/14 PASSED Code: 700+ lines (header + impl + tests) Performance: Production-ready</p>"},{"location":"sprint_a_plan/","title":"Sprint A Plan (RAG/CDC)","text":"<p>Ziel: APIs und Grundger\u00fcste f\u00fcr RAG\u2011nahe Features (Semantic Cache, CoT Storage) und Minimal\u2011CDC bereitstellen. Fokus auf OpenAPI, Feature\u2011Flags, DoD, Tests.</p>"},{"location":"sprint_a_plan/#deliverables","title":"Deliverables","text":"<ul> <li>OpenAPI\u2011Stubs f\u00fcr</li> <li>Semantic Cache v1: POST /cache/query, POST /cache/put, GET /cache/stats</li> <li>CoT Storage v1: POST /llm/interaction, GET /llm/interaction/{id}, GET /llm/interaction</li> <li>CDC Minimal: GET /changefeed?from_seq&amp;limit&amp;long_poll_ms</li> <li>Server\u2011Feature\u2011Flags (konfigurierbar)</li> <li>Handler\u2011Skeletons (HTTP 501 Not Implemented) optional</li> <li>Docs aktualisiert (OpenAPI in <code>openapi/</code> und <code>docs/</code>)</li> </ul>"},{"location":"sprint_a_plan/#scope-dod","title":"Scope &amp; DoD","text":"<ul> <li>Scope: Nur Schnittstellen und Validierung; keine persistente Implementierung erforderlich (kann No\u2011Op oder In\u2011Memory Mock sein)</li> <li>DoD:</li> <li>OpenAPI linted (schematisch g\u00fcltig), Beispiele vorhanden</li> <li>Server startet mit geflaggten Endpunkten (falls Skeletons), ansonsten 404 f\u00fcr deaktivierte Features</li> <li>Minimaltests: 200/400/404\u2011F\u00e4lle je Endpoint (Mock)</li> </ul>"},{"location":"sprint_a_plan/#feature-flags","title":"Feature Flags","text":"<ul> <li>config.json \u2192 <code>features</code>: { <code>semantic_cache</code>: true, <code>llm_store</code>: true, <code>cdc</code>: true }</li> <li>Endpoints nur aktiv, wenn Feature true (sonst 404)</li> </ul>"},{"location":"sprint_a_plan/#risiken-notizen","title":"Risiken &amp; Notizen","text":"<ul> <li>LLM/CoT Inhalte potenziell sensibel \u2192 PII\u2011Maskierung bei Logs/Tracing</li> <li>CDC Long\u2011Polling: Timeouts sauber konfigurieren (server.request_timeout_ms nutzen)</li> </ul>"},{"location":"sprint_a_plan/#nachste-schritte","title":"N\u00e4chste Schritte","text":"<p>1) Flags in Config einf\u00fchren und am Router verankern 2) Handler\u2011Skeletons (501) mit Request\u2011Schema\u2011Validierung 3) Tests (HTTP) f\u00fcr Happy/Fehlerpfade 4) Iteration f\u00fcr Persistenzdesign (Phase B)</p>"},{"location":"styleguide/","title":"Styleguide &amp; Konventionen \u2013 THEMIS","text":"<p>Version: 2.0 Status: Implementiert Letzte Aktualisierung: 2. November 2025</p>"},{"location":"styleguide/#ubersicht","title":"\u00dcbersicht","text":"<p>Dieser Styleguide definiert Coding-Standards, Namenskonventionen, Error Handling und Logging-Richtlinien f\u00fcr das THEMIS-Projekt. Ziel ist Konsistenz, Wartbarkeit und Qualit\u00e4t \u00fcber alle C++-Module hinweg.</p>"},{"location":"styleguide/#1-c-coding-standards","title":"1. C++ Coding Standards","text":""},{"location":"styleguide/#11-c-version-compiler","title":"1.1 C++ Version &amp; Compiler","text":"<ul> <li>Standard: C++17 (minimum)</li> <li>Compiler: MSVC (Windows), GCC/Clang (Linux)</li> <li>Features: STL, <code>std::optional</code>, <code>std::variant</code>, <code>std::string_view</code>, structured bindings</li> </ul>"},{"location":"styleguide/#12-header-guards","title":"1.2 Header Guards","text":"<pre><code>#pragma once  // Bevorzugt (MSVC/GCC/Clang)\n</code></pre> <p>Alternativ (klassisch):</p> <pre><code>#ifndef THEMIS_MODULE_HEADER_H\n#define THEMIS_MODULE_HEADER_H\n// ...\n#endif // THEMIS_MODULE_HEADER_H\n</code></pre>"},{"location":"styleguide/#13-includes","title":"1.3 Includes","text":"<p>Reihenfolge: 1. Eigener Header (<code>.cpp</code> \u2192 <code>.h</code>) 2. Themis-Headers (<code>include/...</code>) 3. Externe Libraries (RocksDB, Boost, spdlog) 4. STL-Headers (<code>&lt;memory&gt;</code>, <code>&lt;string&gt;</code>, etc.)</p> <pre><code>#include \"storage/base_entity.h\"        // 1. Eigener Header\n\n#include \"index/secondary_index.h\"      // 2. Themis-Headers\n#include \"utils/logger.h\"\n\n#include &lt;rocksdb/db.h&gt;                 // 3. Externe Libraries\n#include &lt;boost/beast/http.hpp&gt;\n\n#include &lt;memory&gt;                       // 4. STL\n#include &lt;string&gt;\n#include &lt;vector&gt;\n</code></pre>"},{"location":"styleguide/#2-naming-conventions","title":"2. Naming Conventions","text":""},{"location":"styleguide/#21-klassen-structs","title":"2.1 Klassen &amp; Structs","text":"<p>PascalCase mit sprechenden Namen:</p> <pre><code>class BaseEntity { };\nclass SecondaryIndexManager { };\nclass TransactionManager { };\nstruct Status { };\nstruct DataPoint { };\n</code></pre>"},{"location":"styleguide/#22-funktionen-methoden","title":"2.2 Funktionen &amp; Methoden","text":"<p>camelCase mit Verben (get/set/create/delete/has/is):</p> <pre><code>class BaseEntity {\npublic:\n    const std::string&amp; getPrimaryKey() const;\n    void setPrimaryKey(std::string_view pk);\n    bool hasField(std::string_view field_name) const;\n\n    static BaseEntity fromJson(std::string_view pk, std::string_view json);\n    static BaseEntity deserialize(std::string_view pk, const Blob&amp; blob);\n};\n</code></pre>"},{"location":"styleguide/#23-variablen","title":"2.3 Variablen","text":"<p>snake_case f\u00fcr Member-Variablen (mit Unterstrich-Suffix):</p> <pre><code>class BaseEntity {\nprivate:\n    std::string primary_key_;\n    Blob blob_;\n    Format format_;\n    mutable std::shared_ptr&lt;FieldMap&gt; field_cache_;\n};\n</code></pre> <p>camelCase f\u00fcr lokale Variablen:</p> <pre><code>void processEntity() {\n    std::string entityKey = makeKey(\"users\", \"alice\");\n    auto blob = db.get(entityKey);\n    BaseEntity entity = BaseEntity::deserialize(\"alice\", *blob);\n}\n</code></pre>"},{"location":"styleguide/#24-konstanten-enums","title":"2.4 Konstanten &amp; Enums","text":"<p>UPPER_CASE f\u00fcr Makros/Konstanten:</p> <pre><code>#define THEMIS_INFO(...) ::themis::utils::Logger::info(__VA_ARGS__)\n\nstatic constexpr const char* KEY_PREFIX = \"ts:\";\nstatic constexpr size_t MAX_BATCH_SIZE = 1000;\n</code></pre> <p>PascalCase f\u00fcr Enums:</p> <pre><code>enum class Format {\n    BINARY,\n    JSON\n};\n\nenum class Level {\n    TRACE, DEBUG, INFO, WARN, ERROR, CRITICAL\n};\n</code></pre>"},{"location":"styleguide/#25-namespaces","title":"2.5 Namespaces","text":"<p>lowercase mit Sub-Namespaces:</p> <pre><code>namespace themis {\nnamespace utils {\n\nclass Logger { };\n\n} // namespace utils\n} // namespace themis\n</code></pre> <p>Verwendung:</p> <pre><code>using themis::BaseEntity;\nusing themis::utils::Logger;\n</code></pre>"},{"location":"styleguide/#3-error-handling","title":"3. Error Handling","text":""},{"location":"styleguide/#31-status-objekt-kein-exceptions","title":"3.1 Status-Objekt (kein Exceptions)","text":"<p>Alle \u00f6ffentlichen APIs verwenden <code>Status</code>-Objekte statt Exceptions:</p> <pre><code>struct Status {\n    bool ok = true;\n    std::string message;\n\n    static Status OK() { return {}; }\n    static Status Error(std::string msg) { return Status{false, std::move(msg)}; }\n};\n</code></pre> <p>Verwendung:</p> <pre><code>// \u2705 RICHTIG: Status zur\u00fcckgeben\nStatus createIndex(std::string_view table, std::string_view column) {\n    if (table.empty()) {\n        return Status::Error(\"createIndex: table darf nicht leer sein\");\n    }\n    // ...\n    return Status::OK();\n}\n\n// Aufrufer pr\u00fcft Status\nauto status = idx.createIndex(\"users\", \"age\");\nif (!status.ok) {\n    THEMIS_ERROR(\"Index creation failed: {}\", status.message);\n    return;\n}\n</code></pre>"},{"location":"styleguide/#32-stdoptional-fur-optionale-werte","title":"3.2 std::optional f\u00fcr optionale Werte","text":"<pre><code>// \u2705 RICHTIG: optional f\u00fcr fehlende Werte\nstd::optional&lt;std::string&gt; getFieldAsString(std::string_view field_name) const;\n\nauto name = entity.getFieldAsString(\"name\");\nif (name) {\n    std::cout &lt;&lt; *name &lt;&lt; \"\\n\";\n}\n\n// \u274c FALSCH: nullptr zur\u00fcckgeben (unsicher)\nstd::string* getFieldAsString(std::string_view field_name) const;  // NEIN!\n</code></pre>"},{"location":"styleguide/#33-stdpair-fur-status-wert","title":"3.3 std::pair f\u00fcr Status + Wert","text":"<pre><code>// Query mit Result\nstd::pair&lt;Status, std::vector&lt;std::string&gt;&gt; scanKeysEqual(\n    std::string_view table,\n    std::string_view column,\n    std::string_view value\n) const;\n\n// Aufrufer\nauto [status, keys] = idx.scanKeysEqual(\"users\", \"age\", \"30\");\nif (!status.ok) {\n    THEMIS_ERROR(\"Scan failed: {}\", status.message);\n    return;\n}\nfor (const auto&amp; key : keys) {\n    // Process keys\n}\n</code></pre>"},{"location":"styleguide/#4-logging","title":"4. Logging","text":""},{"location":"styleguide/#41-logger-makros","title":"4.1 Logger-Makros","text":"<p>Verf\u00fcgbare Level:</p> <pre><code>THEMIS_TRACE(...)     // Detaillierte Debug-Info (selten verwendet)\nTHEMIS_DEBUG(...)     // Debug-Informationen (Development)\nTHEMIS_INFO(...)      // Allgemeine Informationen\nTHEMIS_WARN(...)      // Warnungen (nicht kritisch)\nTHEMIS_ERROR(...)     // Fehler (kritisch, aber nicht fatal)\nTHEMIS_CRITICAL(...)  // Fatale Fehler (Server-Absturz)\n</code></pre>"},{"location":"styleguide/#42-logging-best-practices","title":"4.2 Logging-Best Practices","text":"<pre><code>// \u2705 RICHTIG: Strukturiertes Logging mit fmt-Syntax\nTHEMIS_INFO(\"Index erstellt: {}.{}\", table, column);\nTHEMIS_ERROR(\"Put fehlgeschlagen: {}, Key: {}\", status.message, key);\nTHEMIS_DEBUG(\"Cache hit: {}, Size: {} bytes\", pk, blob.size());\n\n// \u2705 RICHTIG: Sensible Daten vermeiden\nTHEMIS_INFO(\"User authenticated: id={}\", userId);  // OK\nTHEMIS_ERROR(\"Auth failed for user: {}\", username);  // \u274c PII!\n\n// \u2705 RICHTIG: Error-Kontext\nif (!db.put(key, value)) {\n    THEMIS_ERROR(\"RocksDB put failed: key={}, table={}\", key, table);\n}\n\n// \u274c FALSCH: std::cout/printf verwenden\nstd::cout &lt;&lt; \"Index created\\n\";  // NEIN! Nutze Logger\n</code></pre>"},{"location":"styleguide/#43-log-initialisierung","title":"4.3 Log-Initialisierung","text":"<pre><code>// main_server.cpp\nLogger::init(\"themis_server.log\", Logger::Level::INFO);\n\n// Runtime-\u00c4nderung\nLogger::setLevel(Logger::Level::DEBUG);\nLogger::setPattern(\"[%Y-%m-%d %H:%M:%S.%e] [%^%l%$] [thread %t] %v\");\n</code></pre>"},{"location":"styleguide/#5-code-struktur","title":"5. Code-Struktur","text":""},{"location":"styleguide/#51-klassen-layout","title":"5.1 Klassen-Layout","text":"<pre><code>class SecondaryIndexManager {\npublic:\n    // 1. Nested Types\n    struct Status { };\n    enum class IndexType { };\n\n    // 2. Konstruktoren\n    explicit SecondaryIndexManager(RocksDBWrapper&amp; db);\n\n    // 3. \u00d6ffentliche API (alphabetisch oder logisch gruppiert)\n    Status createIndex(std::string_view table, std::string_view column);\n    Status dropIndex(std::string_view table, std::string_view column);\n    bool hasIndex(std::string_view table, std::string_view column) const;\n\nprivate:\n    // 4. Private Helper-Methoden\n    std::string makeIndexKey_(std::string_view table, std::string_view column);\n\n    // 5. Member-Variablen (mit Unterstrich-Suffix)\n    RocksDBWrapper&amp; db_;\n    std::unordered_set&lt;std::string&gt; indexed_columns_;\n};\n</code></pre>"},{"location":"styleguide/#52-funktions-reihenfolge","title":"5.2 Funktions-Reihenfolge","text":"<ol> <li>\u00d6ffentliche API (Header + Implementierung)</li> <li>Private Helper (nur Implementierung)</li> <li>Static Utilities (am Ende)</li> </ol>"},{"location":"styleguide/#53-kommentare","title":"5.3 Kommentare","text":"<pre><code>// \u2705 RICHTIG: Doxygen-Style f\u00fcr \u00f6ffentliche APIs\n/**\n * @brief Create secondary index on table column\n * @param table Table name\n * @param column Column name\n * @param unique If true, enforce unique values\n * @return Status OK or Error with message\n */\nStatus createIndex(std::string_view table, std::string_view column, bool unique = false);\n\n// \u2705 RICHTIG: Inline-Kommentare f\u00fcr komplexe Logik\n// Calculate expire timestamp: now + TTL seconds\nauto now = std::chrono::system_clock::now();\nint64_t expireTimestamp = currentTimestamp + ttlSeconds;\n\n// \u274c FALSCH: Offensichtliches kommentieren\ni++;  // increment i\n</code></pre>"},{"location":"styleguide/#6-speicher-management","title":"6. Speicher-Management","text":""},{"location":"styleguide/#61-smart-pointers","title":"6.1 Smart Pointers","text":"<pre><code>// \u2705 RICHTIG: std::unique_ptr f\u00fcr Ownership\nstd::unique_ptr&lt;BaseEntity&gt; entity = std::make_unique&lt;BaseEntity&gt;(\"alice\");\n\n// \u2705 RICHTIG: std::shared_ptr f\u00fcr Shared Ownership\nmutable std::shared_ptr&lt;FieldMap&gt; field_cache_;\n\n// \u274c FALSCH: Raw Pointers (au\u00dfer f\u00fcr Nicht-Owning-References)\nBaseEntity* entity = new BaseEntity(\"alice\");  // NEIN!\n</code></pre>"},{"location":"styleguide/#62-string-handling","title":"6.2 String-Handling","text":"<pre><code>// \u2705 RICHTIG: std::string_view f\u00fcr Read-Only-Parameter\nvoid processKey(std::string_view key);\n\n// \u2705 RICHTIG: std::string f\u00fcr Ownership\nstd::string makeKey(std::string_view table, std::string_view pk) {\n    return std::string(table) + \":\" + std::string(pk);\n}\n\n// \u274c FALSCH: const char* (unsicher bei tempor\u00e4ren Strings)\nvoid processKey(const char* key);  // Verwende string_view!\n</code></pre>"},{"location":"styleguide/#7-testing-assertions","title":"7. Testing &amp; Assertions","text":""},{"location":"styleguide/#71-unit-tests-google-test","title":"7.1 Unit Tests (Google Test)","text":"<pre><code>TEST_F(SecondaryIndexTest, CreateIndex) {\n    auto status = idx_-&gt;createIndex(\"users\", \"age\");\n    ASSERT_TRUE(status.ok);\n\n    EXPECT_TRUE(idx_-&gt;hasIndex(\"users\", \"age\"));\n}\n\nTEST_F(SecondaryIndexTest, CreateIndex_EmptyTable) {\n    auto status = idx_-&gt;createIndex(\"\", \"age\");\n    EXPECT_FALSE(status.ok);\n    EXPECT_NE(status.message.find(\"table\"), std::string::npos);\n}\n</code></pre>"},{"location":"styleguide/#72-runtime-assertions-development","title":"7.2 Runtime-Assertions (Development)","text":"<pre><code>#include &lt;cassert&gt;\n\n// Nur in Debug-Builds\nassert(pk.size() &gt; 0 &amp;&amp; \"Primary key must not be empty\");\nassert(dim &gt; 0 &amp;&amp; \"Vector dimension must be positive\");\n</code></pre>"},{"location":"styleguide/#8-dokumentations-standards","title":"8. Dokumentations-Standards","text":""},{"location":"styleguide/#81-sprache","title":"8.1 Sprache","text":"<ul> <li>Code-Kommentare: Deutsch (Doku-Konsistenz)</li> <li>API-Doku (Doxygen): Deutsch</li> <li>Logs: Deutsch (Fehlermeldungen)</li> <li>Variablen/Funktionen: Englisch (etablierte Begriffe wie <code>getPrimaryKey</code>, <code>serialize</code>)</li> </ul>"},{"location":"styleguide/#82-markdown-dokumentation","title":"8.2 Markdown-Dokumentation","text":"<ul> <li>Dateinamen: <code>kebab-case.md</code> oder <code>snake_case.md</code> (z. B. <code>base_entity.md</code>)</li> <li>\u00dcberschriften: Eine <code>#</code> pro Datei, dann <code>##</code>-Abschnitte</li> <li>Code-Bl\u00f6cke: Sprache angeben (<code>cpp,</code>json, ```http)</li> <li>Verweise: Backticks f\u00fcr Code/Dateien (<code>src/server/http_server.cpp</code>)</li> </ul>"},{"location":"styleguide/#83-beispiel","title":"8.3 Beispiel","text":"<pre><code>## BaseEntity \u2013 Verwendung\n\n```cpp\n// Entity erstellen\nBaseEntity user = BaseEntity::fromJson(\"alice\", json_string);\n\n// Feld lesen\nauto name = user.getFieldAsString(\"name\");\nif (name) {\n    THEMIS_INFO(\"User: {}\", *name);\n}\n```\n\n**Siehe auch:** [RocksDB Storage](storage/rocksdb_layout.md)\n</code></pre>"},{"location":"styleguide/#9-performance-best-practices","title":"9. Performance-Best Practices","text":""},{"location":"styleguide/#91-vermeidung-von-kopien","title":"9.1 Vermeidung von Kopien","text":"<pre><code>// \u2705 RICHTIG: string_view f\u00fcr Parameter (keine Kopie)\nvoid processKey(std::string_view key);\n\n// \u2705 RICHTIG: const&amp; f\u00fcr gro\u00dfe Objekte\nvoid processEntity(const BaseEntity&amp; entity);\n\n// \u274c FALSCH: Pass-by-Value f\u00fcr gro\u00dfe Objekte\nvoid processEntity(BaseEntity entity);  // Kopiert Blob!\n</code></pre>"},{"location":"styleguide/#92-reserve-fur-vektoren","title":"9.2 Reserve f\u00fcr Vektoren","text":"<pre><code>// \u2705 RICHTIG: reserve() vor Push-Schleife\nstd::vector&lt;std::string&gt; keys;\nkeys.reserve(expectedSize);\nfor (...) {\n    keys.push_back(key);\n}\n</code></pre>"},{"location":"styleguide/#93-move-semantik","title":"9.3 Move-Semantik","text":"<pre><code>// \u2705 RICHTIG: std::move f\u00fcr Ownership-Transfer\nstd::string value = std::move(tempValue);\nbatch-&gt;put(key, std::move(blob));\n\n// \u2705 RICHTIG: Return-Value-Optimization (RVO)\nBaseEntity createEntity() {\n    BaseEntity entity(\"alice\");\n    // ... fill fields\n    return entity;  // RVO, keine Kopie\n}\n</code></pre>"},{"location":"styleguide/#10-definition-of-done-code","title":"10. Definition of Done (Code)","text":"<p>Bevor Code committed wird:</p> <ul> <li>[ ] Kompiliert ohne Warnings (MSVC <code>/W4</code>, GCC <code>-Wall -Wextra</code>)</li> <li>[ ] Unit Tests vorhanden und gr\u00fcn</li> <li>[ ] Logging an kritischen Stellen (Error Paths)</li> <li>[ ] Status-Objekt f\u00fcr Fehlerbehandlung (keine Exceptions in \u00f6ffentlichen APIs)</li> <li>[ ] Doxygen-Kommentare f\u00fcr \u00f6ffentliche APIs</li> <li>[ ] Code-Review abgeschlossen</li> <li>[ ] Dokumentation aktualisiert (wenn n\u00f6tig)</li> </ul>"},{"location":"styleguide/#11-definition-of-done-dokumentation","title":"11. Definition of Done (Dokumentation)","text":"<p>Bevor Doku als \"fertig\" gilt:</p> <ul> <li>[ ] Inhalt korrekt (mit Source-Code abgeglichen)</li> <li>[ ] Beispiele valide (kompilierbar/ausf\u00fchrbar)</li> <li>[ ] Interne Verweise funktionieren</li> <li>[ ] Navigation in <code>mkdocs.yml</code> verlinkt</li> <li>[ ] Rechtschreibung gepr\u00fcft (DE)</li> </ul>"},{"location":"styleguide/#referenzen","title":"Referenzen","text":"<ul> <li>Logger: <code>include/utils/logger.h</code></li> <li>Status Pattern: <code>include/index/secondary_index.h</code> (Status struct)</li> <li>BaseEntity: <code>include/storage/base_entity.h</code></li> <li>Google Test: https://github.com/google/googletest</li> <li>spdlog: https://github.com/gabime/spdlog</li> </ul>"},{"location":"temporal_graphs/","title":"Temporal Graphs - Themis","text":""},{"location":"temporal_graphs/#overview","title":"Overview","text":"<p>Themis' Temporal Graph implementation adds time-awareness to graph edges, enabling historical queries and point-in-time graph traversals. This is critical for tracking relationship evolution, knowledge graph versioning, and time-series network analysis.</p> <p>Key Features: - Temporal Edges: Edges with <code>valid_from</code> and <code>valid_to</code> timestamps - Point-in-Time Queries: Traverse graph as it existed at specific timestamp - Historical Analysis: Track how relationships changed over time - Flexible Validity: Unbounded intervals supported (null = forever/since beginning) - Efficient Filtering: Temporal checks integrated into BFS/Dijkstra algorithms</p>"},{"location":"temporal_graphs/#architecture","title":"Architecture","text":""},{"location":"temporal_graphs/#data-model","title":"Data Model","text":"<p>Temporal Edge Schema:</p> <pre><code>struct Edge {\n    std::string id;\n    std::string _from;              // Source node\n    std::string _to;                // Target node\n    double _weight = 1.0;           // Edge weight for pathfinding\n\n    // Temporal fields (optional)\n    std::optional&lt;int64_t&gt; valid_from;  // Start of validity (ms since epoch)\n    std::optional&lt;int64_t&gt; valid_to;    // End of validity (ms since epoch)\n}\n</code></pre> <p>Validity Semantics: - <code>valid_from = null</code>: Edge valid since beginning of time - <code>valid_to = null</code>: Edge valid indefinitely into future - <code>valid_from = T1, valid_to = T2</code>: Edge valid during interval [T1, T2] - Both <code>null</code>: Edge always valid (eternal)</p> <p>Temporal Filter Logic:</p> <pre><code>bool isValid(query_timestamp, valid_from, valid_to) {\n    if (valid_from.has_value() &amp;&amp; query_timestamp &lt; valid_from) {\n        return false;  // Not yet valid\n    }\n    if (valid_to.has_value() &amp;&amp; query_timestamp &gt; valid_to) {\n        return false;  // No longer valid\n    }\n    return true;  // Valid at query time\n}\n</code></pre>"},{"location":"temporal_graphs/#api-reference","title":"API Reference","text":""},{"location":"temporal_graphs/#c-api","title":"C++ API","text":""},{"location":"temporal_graphs/#1-bfs-at-time","title":"1. BFS At Time","text":"<p>Breadth-first search with temporal filtering.</p> <p>Signature:</p> <pre><code>std::pair&lt;Status, std::vector&lt;std::string&gt;&gt; bfsAtTime(\n    std::string_view startPk,\n    int64_t timestamp_ms,\n    int maxDepth = 3\n) const;\n</code></pre> <p>Parameters: - <code>startPk</code>: Starting node primary key - <code>timestamp_ms</code>: Query timestamp (milliseconds since epoch) - <code>maxDepth</code>: Maximum traversal depth</p> <p>Returns: - <code>Status</code>: Success/error status - <code>std::vector&lt;std::string&gt;</code>: Reachable nodes (BFS order)</p> <p>Example:</p> <pre><code>// Query: Which nodes could Alice reach in January 2023?\nauto [st, nodes] = graph_mgr-&gt;bfsAtTime(\"Alice\", 1672531200000, 5);\nif (st.ok) {\n    for (const auto&amp; node : nodes) {\n        std::cout &lt;&lt; \"Reachable: \" &lt;&lt; node &lt;&lt; \"\\n\";\n    }\n}\n</code></pre>"},{"location":"temporal_graphs/#2-dijkstra-at-time","title":"2. Dijkstra At Time","text":"<p>Shortest path with temporal filtering.</p> <p>Signature:</p> <pre><code>std::pair&lt;Status, PathResult&gt; dijkstraAtTime(\n    std::string_view startPk,\n    std::string_view targetPk,\n    int64_t timestamp_ms\n) const;\n</code></pre> <p>Returns: - <code>PathResult.path</code>: Nodes from start to target - <code>PathResult.totalCost</code>: Total path cost (sum of weights)</p> <p>Example:</p> <pre><code>// Query: Shortest path from Alice to CompanyX in 2022?\nauto [st, path] = graph_mgr-&gt;dijkstraAtTime(\"Alice\", \"CompanyX\", 1640995200000);\nif (st.ok) {\n    std::cout &lt;&lt; \"Path cost: \" &lt;&lt; path.totalCost &lt;&lt; \"\\n\";\n    for (const auto&amp; node : path.path) {\n        std::cout &lt;&lt; node &lt;&lt; \" -&gt; \";\n    }\n}\n</code></pre>"},{"location":"temporal_graphs/#aql-integration-future","title":"AQL Integration (Future)","text":"<p>Planned AQL syntax for temporal queries:</p> <pre><code>// Find all documents cited by Doc1 in 2022\nFOR v IN 1..3 OUTBOUND 'Doc1' citations\n    FILTER e.valid_from &lt;= @timestamp AND e.valid_to &gt;= @timestamp\n    RETURN v\n\n// Shortest path at specific time\nFOR p IN SHORTEST_PATH 'Alice' TO 'CompanyX' GRAPH employment_graph\n    FILTER PATH.ALL(e, e.valid_from &lt;= @timestamp AND e.valid_to &gt;= @timestamp)\n    RETURN p\n</code></pre>"},{"location":"temporal_graphs/#test-validation-30102025","title":"Test Validation (30.10.2025)","text":""},{"location":"temporal_graphs/#test-suite-18-tests-all-passed","title":"Test Suite: 18 Tests - ALL PASSED \u2705","text":""},{"location":"temporal_graphs/#unit-tests-temporalfilter","title":"Unit Tests (TemporalFilter)","text":"<p>Test 1: NoFilter_AcceptsAll \u2705 - Filter with <code>timestamp = null</code> accepts all edges - Validates unbounded interval support</p> <p>Test 2: WithTimestamp_FiltersCorrectly \u2705 - Edges before <code>valid_from</code> \u2192 rejected - Edges after <code>valid_to</code> \u2192 rejected - Edges during validity period \u2192 accepted - Unbounded intervals handled correctly</p> <p>Test 3: BoundaryConditions \u2705 - Query at exact <code>valid_from</code> \u2192 accepted - Query at exact <code>valid_to</code> \u2192 accepted - Edge valid only at query time \u2192 accepted</p>"},{"location":"temporal_graphs/#bfs-temporal-tests","title":"BFS Temporal Tests","text":"<p>Test 4: NoTemporalEdges_ReturnsAllNeighbors \u2705 - Graph without temporal constraints behaves normally - All nodes reachable regardless of timestamp</p> <p>Test 5: FiltersByValidFrom \u2705 - Edge A\u2192B valid from 2022 onwards - Query at 2021: Only A reachable - Query at 2023: A\u2192B\u2192C reachable</p> <p>Test 6: FiltersByValidTo \u2705 - Edge A\u2192B valid until 2022 - Query at 2021: Full graph accessible - Query at 2023: A isolated (edge expired)</p> <p>Test 7: FiltersByValidRange \u2705 - Edge A\u2192B valid from 2021 to 2023 - Query at 2020: A isolated - Query at 2022: Full graph - Query at 2024: A isolated</p> <p>Test 8: MultiplePathsOverTime \u2705 - Complex scenario: paths change over time - Period 2020-2021: A\u2192B\u2192D - Period 2022-2023: A\u2192C\u2192D - Period 2024+: Both paths active</p> <p>Test 9: IsolatedNodeAfterExpiration \u2705 - All outgoing edges expire - Node becomes isolated after expiration time</p>"},{"location":"temporal_graphs/#dijkstra-temporal-tests","title":"Dijkstra Temporal Tests","text":"<p>Test 10: FindsShortestPathAtTime \u2705 - Two paths: A\u2192B\u2192D (cost 2) and A\u2192C\u2192D (cost 6) - Before C\u2192D becomes valid: uses A\u2192B\u2192D - After both paths valid: still uses shorter path</p> <p>Test 11: PathChangesOverTime \u2705 - Path A\u2192B\u2192D valid 2020-2022 (cost 3) - Path A\u2192C\u2192D valid 2023+ (cost 2) - Algorithm correctly switches to cheaper path when available</p> <p>Test 12: NoPathAtTime \u2705 - All edges to target expired - Returns error: \"Kein Pfad gefunden\"</p>"},{"location":"temporal_graphs/#edge-cases","title":"Edge Cases","text":"<p>Test 13-15: Input Validation \u2705 - Empty node names \u2192 error - Negative depth \u2192 error - Proper error messages returned</p> <p>Test 16: MaxDepthZero_ReturnsOnlyStart \u2705 - Depth limit of 0 returns only starting node</p>"},{"location":"temporal_graphs/#real-world-scenarios","title":"Real-World Scenarios","text":"<p>Test 17: EmploymentHistory \u2705 - Models: Alice worked at CompanyA (2020-2022), CompanyB (2023+) - Query 2021: Alice\u2192CompanyA - Query 2023: Alice\u2192CompanyB</p> <p>Test 18: KnowledgeGraphEvolution \u2705 - Document citation network evolves over time - Citations added/retracted - Historical queries return correct citation graph state</p>"},{"location":"temporal_graphs/#use-cases","title":"Use Cases","text":""},{"location":"temporal_graphs/#1-employmentorganizational-networks","title":"1. Employment/Organizational Networks","text":"<p>Track employee-company relationships over time:</p> <pre><code>// Create temporal employment edge\nauto e1 = createTemporalEdge(\n    \"emp1\",\n    \"Alice\",\n    \"CompanyA\",\n    toTimestamp(2020, 1, 1),  // started Jan 2020\n    toTimestamp(2022, 12, 31) // ended Dec 2022\n);\ngraph_mgr-&gt;addEdge(e1);\n\n// Query: Where did Alice work in 2021?\nauto [st, nodes] = graph_mgr-&gt;bfsAtTime(\"Alice\", toTimestamp(2021, 6, 1), 1);\n// Returns: [\"Alice\", \"CompanyA\"]\n</code></pre>"},{"location":"temporal_graphs/#2-knowledge-graph-versioning","title":"2. Knowledge Graph Versioning","text":"<p>Track evolving knowledge and citations:</p> <pre><code>// Citation retracted in 2023\nauto cite = createTemporalEdge(\n    \"cite1\",\n    \"Paper1\",\n    \"Paper2\",\n    toTimestamp(2020, 1, 1),\n    toTimestamp(2023, 1, 1)  // retracted\n);\n\n// Query: What did Paper1 cite in 2021?\nauto [st, citations] = graph_mgr-&gt;bfsAtTime(\"Paper1\", toTimestamp(2021, 1, 1), 1);\n// Returns: [\"Paper1\", \"Paper2\"]\n\n// Query: What does Paper1 cite in 2024?\nauto [st2, citations2] = graph_mgr-&gt;bfsAtTime(\"Paper1\", toTimestamp(2024, 1, 1), 1);\n// Returns: [\"Paper1\"] (citation retracted)\n</code></pre>"},{"location":"temporal_graphs/#3-social-network-evolution","title":"3. Social Network Evolution","text":"<p>Model friendships, follows, and connections over time:</p> <pre><code>// Alice followed Bob from 2020-2022, then unfollowed\nauto follow = createTemporalEdge(\n    \"follow1\",\n    \"Alice\",\n    \"Bob\",\n    toTimestamp(2020, 1, 1),\n    toTimestamp(2022, 12, 31)\n);\n\n// Query: Who could Alice reach in 2021?\nauto [st, network] = graph_mgr-&gt;bfsAtTime(\"Alice\", toTimestamp(2021, 1, 1), 2);\n// Returns: Alice's network including Bob\n\n// Query: Who can Alice reach in 2023?\nauto [st2, network2] = graph_mgr-&gt;bfsAtTime(\"Alice\", toTimestamp(2023, 1, 1), 2);\n// Returns: Alice's network excluding Bob\n</code></pre>"},{"location":"temporal_graphs/#4-infrastructurenetwork-changes","title":"4. Infrastructure/Network Changes","text":"<p>Track network topology changes:</p> <pre><code>// Router1 -&gt; Router2 link active 2020-2022\n// Router1 -&gt; Router3 link active 2023+\n// Query shortest path at different times\nauto [st1, path1] = graph_mgr-&gt;dijkstraAtTime(\"Router1\", \"Server1\", toTimestamp(2021, 1, 1));\nauto [st2, path2] = graph_mgr-&gt;dijkstraAtTime(\"Router1\", \"Server1\", toTimestamp(2024, 1, 1));\n// Paths differ based on network topology at query time\n</code></pre>"},{"location":"temporal_graphs/#performance-considerations","title":"Performance Considerations","text":""},{"location":"temporal_graphs/#current-implementation","title":"Current Implementation","text":"<p>Time Complexity: - BFS at time: O(V + E * T) where T = edge load time - Dijkstra at time: O((V + E) * log V * T)</p> <p>Edge Load Overhead: Each edge requires: 1. RocksDB Get (~1-2ms for SSD) 2. Deserialization (~0.1ms) 3. Temporal filter check (~0.001ms)</p> <p>Optimization Strategies:</p> <ol> <li> <p>Batch Edge Loading: <code>cpp    // Instead of individual Gets, use MultiGet    std::vector&lt;std::string&gt; edge_keys;    for (auto&amp; adj : adjacency) {        edge_keys.push_back(makeGraphEdgeKey(adj.edgeId));    }    auto edges = db_.multiGet(edge_keys);  // Single batch call</code></p> </li> <li> <p>Temporal Index: <code>cpp    // Secondary index: valid_at_timestamp -&gt; [edge_ids]    // Enables fast \"give me all edges valid at time T\"    Key: \"temporal_index:2023-01-01:edge1\" -&gt; \"\"</code></p> </li> <li> <p>Caching: <code>cpp    // Cache edge validity info (avoid deserialization)    struct EdgeValidityCache {        std::string edge_id;        std::optional&lt;int64_t&gt; valid_from;        std::optional&lt;int64_t&gt; valid_to;    };</code></p> </li> </ol>"},{"location":"temporal_graphs/#limitations-future-enhancements","title":"Limitations &amp; Future Enhancements","text":""},{"location":"temporal_graphs/#current-limitations","title":"Current Limitations","text":"<ol> <li>No Temporal Aggregation: Cannot query \"How many times did this edge exist?\"</li> <li>No Event Streams: Cannot subscribe to temporal changes</li> <li>Single Timestamp Queries: No interval queries (e.g., \"valid anytime during 2020-2022\")</li> <li>No Temporal Joins: Cannot correlate temporal patterns across graphs</li> </ol>"},{"location":"temporal_graphs/#planned-enhancements-sprint-c","title":"Planned Enhancements (Sprint C+)","text":"<ol> <li> <p>Temporal Range Queries: <code>cpp    // Find all edges that were ever valid during interval    auto edges = graph_mgr-&gt;getEdgesValidDuring(t_start, t_end);</code></p> </li> <li> <p>Temporal Aggregations: <code>cpp    // How long was this edge valid?    auto duration = graph_mgr-&gt;getTotalValidDuration(edge_id);</code></p> </li> <li> <p>AQL Integration: <code>aql    FOR v IN 1..3 OUTBOUND 'Doc1' citations        OPTIONS {timestamp: @query_time}        RETURN v</code></p> </li> <li> <p>Temporal Predicates: <code>aql    // Find nodes reachable at ANY point during 2022    FOR v IN 1..3 OUTBOUND 'Alice' friends        FILTER e.valid_from &lt;= '2022-12-31' AND e.valid_to &gt;= '2022-01-01'        RETURN DISTINCT v</code></p> </li> <li> <p>Change Stream: <code>cpp    // Subscribe to temporal edge changes    graph_mgr-&gt;watchTemporalChanges(callback);</code></p> </li> </ol>"},{"location":"temporal_graphs/#implementation-notes","title":"Implementation Notes","text":""},{"location":"temporal_graphs/#temporal-filter","title":"Temporal Filter","text":"<p>Located in <code>include/index/temporal_graph.h</code>:</p> <pre><code>struct TemporalFilter {\n    std::optional&lt;int64_t&gt; timestamp_ms;\n\n    bool isValid(std::optional&lt;int64_t&gt; valid_from, \n                 std::optional&lt;int64_t&gt; valid_to) const {\n        if (!timestamp_ms.has_value()) return true;  // No filter\n\n        int64_t t = *timestamp_ms;\n        if (valid_from.has_value() &amp;&amp; t &lt; *valid_from) return false;\n        if (valid_to.has_value() &amp;&amp; t &gt; *valid_to) return false;\n        return true;\n    }\n\n    static TemporalFilter now();\n    static TemporalFilter at(int64_t timestamp_ms);\n    static TemporalFilter all();  // No temporal filtering\n};\n</code></pre>"},{"location":"temporal_graphs/#bfs-implementation","title":"BFS Implementation","text":"<p>Located in <code>src/index/graph_index.cpp</code>:</p> <pre><code>std::pair&lt;Status, std::vector&lt;std::string&gt;&gt; \nGraphIndexManager::bfsAtTime(std::string_view startPk, \n                             int64_t timestamp_ms, \n                             int maxDepth) const {\n    TemporalFilter filter = TemporalFilter::at(timestamp_ms);\n\n    // Standard BFS with temporal edge filtering\n    for (const auto&amp; info : adjacency) {\n        // Load edge to check validity\n        BaseEntity edge = BaseEntity::deserialize(edgeKey, *blob);\n\n        std::optional&lt;int64_t&gt; valid_from = edge.getFieldAsInt(\"valid_from\");\n        std::optional&lt;int64_t&gt; valid_to = edge.getFieldAsInt(\"valid_to\");\n\n        if (!filter.isValid(valid_from, valid_to)) {\n            continue;  // Skip invalid edge\n        }\n\n        // Process valid neighbor\n        // ...\n    }\n}\n</code></pre>"},{"location":"temporal_graphs/#testing","title":"Testing","text":""},{"location":"temporal_graphs/#run-temporal-graph-tests","title":"Run Temporal Graph Tests","text":"<pre><code># Run all temporal graph tests\ncd build\n.\\Release\\themis_tests.exe --gtest_filter=\"TemporalGraphTest.*\"\n\n# Expected output:\n# [==========] Running 18 tests from 1 test suite.\n# [  PASSED  ] 18 tests.\n</code></pre>"},{"location":"temporal_graphs/#test-coverage","title":"Test Coverage","text":"<ul> <li>\u2705 TemporalFilter logic (3 tests)</li> <li>\u2705 BFS temporal traversal (6 tests)</li> <li>\u2705 Dijkstra shortest path (3 tests)</li> <li>\u2705 Edge cases &amp; validation (3 tests)</li> <li>\u2705 Real-world scenarios (3 tests)</li> </ul> <p>Total: 18 tests, 100% passing</p>"},{"location":"temporal_graphs/#configuration","title":"Configuration","text":""},{"location":"temporal_graphs/#enable-temporal-graph-default-enabled","title":"Enable Temporal Graph (Default: Enabled)","text":"<p>No special configuration required - temporal edges work alongside regular edges.</p> <p>Optional: Temporal Index (Future):</p> <pre><code>{\n  \"graph\": {\n    \"temporal_index\": true,\n    \"temporal_cache_size_mb\": 256\n  }\n}\n</code></pre>"},{"location":"temporal_graphs/#summary","title":"Summary","text":"<p>Sprint B - Temporal Graphs: \u2705 PRODUCTION READY</p> <ul> <li>\u2705 Temporal edge support with <code>valid_from</code>/<code>valid_to</code></li> <li>\u2705 BFS at time implementation</li> <li>\u2705 Dijkstra at time implementation</li> <li>\u2705 18 comprehensive Google Tests (all passing)</li> <li>\u2705 Real-world scenario validation</li> <li>\u2705 Documentation complete</li> </ul> <p>Use Cases Validated: - Employment history tracking - Knowledge graph versioning - Social network evolution - Infrastructure change management</p> <p>Next Steps: - Temporal range queries - AQL integration - Temporal aggregations - Change streams</p>"},{"location":"temporal_time_range_queries/","title":"Temporal Time-Range Queries","text":"<p>Status: \u2705 Implemented &amp; Tested (8/8 tests passing) Feature: Extended temporal graph queries with time-window filtering Date: 2025-01-15</p>"},{"location":"temporal_time_range_queries/#overview","title":"Overview","text":"<p>This feature extends Themis's temporal graph capabilities from single-timestamp queries to time-range queries. You can now find all edges that overlap with or are fully contained within a specified time window.</p>"},{"location":"temporal_time_range_queries/#use-cases","title":"Use Cases","text":"<ul> <li>Audit Queries: \"Show all relationships valid during Q4 2024\"</li> <li>Compliance: \"Find edges fully contained within investigation period\"</li> <li>Historical Analysis: \"What connections existed between 2020-2022?\"</li> <li>Temporal Analytics: \"Relationships overlapping with event timeframe\"</li> </ul>"},{"location":"temporal_time_range_queries/#api-reference","title":"API Reference","text":""},{"location":"temporal_time_range_queries/#timerangefilter-structure","title":"TimeRangeFilter Structure","text":"<pre><code>struct TimeRangeFilter {\n    int64_t start_ms;  // Range start (milliseconds since epoch)\n    int64_t end_ms;    // Range end (milliseconds since epoch)\n\n    // Factory methods\n    static TimeRangeFilter between(int64_t start, int64_t end);\n    static TimeRangeFilter since(int64_t start);\n    static TimeRangeFilter until(int64_t end);\n    static TimeRangeFilter all();\n\n    // Filtering methods\n    bool hasOverlap(std::optional&lt;int64_t&gt; edge_valid_from, \n                    std::optional&lt;int64_t&gt; edge_valid_to) const;\n    bool fullyContains(std::optional&lt;int64_t&gt; edge_valid_from,\n                       std::optional&lt;int64_t&gt; edge_valid_to) const;\n};\n</code></pre>"},{"location":"temporal_time_range_queries/#edgeinfo-structure","title":"EdgeInfo Structure","text":"<pre><code>struct EdgeInfo {\n    std::string edgeId;                     // Edge identifier\n    std::string fromPk;                     // Source node primary key\n    std::string toPk;                       // Target node primary key\n    std::optional&lt;int64_t&gt; valid_from;      // Edge valid from (ms)\n    std::optional&lt;int64_t&gt; valid_to;        // Edge valid to (ms)\n};\n</code></pre>"},{"location":"temporal_time_range_queries/#query-methods","title":"Query Methods","text":""},{"location":"temporal_time_range_queries/#global-time-range-query","title":"Global Time-Range Query","text":"<pre><code>std::pair&lt;Status, std::vector&lt;EdgeInfo&gt;&gt; \ngetEdgesInTimeRange(int64_t range_start_ms, \n                    int64_t range_end_ms,\n                    bool require_full_containment = false) const;\n</code></pre> <p>Parameters: - <code>range_start_ms</code>: Query time window start (milliseconds since epoch) - <code>range_end_ms</code>: Query time window end (milliseconds since epoch) - <code>require_full_containment</code>:    - <code>false</code> (default): Returns edges with any overlap with query window   - <code>true</code>: Returns edges fully contained within query window</p> <p>Returns:  - <code>Status</code>: Operation success/failure - <code>vector&lt;EdgeInfo&gt;</code>: All matching edges with temporal metadata</p> <p>Time Complexity: O(E) where E = total edges in database</p>"},{"location":"temporal_time_range_queries/#node-specific-time-range-query","title":"Node-Specific Time-Range Query","text":"<pre><code>std::pair&lt;Status, std::vector&lt;EdgeInfo&gt;&gt;\ngetOutEdgesInTimeRange(std::string_view fromPk,\n                       int64_t range_start_ms,\n                       int64_t range_end_ms, \n                       bool require_full_containment = false) const;\n</code></pre> <p>Parameters: - <code>fromPk</code>: Source node primary key - <code>range_start_ms</code>: Query time window start (milliseconds since epoch) - <code>range_end_ms</code>: Query time window end (milliseconds since epoch) - <code>require_full_containment</code>: Same as global query</p> <p>Returns:  - <code>Status</code>: Operation success/failure - <code>vector&lt;EdgeInfo&gt;</code>: All matching outgoing edges from <code>fromPk</code></p> <p>Time Complexity: O(d) where d = out-degree of node</p>"},{"location":"temporal_time_range_queries/#usage-examples","title":"Usage Examples","text":""},{"location":"temporal_time_range_queries/#example-1-overlap-query-default","title":"Example 1: Overlap Query (Default)","text":"<p>Find all edges with any overlap with time window [1000, 2000]:</p> <pre><code>GraphIndexManager graph(db);\n\n// Add edges with different temporal periods\nBaseEntity e1(\"edge1\");\ne1.setField(\"_from\", \"A\");\ne1.setField(\"_to\", \"B\");\ne1.setField(\"valid_from\", 500);   // Partially overlaps\ne1.setField(\"valid_to\", 1500);\ngraph.addEdge(e1);\n\nBaseEntity e2(\"edge2\");\ne2.setField(\"_from\", \"A\");\ne2.setField(\"_to\", \"C\");\ne2.setField(\"valid_from\", 1200);  // Fully inside\ne2.setField(\"valid_to\", 1800);\ngraph.addEdge(e2);\n\nBaseEntity e3(\"edge3\");\ne3.setField(\"_from\", \"B\");\ne3.setField(\"_to\", \"C\");\ne3.setField(\"valid_from\", 2500);  // No overlap\ne3.setField(\"valid_to\", 3000);\ngraph.addEdge(e3);\n\n// Query: Find edges overlapping [1000, 2000]\nauto [status, edges] = graph.getEdgesInTimeRange(1000, 2000);\n\n// Result: edges = [edge1, edge2]\n// edge1: overlaps (500-1500 overlaps with 1000-2000)\n// edge2: fully inside (1200-1800 inside 1000-2000)\n// edge3: no overlap (2500-3000 is after 2000)\n</code></pre>"},{"location":"temporal_time_range_queries/#example-2-full-containment-query","title":"Example 2: Full Containment Query","text":"<p>Find edges fully contained within time window [1000, 3000]:</p> <pre><code>// Same edges as Example 1\n\n// Query: Find edges FULLY INSIDE [1000, 3000]\nauto [status, edges] = graph.getEdgesInTimeRange(1000, 3000, true);\n\n// Result: edges = [edge2, edge3]\n// edge1: NOT included (500-1500 starts before 1000)\n// edge2: included (1200-1800 fully inside 1000-3000)\n// edge3: included (2500-3000 fully inside 1000-3000)\n</code></pre>"},{"location":"temporal_time_range_queries/#example-3-node-specific-time-range-query","title":"Example 3: Node-Specific Time-Range Query","text":"<p>Find outgoing edges from specific node in time window:</p> <pre><code>// Add edges from node \"user1\"\nBaseEntity e1(\"follow1\");\ne1.setField(\"_from\", \"user1\");\ne1.setField(\"_to\", \"user2\");\ne1.setField(\"valid_from\", 1000000);\ne1.setField(\"valid_to\", 2000000);\ngraph.addEdge(e1);\n\nBaseEntity e2(\"follow2\");\ne2.setField(\"_from\", \"user1\");\ne2.setField(\"_to\", \"user3\");\ne2.setField(\"valid_from\", 1500000);\ne2.setField(\"valid_to\", 2500000);\ngraph.addEdge(e2);\n\nBaseEntity e3(\"follow3\");\ne3.setField(\"_from\", \"user2\");  // Different source!\ne3.setField(\"_to\", \"user3\");\ne3.setField(\"valid_from\", 1200000);\ne3.setField(\"valid_to\", 1800000);\ngraph.addEdge(e3);\n\n// Query: Find user1's outgoing edges in [1100000, 1900000]\nauto [status, edges] = graph.getOutEdgesInTimeRange(\"user1\", 1100000, 1900000);\n\n// Result: edges = [follow1, follow2]\n// follow1: from user1, overlaps query window\n// follow2: from user1, overlaps query window\n// follow3: NOT included (from user2, not user1)\n</code></pre>"},{"location":"temporal_time_range_queries/#example-4-unbounded-edges-always-valid","title":"Example 4: Unbounded Edges (Always Valid)","text":"<p>Edges without <code>valid_from</code>/<code>valid_to</code> match all time queries:</p> <pre><code>BaseEntity unbounded(\"always_active\");\nunbounded.setField(\"_from\", \"A\");\nunbounded.setField(\"_to\", \"B\");\n// NO valid_from/valid_to fields = unbounded temporal range\ngraph.addEdge(unbounded);\n\nBaseEntity bounded(\"temporary\");\nbounded.setField(\"_from\", \"A\");\nbounded.setField(\"_to\", \"C\");\nbounded.setField(\"valid_from\", 1000);\nbounded.setField(\"valid_to\", 2000);\ngraph.addEdge(bounded);\n\n// Query: Find edges in [500, 1500]\nauto [status, edges] = graph.getEdgesInTimeRange(500, 1500);\n\n// Result: edges = [always_active, temporary]\n// always_active: unbounded edges always included\n// temporary: 1000-2000 overlaps 500-1500\n</code></pre>"},{"location":"temporal_time_range_queries/#filtering-semantics","title":"Filtering Semantics","text":""},{"location":"temporal_time_range_queries/#overlap-vs-full-containment","title":"Overlap vs. Full Containment","text":"<p>Overlap (<code>require_full_containment = false</code>): - Default behavior - Returns edges with any temporal overlap with query window - Includes partially overlapping edges - Formula: <code>edge_start &lt;= query_end AND edge_end &gt;= query_start</code></p> <p>Full Containment (<code>require_full_containment = true</code>): - Strict containment - Returns edges fully inside query window - Excludes partially overlapping edges - Formula: <code>edge_start &gt;= query_start AND edge_end &lt;= query_end</code></p>"},{"location":"temporal_time_range_queries/#timerangefilter-behavior","title":"TimeRangeFilter Behavior","text":"Edge Period Query Window hasOverlap() fullyContains() [500, 1500] [1000, 2000] \u2705 true \u274c false [1200, 1800] [1000, 2000] \u2705 true \u2705 true [2500, 3000] [1000, 2000] \u274c false \u274c false [null, null] [1000, 2000] \u2705 true \u2705 true [500, null] [1000, 2000] \u2705 true \u274c false [null, 3000] [1000, 2000] \u2705 true \u274c false <p>Unbounded Edges: - Edges without <code>valid_from</code>/<code>valid_to</code> are treated as unbounded (always valid) - <code>hasOverlap()</code> always returns <code>true</code> for unbounded edges - <code>fullyContains()</code> always returns <code>true</code> for unbounded edges</p>"},{"location":"temporal_time_range_queries/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"temporal_time_range_queries/#global-query-getedgesintimerange","title":"Global Query: <code>getEdgesInTimeRange()</code>","text":"<ul> <li>Time Complexity: O(E) where E = total edges in database</li> <li>Space Complexity: O(R) where R = number of matching edges</li> <li>Database Scans: Full scan of <code>graph:out:*</code> prefix</li> <li>Entity Loads: One <code>db.get(\"edge:*\")</code> per edge</li> </ul> <p>Optimization Opportunities: - Add temporal index for bounded time ranges - Sorted temporal B-tree for range scans - Materialized views for common time windows</p>"},{"location":"temporal_time_range_queries/#node-specific-query-getoutedgesintimerange","title":"Node-Specific Query: <code>getOutEdgesInTimeRange()</code>","text":"<ul> <li>Time Complexity: O(d) where d = out-degree of source node</li> <li>Space Complexity: O(R) where R = number of matching edges</li> <li>Database Scans: Prefix scan of <code>graph:out:&lt;fromPk&gt;:*</code></li> <li>Entity Loads: One <code>db.get(\"edge:*\")</code> per outgoing edge</li> </ul> <p>Much Faster Than Global Query: - Only scans edges from specific node - Leverages existing <code>graph:out:</code> adjacency index - Suitable for high-frequency queries on specific nodes</p>"},{"location":"temporal_time_range_queries/#implementation-details","title":"Implementation Details","text":""},{"location":"temporal_time_range_queries/#key-schema","title":"Key Schema","text":"<pre><code># Edge entity storage\nedge:&lt;edge_id&gt; -&gt; BaseEntity(id, _from, _to, valid_from, valid_to, ...)\n\n# Graph adjacency indices (temporal data stored in entity, not index)\ngraph:out:&lt;from_pk&gt;:&lt;edge_id&gt; -&gt; &lt;to_pk&gt;\ngraph:in:&lt;to_pk&gt;:&lt;edge_id&gt; -&gt; &lt;from_pk&gt;\n</code></pre> <p>Design Choice: - Temporal fields (<code>valid_from</code>, <code>valid_to</code>) stored in edge entity, not in index keys - Requires entity load to check temporal bounds - Simplifies index structure (no temporal key encoding) - Trade-off: Extra <code>db.get()</code> per edge vs. complex temporal index</p>"},{"location":"temporal_time_range_queries/#algorithm-getedgesintimerange","title":"Algorithm (getEdgesInTimeRange)","text":"<pre><code>1. Create TimeRangeFilter from query parameters\n2. Scan all edges with prefix \"graph:out:\"\n3. For each edge key \"graph:out:&lt;from&gt;:&lt;edgeId&gt;\":\n   a. Parse edgeId from key\n   b. Load edge entity from \"edge:&lt;edgeId&gt;\"\n   c. Extract valid_from, valid_to fields\n   d. Check temporal match (overlap or containment)\n   e. If match, add EdgeInfo to results\n4. Return filtered results\n</code></pre>"},{"location":"temporal_time_range_queries/#algorithm-getoutedgesintimerange","title":"Algorithm (getOutEdgesInTimeRange)","text":"<pre><code>1. Create TimeRangeFilter from query parameters\n2. Scan edges with prefix \"graph:out:&lt;fromPk&gt;:\"\n3. For each edge (same as global query):\n   a-e. (identical to global query)\n4. Return filtered results\n</code></pre>"},{"location":"temporal_time_range_queries/#testing","title":"Testing","text":""},{"location":"temporal_time_range_queries/#test-coverage-88-passing","title":"Test Coverage (8/8 Passing)","text":"<ol> <li>TimeRangeFilter_Overlap - Filter logic: overlap detection</li> <li>TimeRangeFilter_FullContainment - Filter logic: containment check</li> <li>GetEdgesInTimeRange_Overlap - Global query: overlap mode</li> <li>GetEdgesInTimeRange_FullContainment - Global query: containment mode</li> <li>GetOutEdgesInTimeRange - Node-specific query: basic functionality</li> <li>GetOutEdgesInTimeRange_NoMatch - Node-specific query: no results</li> <li>UnboundedEdges_AlwaysIncluded - Unbounded edges match all queries</li> <li>EdgeInfo_ContainsTemporalData - Result structure validation</li> </ol>"},{"location":"temporal_time_range_queries/#test-file","title":"Test File","text":"<pre><code># Run all time-range tests\n./themis_tests --gtest_filter=\"TimeRangeQueryTest.*\"\n\n# Expected output:\n# [  PASSED  ] 8 tests.\n</code></pre>"},{"location":"temporal_time_range_queries/#integration-with-existing-features","title":"Integration with Existing Features","text":""},{"location":"temporal_time_range_queries/#works-with-recursive-path-queries","title":"Works With Recursive Path Queries","text":"<pre><code>// Step 1: Find temporal path\nRecursivePathQuery rpq;\nrpq.start_node = \"user1\";\nrpq.end_node = \"user5\";\nrpq.max_depth = 3;\nrpq.valid_from = 1500000;  // Single timestamp\nrpq.valid_to = 1500000;\nauto [status, path] = queryEngine.executeRecursivePathQuery(rpq);\n\n// Step 2: Verify all edges in path valid during time window\nauto [st, edges] = graph.getEdgesInTimeRange(1400000, 1600000);\nfor (const auto&amp; edgeInfo : edges) {\n    // Check if edge in path is valid throughout window\n}\n</code></pre>"},{"location":"temporal_time_range_queries/#temporal-graph-capabilities","title":"Temporal Graph Capabilities","text":"Feature Single Timestamp Time Range Status BFS/Dijkstra at time T \u2705 <code>bfsAtTime()</code> \u274c Implemented Shortest path at time T \u2705 <code>dijkstraAtTime()</code> \u274c Implemented Find edges in window \u274c \u2705 <code>getEdgesInTimeRange()</code> Implemented \u2728 Find node edges in window \u274c \u2705 <code>getOutEdgesInTimeRange()</code> Implemented \u2728 Temporal aggregation \u274c \u274c Future work"},{"location":"temporal_time_range_queries/#future-enhancements","title":"Future Enhancements","text":""},{"location":"temporal_time_range_queries/#1-temporal-index","title":"1. Temporal Index","text":"<p>Problem: O(E) scan for global queries Solution: B-tree index on <code>(valid_from, valid_to)</code> pairs</p> <pre><code>// Hypothetical API\nauto edges = graph.getEdgesInTimeRange_Indexed(1000, 2000);\n// Time complexity: O(log E + R) vs. current O(E)\n</code></pre>"},{"location":"temporal_time_range_queries/#2-time-window-path-queries","title":"2. Time-Window Path Queries","text":"<p>Problem: Current path queries use single timestamp Solution: Extend <code>RecursivePathQuery</code> with time windows</p> <pre><code>RecursivePathQuery rpq;\nrpq.window_start = 1000000;\nrpq.window_end = 2000000;\n// Find paths where ALL edges valid during [1000000, 2000000]\n</code></pre>"},{"location":"temporal_time_range_queries/#3-temporal-aggregations","title":"3. Temporal Aggregations","text":"<p>Problem: No aggregate queries over time windows Solution: Add temporal statistics</p> <pre><code>auto stats = graph.getTemporalStats(1000, 2000);\n// { edge_count, avg_duration, node_degree_distribution, ... }\n</code></pre>"},{"location":"temporal_time_range_queries/#4-streaming-time-range-queries","title":"4. Streaming Time-Range Queries","text":"<p>Problem: Large result sets exhaust memory Solution: Iterator-based API</p> <pre><code>auto iter = graph.streamEdgesInTimeRange(1000, 2000);\nwhile (iter.hasNext()) {\n    EdgeInfo edge = iter.next();\n    // Process one edge at a time\n}\n</code></pre>"},{"location":"temporal_time_range_queries/#known-limitations","title":"Known Limitations","text":"<ol> <li>No Temporal Index: Global queries scan all edges (O(E))</li> <li>Entity Load Overhead: One <code>db.get()</code> per edge (network/disk I/O)</li> <li>No Streaming API: Large result sets loaded into memory</li> <li>No Temporal Joins: Cannot join time-range results with other queries</li> <li>No Unbounded Query Optimization: Unbounded edges checked even when range is bounded</li> </ol>"},{"location":"temporal_time_range_queries/#changelog","title":"Changelog","text":"<ul> <li>2025-01-15: Initial implementation</li> <li>Added <code>TimeRangeFilter</code> structure to <code>temporal_graph.h</code></li> <li>Added <code>EdgeInfo</code> structure to <code>graph_index.h</code></li> <li>Implemented <code>getEdgesInTimeRange()</code> in <code>graph_index.cpp</code></li> <li>Implemented <code>getOutEdgesInTimeRange()</code> in <code>graph_index.cpp</code></li> <li>Created 8 comprehensive tests (all passing)</li> <li>Documentation created</li> </ul>"},{"location":"temporal_time_range_queries/#see-also","title":"See Also","text":"<ul> <li>Recursive Path Queries - Multi-hop temporal reasoning</li> <li>Temporal Graph Design - Overall temporal architecture</li> <li>Graph Index - Adjacency index design</li> <li>MVCC Design - Transaction temporal semantics</li> </ul>"},{"location":"time_series/","title":"Time-Series Engine (TSStore)","text":"<p>Stand: Implementiert und per HTTP-API nutzbar. Diese Seite ist mit dem Quellcode abgeglichen.</p>"},{"location":"time_series/#uberblick","title":"\u00dcberblick","text":"<p>Funktionen: - Speicherung von Zeitreihenpunkten in RocksDB (Schl\u00fcssel-Schema <code>ts:{metric}:{entity}:{timestamp_ms}</code>) - Abfragen \u00fcber Zeitbereiche mit Filter (Metric, Entity, Tags) und Limit - On-the-fly Aggregationen: min, max, avg, sum, count - Manuelle Retention (global oder pro Metric) - Kontinuierliche Aggregationen (abgeleitete Metriken) \u2013 MVP-Hilfsklasse - Optionaler Gorilla-Codec (f\u00fcr zuk\u00fcnftige Blockspeicherung)</p> <p>Hinweis zur Implementierung: - Canonical ist <code>TSStore</code> (mit Tags/Metadata). <code>TimeSeriesStore</code> ist eine einfachere Variante und wird serverseitig nur f\u00fcr \u00dcbergangstypen verwendet.</p>"},{"location":"time_series/#komponenten","title":"Komponenten","text":"<ul> <li>TSStore (<code>include/timeseries/tsstore.h</code>): Haupt-API (DataPoint, QueryOptions, AggregationResult)</li> <li>TimeSeriesStore (<code>include/timeseries/timeseries.h</code>): einfache Struktur (nur Wert/Meta), legacy</li> <li>RetentionManager (<code>include/timeseries/retention.h</code>): setzt per-Metrik-Retention um</li> <li>ContinuousAggregateManager (<code>include/timeseries/continuous_agg.h</code>): erstellt abgeleitete Metriken in Fenstern</li> <li>Gorilla-Codec (Tests/Utils): Kompression f\u00fcr (timestamp,double)</li> </ul>"},{"location":"time_series/#datenmodell-tsstore","title":"Datenmodell (TSStore)","text":"<p>Key: <code>ts:{metric}:{entity}:{timestamp_ms}</code></p> <p>DataPoint:</p> <pre><code>{\n  \"metric\": \"cpu\",\n  \"entity\": \"server01\",\n  \"timestamp_ms\": 1700000000000,\n  \"value\": 0.73,\n  \"tags\": { \"env\": \"prod\" },\n  \"metadata\": {}\n}\n</code></pre> <p>QueryOptions:</p> <pre><code>{\n  \"metric\": \"cpu\",\n  \"entity\": \"server01\",      // optional in TSStore, im HTTP-API derzeit erforderlich\n  \"from_ms\": 0,\n  \"to_ms\": 9223372036854775807,\n  \"limit\": 1000,\n  \"tag_filter\": { \"env\": \"prod\" } // exakter Match\n}\n</code></pre> <p>AggregationResult:</p> <pre><code>{\n  \"min\": 0.1,\n  \"max\": 0.9,\n  \"avg\": 0.5,\n  \"sum\": 5.0,\n  \"count\": 10,\n  \"first_timestamp_ms\": 1700000000000,\n  \"last_timestamp_ms\": 1700000060000\n}\n</code></pre> <p>Wichtige Methoden (TSStore): - <code>putDataPoint(DataPoint)</code> / <code>putDataPoints([...])</code> - <code>query(QueryOptions)</code> \u2192 <code>(Status, vector&lt;DataPoint&gt;)</code> - <code>aggregate(QueryOptions)</code> \u2192 <code>(Status, AggregationResult)</code> - <code>getStats()</code> \u2192 <code>Stats</code> - <code>deleteOldData(cutoff_ms)</code> / <code>deleteOldDataForMetric(metric, cutoff_ms)</code> / <code>deleteMetric(metric)</code></p>"},{"location":"time_series/#http-endpoints-server","title":"HTTP-Endpoints (Server)","text":"<p>Zeitreihen sind \u00fcber folgende Endpunkte nutzbar (Feature-Flag <code>features.timeseries=true</code>):</p> <ul> <li>POST <code>/ts/put</code></li> <li>Body:     <code>json     { \"metric\": \"cpu\", \"entity\": \"srv1\", \"value\": 0.7, \"timestamp_ms\": 1700000000000, \"metadata\": { \"env\": \"prod\" } }</code></li> <li> <p>Antwort: <code>201 Created</code> mit <code>{ success, metric, entity, timestamp_ms }</code></p> </li> <li> <p>POST <code>/ts/query</code></p> </li> <li>Body:     <code>json     { \"metric\": \"cpu\", \"entity\": \"srv1\", \"from_ms\": 1700000000000, \"to_ms\": 1700003600000, \"limit\": 1000 }</code></li> <li> <p>Antwort: <code>200 OK</code> mit <code>{ metric, entity, count, data: [ { timestamp_ms, value, tags } ] }</code></p> </li> <li> <p>POST <code>/ts/aggregate</code></p> </li> <li>Body wie bei <code>/ts/query</code> (entity erforderlich)</li> <li>Antwort: <code>200 OK</code> mit <code>{ metric, entity, aggregation: { min,max,avg,sum,count,first_timestamp_ms,last_timestamp_ms } }</code></li> </ul> <p>Hinweise: - Tag-Filter sind in der TSStore-API vorhanden (<code>tag_filter</code>), in den aktuellen HTTP-Endpunkten aber (noch) nicht explizit verdrahtet. - Die Server-Handler verwenden intern <code>TSStore</code> (<code>putDataPoint</code>, <code>query</code>, <code>aggregate</code>).</p>"},{"location":"time_series/#retention","title":"Retention","text":"<ul> <li>Global: <code>deleteOldData(cutoff_ms)</code></li> <li>Pro Metric: <code>deleteOldDataForMetric(metric, cutoff_ms)</code></li> <li>Manager: <code>RetentionManager</code> mit <code>RetentionPolicy.per_metric[metric] = &lt;Duration&gt;</code></li> </ul> <p>Beispiel:</p> <pre><code>RetentionPolicy pol;\npol.per_metric[\"cpu\"] = std::chrono::minutes(30);\npol.per_metric[\"mem\"] = std::chrono::hours(2);\nRetentionManager rm(&amp;tsstore, pol);\nsize_t deleted = rm.apply();\n</code></pre>"},{"location":"time_series/#kontinuierliche-aggregationen-mvp","title":"Kontinuierliche Aggregationen (MVP)","text":"<ul> <li>Abgeleitete Metrik: <code>{metric}__agg_{window_ms}</code></li> <li>Ein Punkt pro Fensterende; <code>value = avg</code>, \u00fcbrige Kennzahlen in <code>metadata</code></li> </ul> <pre><code>ContinuousAggregateManager mgr(&amp;tsstore);\nAggConfig cfg{ .metric = \"temp\", .entity = std::string(\"sensorA\"), .window = {std::chrono::minutes(1)} };\nmgr.refresh(cfg, from_ms, to_ms);\n</code></pre>"},{"location":"time_series/#gorilla-codec-optional","title":"Gorilla-Codec (optional)","text":"<ul> <li>Timestamps: Delta-of-Delta, ZigZag + Varint</li> <li>Werte: XOR der IEEE\u2011754 Repr\u00e4sentation mit Leading/Trailing\u2011Zero\u2011Packing</li> </ul> <pre><code>GorillaEncoder enc;\nenc.add(ts, value);\nauto bytes = enc.finish();\nGorillaDecoder dec(bytes);\nwhile (auto p = dec.next()) { /* ... */ }\n</code></pre>"},{"location":"time_series/#tests","title":"Tests","text":"<ul> <li><code>tests/test_tsstore.cpp</code> \u2013 TSStore: CRUD, Query, Aggregation, Stats</li> <li><code>tests/test_timeseries_retention.cpp</code> \u2013 Retention pro Metric</li> <li><code>tests/test_gorilla.cpp</code> \u2013 Codec\u2011Roundtrip/Kompression</li> </ul>"},{"location":"time_series/#limitierungen-aktuell","title":"Limitierungen (aktuell)","text":"<ul> <li>Kein automatisches Downsampling/TTL \u2013 Retention ist manuell bzw. per Job</li> <li>HTTP-Endpunkte erfordern <code>entity</code>; TSStore unterst\u00fctzt zudem Tag\u2011Filter (noch nicht im Endpoint)</li> <li>Kompression standardm\u00e4\u00dfig deaktiviert (<code>CompressionType::None</code>)</li> </ul>"},{"location":"tracing/","title":"OpenTelemetry Distributed Tracing","text":"<p>Themis unterst\u00fctzt verteiltes Tracing via OpenTelemetry f\u00fcr Production-Debugging und Performance-Analyse.</p>"},{"location":"tracing/#features","title":"Features","text":"<ul> <li>OTLP HTTP Exporter: Sendet Traces an Jaeger, Grafana Tempo oder andere OTLP-kompatible Backends</li> <li>RAII Span Management: Automatisches Span-Lifetime-Management via C++ RAII</li> <li>Conditional Compilation: Tracing kann zur Build-Zeit deaktiviert werden (kein Runtime-Overhead)</li> <li>Flexible Configuration: Runtime-Konfiguration via <code>config.json</code></li> </ul>"},{"location":"tracing/#architektur","title":"Architektur","text":""},{"location":"tracing/#komponenten","title":"Komponenten","text":"<ol> <li>Tracer Wrapper (<code>utils/tracing.h</code>/<code>.cpp</code>)</li> <li>Initialisierung des OTLP HTTP Exporters</li> <li>TracerProvider mit Resource Attributes (service.name, version)</li> <li> <p>SimpleSpanProcessor f\u00fcr sofortigen Export</p> </li> <li> <p>Span RAII Wrapper</p> </li> <li><code>Tracer::Span</code>: Move-only Span mit automatischem <code>end()</code> im Destruktor</li> <li><code>ScopedSpan</code>: Convenience-Wrapper f\u00fcr lokale Spans</li> <li> <p>Attribute-Support: <code>setAttribute(key, value)</code> f\u00fcr string, int64, double, bool</p> </li> <li> <p>No-Op Fallback</p> </li> <li>Wenn <code>THEMIS_ENABLE_TRACING</code> nicht definiert, sind alle Methoden No-Ops</li> <li>Kein Linking gegen OpenTelemetry-Libraries notwendig</li> </ol>"},{"location":"tracing/#datenfluss","title":"Datenfluss","text":"<pre><code>HTTP Request \u2192 ScopedSpan(\"handleAqlQuery\")\n                \u2193\n           QueryEngine::executeQuery() \u2192 ScopedSpan(\"executeQuery\")\n                \u2193\n           Index Scans \u2192 Child Spans\n                \u2193\n         OTLP HTTP Exporter \u2192 Jaeger/Tempo/Collector\n</code></pre>"},{"location":"tracing/#konfiguration","title":"Konfiguration","text":""},{"location":"tracing/#build-zeit","title":"Build-Zeit","text":"<p>In <code>CMakeLists.txt</code>:</p> <pre><code>option(THEMIS_ENABLE_TRACING \"Enable OpenTelemetry distributed tracing\" ON)\n</code></pre> <p>Deaktivieren:</p> <pre><code>cmake -DTHEMIS_ENABLE_TRACING=OFF ..\n</code></pre>"},{"location":"tracing/#runtime","title":"Runtime","text":"<p>In <code>config/config.json</code>:</p> <pre><code>{\n  \"tracing\": {\n    \"enabled\": true,\n    \"service_name\": \"themis-server\",\n    \"otlp_endpoint\": \"http://localhost:4318\"\n  }\n}\n</code></pre> <p>Wichtig: <code>otlp_endpoint</code> ist der Base-URL des OTLP HTTP Receivers. Der Tracer f\u00fcgt automatisch <code>/v1/traces</code> hinzu.</p>"},{"location":"tracing/#nutzung","title":"Nutzung","text":""},{"location":"tracing/#instrumentierte-komponenten-aktuell","title":"Instrumentierte Komponenten (aktuell)","text":""},{"location":"tracing/#http-handler-top-level-spans","title":"HTTP-Handler (Top-Level Spans)","text":"<ul> <li>GET /entities/:key: <code>entity.key</code>, <code>entity.size_bytes</code></li> <li>PUT /entities/:key: <code>entity.key</code>, <code>entity.table</code>, <code>entity.pk</code>, <code>entity.size_bytes</code>, <code>entity.cdc_recorded</code></li> <li>DELETE /entities/:key: <code>entity.key</code>, <code>entity.table</code>, <code>entity.pk</code>, <code>entity.cdc_recorded</code></li> <li>POST /query: <code>query.table</code>, <code>query.predicates_count</code>, <code>query.exec_mode</code>, <code>query.result_count</code></li> <li>POST /query/aql: <code>aql.query</code>, <code>aql.explain</code>, <code>aql.optimize</code>, <code>aql.allow_full_scan</code>, <code>aql.result_count</code></li> <li>POST /graph/traverse: <code>graph.start_vertex</code>, <code>graph.max_depth</code>, <code>graph.visited_count</code></li> <li>POST /vector/search: <code>vector.dimension</code>, <code>vector.k</code>, <code>vector.results_count</code></li> </ul>"},{"location":"tracing/#queryengine-query-execution-spans","title":"QueryEngine (Query Execution Spans)","text":"<ul> <li>QueryEngine.executeAndKeys: <code>query.table</code>, <code>query.eq_count</code>, <code>query.range_count</code>, <code>query.order_by</code>, <code>query.result_count</code></li> <li>QueryEngine.executeAndEntities: <code>query.table</code>, <code>query.entities_count</code></li> <li>QueryEngine.executeOrKeys: <code>query.table</code>, <code>query.disjuncts</code>, <code>query.result_count</code></li> <li>QueryEngine.executeOrEntities: <code>query.table</code>, <code>query.entities_count</code></li> <li>QueryEngine.executeAndKeysSequential: <code>query.table</code>, <code>query.eq_count</code>, <code>query.result_count</code></li> <li>QueryEngine.executeAndEntitiesSequential: <code>query.table</code>, <code>query.entities_count</code></li> <li>QueryEngine.fullScan: <code>query.table</code>, <code>query.eq_count</code>, <code>query.range_count</code>, <code>fullscan.scanned</code>, <code>query.result_count</code></li> <li>QueryEngine.executeAndKeysWithFallback: <code>query.table</code>, <code>query.exec_mode</code> (full_scan, range_aware, index_optimized, index_parallel, full_scan_fallback), <code>query.result_count</code></li> <li>QueryEngine.executeAndEntitiesWithFallback: <code>query.table</code>, <code>query.entities_count</code></li> <li>QueryEngine.executeAndKeysRangeAware: <code>query.table</code>, <code>query.range_count</code>, <code>query.result_count</code> oder <code>query.ordered_count</code></li> <li>QueryEngine.executeAndEntitiesRangeAware: <code>query.table</code>, <code>query.entities_count</code></li> </ul>"},{"location":"tracing/#aql-execution-pipeline-operator-level-spans","title":"AQL Execution Pipeline (Operator-Level Spans)","text":"<ul> <li>aql.parse: <code>aql.query_length</code> - Parsen der AQL-Query in AST</li> <li>aql.translate - \u00dcbersetzung des AST in ConjunctiveQuery oder TraversalQuery</li> <li>aql.for: <code>for.table</code>, <code>for.predicates_count</code>, <code>for.range_predicates_count</code>, <code>for.order_by</code>, <code>for.order_desc</code>, <code>for.result_count</code>, <code>for.exec_mode</code></li> <li>Iteriert \u00fcber Collection (scan oder traversal)</li> <li>aql.filter - Filterung der Ergebnisse (innerhalb von Traversal/FOR)</li> <li>Bei Traversal: <code>filter.evaluations_total</code>, <code>filter.short_circuits</code></li> <li>aql.limit: <code>limit.offset</code>, <code>limit.count</code>, <code>limit.input_count</code>, <code>limit.output_count</code></li> <li>Begrenzt Ergebnismenge (LIMIT offset, count)</li> <li>aql.collect: <code>collect.input_count</code>, <code>collect.group_by_count</code>, <code>collect.aggregates_count</code>, <code>collect.group_count</code></li> <li>Gruppierung und Aggregation (GROUP BY, SUM, AVG, COUNT, MIN, MAX)</li> <li>aql.return: <code>return.input_count</code></li> <li>Finalisiert Ausgabe und serialisiert Entities</li> <li>aql.traversal: <code>traversal.start_vertex</code>, <code>traversal.min_depth</code>, <code>traversal.max_depth</code>, <code>traversal.direction</code>, <code>traversal.result_count</code></li> <li>Child-Span: aql.traversal.bfs: <code>traversal.max_frontier_size_limit</code>, <code>traversal.max_results_limit</code>, <code>traversal.visited_count</code>, <code>traversal.edges_expanded</code>, <code>traversal.filter_evaluations</code></li> </ul>"},{"location":"tracing/#index-scans-child-spans","title":"Index-Scans (Child-Spans)","text":"<ul> <li>index.scanEqual: <code>index.table</code>, <code>index.column</code>, <code>index.result_count</code></li> <li>index.scanRange: <code>index.table</code>, <code>index.column</code>, <code>index.result_count</code>, <code>range.has_lower</code>, <code>range.has_upper</code>, <code>range.includeLower</code>, <code>range.includeUpper</code></li> <li>or.disjunct.execute: <code>disjunct.eq_count</code>, <code>disjunct.range_count</code>, <code>disjunct.result_count</code></li> </ul> <p>Diese Spans erlauben die Analyse von Ausf\u00fchrungsmodus, Cardinalities und Hotspots pro Pr\u00e4dikat/Operator.</p>"},{"location":"tracing/#span-in-http-handler-erstellen","title":"Span in HTTP Handler erstellen","text":"<pre><code>#include \"utils/tracing.h\"\n\nvoid handleAqlQuery(const Request&amp; req, Response&amp; res) {\n    auto span = Tracer::ScopedSpan(\"handleAqlQuery\");\n    span.setAttribute(\"http.method\", \"POST\");\n    span.setAttribute(\"http.path\", \"/aql\");\n\n    try {\n        // ... query execution ...\n      span.setAttribute(\"query.table\", tableName);\n      span.setStatus(true);\n    } catch (const std::exception&amp; e) {\n        span.recordError(e.what());\n      span.setStatus(false, e.what());\n        throw;\n    }\n}\n</code></pre>"},{"location":"tracing/#child-span-erstellen","title":"Child Span erstellen","text":"<pre><code>void QueryEngine::executeQuery(...) {\n    auto parentSpan = Tracer::ScopedSpan(\"executeQuery\");\n\n    {\n        auto childSpan = Tracer::startSpan(\"loadIndexes\");\n        childSpan.setAttribute(\"index.count\", indexCount);\n        // ... index loading ...\n    } // childSpan endet automatisch\n\n    // ... weiter mit parentSpan ...\n}\n</code></pre>"},{"location":"tracing/#fehler-aufzeichnen","title":"Fehler aufzeichnen","text":"<pre><code>try {\n    // ... operation ...\n} catch (const std::exception&amp; e) {\n    span.recordError(e.what());\n     span.setStatus(false, errorMessage);\n    throw;\n}\n</code></pre>"},{"location":"tracing/#jaeger-integration-development","title":"Jaeger Integration (Development)","text":""},{"location":"tracing/#jaeger-via-docker-starten","title":"Jaeger via Docker starten","text":"<pre><code>docker run -d --name jaeger \\\n  -p 4318:4318 \\\n  -p 16686:16686 \\\n  jaegertracing/all-in-one:latest\n</code></pre> <p>Ports: - <code>4318</code>: OTLP HTTP receiver (f\u00fcr Themis) - <code>16686</code>: Jaeger UI</p>"},{"location":"tracing/#themis-konfigurieren","title":"Themis konfigurieren","text":"<pre><code>{\n  \"tracing\": {\n    \"enabled\": true,\n    \"service_name\": \"themis-dev\",\n    \"otlp_endpoint\": \"http://localhost:4318\"\n  }\n}\n</code></pre>"},{"location":"tracing/#themis-starten","title":"Themis starten","text":"<pre><code>.\\build\\Release\\themis_server.exe\n</code></pre>"},{"location":"tracing/#traces-anzeigen","title":"Traces anzeigen","text":"<ol> <li>\u00d6ffne http://localhost:16686 (Jaeger UI)</li> <li>W\u00e4hle Service \"themis-dev\"</li> <li>Klicke \"Find Traces\"</li> </ol>"},{"location":"tracing/#grafana-tempo-integration-production","title":"Grafana Tempo Integration (Production)","text":""},{"location":"tracing/#tempo-via-docker-compose","title":"Tempo via Docker Compose","text":"<pre><code>version: '3'\nservices:\n  tempo:\n    image: grafana/tempo:latest\n    command: [\"-config.file=/etc/tempo.yaml\"]\n    volumes:\n      - ./tempo.yaml:/etc/tempo.yaml\n    ports:\n      - \"4318:4318\"   # OTLP HTTP\n      - \"3200:3200\"   # Tempo API\n\n  grafana:\n    image: grafana/grafana:latest\n    ports:\n      - \"3000:3000\"\n    environment:\n      - GF_AUTH_ANONYMOUS_ENABLED=true\n</code></pre> <p>tempo.yaml:</p> <pre><code>server:\n  http_listen_port: 3200\n\ndistributor:\n  receivers:\n    otlp:\n      protocols:\n        http:\n          endpoint: 0.0.0.0:4318\n\nstorage:\n  trace:\n    backend: local\n    local:\n      path: /tmp/tempo/traces\n</code></pre>"},{"location":"tracing/#grafana-datasource","title":"Grafana Datasource","text":"<ol> <li>\u00d6ffne http://localhost:3000</li> <li>Configuration \u2192 Data Sources \u2192 Add data source</li> <li>W\u00e4hle \"Tempo\"</li> <li>URL: <code>http://tempo:3200</code></li> <li>Save &amp; Test</li> </ol>"},{"location":"tracing/#performance-hinweise","title":"Performance-Hinweise","text":""},{"location":"tracing/#span-overhead","title":"Span-Overhead","text":"<ul> <li>Mit Tracing aktiviert: ~5-10 \u00b5s pro Span (inkl. Attribut-Serialisierung)</li> <li>Ohne Tracing (THEMIS_ENABLE_TRACING=OFF): 0 \u00b5s (inline no-ops)</li> </ul>"},{"location":"tracing/#best-practices","title":"Best Practices","text":"<ol> <li>Granularit\u00e4t: Erstelle Spans f\u00fcr HTTP-Requests, Query-Execution, Index-Scans</li> <li>Attribute: F\u00fcge relevante Metadaten hinzu (table, index_type, row_count)</li> <li>Sampling (zuk\u00fcnftig): F\u00fcr High-Throughput-Szenarien Sampling verwenden</li> <li>Batch Processor (zuk\u00fcnftig): SimpleSpanProcessor \u2192 BatchSpanProcessor f\u00fcr bessere Performance</li> </ol>"},{"location":"tracing/#api-referenz","title":"API-Referenz","text":""},{"location":"tracing/#tracerinitialize","title":"Tracer::initialize()","text":"<pre><code>bool Tracer::initialize(const std::string&amp; serviceName, \n                       const std::string&amp; endpoint);\n</code></pre> <p>Initialisiert den OpenTelemetry Tracer mit OTLP HTTP Exporter.</p> <p>Parameter: - <code>serviceName</code>: Name des Services (erscheint in Jaeger/Tempo) - <code>endpoint</code>: OTLP HTTP Receiver URL (z.B. <code>http://localhost:4318</code>)</p> <p>Returns: <code>true</code> bei Erfolg, <code>false</code> bei Fehler</p>"},{"location":"tracing/#tracerstartspan","title":"Tracer::startSpan()","text":"<pre><code>Tracer::Span Tracer::startSpan(const std::string&amp; name);\n</code></pre> <p>Erstellt einen neuen Span mit dem gegebenen Namen.</p> <p>Returns: Move-only <code>Span</code> Objekt</p>"},{"location":"tracing/#scopedspan","title":"ScopedSpan","text":"<pre><code>Tracer::ScopedSpan span(\"operationName\");\nspan.setAttribute(\"key\", \"value\");\n</code></pre> <p>RAII-Wrapper f\u00fcr automatisches Span-Lifetime-Management.</p>"},{"location":"tracing/#spansetattribute","title":"Span::setAttribute()","text":"<pre><code>void setAttribute(const std::string&amp; key, const std::string&amp; value);\nvoid setAttribute(const std::string&amp; key, int64_t value);\nvoid setAttribute(const std::string&amp; key, double value);\nvoid setAttribute(const std::string&amp; key, bool value);\n</code></pre> <p>F\u00fcgt Attribute zum Span hinzu.</p>"},{"location":"tracing/#spanrecorderror","title":"Span::recordError()","text":"<pre><code>void recordError(const std::string&amp; errorMessage);\n</code></pre> <p>Zeichnet einen Fehler auf und setzt den Span-Status auf <code>kError</code>.</p>"},{"location":"tracing/#spansetstatus","title":"Span::setStatus()","text":"<pre><code>void setStatus(StatusCode code);\n</code></pre> <p>Setzt den Span-Status (<code>kOk</code>, <code>kError</code>, <code>kUnset</code>).</p>"},{"location":"tracing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tracing/#tracer-not-initialized-warning","title":"\"Tracer not initialized\" Warning","text":"<p>Symptom: Log-Meldung \"Tracer not initialized, call Tracer::initialize() first\"</p> <p>L\u00f6sung: Stelle sicher, dass <code>Tracer::initialize()</code> vor dem ersten <code>startSpan()</code> aufgerufen wird.</p>"},{"location":"tracing/#keine-traces-in-jaeger-sichtbar","title":"Keine Traces in Jaeger sichtbar","text":"<p>Pr\u00fcfe: 1. L\u00e4uft Jaeger? <code>docker ps | grep jaeger</code> 2. Ist Tracing aktiviert? <code>\"tracing.enabled\": true</code> in config.json 3. Richtiger Endpoint? <code>http://localhost:4318</code> (nicht 4317 f\u00fcr gRPC!) 4. Firewall/Network-Einstellungen</p> <p>Debug:</p> <pre><code># Log-Level auf DEBUG setzen in config.json\n\"log_level\": \"debug\"\n\n# Themis-Logs pr\u00fcfen\ngrep -i \"telemetry\\|tracer\\|span\" themis.log\n</code></pre>"},{"location":"tracing/#build-fehler-mit-opentelemetry","title":"Build-Fehler mit OpenTelemetry","text":"<p>Symptom: <code>error: opentelemetry/... not found</code></p> <p>L\u00f6sung:</p> <pre><code># vcpkg-Cache l\u00f6schen und neu installieren\nrm -rf build/vcpkg_installed\n.\\build.ps1\n</code></pre>"},{"location":"tracing/#implementierungsstatus","title":"Implementierungsstatus","text":"<ul> <li>\u2705 Infrastruktur: Tracer-Wrapper, OTLP HTTP Exporter</li> <li>\u2705 Configuration: config.json + CMake-Option</li> <li>\u2705 Build: Kompiliert mit opentelemetry-cpp v1.23.0</li> <li>\u2705 Tests: 303/303 Tests bestanden</li> <li>\u26a0\ufe0f Instrumentierung: HTTP-Handler noch nicht instrumentiert</li> <li>\u26a0\ufe0f Dokumentation: Deployment-Guide f\u00fcr Production</li> </ul>"},{"location":"tracing/#nachste-schritte","title":"N\u00e4chste Schritte","text":"<ol> <li>HTTP-Handler instrumentieren: Spans f\u00fcr alle <code>/aql</code>, <code>/vector</code>, <code>/graph</code> Endpoints</li> <li>Query-Engine instrumentieren: Child Spans f\u00fcr Index-Scans, Filter-Operationen</li> <li>Sampling implementieren: Probabilistic Sampling f\u00fcr High-Throughput</li> <li>BatchSpanProcessor: Performance-Optimierung f\u00fcr Production</li> <li>Context Propagation: W3C Trace Context f\u00fcr verteilte Systeme</li> </ol>"},{"location":"tracing/#siehe-auch","title":"Siehe auch","text":"<ul> <li>OpenTelemetry C++ SDK Documentation</li> <li>Jaeger Documentation</li> <li>Grafana Tempo Documentation</li> <li>OTLP Specification</li> </ul>"},{"location":"transactions/","title":"Transaction Management in THEMIS","text":"<p>Version: 1.1 Datum: 2. November 2025</p>"},{"location":"transactions/#uberblick","title":"\u00dcberblick","text":"<p>THEMIS bietet ACID-konforme Transaktionen \u00fcber alle Index-Typen hinweg (Relational, Graph, Vector). Transaktionen basieren auf MVCC mit Snapshot-Isolation und Konflikterkennung; Updates \u00fcber Sekund\u00e4r-, Graph- und Vektorindizes erfolgen atomar innerhalb der Transaktion.</p>"},{"location":"transactions/#kernfeatures","title":"Kernfeatures","text":"<ul> <li>Atomicity: Alle Operationen innerhalb einer Transaktion werden atomar ausgef\u00fchrt (all-or-nothing)</li> <li>MVCC &amp; Isolation: ReadCommitted (default) und Snapshot-Isolation mit konsistentem Sichtfenster</li> <li>Konflikterkennung: Write-Write-Konflikte werden beim Commit/Put erkannt und f\u00fchren zu Fehlern/Abbr\u00fcchen</li> <li>Session-Management: Transaktionen sind \u00fcber eindeutige Transaction-IDs identifizierbar</li> <li>Statistics Tracking: Umfassende Metriken (begun, committed, aborted, durations, success rate)</li> <li>Auto-Rollback: RAII-Pattern f\u00fcr automatisches Rollback bei Exception/Destruktion</li> <li>Multi-Index Support: Konsistente Updates \u00fcber Secondary, Graph und Vector-Indizes</li> </ul>"},{"location":"transactions/#architektur","title":"Architektur","text":""},{"location":"transactions/#transactionmanager","title":"TransactionManager","text":"<p>Zentrale Komponente f\u00fcr Session-basiertes Transaction-Management:</p> <pre><code>class TransactionManager {\npublic:\n    // Session-based API (empfohlen f\u00fcr HTTP/Multi-Client)\n    TransactionId beginTransaction(IsolationLevel isolation = IsolationLevel::ReadCommitted);\n    Status commitTransaction(TransactionId id);\n    void rollbackTransaction(TransactionId id);\n    std::shared_ptr&lt;Transaction&gt; getTransaction(TransactionId id);\n\n    // Direct API (f\u00fcr Single-Threaded/Embedded)\n    Transaction begin(IsolationLevel isolation = IsolationLevel::ReadCommitted);\n\n    // Statistics\n    Stats getStats() const;\n    void cleanupOldTransactions(std::chrono::seconds max_age);\n};\n</code></pre>"},{"location":"transactions/#transaction-class","title":"Transaction Class","text":"<p>Stellt Operationen innerhalb einer Transaktion bereit:</p> <pre><code>class Transaction {\npublic:\n    // Metadata\n    TransactionId getId() const;\n    IsolationLevel getIsolationLevel() const;\n    uint64_t getDurationMs() const;\n\n    // Relational Operations\n    Status putEntity(std::string_view table, const BaseEntity&amp; entity);\n    Status eraseEntity(std::string_view table, std::string_view pk);\n\n    // Graph Operations\n    Status addEdge(const BaseEntity&amp; edgeEntity);\n    Status deleteEdge(std::string_view edgeId);\n\n    // Vector Operations\n    Status addVector(const BaseEntity&amp; entity, std::string_view vectorField = \"embedding\");\n    Status updateVector(const BaseEntity&amp; entity, std::string_view vectorField = \"embedding\");\n    Status removeVector(std::string_view pk);\n\n    // Finalization\n    Status commit();\n    void rollback();\n};\n</code></pre>"},{"location":"transactions/#isolation-levels","title":"Isolation Levels","text":""},{"location":"transactions/#readcommitted-default","title":"ReadCommitted (Default)","text":"<ul> <li>Lesezugriffe sehen nur committed data</li> <li>Keine Dirty Reads</li> <li>Non-Repeatable Reads m\u00f6glich</li> <li>Geeignet f\u00fcr: Standard OLTP-Workloads</li> </ul>"},{"location":"transactions/#snapshot","title":"Snapshot","text":"<ul> <li>Point-in-time Konsistenz (Sichtfenster fixiert beim Begin)</li> <li>Repeatable Reads innerhalb der Transaktion</li> <li>H\u00f6here Isolation, potenziell h\u00f6herer Overhead</li> <li>Geeignet f\u00fcr: Analytische Queries, konsistente Reports</li> </ul>"},{"location":"transactions/#http-rest-api","title":"HTTP REST API","text":""},{"location":"transactions/#post-transactionbegin","title":"POST /transaction/begin","text":"<p>Startet eine neue Transaktion.</p> <p>Request:</p> <pre><code>{\n  \"isolation\": \"read_committed\"  // optional, default: \"read_committed\"\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"transaction_id\": 42,\n  \"isolation\": \"read_committed\",\n  \"status\": \"begun\"\n}\n</code></pre> <p>cURL Beispiel:</p> <pre><code>curl -X POST http://localhost:8080/transaction/begin \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"isolation\": \"snapshot\"}'\n</code></pre>"},{"location":"transactions/#post-transactioncommit","title":"POST /transaction/commit","text":"<p>Committed eine Transaktion.</p> <p>Request:</p> <pre><code>{\n  \"transaction_id\": 42\n}\n</code></pre> <p>Response (Success):</p> <pre><code>{\n  \"transaction_id\": 42,\n  \"status\": \"committed\",\n  \"message\": \"Transaction committed successfully\"\n}\n</code></pre> <p>Response (Error):</p> <pre><code>{\n  \"transaction_id\": 42,\n  \"status\": \"error\",\n  \"error\": \"Transaction not found or already completed\"\n}\n</code></pre> <p>cURL Beispiel:</p> <pre><code>curl -X POST http://localhost:8080/transaction/commit \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"transaction_id\": 42}'\n</code></pre>"},{"location":"transactions/#post-transactionrollback","title":"POST /transaction/rollback","text":"<p>Rollt eine Transaktion zur\u00fcck.</p> <p>Request:</p> <pre><code>{\n  \"transaction_id\": 42\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"transaction_id\": 42,\n  \"status\": \"rolled_back\",\n  \"message\": \"Transaction rolled back successfully\"\n}\n</code></pre> <p>cURL Beispiel:</p> <pre><code>curl -X POST http://localhost:8080/transaction/rollback \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"transaction_id\": 42}'\n</code></pre>"},{"location":"transactions/#get-transactionstats","title":"GET /transaction/stats","text":"<p>Liefert Statistiken \u00fcber alle Transaktionen.</p> <p>Response:</p> <pre><code>{\n  \"total_begun\": 1523,\n  \"total_committed\": 1401,\n  \"total_aborted\": 122,\n  \"active_count\": 3,\n  \"avg_duration_ms\": 45,\n  \"max_duration_ms\": 523,\n  \"success_rate\": 0.92\n}\n</code></pre> <p>cURL Beispiel:</p> <pre><code>curl http://localhost:8080/transaction/stats\n</code></pre>"},{"location":"transactions/#use-cases-best-practices","title":"Use Cases &amp; Best Practices","text":""},{"location":"transactions/#1-atomares-multi-entity-update","title":"1. Atomares Multi-Entity Update","text":"<p>Problem: Mehrere Entities mit verschiedenen Indizes m\u00fcssen atomar gespeichert werden.</p> <p>L\u00f6sung:</p> <pre><code># Begin transaction\nTXN_ID=$(curl -s -X POST http://localhost:8080/transaction/begin | jq -r '.transaction_id')\n\n# Insert entities via transaction (hypothetisch - API-Erweiterung erforderlich)\n# Aktuell: Direkte C++ API verwenden\n\n# C++ Code:\nauto txn_id = tx_manager-&gt;beginTransaction();\nauto txn = tx_manager-&gt;getTransaction(txn_id);\n\nBaseEntity user(\"user123\");\nuser.setField(\"name\", std::string(\"Alice\"));\nuser.setField(\"city\", std::string(\"Berlin\"));\ntxn-&gt;putEntity(\"users\", user);\n\nBaseEntity order(\"order456\");\norder.setField(\"user_id\", std::string(\"user123\"));\norder.setField(\"total\", 99.99);\ntxn-&gt;putEntity(\"orders\", order);\n\n// Commit via HTTP\ncurl -X POST http://localhost:8080/transaction/commit \\\n  -d \"{\\\"transaction_id\\\": $TXN_ID}\"\n</code></pre>"},{"location":"transactions/#2-graph-operationen-mit-rollback","title":"2. Graph-Operationen mit Rollback","text":"<p>Problem: Mehrere Graph-Edges sollen atomar hinzugef\u00fcgt werden, bei Fehler Rollback.</p> <p>C++ Beispiel:</p> <pre><code>auto txn_id = tx_manager-&gt;beginTransaction();\nauto txn = tx_manager-&gt;getTransaction(txn_id);\n\ntry {\n    // Add multiple edges\n    BaseEntity edge1(\"edge1\");\n    edge1.setField(\"_from\", std::string(\"user1\"));\n    edge1.setField(\"_to\", std::string(\"user2\"));\n    edge1.setField(\"type\", std::string(\"follows\"));\n    txn-&gt;addEdge(edge1);\n\n    BaseEntity edge2(\"edge2\");\n    edge2.setField(\"_from\", std::string(\"user1\"));\n    edge2.setField(\"_to\", std::string(\"user3\"));\n    edge2.setField(\"type\", std::string(\"follows\"));\n    txn-&gt;addEdge(edge2);\n\n    // Validate business logic\n    if (!validateFollowerLimit(txn)) {\n        tx_manager-&gt;rollbackTransaction(txn_id);\n        return Status::Error(\"Follower limit exceeded\");\n    }\n\n    // Commit if all OK\n    return tx_manager-&gt;commitTransaction(txn_id);\n} catch (...) {\n    tx_manager-&gt;rollbackTransaction(txn_id);\n    throw;\n}\n</code></pre>"},{"location":"transactions/#3-vector-index-mit-transaktionen","title":"3. Vector-Index mit Transaktionen","text":"<p>Problem: Vector-Embedding und Metadaten sollen atomar gespeichert werden.</p> <p>C++ Beispiel:</p> <pre><code>auto txn_id = tx_manager-&gt;beginTransaction();\nauto txn = tx_manager-&gt;getTransaction(txn_id);\n\n// Document with embedding\nBaseEntity doc(\"doc123\");\ndoc.setField(\"title\", std::string(\"AI Research Paper\"));\ndoc.setField(\"author\", std::string(\"Dr. Smith\"));\nstd::vector&lt;float&gt; embedding = {0.23f, 0.45f, 0.67f, /* ... 768 dims */};\ndoc.setField(\"embedding\", embedding);\n\n// Store entity (relational)\nauto status = txn-&gt;putEntity(\"documents\", doc);\nif (!status.ok) {\n    tx_manager-&gt;rollbackTransaction(txn_id);\n    return status;\n}\n\n// Store vector (vector index)\nstatus = txn-&gt;addVector(doc, \"embedding\");\nif (!status.ok) {\n    tx_manager-&gt;rollbackTransaction(txn_id);\n    return status;\n}\n\n// Commit both atomically\nreturn tx_manager-&gt;commitTransaction(txn_id);\n</code></pre>"},{"location":"transactions/#4-long-running-transactions-cleanup","title":"4. Long-Running Transactions &amp; Cleanup","text":"<p>Problem: Vergessene/abgest\u00fcrzte Clients hinterlassen offene Transaktionen.</p> <p>Best Practice:</p> <pre><code>// Periodischer Cleanup (z.B. via Cronjob oder Background-Thread)\ntx_manager-&gt;cleanupOldTransactions(std::chrono::hours(1));\n\n// Metriken \u00fcberwachen\nauto stats = tx_manager-&gt;getStats();\nif (stats.active_count &gt; 100) {\n    THEMIS_WARN(\"High number of active transactions: {}\", stats.active_count);\n}\n</code></pre> <p>HTTP Monitoring:</p> <pre><code># Statistiken abrufen\ncurl http://localhost:8080/transaction/stats | jq '.active_count'\n\n# Alert bei hoher Anzahl\nif [ $(curl -s http://localhost:8080/transaction/stats | jq '.active_count') -gt 50 ]; then\n  echo \"WARNING: Too many active transactions\"\nfi\n</code></pre>"},{"location":"transactions/#performance-uberlegungen","title":"Performance-\u00dcberlegungen","text":""},{"location":"transactions/#mvcc-overhead","title":"MVCC Overhead","text":"<ul> <li>Snapshot-Verwaltung und Konflikterkennung erzeugen geringen Overhead gegen\u00fcber einfachen Writes</li> <li>Benefit: Korrektheit unter Parallelit\u00e4t (kein Last-Write-Wins), konsistente Sicht</li> </ul>"},{"location":"transactions/#isolation-level-trade-offs","title":"Isolation Level Trade-offs","text":"Isolation Level Read Overhead Write Overhead Use Case ReadCommitted Minimal Minimal OLTP, Standard-Queries Snapshot +5-10% +5-10% Reports, Analytics"},{"location":"transactions/#index-spezifische-kosten","title":"Index-spezifische Kosten","text":"<ul> <li>Secondary Index: ~0.05ms pro Index-Entry (Put/Delete)</li> <li>Graph Index: ~0.1ms pro Edge (2x Index-Entries: out + in)</li> <li>Vector Index: ~0.5-2ms (abh\u00e4ngig von HNSW-Parametern, Dimension)</li> </ul>"},{"location":"transactions/#bekannte-einschrankungen","title":"Bekannte Einschr\u00e4nkungen","text":""},{"location":"transactions/#1-vector-index-in-memory-cache","title":"1. Vector Index In-Memory Cache","text":"<p>Problem: Der Vector-Index h\u00e4lt einen In-Memory Cache (HNSW-Struktur, <code>cache_</code> map). Bei Rollback werden RocksDB-\u00c4nderungen r\u00fcckg\u00e4ngig gemacht, aber der Cache bleibt inkonsistent.</p> <p>Auswirkung: - Nach Rollback k\u00f6nnen Vector-Searches falsch-positive Ergebnisse liefern - Cache enth\u00e4lt Vektoren, die in RocksDB nicht existieren</p> <p>Workaround:</p> <pre><code>// Nach Rollback: Vector-Index neu laden\nvector_index-&gt;rebuildFromStorage();\n</code></pre> <p>Zuk\u00fcnftige Verbesserung: Callback-Mechanismus f\u00fcr commit/rollback, um Cache synchron zu halten.</p>"},{"location":"transactions/#2-konflikte-unter-parallelitat","title":"2. Konflikte unter Parallelit\u00e4t","text":"<p>Verhalten: Write-Write-Konflikte werden erkannt und f\u00fchren zu Fehlern beim Commit/Put. Clients sollten Retry-Logik mit Backoff implementieren, wenn eine Transaktion aufgrund eines Konflikts abgelehnt wird.</p>"},{"location":"transactions/#3-transaction-timeout","title":"3. Transaction Timeout","text":"<p>Limitation: Keine automatischen Timeouts f\u00fcr aktive Transaktionen implementiert.</p> <p>Empfehlung:</p> <pre><code>// Client-seitig: Timeout \u00fcberwachen\nauto start = std::chrono::system_clock::now();\nauto txn_id = tx_manager-&gt;beginTransaction();\n\n// ... operations ...\n\nauto duration = std::chrono::system_clock::now() - start;\nif (duration &gt; std::chrono::seconds(30)) {\n    tx_manager-&gt;rollbackTransaction(txn_id);\n    return Status::Error(\"Transaction timeout\");\n}\n</code></pre>"},{"location":"transactions/#fehlerbehandlung","title":"Fehlerbehandlung","text":""},{"location":"transactions/#commit-failures","title":"Commit Failures","text":"<pre><code>auto status = tx_manager-&gt;commitTransaction(txn_id);\nif (!status.ok) {\n    // M\u00f6gliche Ursachen:\n    // - Transaction nicht gefunden\n    // - Bereits committed/rolled back\n    // - RocksDB Write-Fehler (Disk-Full, Permissions)\n\n    THEMIS_ERROR(\"Commit failed: {}\", status.message);\n\n    // Cleanup\n    tx_manager-&gt;rollbackTransaction(txn_id);  // Safe auch bei bereits abgeschlossener Txn\n}\n</code></pre>"},{"location":"transactions/#network-failures-http","title":"Network Failures (HTTP)","text":"<pre><code># Retry-Logic mit Exponential Backoff\nfor i in {1..3}; do\n  if curl -X POST http://localhost:8080/transaction/commit \\\n       -d \"{\\\"transaction_id\\\": $TXN_ID}\" \\\n       --max-time 5; then\n    break\n  fi\n  sleep $((2**i))\ndone\n</code></pre>"},{"location":"transactions/#auto-rollback-bei-exception","title":"Auto-Rollback bei Exception","text":"<pre><code>{\n    auto txn = tx_manager-&gt;begin();  // Direct API\n\n    txn.putEntity(\"users\", user);\n\n    // Exception thrown -&gt; Destruktor ruft automatisch rollback()\n    throw std::runtime_error(\"Business logic error\");\n\n}  // txn Destruktor: THEMIS_WARN + rollback()\n</code></pre>"},{"location":"transactions/#metriken-monitoring","title":"Metriken &amp; Monitoring","text":""},{"location":"transactions/#prometheus-integration","title":"Prometheus-Integration","text":"<p>Transaction-Statistiken sind via <code>/metrics</code> Endpoint verf\u00fcgbar:</p> <pre><code># TYPE vccdb_transactions_begun_total counter\nvccdb_transactions_begun_total 1523\n\n# TYPE vccdb_transactions_committed_total counter\nvccdb_transactions_committed_total 1401\n\n# TYPE vccdb_transactions_aborted_total counter\nvccdb_transactions_aborted_total 122\n\n# TYPE vccdb_transactions_active gauge\nvccdb_transactions_active 3\n\n# TYPE vccdb_transaction_duration_ms histogram\nvccdb_transaction_duration_ms_bucket{le=\"10\"} 834\nvccdb_transaction_duration_ms_bucket{le=\"50\"} 1245\nvccdb_transaction_duration_ms_bucket{le=\"100\"} 1398\nvccdb_transaction_duration_ms_bucket{le=\"+Inf\"} 1523\nvccdb_transaction_duration_ms_sum 68035\nvccdb_transaction_duration_ms_count 1523\n</code></pre>"},{"location":"transactions/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>Empfohlene Metriken: - Transaction Rate: <code>rate(vccdb_transactions_begun_total[5m])</code> - Success Rate: <code>vccdb_transactions_committed_total / vccdb_transactions_begun_total</code> - Active Transactions: <code>vccdb_transactions_active</code> - Avg Duration: <code>vccdb_transaction_duration_ms_sum / vccdb_transaction_duration_ms_count</code></p>"},{"location":"transactions/#migrationshinweise","title":"Migrationshinweise","text":""},{"location":"transactions/#von-direct-api-zu-session-based-api","title":"Von Direct API zu Session-based API","text":"<p>Vorher (Direct):</p> <pre><code>auto txn = tx_manager-&gt;begin();\ntxn.putEntity(\"users\", user);\ntxn.commit();\n</code></pre> <p>Nachher (Session-based, HTTP-kompatibel):</p> <pre><code>auto txn_id = tx_manager-&gt;beginTransaction();\nauto txn = tx_manager-&gt;getTransaction(txn_id);\ntxn-&gt;putEntity(\"users\", user);\ntx_manager-&gt;commitTransaction(txn_id);\n</code></pre> <p>Vorteil: Transaction-ID kann \u00fcber HTTP/Network \u00fcbertragen werden.</p>"},{"location":"transactions/#weiterfuhrende-dokumentation","title":"Weiterf\u00fchrende Dokumentation","text":"<ul> <li>Architecture Overview - Systemarchitektur</li> <li>MVCC Design - Hintergr\u00fcnde &amp; Optionen</li> <li>RocksDB Storage - WAL/Snapshots/Compaction</li> <li>Deployment Guide - Production Setup</li> <li>OpenAPI Specification - Vollst\u00e4ndige API-Referenz</li> <li>Base Entity Documentation - Entity-Serialisierung</li> </ul>"},{"location":"transactions/#changelog","title":"Changelog","text":""},{"location":"transactions/#version-10-28-oktober-2025","title":"Version 1.0 (28. Oktober 2025)","text":"<ul> <li>Initial release</li> <li>Session-based Transaction Management</li> <li>Isolation Levels: ReadCommitted, Snapshot</li> <li>Multi-Index Support: Secondary, Graph, Vector</li> <li>HTTP REST API: begin, commit, rollback, stats</li> <li>Comprehensive Statistics &amp; Monitoring</li> <li>23 Unit-Tests (100% Pass-Rate)</li> </ul>"},{"location":"vector_ops/","title":"Vector Operations","text":"<p>Dieses Dokument beschreibt die Vektor-Indexierungs- und Suchoperationen in Themis.</p>"},{"location":"vector_ops/#ubersicht","title":"\u00dcbersicht","text":"<p>Der <code>VectorIndexManager</code> unterst\u00fctzt:</p> <ul> <li>Batch-Einf\u00fcgung (<code>POST /vector/batch_insert</code>) f\u00fcr performante Massenimporte</li> <li>Gezielte L\u00f6schung (<code>DELETE /vector/by-filter</code>) via PK-Liste oder Key-Pr\u00e4fix</li> <li>KNN-Suche (<code>POST /vector/search</code>) mit optionaler Cursor-Pagination</li> <li>Persistenz (<code>POST /vector/index/save</code>, <code>POST /vector/index/load</code>) f\u00fcr HNSW-Index</li> <li>Konfiguration (<code>GET/PUT /vector/index/config</code>) zur Laufzeit (z. B. <code>efSearch</code>)</li> <li>Statistiken (<code>GET /vector/index/stats</code>) f\u00fcr Index-Kennzahlen</li> </ul>"},{"location":"vector_ops/#batch-insert","title":"Batch Insert","text":""},{"location":"vector_ops/#endpoint","title":"Endpoint","text":"<pre><code>POST /vector/batch_insert\n</code></pre>"},{"location":"vector_ops/#anfrage","title":"Anfrage","text":"<pre><code>{\n  \"vector_field\": \"embedding\",  // Standard: \"embedding\"\n  \"items\": [\n    {\n      \"pk\": \"doc1\",\n      \"vector\": [0.1, 0.2, 0.3],\n      \"fields\": {\n        \"title\": \"Beispiel\",\n        \"category\": \"test\"\n      }\n    },\n    {\n      \"pk\": \"doc2\",\n      \"vector\": [0.4, 0.5, 0.6],\n      \"fields\": {\n        \"title\": \"Another\",\n        \"category\": \"demo\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"vector_ops/#antwort","title":"Antwort","text":"<pre><code>{\n  \"inserted\": 2,\n  \"errors\": 0,\n  \"objectName\": \"vectors\",\n  \"dimension\": 3\n}\n</code></pre>"},{"location":"vector_ops/#best-practices","title":"Best Practices","text":"<ul> <li>Batch-Gr\u00f6\u00dfe: 100\u20131000 Eintr\u00e4ge pro Request f\u00fcr optimales Latenz/Durchsatz-Verh\u00e4ltnis</li> <li>Auto-Init: Wenn <code>dimension</code> = 0, wird der Index automatisch mit der Dimension des ersten Vektors initialisiert</li> <li>Fehlerbehandlung: Einzelne fehlerhafte Items werden \u00fcbersprungen; <code>errors</code>-Feld z\u00e4hlt Ausnahmen</li> <li>Transaktionssicherheit: Jedes Item wird atomar geschrieben (RocksDB WriteBatch)</li> </ul>"},{"location":"vector_ops/#delete-by-filter","title":"Delete by Filter","text":""},{"location":"vector_ops/#endpoint_1","title":"Endpoint","text":"<pre><code>DELETE /vector/by-filter\n</code></pre>"},{"location":"vector_ops/#anfrage-pk-liste","title":"Anfrage (PK-Liste)","text":"<pre><code>{\n  \"pks\": [\"doc1\", \"doc2\", \"doc3\"]\n}\n</code></pre>"},{"location":"vector_ops/#anfrage-prafix-filter","title":"Anfrage (Pr\u00e4fix-Filter)","text":"<pre><code>{\n  \"prefix\": \"temp-\"\n}\n</code></pre>"},{"location":"vector_ops/#antwort_1","title":"Antwort","text":"<pre><code>{\n  \"deleted\": 3,\n  \"method\": \"pks\"  // oder \"prefix\"\n}\n</code></pre>"},{"location":"vector_ops/#anwendungsfalle","title":"Anwendungsf\u00e4lle","text":"<ul> <li>Cleanup: L\u00f6schen tempor\u00e4rer oder veralteter Vektoren via Pr\u00e4fix (z. B. <code>tmp-</code>, <code>staging-</code>)</li> <li>Bulk-Removal: Liste spezifischer Dokument-IDs nach Qualit\u00e4tskontrolle</li> <li>Namensraum-Bereinigung: Entfernen aller Eintr\u00e4ge eines bestimmten Namensraums</li> </ul>"},{"location":"vector_ops/#knn-suche-mit-cursor-pagination","title":"KNN-Suche mit Cursor-Pagination","text":""},{"location":"vector_ops/#endpoint_2","title":"Endpoint","text":"<pre><code>POST /vector/search\n</code></pre>"},{"location":"vector_ops/#anfrage-legacy-modus","title":"Anfrage (Legacy-Modus)","text":"<pre><code>{\n  \"vector\": [0.1, 0.2, 0.3],\n  \"k\": 10\n}\n</code></pre>"},{"location":"vector_ops/#antwort-legacy","title":"Antwort (Legacy)","text":"<pre><code>{\n  \"results\": [\n    {\"pk\": \"doc1\", \"distance\": 0.05},\n    {\"pk\": \"doc2\", \"distance\": 0.12}\n  ],\n  \"k\": 10,\n  \"count\": 2\n}\n</code></pre>"},{"location":"vector_ops/#anfrage-cursor-pagination","title":"Anfrage (Cursor-Pagination)","text":"<pre><code>{\n  \"vector\": [0.1, 0.2, 0.3],\n  \"k\": 10,\n  \"use_cursor\": true,\n  \"cursor\": \"20\"  // optional; Offset der vorherigen Seite\n}\n</code></pre>"},{"location":"vector_ops/#antwort-cursor-pagination","title":"Antwort (Cursor-Pagination)","text":"<pre><code>{\n  \"items\": [\n    {\"pk\": \"doc21\", \"distance\": 0.08},\n    {\"pk\": \"doc22\", \"distance\": 0.09}\n  ],\n  \"batch_size\": 2,\n  \"has_more\": true,\n  \"next_cursor\": \"30\"\n}\n</code></pre>"},{"location":"vector_ops/#best-practices_1","title":"Best Practices","text":"<ul> <li>Page-Size: k = 10\u2013100 f\u00fcr typische UI-Pagination; k = 100\u20131000 f\u00fcr Batch-Verarbeitung</li> <li>HNSW efSearch: Setze <code>efSearch</code> \u2265 k f\u00fcr gute Recall; 64\u2013128 ist ein guter Start</li> <li>Distanz-Metrik: COSINE (Standard) f\u00fcr normalisierte Embeddings, L2 f\u00fcr r\u00e4umliche Daten</li> <li>Cursor-Verwendung: F\u00fcr gro\u00dfe Result-Sets (&gt; k) aktiviere <code>use_cursor</code> um Memory-Druck zu reduzieren</li> </ul>"},{"location":"vector_ops/#persistenz","title":"Persistenz","text":""},{"location":"vector_ops/#speichern","title":"Speichern","text":"<pre><code>POST /vector/index/save\n{ \"directory\": \"./data/vector_index\" }\n</code></pre> <p>Speichert: - <code>meta.txt</code>: objectName, dimension, metric, efSearch, M, efConstruction - <code>labels.txt</code>: PK-Mapping (id \u2192 PK) - <code>index.bin</code>: HNSW-Struktur (wenn HNSW aktiviert)</p>"},{"location":"vector_ops/#laden","title":"Laden","text":"<pre><code>POST /vector/index/load\n{ \"directory\": \"./data/vector_index\" }\n</code></pre> <p>L\u00e4dt den Index aus persistierten Dateien; \u00fcberschreibt aktuelle In-Memory-Struktur.</p>"},{"location":"vector_ops/#auto-save","title":"Auto-Save","text":"<p>Setze <code>auto_save=true</code> und <code>savePath</code> via <code>VectorIndexManager::setAutoSavePath()</code> f\u00fcr automatisches Speichern beim Server-Shutdown.</p>"},{"location":"vector_ops/#konfiguration-zur-laufzeit","title":"Konfiguration zur Laufzeit","text":""},{"location":"vector_ops/#get-vectorindexconfig","title":"GET /vector/index/config","text":"<pre><code>{\n  \"objectName\": \"vectors\",\n  \"dimension\": 768,\n  \"metric\": \"COSINE\",\n  \"efSearch\": 64,\n  \"M\": 16,\n  \"efConstruction\": 200,\n  \"hnswEnabled\": true\n}\n</code></pre>"},{"location":"vector_ops/#put-vectorindexconfig","title":"PUT /vector/index/config","text":"<pre><code>{\n  \"efSearch\": 128\n}\n</code></pre> <p>Hinweis: <code>M</code> und <code>efConstruction</code> erfordern Index-Rebuild und k\u00f6nnen zur Laufzeit nicht ge\u00e4ndert werden.</p>"},{"location":"vector_ops/#statistiken","title":"Statistiken","text":""},{"location":"vector_ops/#get-vectorindexstats","title":"GET /vector/index/stats","text":"<pre><code>{\n  \"objectName\": \"vectors\",\n  \"dimension\": 768,\n  \"metric\": \"COSINE\",\n  \"vectorCount\": 123456,\n  \"efSearch\": 64,\n  \"M\": 16,\n  \"efConstruction\": 200,\n  \"hnswEnabled\": true\n}\n</code></pre>"},{"location":"vector_ops/#performance-ziele","title":"Performance-Ziele","text":"Operation Ziel Bemerkungen Batch Insert &lt; 500 ms / 1000 Items Mit HNSW M=16, efConstruction=200 KNN Search (k=10) &lt; 10 ms efSearch=64, ~100k Vektoren Delete by PKs (100) &lt; 50 ms Markiert als gel\u00f6scht in HNSW Delete by Prefix &lt; 200 ms / 1000 Items Scan + Batch-Delete Index Save &lt; 2 s / 100k Vectors Abh\u00e4ngig von IO-Geschwindigkeit Index Load &lt; 1 s / 100k Vectors Memory-Mapping wenn m\u00f6glich"},{"location":"vector_ops/#metriken-prometheus","title":"Metriken (Prometheus)","text":"<p>Die folgenden Metriken sind unter <code>GET /metrics</code> verf\u00fcgbar:</p> <ul> <li><code>vccdb_vector_index_size_bytes</code>: Gesch\u00e4tzte Gr\u00f6\u00dfe des In-Memory-Index</li> <li><code>vccdb_vector_search_duration_ms</code>: Histogram der Suchlatenz in Millisekunden</li> <li><code>vccdb_vector_batch_insert_duration_ms</code>: Histogram der Batch-Insert-Latenz</li> <li><code>vccdb_vector_batch_insert_total</code>: Counter der gesamten Batch-Insert-Operationen</li> <li><code>vccdb_vector_batch_insert_items_total</code>: Counter aller eingef\u00fcgten Items</li> <li><code>vccdb_vector_delete_by_filter_total</code>: Counter der Delete-by-Filter-Operationen</li> <li><code>vccdb_vector_delete_by_filter_items_total</code>: Counter aller gel\u00f6schten Items</li> </ul>"},{"location":"vector_ops/#haufige-fragen-faq","title":"H\u00e4ufige Fragen (FAQ)","text":""},{"location":"vector_ops/#q-wie-gehe-ich-mit-groen-datenmengen-um-1-mio-vektoren","title":"Q: Wie gehe ich mit gro\u00dfen Datenmengen um (&gt; 1 Mio. Vektoren)?","text":"<p>A:  1. Batch-Insert in Bl\u00f6cken von 500\u20131000 Items 2. Setze <code>M=32</code> und <code>efConstruction=400</code> f\u00fcr bessere Qualit\u00e4t (h\u00f6here Build-Zeit) 3. Nutze <code>efSearch=128\u2013200</code> zur Suche f\u00fcr h\u00f6here Recall 4. Aktiviere Auto-Save + regelm\u00e4\u00dfige Checkpoints 5. Erw\u00e4ge Sharding (mehrere Indizes) f\u00fcr Skalierung \u00fcber 10 Mio. Vektoren</p>"},{"location":"vector_ops/#q-wie-optimiere-ich-die-suche-fur-niedrige-latenz","title":"Q: Wie optimiere ich die Suche f\u00fcr niedrige Latenz?","text":"<p>A: 1. Reduziere <code>efSearch</code> auf 32\u201364 (Kompromiss: niedrigere Recall) 2. Setze <code>k</code> so niedrig wie m\u00f6glich (z. B. k=10 statt k=100) 3. Nutze Cursor-Pagination f\u00fcr gro\u00dfe Result-Sets 4. Cache h\u00e4ufige Queries (siehe <code>docs/cdc.md</code> f\u00fcr Semantic Cache)</p>"},{"location":"vector_ops/#q-kann-ich-mehrere-vektorindizes-parallel-betreiben","title":"Q: Kann ich mehrere Vektorindizes parallel betreiben?","text":"<p>A: Im aktuellen MVP unterst\u00fctzt <code>VectorIndexManager</code> einen Index pro Instanz. F\u00fcr mehrere Namensr\u00e4ume: - Option 1: Separater <code>VectorIndexManager</code> pro Namespace (mehrere Server-Instanzen) - Option 2: Pr\u00e4fix-Trennung im objectName (z. B. <code>docs_en</code>, <code>docs_de</code>)</p>"},{"location":"vector_ops/#q-was-passiert-bei-dimensionskonflikten","title":"Q: Was passiert bei Dimensionskonflikten?","text":"<p>A: Wenn ein Vektor mit falscher Dimension eingef\u00fcgt wird: - Batch-Insert: Item wird \u00fcbersprungen, <code>errors</code>-Counter erh\u00f6ht - Single-Insert: Fehler wird sofort zur\u00fcckgegeben - Search: Anfrage wird abgelehnt mit HTTP 400</p>"},{"location":"vector_ops/#q-wie-werden-geloschte-vektoren-behandelt","title":"Q: Wie werden gel\u00f6schte Vektoren behandelt?","text":"<p>A: - HNSW: <code>markDelete()</code> markiert Vektoren als gel\u00f6scht; physisches Entfernen erfordert Rebuild - Cache: Sofortige Entfernung aus PK-Mapping und Cache - RocksDB: L\u00f6schung via WriteBatch (kompaktiert in n\u00e4chster Compaction)</p>"},{"location":"vector_ops/#beispiele","title":"Beispiele","text":""},{"location":"vector_ops/#1-massenimport-aus-csv","title":"1. Massenimport aus CSV","text":"<pre><code>import csv\nimport requests\nimport numpy as np\n\nurl = \"http://localhost:8765/vector/batch_insert\"\nbatch_size = 500\n\nwith open(\"embeddings.csv\") as f:\n    reader = csv.DictReader(f)\n    batch = []\n    for row in reader:\n        vec = np.fromstring(row[\"embedding\"], sep=\",\").tolist()\n        batch.append({\n            \"pk\": row[\"id\"],\n            \"vector\": vec,\n            \"fields\": {\"title\": row[\"title\"]}\n        })\n        if len(batch) &gt;= batch_size:\n            resp = requests.post(url, json={\"items\": batch})\n            print(f\"Inserted {resp.json()['inserted']}, errors: {resp.json()['errors']}\")\n            batch = []\n    if batch:\n        resp = requests.post(url, json={\"items\": batch})\n        print(f\"Final batch: {resp.json()['inserted']} inserted\")\n</code></pre>"},{"location":"vector_ops/#2-prafix-basierte-bereinigung","title":"2. Pr\u00e4fix-basierte Bereinigung","text":"<pre><code># Alle tempor\u00e4ren Vektoren l\u00f6schen\ncurl -X DELETE http://localhost:8765/vector/by-filter \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"prefix\": \"temp-\"}'\n\n# Ausgabe: {\"deleted\": 42, \"method\": \"prefix\"}\n</code></pre>"},{"location":"vector_ops/#3-paginierte-suche","title":"3. Paginierte Suche","text":"<pre><code>import requests\n\nurl = \"http://localhost:8765/vector/search\"\nquery_vec = [0.1, 0.2, 0.3]  # Beispiel-Embedding\ncursor = None\nall_results = []\n\nwhile True:\n    payload = {\"vector\": query_vec, \"k\": 20, \"use_cursor\": True}\n    if cursor:\n        payload[\"cursor\"] = cursor\n\n    resp = requests.post(url, json=payload).json()\n    all_results.extend(resp[\"items\"])\n\n    if not resp[\"has_more\"]:\n        break\n    cursor = resp[\"next_cursor\"]\n\nprint(f\"Total results: {len(all_results)}\")\n</code></pre>"},{"location":"vector_ops/#siehe-auch","title":"Siehe auch","text":"<ul> <li>AQL Syntax \u2013 Hybrid-Queries mit Vektorsuche</li> <li>Indexes \u2013 Sekund\u00e4r- und Range-Indizes</li> <li>Deployment \u2013 Production-Setup und Tuning</li> <li>Tracing \u2013 Performance-Debugging mit OpenTelemetry</li> </ul>"},{"location":"apis/openapi/","title":"OpenAPI &amp; Endpunkte","text":"<p>Die vollst\u00e4ndige API-Spezifikation liegt als YAML vor:</p> <ul> <li><code>docs/openapi.yaml</code> (aktuell)</li> <li>optional: <code>openapi/openapi.yaml</code> (alternativ, ggf. konsolidieren)</li> </ul> <p>Aktualisierungen anstehend: - Aufnahme der neuen Endpunkte f\u00fcr Keys, Classification, Reports (bereits in <code>docs/openapi.yaml</code> erg\u00e4nzt) - Beispiele mit Request/Response und Fehlercodes - Hinweis: Das SSE-Streaming <code>GET /changefeed/stream</code> ist nicht Teil der OpenAPI (Content-Type <code>text/event-stream</code>). Details siehe \u201eChange Data Capture (CDC)\u201c.</p> <p>Hinweis: F\u00fcr eine gerenderte Ansicht (Swagger/Redoc) kann sp\u00e4ter ein MkDocs-Plugin erg\u00e4nzt werden. Bis dahin bitte die YAML-Datei direkt \u00f6ffnen oder mit einem lokalen Viewer betrachten.</p>"},{"location":"apis/openapi/#sse-streaming-changefeed","title":"SSE-Streaming (Changefeed)","text":"<p>Dieser Endpoint ist nicht Teil der OpenAPI-Spezifikation, da er <code>text/event-stream</code> zur\u00fcckliefert.</p> <ul> <li>Endpoint: <code>GET /changefeed/stream</code></li> <li>Query-Parameter:<ul> <li><code>from_seq</code> (optional, uint64): Start-Sequenz (exklusiv); Standard 0</li> <li><code>key_prefix</code> (optional, string): Filtert Events nach Schl\u00fcsselpr\u00e4fix</li> <li><code>keep_alive</code> (optional, bool): H\u00e4lt die Verbindung offen und streamt fortlaufend; Standard <code>true</code></li> <li><code>max_seconds</code> (optional, int): Maximale Streamdauer, 1..60 Sekunden (Standard 30) \u2013 f\u00fcr Rotation/Tests</li> <li><code>heartbeat_ms</code> (optional, int): Test-Override f\u00fcr Heartbeat-Intervall (min. 100ms); in Produktion nicht n\u00f6tig</li> </ul> </li> </ul> <p>Antwort: - Content-Type: <code>text/event-stream</code> - Format: jeweils eine Zeile pro Event <code>data: {JSON}\\n\\n</code>; bei Leerlauf Heartbeats <code>: heartbeat\\n\\n</code></p> <p>Beispiel (curl, Einmal-Stream f\u00fcr 10s):</p> <pre><code>curl -N \"http://localhost:8765/changefeed/stream?from_seq=0&amp;keep_alive=true&amp;max_seconds=10\"\n</code></pre> <p>Weitere Details und Best Practices (Checkpointing, Heartbeats, Reverse Proxy) siehe \u201eChange Data Capture (CDC)\u201c unter Deployment &amp; Betrieb.</p>"},{"location":"content/geo_processor_design/","title":"GeoProcessor \u2013 Design (Phase 4)","text":"<p>Dieses Dokument beschreibt die Verarbeitung von Geo-Daten (GeoJSON/GPX) im Content/Filesystem-Layer.</p>"},{"location":"content/geo_processor_design/#ziele","title":"Ziele","text":"<ul> <li>Extraktion und Normalisierung von Geometrien (Point/LineString/Polygon) nach EPSG:4326</li> <li>Berechnung der Bounding Box und optionale Vereinfachung</li> <li>Chunking in r\u00e4umliche Tiles (z. B. quadtree-\u00e4hnlich oder fixes Grid)</li> <li>Embedding aus lat/lon (grid-based) f\u00fcr grobe semantische N\u00e4he</li> </ul>"},{"location":"content/geo_processor_design/#contract","title":"Contract","text":"<ul> <li>extract(blob/json, content_type: application/geo+json | application/gpx+xml) \u2192 ExtractionResult</li> <li>fields:<ul> <li>geometry_type: Point | LineString | Polygon | Multi*</li> <li>coordinates (normalisiert, lon/lat)</li> <li>bbox: [minLon, minLat, maxLon, maxLat]</li> <li>properties: Map <li>chunk(extraction, cfg: { tile_size_deg: 0.1, max_tiles?: 64 }) \u2192 [Chunk]</li> <li>Schneidet Geometrie gegen ein regul\u00e4res Lon/Lat-Grid (Kachelung)</li> <li>payload je Chunk: { tile_bbox, geom_fraction, length_or_area }</li> <li>generateEmbedding(chunk_payload) \u2192 float[128]</li> <li>128D Vektor aus (tile center lon/lat) + scale; normalisiert</li>"},{"location":"content/geo_processor_design/#datenablage-verweis","title":"Datenablage (Verweis)","text":"<ul> <li>siehe <code>docs/storage/geo_relational_schema.md</code> (features/points/lines/polygons)</li> <li>Content-Layer speichert zus\u00e4tzlich <code>content:&lt;id&gt;</code> Meta (bbox, type, props)</li> </ul>"},{"location":"content/geo_processor_design/#normalisierung","title":"Normalisierung","text":"<ul> <li>CRS nach EPSG:4326 (lon/lat)</li> <li>BBox aus Geometrie berechnen</li> <li>MultiGeometrien in Einzelgeometrien aufteilen (optional)</li> </ul>"},{"location":"content/geo_processor_design/#chunking","title":"Chunking","text":"<ul> <li>Regul\u00e4res Grid \u00fcber BBox; f\u00fcr jede Kachel, die Geometrie schneidet \u2192 Chunk</li> <li><code>geom_fraction</code>: Anteil der Geometrie in der Kachel (Heuristik)</li> <li><code>length_or_area</code>: Metrik (Linienl\u00e4nge/Polygonfl\u00e4che) innerhalb der Kachel</li> </ul>"},{"location":"content/geo_processor_design/#embedding-grid-based","title":"Embedding (grid-based)","text":"<ul> <li>Positionsembedding \u00fcber sinus/cosinus Kodierung der lon/lat des Kachelzentrums</li> <li>Skalierung \u00fcber Zoom/Frequenzen; Ausgabe 128D, L2-normalisiert</li> </ul>"},{"location":"content/geo_processor_design/#tests-20-unit-tests","title":"Tests (20 Unit Tests)","text":"<p>1) extract: Point korrekt normalisiert + bbox 2-3) extract: LineString/Polygon bbox korrekt 4) extract: MultiPolygon \u2192 mehrere Einheiten (optional) 5-8) chunk: Kachelz\u00e4hlung abh\u00e4ngig von bbox/tile_size 9-12) chunk: geom_fraction plausibel (0..1) 13-14) chunk: length/area konsistent 15-17) embedding: 128D, L2\u22481.0, deterministisch 18-20) integration: insert + index + query stub</p>"},{"location":"content/geo_processor_design/#open-points","title":"Open Points","text":"<ul> <li>GPX H\u00f6henprofil/Elevation, Zeitstempel</li> <li>Genauere Fl\u00e4chen-/L\u00e4ngenberechnung (Geod\u00e4sie)</li> <li>Integration mit r\u00e4umlichen Indizes (RocksDB sekund\u00e4r vs. externer Store)</li> </ul>"},{"location":"content/image_processor_design/","title":"ImageProcessor \u2013 Design (Phase 4)","text":"<p>Dieses Dokument beschreibt die Architektur und Testspezifikation f\u00fcr den Bildverarbeitungsprozessor innerhalb des Content/Filesystem-Layers.</p>"},{"location":"content/image_processor_design/#ziele","title":"Ziele","text":"<ul> <li>Einheitliche Verarbeitung von Image-Content (JPEG/PNG) \u00fcber das Processor-Plugin-Modell</li> <li>Extraktion von EXIF/Meta (Dimensionen, GPS, Kamera), Thumbnail-Erzeugung</li> <li>Chunking als 3x3 Tile-Grid f\u00fcr lokale Features</li> <li>Mock-Embedding (768D) kompatibel zum bestehenden Vector-Index (Cosine)</li> </ul>"},{"location":"content/image_processor_design/#contract","title":"Contract","text":"<ul> <li>extract(blob, content_type: image/*) \u2192 ExtractionResult</li> <li>fields:<ul> <li>width, height (px)</li> <li>exif: { camera_make, camera_model, focal_length, iso, datetime_original?, gps_lat?, gps_lon? }</li> <li>mime_type</li> <li>thumbnail (optional, z. B. 256px Kante, JPEG/PNG)</li> </ul> </li> <li>chunk(extraction, cfg: { grid: 3x3, overlap_px?: 0 }) \u2192 [Chunk]</li> <li>Jeder Chunk repr\u00e4sentiert ein Tile (row, col, bbox_px)</li> <li>payload: { tile_bbox: {x,y,w,h}, stats: { mean_rgb, std_rgb } }</li> <li>generateEmbedding(chunk_payload) \u2192 float[768]</li> <li>Mock-CLIP: deterministische Hash-Verteilung \u00fcber Pixel-Statistiken + Position</li> <li>L2-normalisiert</li> </ul>"},{"location":"content/image_processor_design/#datenablage-schlusseljson","title":"Datenablage (Schl\u00fcssel/JSON)","text":"<ul> <li>content: \u2192 Meta (mime_type,image meta, exif, dims) <li>content_blob: \u2192 Originalbild (binary) <li>content_thumbnail: \u2192 Thumbnail (binary) <li>content_chunks: \u2192 [chunk_ids] <li>chunk: \u2192 { parent_id, row, col, bbox_px, stats, embedding_ref } <li>Hinweis: Vector-Index unter Namespace \"chunks\" (dim=768, COSINE)</li>"},{"location":"content/image_processor_design/#tile-spezifikation","title":"Tile-Spezifikation","text":"<ul> <li>Grid 3x3 \u00fcber (width,height)</li> <li>bbox_px Berechnung: floor/ceil so verteilen, dass alle Pixel abgedeckt sind</li> <li>stats: mean/std RGB (grob, optional proxy aus Thumbnail/Downscale)</li> </ul>"},{"location":"content/image_processor_design/#embedding-mock","title":"Embedding (Mock)","text":"<ul> <li>Input: { mean_rgb, std_rgb, row, col, width, height }</li> <li>Hash-basierte Projektion mit 3 Seeds \u2192 768D; leichte Positionskodierung</li> <li>L2-Normalisierung (Cosine-kompatibel)</li> </ul>"},{"location":"content/image_processor_design/#exifmeta","title":"EXIF/Meta","text":"<ul> <li>Felder:</li> <li>Dimensionen: width/height</li> <li>Kamera: make/model</li> <li>Aufnahme: datetime_original, iso, focal_length</li> <li>GPS: gps_lat, gps_lon (falls vorhanden)</li> <li>Fehlertoleranz: fehlende EXIF zul\u00e4ssig; gps optional</li> </ul>"},{"location":"content/image_processor_design/#tests-20-unit-tests","title":"Tests (20 Unit Tests)","text":"<p>1-3) extract: liest width/height korrekt (JPEG/PNG Samples) 4) extract: fehlende EXIF \u2192 Felder optional 5) extract: GPS parsing korrekt 6-10) chunk: 3x3 Tiles count/bbox korrekt, Gesamtfl\u00e4che abgedeckt 11-13) chunk: stats plausibel (mean in [0,1], std \u2265 0) 14-17) embedding: dimension=768, L2\u22481.0, deterministisch bei idempotentem Input 18) embedding: unterschiedliche Tiles \u2192 unterschiedliche Vektoren (cosine&lt;0.99) 19) integration: ingest \u2192 vector index init (dim 768) 20) integration: retrieval of chunks ohne Embeddings (Datenschutz/Antwortgr\u00f6\u00dfe)</p>"},{"location":"content/image_processor_design/#open-points","title":"Open Points","text":"<ul> <li>Farbmanagement/EXIF-Orientierung ber\u00fccksichtigen (Rotation)</li> <li>Downscale-Strategie (schneller Pfad via Thumbnail)</li> <li>Erweiterung: Face/Logo-Detektion (sp\u00e4ter, extern)</li> </ul>"},{"location":"content/ingestion/","title":"Content v0: Bulk Ingestion","text":"<p>Dieses Dokument beschreibt das v0-Schema f\u00fcr den Bulk-Import von bereits vorverarbeiteten Inhalten \u00fcber die HTTP-API. Ziel: Einfache, robuste \u00dcbernahme von Content-Metadaten, optionalem Original-Blob, Chunks (inkl. Embeddings) und optionalen Graph-Kanten.</p> <p>Stand: MVP, stabil genug f\u00fcr erste Integrationen. Erweiterungen (z. B. SSE-CDC, fortgeschrittene Filter) folgen sp\u00e4ter.</p>"},{"location":"content/ingestion/#endpunkte","title":"Endpunkte","text":"<ul> <li>POST /content/import</li> <li>Nimmt einen strukturierten JSON-Spec entgegen und speichert Content-Meta, Chunk-Metas, optional den Original-Blob sowie optional Graph-Kanten.</li> <li>GET /content/{id}</li> <li>Liefert die Content-Metadaten zur\u00fcck.</li> <li>GET /content/{id}/blob</li> <li>Liefert den gespeicherten Bin\u00e4rblob (Content-Type aus <code>mime_type</code>).</li> <li>GET /content/{id}/chunks</li> <li>Liefert alle Chunks (Metadaten). Aus Platzgr\u00fcnden wird die <code>embedding</code>-Liste in der Antwort auf leere Arrays normalisiert.</li> </ul> <p>Hinweis: Alle IDs k\u00f6nnen mit oder ohne Prefix \u00fcbergeben werden. Intern werden folgende Keys verwendet: - content:{id}, content_blob:{id}, content_chunks:{id} - chunk:{id}</p>"},{"location":"content/ingestion/#import-schema-request","title":"Import-Schema (Request)","text":"<p>Request-Body f\u00fcr POST /content/import:</p> <p>{   \"content\": {     \"id\": \"optional-string-uuid\",     \"mime_type\": \"text/plain\",     \"category\": 0,     \"original_filename\": \"optional.txt\",     \"size_bytes\": 0,     \"created_at\": 0,     \"modified_at\": 0,     \"hash_sha256\": \"\",     \"text_extracted\": false,     \"chunked\": false,     \"indexed\": false,     \"chunk_count\": 0,     \"embedding_dim\": 0,     \"extracted_metadata\": {},     \"user_metadata\": {},     \"tags\": [\"optional\", \"tags\"],     \"parent_id\": \"\",     \"child_ids\": []   },   \"chunks\": [     {       \"id\": \"optional-chunk-id\",       \"content_id\": \"optional-content-id\",       \"seq_num\": 0,       \"chunk_type\": \"text\",       \"text\": \"optional chunk text\",       \"data\": {},       \"blob_ref\": \"\",       \"start_offset\": 0,       \"end_offset\": 0,       \"embedding\": [/ optional float[] /],       \"embedding_indexed\": false,       \"created_at\": 0     }   ],   \"edges\": [     { \"from\": \"nodeA\", \"to\": \"nodeB\", \"type\": \"next\", \"weight\": 1.0 }   ],   \"blob\": \"optional raw blob als String\"    // alternativ: \"blob_base64\": \"...\" (derzeit ohne Dekodierung im Server-MVP) }</p> <p>Erl\u00e4uterungen: - content.id: Wenn nicht gesetzt, wird serverseitig eine UUID generiert. - blob: Wird unter key \"content_blob:{id}\" gespeichert. Gr\u00f6\u00dfe wird in <code>content.size_bytes</code> \u00fcbernommen. - chunks[].id: Wird generiert, falls nicht angegeben. <code>content_id</code> wird auf die Content-ID normiert. - chunks[].embedding: Falls gesetzt und Dimension zum initialisierten Vektorindex passt, wird ein Vektorobjekt mit PK \"chunks:{chunk_id}\" im VectorIndex angelegt. Ist noch kein Index initialisiert, wird er implizit mit Objektname \"chunks\" und COSINE-Metrik anhand der ersten Embedding-Dimension initialisiert. - edges: Optionale Kanten, die als Graph-Edges gespeichert werden (frei gestaltbares Feldschema; h\u00e4ufig: from, to, type, weight).</p>"},{"location":"content/ingestion/#antworten","title":"Antworten","text":"<ul> <li>200 OK: { \"status\": \"success\", \"content_id\": \"...\" }</li> <li>4xx/5xx mit Schema { error: true, message: string, status_code: number }</li> </ul>"},{"location":"content/ingestion/#beispiele","title":"Beispiele","text":"<p>Minimaler Text-Import ohne Embeddings:</p> <p>POST /content/import Content-Type: application/json</p> <p>{   \"content\": {     \"id\": \"doc-001\",     \"mime_type\": \"text/plain\",     \"user_metadata\": {\"dataset\": \"alpha\"},     \"tags\": [\"demo\"]   },   \"blob\": \"Hello world\",   \"chunks\": [     {\"seq_num\": 0, \"chunk_type\": \"text\", \"text\": \"Hello\"},     {\"seq_num\": 1, \"chunk_type\": \"text\", \"text\": \"world\"}   ] }</p> <p>Antwort:</p> <p>{   \"status\": \"success\",   \"content_id\": \"doc-001\" }</p> <p>Abfrage der Metadaten: - GET /content/doc-001 \u2192 ContentMeta inkl. chunk_count - GET /content/doc-001/chunks \u2192 { count, chunks: [...] } (embedding-Felder leere Arrays) - GET /content/doc-001/blob \u2192 liefert den Blob (Content-Type: text/plain)</p>"},{"location":"content/ingestion/#filter-und-graph-funktionen-ausblick","title":"Filter- und Graph-Funktionen (Ausblick)","text":"<ul> <li>Hybrid-/Vektorsuche: POST /search/hybrid (siehe allgemeine Doku); nutzt VectorIndex plus optionale Graph-Expansion.</li> <li>Filterkonfiguration: GET/PUT /config/content-filters</li> <li>Schema: { field_map: { alias: \"json.pfad.im.contentmeta\" } }</li> <li>Dient der Deklaration, welche Felder in Content-Metadaten f\u00fcr Filter verwendet werden k\u00f6nnen.</li> <li>Kanten-Gewichte: GET/PUT /config/edge-weights</li> </ul>"},{"location":"content/ingestion/#kompatibilitat-und-grenzen","title":"Kompatibilit\u00e4t und Grenzen","text":"<ul> <li><code>blob_base64</code> wird aktuell nicht automatisch dekodiert; bitte <code>blob</code> verwenden oder selbst dekodieren, bevor es gesendet wird.</li> <li><code>category</code> ist derzeit als numerischer Enumwert erwartbar (0=TEXT, 1=IMAGE, ...); ist optional, da <code>mime_type</code> f\u00fcr viele Workflows ausreichend ist.</li> <li>Embeddings erfordern einen initialisierten VectorIndex (wird bei erstem Einf\u00fcgen implizit f\u00fcr Objektname \"chunks\" angelegt).</li> </ul>"},{"location":"content/ingestion/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>400 Invalid JSON: Request-Body ist kein valides JSON.</li> <li>500 failed to store ...: Persistenzfehler (RocksDB). Logs pr\u00fcfen.</li> <li>Chunks erscheinen ohne Embeddings: Pr\u00fcfen, ob Dimension konsistent ist bzw. ob \u00fcberhaupt Embeddings \u00fcbergeben wurden.</li> </ul>"},{"location":"content/ingestion/#ingestion-leitfaden-vorverarbeitung-vor-dem-import-maximale-verknupfbarkeit","title":"Ingestion-Leitfaden: Vorverarbeitung vor dem Import (Maximale Verkn\u00fcpfbarkeit)","text":"<p>Ziel dieses Leitfadens ist es, externe Ingestion-Pipelines so zu beschreiben, dass Inhalte vor dem Schreiben in THEMIS maximal verkn\u00fcpfbar sind. Die DB selbst f\u00fchrt keine Extraktion durch \u2013 sie erwartet bereits strukturierte JSON-Daten gem\u00e4\u00df <code>POST /content/import</code> und baut darauf Indexe (Dokument-, Graph- und Vektorindex) auf.</p> <p>Die folgenden Empfehlungen liefern pro Datentyp konkrete Schritte, Felder und Kanten-Modelle, um Breite (viele Verbindungsm\u00f6glichkeiten) und Tiefe (hohe semantische Dichte) zu maximieren.</p>"},{"location":"content/ingestion/#grundprinzipien","title":"Grundprinzipien","text":"<ul> <li>Eindeutige, stabile IDs: Bestimmen Sie <code>content.id</code> deterministisch (z. B. Hash aus Normal-Form des Quellobjekts). Chunk-IDs k\u00f6nnen aus <code>content.id</code> + Positionsmerkmalen abgeleitet werden.</li> <li>Chunking vor Embedding: Zerlegen Sie Inhalte semantisch (Abs\u00e4tze, Szenen, Segmente, Zeilen, Komponenten), erzeugen Sie dann pro Chunk Embeddings. So bleiben Kanten und Kontext fein granular.</li> <li>Kanonisches Schema nutzen: Mappen Sie alles auf <code>content</code> (Metadaten), <code>chunks</code> (Kleinstrukturen), <code>edges</code> (Relationen). Halten Sie sich an wiederkehrende Schl\u00fcssel:</li> <li><code>source_uri</code>, <code>hash_sha256</code>, <code>created_at</code>, <code>modified_at</code>, <code>language</code>, <code>authors</code>, <code>topics</code>, <code>tags</code></li> <li>Zeitliche Felder: <code>start_ms</code>, <code>end_ms</code> (Audio/Video-Segmente)</li> <li>R\u00e4umliche Felder: <code>lat</code>, <code>lon</code>, <code>bbox</code>, <code>srid</code>, <code>geometry</code></li> <li>Strukturfelder in <code>chunks[*].data</code>: typ-spezifisch (siehe unten)</li> <li>Ontologien &amp; kontrollierte Vokabulare: Verwenden Sie normierte Werte (ISO-Sprachcodes, EPSG f\u00fcr Geo, Standard-Einheiten, taxonomische Kategorien), um Abgleich/Join zu erleichtern.</li> <li>Kanten explizit modellieren: Nutzen Sie <code>edges</code> mit <code>type</code> und optional <code>weight</code>. Empfohlene Typen: <code>derived_from</code>, <code>contains</code>, <code>references</code>, <code>mentions</code>, <code>same_as</code>, <code>next</code>, <code>similar</code>, <code>depicts</code>, <code>located_in</code>, <code>belongs_to</code>, <code>mate</code> (CAD).</li> <li>Datenschutz: Entfernen/Maskieren Sie PII fr\u00fchzeitig. Speichern Sie nur notwendige Felder, nutzen Sie Pseudonyme/Hashes bei Bedarf.</li> </ul>"},{"location":"content/ingestion/#modalitatsspezifische-leitfaden","title":"Modalit\u00e4tsspezifische Leitf\u00e4den","text":""},{"location":"content/ingestion/#1-bilder-rastergrafiken","title":"1) Bilder (Rastergrafiken)","text":"<p>Pipeline-Schritte: - EXIF/Metadaten extrahieren (Kamera, Zeit, GPS) - Objekterkennung/Tags (z. B. Personen, Orte, Dinge) \u2013 <code>chunks[*].data.objects</code> - OCR f\u00fcr eingebetteten Text \u2013 Ergebnisse als eigener Text-Chunk - Bildunterschrift/Captioning \u2013 kurze Beschreibung als Text-Chunk - Perceptual Hash (pHash/aHash) \u2013 Deduplikation/\u00c4hnlichkeit - Multimodales Embedding (z. B. CLIP) f\u00fcr Retrieval</p> <p>Mapping: - <code>content.mime_type = image/jpeg|png</code> | <code>category = IMAGE</code> - Chunks:   - <code>chunk_type = image_meta</code> mit <code>{ exif: {...}, p_hash: \"...\", colors: [...] }</code>   - <code>chunk_type = text</code> f\u00fcr OCR/Caption (<code>text</code> gesetzt)   - <code>embedding</code> am passenden Chunk (z. B. Caption-Chunk oder <code>image_meta</code>) - Kanten:   - <code>derived_from</code> (zwischen Transformaten/Thumbnails und Original)   - <code>similar</code> (zu anderen Bildern per pHash/Embedding)   - <code>depicts</code> (zu Entit\u00e4ten: Personen, Orte, Objekte)</p> <p>Beispiel (auszugsweise):</p> <pre><code>{\n  \"content\": {\"id\":\"img:beach-001\",\"mime_type\":\"image/jpeg\",\"tags\":[\"beach\",\"sunset\"],\"extracted_metadata\":{\"exif\":{\"gps\":{\"lat\":36.6,\"lon\":-121.9}}}},\n  \"chunks\": [\n    {\"seq_num\":0,\"chunk_type\":\"image_meta\",\"data\":{\"p_hash\":\"cafe1234\",\"objects\":[\"person\",\"sea\"],\"colors\":[\"#ffaa77\",\"#003355\"]},\"embedding\":[...]},\n    {\"seq_num\":1,\"chunk_type\":\"text\",\"text\":\"A person walking along the beach at sunset.\",\"embedding\":[...]}\n  ],\n  \"edges\":[{\"from\":\"img:beach-001\",\"to\":\"place:carmel\",\"type\":\"located_in\",\"weight\":0.9}]\n}\n</code></pre>"},{"location":"content/ingestion/#2-video","title":"2) Video","text":"<p>Pipeline-Schritte: - Szenen-/Shot-Erkennung \u2192 Szenen-Segmente mit <code>start_ms</code>/<code>end_ms</code> - Keyframes extrahieren (als separate Bild-Contents, mit <code>derived_from</code>-Kanten) - ASR-Transkript (Sprache erkennen, ggf. \u00dcbersetzung) + Sprecherdiarisierung - Objekterkennung/Tracking \u00fcber Zeit (Tracks als Arrays) - Segment-Embeddings (z. B. pro Szene, pro 2\u20135 Sekunden)</p> <p>Mapping: - <code>content.mime_type = video/mp4</code> | <code>category = VIDEO</code> - Chunks:   - <code>chunk_type = scene</code> mit <code>{ start_ms, end_ms, transcript, speakers:[...], objects:[...], tracks:[...] }</code>   - <code>chunk_type = text</code> f\u00fcr reine Transkript-Segmente   - Embeddings am jeweiligen Segment-Chunk - Kanten:   - <code>contains</code> (Video \u2192 Keyframe-Bilder), <code>derived_from</code> (Keyframe \u2192 Video)   - <code>mentions</code>/<code>depicts</code> zu erkannten Entit\u00e4ten   - <code>next</code> zwischen Szenen in zeitlicher Reihenfolge</p> <p>Beispiel (auszugsweise):</p> <pre><code>{\n  \"content\":{\"id\":\"vid:promo-2025\",\"mime_type\":\"video/mp4\",\"duration_ms\":90000},\n  \"chunks\":[\n    {\"seq_num\":0,\"chunk_type\":\"scene\",\"data\":{\"start_ms\":0,\"end_ms\":6000,\"transcript\":\"Welcome to...\",\"speakers\":[\"spk1\"]},\"embedding\":[...]},\n    {\"seq_num\":1,\"chunk_type\":\"scene\",\"data\":{\"start_ms\":6000,\"end_ms\":12000,\"transcript\":\"Our product...\"},\"embedding\":[...]}\n  ],\n  \"edges\":[{\"from\":\"vid:promo-2025\",\"to\":\"img:keyframe-abc\",\"type\":\"contains\"}]\n}\n</code></pre>"},{"location":"content/ingestion/#3-audio","title":"3) Audio","text":"<p>Pipeline-Schritte: - ASR-Transkript + Sprecher-Erkennung - Segmentierung (z. B. Voice Activity Detection) mit <code>start_ms</code>/<code>end_ms</code> - Audio-Embeddings pro Segment</p> <p>Mapping: - <code>content.mime_type = audio/mpeg|wav</code> | <code>category = AUDIO</code> - <code>chunk_type = segment|text</code> mit zeitlichen Feldern und <code>text</code> - Kanten: <code>next</code> (Sequenz), <code>mentions</code> (Erw\u00e4hnte Entit\u00e4ten)</p>"},{"location":"content/ingestion/#4-schriftdokumente-pdfdocx","title":"4) Schriftdokumente (PDF/DOCX)","text":"<p>Pipeline-Schritte: - Layout-aware Parsing (Abschnitt, \u00dcberschrift, Absatz, Liste, Tabelle, Fu\u00dfnote) - Semantische Chunking-Regeln (Absatzbl\u00f6cke 200\u2013400 Tokens; Tabellen als eigene Chunks) - Referenzen/Zitationen extrahieren (DOIs, URLs) \u2192 <code>edges: references</code> - Embeddings pro Text-Chunk</p> <p>Mapping: - <code>mime_type = application/pdf|vnd.openxmlformats-officedocument.wordprocessingml.document</code> - Chunks:   - <code>chunk_type = text</code> mit <code>{ section:\"2.3\", page: 5, heading: \"Method\" }</code>   - <code>chunk_type = table</code> mit <code>{ schema: {...}, cells: [...], page: n }</code> (kompakt halten) - Kanten:   - <code>references</code> (Zitationen), <code>mentions</code> (Begriffe), <code>same_as</code> (Duplikat-Funde)</p>"},{"location":"content/ingestion/#5-tabellendokumente-csvxlsx","title":"5) Tabellendokumente (CSV/XLSX)","text":"<p>Pipeline-Schritte: - Schema- und Typinferenz (Datums-/Zahl-/Einheiten-Normalisierung) - Fremdschl\u00fcssel-/Referenzen ableiten (Spalten, die IDs/Schl\u00fcssel enthalten) - Zeilen-Embeddings (aus konkatenierten textuellen Spalten) optional</p> <p>Mapping: - <code>mime_type = text/csv|application/vnd.openxmlformats-officedocument.spreadsheetml.sheet</code> - Chunks:   - <code>chunk_type = row</code> mit <code>{ row_index, values: {col: val, ...}, normalized: {...} }</code>   - <code>chunk_type = schema</code> f\u00fcr Kopf-/Spaltenmetadaten - Kanten:   - <code>references</code>/<code>foreign_key</code> (Zeile \u2192 referenzierte Entit\u00e4t/Content)</p> <p>Beispiel (auszugsweise):</p> <pre><code>{\n  \"content\":{\"id\":\"csv:customers-2025\",\"mime_type\":\"text/csv\",\"user_metadata\":{\"dataset\":\"crm\"}},\n  \"chunks\":[\n    {\"seq_num\":0,\"chunk_type\":\"schema\",\"data\":{\"columns\":[{\"name\":\"customer_id\",\"type\":\"string\"},{\"name\":\"city\",\"type\":\"string\"}]}},\n    {\"seq_num\":1,\"chunk_type\":\"row\",\"data\":{\"row_index\":1,\"values\":{\"customer_id\":\"C-001\",\"city\":\"Berlin\"}}}\n  ],\n  \"edges\":[{\"from\":\"chunk:csv:customers-2025:row:1\",\"to\":\"city:berlin\",\"type\":\"references\",\"weight\":0.8}]\n}\n</code></pre>"},{"location":"content/ingestion/#6-cad-daten-bomassemblies","title":"6) CAD-Daten (BOM/Assemblies)","text":"<p>Pipeline-Schritte: - Ableitung der St\u00fcckliste (BOM), Komponenten, Unterbaugruppen - Geometrische Metadaten (Abmessungen, Material, Toleranzen), optional vereinfachte Meshes/Thumbnails - \u00c4hnlichkeitssuche (Feature-Hash/Embedding) f\u00fcr \u201e\u00e4hnliche Teile\u201c - Constraints/Mates zwischen Komponenten</p> <p>Mapping: - <code>mime_type = application/vnd.cad+zip|step|iges</code> (je nach Quelle) - Chunks:   - <code>chunk_type = cad_part</code> mit <code>{ part_no, name, material, dims:{...}, mass, attributes:{...} }</code>   - <code>chunk_type = cad_assembly</code> mit <code>{ components:[{ref:\"...\", qty:n}], constraints:[...]}</code> - Kanten:   - <code>contains</code> (Assembly \u2192 Part), <code>mate</code> (Part \u2194 Part), <code>similar</code> (Part \u2194 Part)   - <code>derived_from</code> (Darstellungen wie Thumbnails \u2194 Original)</p>"},{"location":"content/ingestion/#7-geodaten","title":"7) Geodaten","text":"<p>Pipeline-Schritte: - Geometrien normieren (GeoJSON), Ziel-SRID EPSG:4326 (WGS84) - Bounding Box berechnen (<code>bbox</code>), ggf. Vereinfachung f\u00fcr \u00dcbersicht - Verkn\u00fcpfungen zu administrativen Einheiten (Gemeinde, Landkreis, Bundesland) \u2013 vorberechnen - Zeitliche G\u00fcltigkeit (falls vorhanden) als Felder abbilden</p> <p>Mapping: - <code>mime_type = application/geo+json|application/json</code> - Chunks:   - <code>chunk_type = feature</code> mit <code>{ geometry: {...}, srid: 4326, bbox: [...], properties: {...} }</code> - Kanten:   - <code>located_in</code> (Feature \u2192 admin Einheit), <code>adjacent_to</code>, <code>part_of</code></p> <p>Beispiel (auszugsweise):</p> <pre><code>{\n  \"content\":{\"id\":\"geo:park-berlin\",\"mime_type\":\"application/geo+json\"},\n  \"chunks\":[{\"seq_num\":0,\"chunk_type\":\"feature\",\"data\":{\"srid\":4326,\"geometry\":{\"type\":\"Polygon\",\"coordinates\":[... ]},\"bbox\":[...],\"properties\":{\"name\":\"Tiergarten\"}}}]\n}\n</code></pre>"},{"location":"content/ingestion/#kanten-design-und-gewichte","title":"Kanten-Design und Gewichte","text":"<ul> <li>Verwenden Sie sprechende <code>type</code>-Werte (siehe oben). Gewichte <code>weight</code> optional verwenden, um Relevanz (0\u20131) zu codieren.</li> <li>Systemweite Gewichtung kann via <code>/config/edge-weights</code> kalibriert werden.</li> <li>Reihenfolge-Kanten (<code>next</code>) erleichtern zeitliche/strukturelle Pfade (z. B. Video-Szenen, Dokument-Abs\u00e4tze).</li> </ul>"},{"location":"content/ingestion/#ids-deduplikation-provenienz","title":"IDs, Deduplikation, Provenienz","text":"<ul> <li>IDs deterministisch: <code>id = prefix:base64(sha256(normalized_source))</code></li> <li><code>hash_sha256</code> am <code>content</code> f\u00fcr schnelle Duplikatpr\u00fcfung</li> <li><code>source_uri</code> und <code>provenance</code> (z. B. Tool-Versionen) in <code>extracted_metadata</code></li> </ul>"},{"location":"content/ingestion/#qualitatssicherung-empfehlungen","title":"Qualit\u00e4tssicherung (Empfehlungen)","text":"<ul> <li>Mindestabdeckung: \u226595% der Chunks mit Spracheintrag <code>language</code> (falls Text vorhanden)</li> <li>Embedding-Dimension konsistent halten; Fehlw\u00fcrfe (NaNs) filtern</li> <li>Tabellen: Typinferenzquote und Normalisierung dokumentieren</li> <li>ASR: Wort-Fehlerrate (WER) erfassen; Sprecherlabels plausibilisieren</li> </ul>"},{"location":"content/ingestion/#performance-groe","title":"Performance &amp; Gr\u00f6\u00dfe","text":"<ul> <li>Text-Chunks 200\u2013400 Tokens f\u00fcr gute Retrieval/Ranking-Qualit\u00e4t</li> <li>Video/Audio-Segmente 2\u201310 Sekunden f\u00fcr annehmbare Granularit\u00e4t</li> <li>Bilder: OCR-Text als eigener Chunk, Bild-Captioning kurz halten (\u2264 200 Zeichen)</li> <li>Gro\u00dfe Payloads ggf. in Batches aufteilen; <code>chunk_count</code> am <code>content</code> liefern</li> </ul>"},{"location":"content/ingestion/#sicherheit-datenschutz","title":"Sicherheit &amp; Datenschutz","text":"<ul> <li>PII vor Import anonymisieren; nur erforderliche Teile speichern</li> <li>Hashen/Pseudonymisieren, wo m\u00f6glich</li> <li>Vollst\u00e4ndige Ereignis-/Zugriffsketten au\u00dferhalb von THEMIS auditieren</li> </ul> <p>Mit diesem Leitfaden werden Inhalte so vorbereitet, dass THEMIS sie optimal \u00fcber Dokument-, Graph- und Vektorindex verkn\u00fcpfen kann. Die Beispiele zeigen, wie Modalit\u00e4ten in das kanonische <code>content/chunks/edges</code>-Schema abgebildet werden, um reichhaltige Abfragen (Hybrid-Suche, Pfad-Expansion, Analysen) zu erm\u00f6glichen.</p>"},{"location":"ingestion/json_ingestion_spec/","title":"JSON Ingestion Spezifikation (Post-Go-Live)","text":"<p>Ziel dieses Dokuments ist, den standardisierten JSON-gest\u00fctzten Ingestion-Prozess (ETL) zu definieren, damit strukturierte, Geo- und Textdaten aus heterogenen Quellen konsistent, abfragefreundlich und revisionssicher in die Kerndatenbank \u00fcbernommen werden.</p>"},{"location":"ingestion/json_ingestion_spec/#zweck-scope","title":"Zweck &amp; Scope","text":"<ul> <li>Einheitlicher Contract f\u00fcr alle Quellen (GeoJSON, GPX, CSV, propriet\u00e4r, Text/Binary mit Metadaten)</li> <li>Abfragef\u00e4higkeit entlang dreier Achsen: Relational (Attribute/Begriffe), R\u00e4umlich (Punkt/Linie/Polygon), Semantisch (Vektor)</li> <li>Qualit\u00e4t, Idempotenz, Deduplikation, Lineage/Audit als First-Class-Bestandteile</li> </ul>"},{"location":"ingestion/json_ingestion_spec/#mini-contract-inputsoutputs","title":"Mini-Contract (Inputs/Outputs)","text":"<ul> <li>Input: JSON-Dokument (Payload) + optionaler Bin\u00e4rblob (z. B. Originaldatei)</li> <li>Output:</li> <li>Relationale Records (Tables: features/points/lines/polygons/terms/synonyms)</li> <li>Optional Blob-Speicher (Original) + Hash</li> <li>Indizes: r\u00e4umlich (BBox/GiST), textuell (B-Tree/FTS/Trigram), vektoriell</li> <li>Fehler/Qualit\u00e4t: Validierungsfehler in DLQ; Metriken/Logs; Retry mit Idempotenz-Schl\u00fcssel</li> </ul>"},{"location":"ingestion/json_ingestion_spec/#json-struktur-generisch","title":"JSON-Struktur (generisch)","text":"<pre><code>{\n  \"source_id\": \"beh\u00f6rde-bayern-lsg-2025\",\n  \"source_pk\": \"ext-12345\",\n  \"content_type\": \"geo\",\n  \"geo\": {\n    \"type\": \"Polygon\",\n    \"crs\": \"EPSG:4326\",\n    \"coordsPath\": \"features[0].geometry.coordinates\",\n    \"bbox\": [minLon, minLat, maxLon, maxLat]\n  },\n  \"text\": {\n    \"language\": \"de\",\n    \"fields\": [\"properties.name\", \"properties.category\"],\n    \"tokenization\": \"default\"\n  },\n  \"mappings\": {\n    \"name\": \"properties.name\",\n    \"class\": \"properties.category\",\n    \"tags\": \"properties.tags\"\n  },\n  \"transforms\": [\n    {\"op\": \"trim\", \"field\": \"name\"},\n    {\"op\": \"upper\", \"field\": \"class\"},\n    {\"op\": \"synonym_map\", \"field\": \"class\", \"dict\": \"geo_classes_v1\"}\n  ],\n  \"provenance\": {\n    \"ingested_at\": \"2025-10-28T12:00:00Z\",\n    \"ingested_by\": \"etl@system\",\n    \"license\": \"CC-BY\"\n  },\n  \"metadata\": {\"version\": 1, \"note\": \"LSG Import 2025\"}\n}\n</code></pre> <p>Hinweis: F\u00fcr reine Textquellen entf\u00e4llt der Block <code>geo</code>. F\u00fcr GPX/LineStrings: <code>type: \"LineString\"</code>. F\u00fcr Punktdaten: <code>type: \"Point\"</code> und <code>coordsPath</code> verweist auf <code>[lon,lat]</code>.</p>"},{"location":"ingestion/json_ingestion_spec/#pipeline-schritte","title":"Pipeline-Schritte","text":"<ol> <li>detect: MIME/Category, ggf. Magic Bytes</li> <li>extract: Quelle lesen (GeoJSON/GPX/CSV/Text)</li> <li>normalize:</li> <li>Geo: nach EPSG:4326 (lon/lat), BBox berechnen, MultiGeometrien aufl\u00f6sen</li> <li>Text: Unicode-Normalisierung, Language-Detection (falls nicht vorgegeben)</li> <li>map: Felder gem\u00e4\u00df <code>mappings</code> extrahieren, <code>transforms</code> anwenden</li> <li>validate(schema): Pflichtfelder, Datentypen, Geometrie-Validit\u00e4t (self-intersections)</li> <li>write:</li> <li>Relationale Tabellen (features + points/lines/polygons)</li> <li>Optional: blobs + content_hash</li> <li>index: r\u00e4umliche Indizes, textuelle Indizes, Vektor-Embeddings (optional)</li> <li>lineage/audit: Provenienz und Hash-Manifest erfassen</li> </ol>"},{"location":"ingestion/json_ingestion_spec/#idempotenz-deduplikation","title":"Idempotenz &amp; Deduplikation","text":"<ul> <li>Idempotenz-Schl\u00fcssel: <code>(source_id, source_pk)</code></li> <li>Deduplizierung: <code>content_hash</code> (SHA-256 des Normalform-JSONs bzw. Blobs)</li> <li>Wiederholungen: Upsert-Strategie mit Versionsz\u00e4hler (optimistische MVCC)</li> </ul>"},{"location":"ingestion/json_ingestion_spec/#qualitatsregeln-fehlerbehandlung","title":"Qualit\u00e4tsregeln &amp; Fehlerbehandlung","text":"<ul> <li>Validation Errors \u2192 DLQ (JSON + Fehlerliste)</li> <li>Retry-Politik mit Backoff; Max-Retries konfigurierbar</li> <li>Metriken: <code>ingested_total</code>, <code>failed_total</code>, <code>duplicates_total</code>, Latenzen je Schritt</li> </ul>"},{"location":"ingestion/json_ingestion_spec/#beispiel-1-lsg-polygon-geojson","title":"Beispiel 1: LSG (Polygon, GeoJSON)","text":"<pre><code>{\n  \"source_id\": \"beh\u00f6rde-bayern-lsg-2025\",\n  \"source_pk\": \"lsg-987\",\n  \"content_type\": \"geo\",\n  \"geo\": {\"type\": \"Polygon\", \"crs\": \"EPSG:4326\", \"coordsPath\": \"geometry.coordinates\"},\n  \"mappings\": {\"name\": \"properties.name\", \"class\": \"properties.category\"},\n  \"transforms\": [{\"op\":\"synonym_map\",\"field\":\"class\",\"dict\":\"geo_classes_v1\"}],\n  \"metadata\": {\"dataset\": \"LSG\", \"year\": 2025}\n}\n</code></pre>"},{"location":"ingestion/json_ingestion_spec/#beispiel-2-fliegewasser-linie-gpx-linestring","title":"Beispiel 2: Flie\u00dfgew\u00e4sser (Linie, GPX \u2192 LineString)","text":"<pre><code>{\n  \"source_id\": \"wasserverband-gpx-2025\",\n  \"source_pk\": \"track-42\",\n  \"content_type\": \"geo\",\n  \"geo\": {\"type\": \"LineString\", \"crs\": \"EPSG:4326\", \"coordsPath\": \"tracks[0].segments[0]\"},\n  \"mappings\": {\"name\": \"metadata.track_name\", \"class\": \"metadata.feature_class\"},\n  \"metadata\": {\"dataset\": \"Flie\u00dfgew\u00e4sser\"}\n}\n</code></pre>"},{"location":"ingestion/json_ingestion_spec/#beispiel-3-textdokument","title":"Beispiel 3: Textdokument","text":"<pre><code>{\n  \"source_id\": \"dms-ordner-a\",\n  \"source_pk\": \"doc-1001\",\n  \"content_type\": \"text\",\n  \"text\": {\"language\": \"de\", \"fields\": [\"title\", \"body\"], \"tokenization\": \"default\"},\n  \"mappings\": {\"name\": \"title\", \"tags\": \"keywords\"},\n  \"metadata\": {\"doctype\": \"bericht\"}\n}\n</code></pre>"},{"location":"ingestion/json_ingestion_spec/#indexierung-hinweise","title":"Indexierung (Hinweise)","text":"<ul> <li>R\u00e4umlich: R-Tree/GiST (BBox bzw. Geometriespalte)</li> <li>Text: B-Tree auf <code>class/name</code>, optional FTS/Trigram f\u00fcr unscharfe Suche</li> <li>Vektor: Embeddings f\u00fcr Name/Tags (optional) + ANN-Index</li> </ul>"},{"location":"ingestion/json_ingestion_spec/#versionierung-governance","title":"Versionierung &amp; Governance","text":"<ul> <li>Schema-Version je Quelle (<code>metadata.version</code>)</li> <li>\u00c4nderungen via Migrationsnotiz; kompatible Evolution bevorzugt</li> <li>Audit: <code>provenance</code> speichern; Hash-Manifest f\u00fcr Unver\u00e4nderlichkeit</li> </ul>"},{"location":"ingestion/json_ingestion_spec/#offene-punkte","title":"Offene Punkte","text":"<ul> <li>Einheitliche Synonymlisten-Verwaltung (z. B. <code>geo_classes_v1</code>)</li> <li>Vereinheitlichung der DLQ-Formate und Monitoring-Alarmierung</li> </ul>"},{"location":"search/hybrid_search_design/","title":"Hybrid Search \u2013 Design (Phase 4)","text":"<p>Kombiniert Vektor\u00e4hnlichkeit (Chunks) mit Graph-Expansion und optionalen Filtern, um robuste Ergebnisse \u00fcber Content-Chunks zu liefern.</p>"},{"location":"search/hybrid_search_design/#ziele","title":"Ziele","text":"<ul> <li>Semantische Suche (Vector Top-K) + Kontext-Expansion (Graph n-hop)</li> <li>Score-Fusion aus Embedding-Similarity und Graph-Distanz/Topologie</li> <li>Filterbarkeit (category, mime_type, metadata-*), Pagination</li> </ul>"},{"location":"search/hybrid_search_design/#ablauf","title":"Ablauf","text":"<p>1) Query-Embedding (dim wie Index; z. B. 768D) 2) Vector Top-K \u00fcber Namespace \"chunks\" (Whitelist optional) 3) Graph-Expansion: f\u00fcr gefundene Chunks \u2192 n-Hop Nachbarn (prev/next/parent/geo) 4) Re-Scoring:    - final = alpha * sim - beta * graph_distance - gamma * hop    - Deduplikation pro Content (Top-Chunk + Bonus f\u00fcr konsistente Mehrfachtreffer) 5) Filter anwenden (serverseitig vor/nach Fusion, je nach Kosten) 6) Sortierung + Pagination (limit/offset oder Cursor)</p>"},{"location":"search/hybrid_search_design/#api-skizze","title":"API (Skizze)","text":"<ul> <li>POST /search/hybrid</li> </ul> <pre><code>{\n  \"query\": \"text or vector\",\n  \"embedding\": [..optional..],\n  \"k\": 20,\n  \"expand\": {\"hops\": 1, \"edges\": [\"parent\",\"next\",\"prev\",\"geo\"]},\n  \"filters\": {\"category\": [\"TEXT\",\"IMAGE\",\"GEO\"], \"mime_type\": [\"image/jpeg\"], \"metadata\": {\"dataset\": \"LSG\"}},\n  \"scoring\": {\"alpha\": 1.0, \"beta\": 0.2, \"gamma\": 0.1}\n}\n</code></pre> <ul> <li>Response: Liste von Chunks (mit parent content meta), Score, ggf. Pfad/Expansion-Evidence</li> </ul>"},{"location":"search/hybrid_search_design/#storageindex-annahmen","title":"Storage/Index-Annahmen","text":"<ul> <li>Vector-Index: \"chunks\" (dim=768 f\u00fcr Text/Image; Geo 128D \u2192 ggf. getrennte Namespaces)</li> <li>Graph: Kanten parent/child, next/prev (Dokument-Order), geo (r\u00e4umliche N\u00e4he)</li> <li>Sekund\u00e4rindizes: category, mime_type, metadata.dataset</li> </ul>"},{"location":"search/hybrid_search_design/#edge-cases","title":"Edge Cases","text":"<ul> <li>Leeres/kurzes Query \u2192 Fallback auf Filter/Graph-only</li> <li>Heterogene Dimensionen (Text 768D, Geo 128D) \u2192 getrennte Indizes + sp\u00e4te Fusion</li> <li>Gro\u00dfe Hops \u2192 harte Limits, Zeitouts, Soft-Cutoff</li> </ul>"},{"location":"search/hybrid_search_design/#tests-skizze","title":"Tests (Skizze)","text":"<ul> <li>Top-K stabil, Fusion deterministisch bei fixierten Parametern</li> <li>Filter wirksam (before/after Fusion), Paginierung korrekt</li> <li>Graph-Expansion erh\u00f6ht Recall (nachweisbar an Testdaten)</li> </ul>"},{"location":"search/pagination_benchmarks/","title":"Pagination Benchmarks: Offset vs Cursor","text":"<p>Dieser Leitfaden beschreibt zwei Microbenchmarks zur Pagination-Performance:</p> <ul> <li>Offset-basierte Pagination (ORDER BY + LIMIT offset,count mit Post-Slicing)</li> <li>Cursor-basierte Pagination (Anchor-based Start-after mit LIMIT count+1)</li> </ul> <p>Quelle: <code>benchmarks/bench_query.cpp</code></p>"},{"location":"search/pagination_benchmarks/#setup","title":"Setup","text":"<p>Beim ersten Lauf wird eine Testdatenbank unter <code>data/themis_bench_query</code> erzeugt. Es werden <code>bench_users</code>-Entities mit Range-Index auf <code>age</code> angelegt.</p>"},{"location":"search/pagination_benchmarks/#benchmarks","title":"Benchmarks","text":"<ul> <li><code>BM_Pagination_Offset(page_size=50, pages=50)</code></li> <li><code>BM_Pagination_Cursor(page_size=50, pages=50)</code></li> </ul> <p>Offset-Variante setzt <code>orderBy.limit = offset + count</code> und schneidet die Seite nachtr\u00e4glich (wie der HTTP-Pfad). Cursor-Variante nutzt <code>(cursor_value, cursor_pk)</code> als Anchor und <code>LIMIT count+1</code> zur <code>has_more</code>-Erkennung.</p>"},{"location":"search/pagination_benchmarks/#ausfuhren-optional","title":"Ausf\u00fchren (optional)","text":"<pre><code># Reconfigure to ensure benchmarks are built (once)\ncmake -S .. -B . -DCMAKE_BUILD_TYPE=Release -DTHEMIS_BUILD_BENCHMARKS=ON\ncmake --build . --config Release --parallel\n\n# Run only pagination benchmarks\n.\\Release\\themis_benchmarks.exe --benchmark_filter=BM_Pagination_.*\n</code></pre> <p>Hinweis: Zeiten k\u00f6nnen durch I/O-Cache und Hardware variieren. F\u00fcr reproduzierbare Messungen ggf. mehrfach ausf\u00fchren und Mittelwerte bilden.</p>"},{"location":"search/pagination_benchmarks/#interpretation","title":"Interpretation","text":"<ul> <li>Offset-Pagination: Aufwand w\u00e4chst mit <code>offset</code> (Index muss die Eintr\u00e4ge bis zur Seite traversieren).</li> <li>Cursor-Pagination: Konstante Arbeit pro Seite (Start-after) \u2013 stabil bei gro\u00dfen Datenmengen.</li> </ul> <p>In Einzelf\u00e4llen kann die Cursor-Variante durch zus\u00e4tzliche Entity-Loads (Anchor-Ermittlung) leicht h\u00f6here CPU-Zeit zeigen; mit warmem Cache und realistischen Daten ist sie bei gro\u00dfen Offsets typischerweise \u00fcberlegen.</p>"},{"location":"security/audit_and_retention/","title":"Audit &amp; Retention","text":"<p>Audit-Trails und Datenaufbewahrung sind Kernbausteine der Sicherheit &amp; Compliance.</p>"},{"location":"security/audit_and_retention/#changefeed-audittrail","title":"Changefeed (Audit\u2011Trail)","text":"<ul> <li>Append\u2011only Log aller Mutationen (PUT/DELETE)</li> <li>Endpunkte:</li> <li>GET /changefeed \u2013 Events listen (Parameter: from_seq, limit, long_poll_ms, key_prefix)</li> <li>GET /changefeed/stats \u2013 Gesamtereignisse, letzte Sequence, Gr\u00f6\u00dfe</li> <li>POST /changefeed/retention \u2013 L\u00f6schung bis Sequence: { \"before_sequence\":  } <li>GET /changefeed/stream \u2013 Server\u2011Sent Events (siehe APIs/SSE)</li> <li>Einsatzzwecke: Echtzeit\u2011Sync, Audit, Event Processing</li> <p>Details: siehe docs/change_data_capture.md</p>"},{"location":"security/audit_and_retention/#retentionpolicies","title":"Retention\u2011Policies","text":"<ul> <li>Changefeed: Sequenz\u2011basierte Bereinigung via /changefeed/retention</li> <li>Time\u2011Series: RetentionManager (per\u2011Metric Policies) \u2013 siehe docs/time_series.md</li> <li>Content/Entities: Fachliche Policies (z. B. DSGVO Art. 17) au\u00dferhalb des Changefeeds umsetzen</li> </ul>"},{"location":"security/audit_and_retention/#empfehlungen","title":"Empfehlungen","text":"<ul> <li>Minimale Aufbewahrungszeit f\u00fcr Audit\u2011Zwecke definieren (rechtlich/organisatorisch)</li> <li>Automatisierte Bereinigung (Cron/Jobs) etablieren; Metriken \u00fcberwachen</li> <li>Export/Archivierung vor L\u00f6schung (WORM\u2011Storage optional)</li> </ul> <p>Weiterlesen: - change_data_capture.md - compliance_audit.md, compliance_governance_strategy.md</p>"},{"location":"security/key_management/","title":"Schl\u00fcsselverwaltung (Key Management)","text":"<p>ThemisDB unterst\u00fctzt eine externe Schl\u00fcsselverwaltung via KeyProvider. Aktuell ist standardm\u00e4\u00dfig ein MockKeyProvider verdrahtet; eine Vault\u2011basierte Implementierung ist vorbereitet.</p>"},{"location":"security/key_management/#schlusselarten-beispiele","title":"Schl\u00fcsselarten (Beispiele)","text":"<ul> <li>LEK: Local Encryption Key</li> <li>KEK: Key Encryption Key</li> <li>DEK: Data Encryption Key</li> </ul> <p>Hinweis: Die konkrete Nomenklatur h\u00e4ngt von der Deployment\u2011Strategie ab (siehe encryption_strategy.md).</p>"},{"location":"security/key_management/#serverapis","title":"Server\u2011APIs","text":"<ul> <li>GET /keys \u2013 Liste verwalteter Schl\u00fcssel</li> <li>POST /keys/rotate \u2013 Schl\u00fcsselrotation ausl\u00f6sen</li> <li>Parameter: key_id (im JSON\u2011Body <code>{ \"key_id\": \"DEK\" }</code> oder Query <code>?key_id=DEK</code>)</li> <li>Antworten: { success, key_id, new_version }</li> </ul> <p>Fehlerf\u00e4lle: - 400 Missing key_id \u2013 Schl\u00fcssel ausw\u00e4hlen - 503 Keys API not available \u2013 KeyProvider nicht initialisiert</p>"},{"location":"security/key_management/#provider","title":"Provider","text":"<ul> <li>MockKeyProvider \u2013 zum Testen/Entwickeln</li> <li>VaultKeyProvider \u2013 vorbereitet (siehe <code>src/security/vault_key_provider.cpp</code>), ben\u00f6tigt Vault\u2011Konfiguration (KV v1/v2, Mount Path, Auth)</li> </ul>"},{"location":"security/key_management/#betrieb","title":"Betrieb","text":"<ul> <li>Absicherung der Endpunkte (Reverse\u2011Proxy/Firewall/RBAC): Nur autorisierte Admins d\u00fcrfen /keys/rotate aufrufen.</li> <li>Rotation regelm\u00e4\u00dfig in der Betriebsroutine einplanen (z. B. DEK monatlich, KEK viertelj\u00e4hrlich).</li> <li>\u00dcberwachung: Anzahl/Versionen der Schl\u00fcssel im Admin\u2011Tool; Alarme f\u00fcr ablaufende Schl\u00fcssel.</li> </ul>"},{"location":"security/key_management/#konfiguration","title":"Konfiguration","text":"<ul> <li>Basis\u2011URL des Servers (Reverse\u2011Proxy ggf. /api \u2192 / umschreiben)</li> <li>Vault\u2011Parameter (bei Nutzung): kv_version, kv_mount_path, Auth\u2011Methode, TLS\u2011Zertifikate</li> </ul> <p>Siehe auch: - Admin\u2011Guide (Routing\u2011Hinweise) - encryption_strategy.md / encryption_deployment.md</p>"},{"location":"security/overview/","title":"Sicherheit &amp; Governance \u2013 \u00dcberblick","text":"<p>Dieser \u00dcberblick fasst die sicherheitsrelevanten Bausteine von ThemisDB zusammen und verlinkt die Detailseiten.</p> <ul> <li>Schl\u00fcsselverwaltung (Key Management): Schl\u00fcsselarten, Rotation, Server-APIs, Provider</li> <li>Verschl\u00fcsselung: Strategie, Deployment, Spaltenverschl\u00fcsselung</li> <li>PII-Erkennung &amp; Klassifizierung: Regeln, Engine, Admin-APIs</li> <li>Audit &amp; Retention: Changefeed (Audit-Trail), Statistiken, Aufbewahrung</li> <li>Threat Model (light): Assets, Akteure, Vertrauensgrenzen, Risiken, Gegenma\u00dfnahmen</li> </ul> <p>Weiterlesen: - Schl\u00fcsselverwaltung: security/key_management.md - PII-Detection: security/pii_detection.md - Audit &amp; Retention: security/audit_and_retention.md - Threat-Model: security/threat_model.md - Verschl\u00fcsselung: encryption_strategy.md, encryption_deployment.md, column_encryption.md</p>"},{"location":"security/pii_detection/","title":"PII\u2011Erkennung &amp; Klassifizierung","text":"<p>ThemisDB nutzt eine regelbasierte PII\u2011Erkennung (PIIDetector) zur Klassifizierung von Inhalten.</p>"},{"location":"security/pii_detection/#komponenten","title":"Komponenten","text":"<ul> <li>PIIDetector (Regex\u2011Engine): erkennt Entit\u00e4ten wie EMAIL, PHONE, IBAN etc.</li> <li>Classification API: stellt Regeln bereit und erm\u00f6glicht Test\u2011Klassifikationen</li> </ul>"},{"location":"security/pii_detection/#serverapis","title":"Server\u2011APIs","text":"<ul> <li>GET /classification/rules \u2013 Liste aktiver Regeln</li> <li>POST /classification/test \u2013 Test einer Probe</li> <li>Body: { \"text\": \"...\", \"metadata\": { ... } }</li> <li>Response (Beispiel): { \"classification\": \"CONFIDENTIAL\", \"confidence\": 0.92, \"detected_entities\": [ { \"type\": \"EMAIL\", \"value\": \"a@b.c\" } ] }</li> </ul> <p>Fehlerf\u00e4lle: - 400 Missing JSON body \u2013 Eingabe erforderlich - 503 Classification API not available \u2013 PIIDetector nicht initialisiert</p>"},{"location":"security/pii_detection/#grenzen-hinweise","title":"Grenzen &amp; Hinweise","text":"<ul> <li>Regex\u2011basiert: Heuristiken, false positives/negatives m\u00f6glich</li> <li>Kontextabh\u00e4ngige Klassifikation kann erg\u00e4nzende Logik/Modelle ben\u00f6tigen</li> <li>Protokollierung sensibler Treffer nur pseudonymisiert/aggregiert ablegen</li> </ul> <p>Weiterlesen: - pii_detection_engines.md - compliance_integration.md</p>"},{"location":"security/security_compliance_review/","title":"Security &amp; Compliance Review","text":"<p>Dieses Dokument fasst den Sicherheits- und Compliance-Status von ThemisDB zusammen, verlinkt die relevanten Detaildokumente und enth\u00e4lt eine \u00fcberpr\u00fcfbare Checkliste f\u00fcr Audits.</p>"},{"location":"security/security_compliance_review/#geltungsbereich","title":"Geltungsbereich","text":"<ul> <li>Daten-at-Rest und Daten-in-Transit</li> <li>Schl\u00fcsselverwaltung und Kryptokonfiguration</li> <li>PII-Erkennung, Audit/Retention</li> <li>H\u00e4rtung, Bedrohungsmodell, Betriebsprozesse</li> <li>Compliance-Mappings (GDPR/DSGVO, ISO 27001-nahe Praktiken)</li> </ul>"},{"location":"security/security_compliance_review/#referenz-dokumente","title":"Referenz-Dokumente","text":"<ul> <li>\u00dcberblick: Security Overview</li> <li>Schl\u00fcsselverwaltung: Key Management</li> <li>Verschl\u00fcsselung: Encryption Strategy, Encryption Deployment, Column Encryption</li> <li>PII: PII Detection (Overview), PII Engines, PII Engine Signing</li> <li>Audit &amp; Retention: Audit &amp; Retention</li> <li>Threat Modeling: Threat Model</li> <li>Hardening: Security Hardening Guide</li> <li>Compliance: Compliance Audit, Governance-Strategie, Compliance-Integration, Governance Usage</li> <li>Operations: Deployment &amp; Betrieb, Operations Runbook, Tracing &amp; Observability</li> </ul>"},{"location":"security/security_compliance_review/#audit-checkliste-kernpunkte","title":"Audit-Checkliste (Kernpunkte)","text":"<ul> <li>Kryptographie</li> <li>Transportverschl\u00fcsselung (TLS/Reverse Proxy) konfiguriert</li> <li>At-Rest: Komponentenspezifische Verschl\u00fcsselung (SST/Blob/Spalten) bewertet und konfiguriert</li> <li>Schl\u00fcsselrotation, KMS-Integration (Konzept &amp; Schnittstellen) dokumentiert</li> <li>Zugriff &amp; AuthZ</li> <li>Admin-Endpoints abgesichert, sensible Operationen geloggt</li> <li>Optionales RBAC/Scopes (Roadmap) definiert</li> <li>PII &amp; Datenschutz</li> <li>PII-Detection Flows und Ausnahmenprozess dokumentiert</li> <li>Retention-Policies (TTL/Archivierung) technisch verankert</li> <li>Auditierbarkeit</li> <li>Audit-Events definiert (Create/Update/Delete, Indexops, Admin)</li> <li>Retention &amp; Export der Auditdaten beschrieben</li> <li>H\u00e4rtung</li> <li>Container/K8s Best Practices, minimaler OS-Footprint, Secrets-Handling</li> <li>Angriffspunkte aus Threat Model gemappt auf Mitigations</li> <li>Observability &amp; Incident Response</li> <li>Prometheus-/Tracing-Integration, Alarme (SLOs) vorhanden</li> <li>Runbook: Playbooks f\u00fcr Ausf\u00e4lle, Rebuilds, Backups</li> </ul>"},{"location":"security/security_compliance_review/#verifikation-stichproben","title":"Verifikation (Stichproben)","text":"<ul> <li>/metrics enth\u00e4lt sicherheitsrelevante Z\u00e4hler (z. B. Fehler, Auth-Fehlschl\u00e4ge sofern implementiert)</li> <li>Konfiguration (Secrets, Ports, CORS) in <code>deployment.md</code>/<code>docker-compose.yml</code> nachvollziehbar</li> <li>CDC-/SSE-Endpunkte: Hinweis auf Reverse-Proxy-Konfiguration (TLS, Timeouts)</li> </ul>"},{"location":"security/security_compliance_review/#offene-punkte-empfehlungen","title":"Offene Punkte / Empfehlungen","text":"<ul> <li>RBAC/Policies: Ausarbeitung und Implementierungsfahrplan (siehe Roadmap)</li> <li>Keys at rest: Optionale Integration externer KMS (HashiCorp Vault, AWS KMS)</li> <li>Secrets-Scanning in CI (gitleaks) und SBOM/Signaturen (Syft/Cosign)</li> <li>Penetrationstest-Checkliste erg\u00e4nzen; Fuzzing-Pfade (Parser) pr\u00fcfen</li> </ul>"},{"location":"security/security_compliance_review/#anderungsverlauf","title":"\u00c4nderungsverlauf","text":"<ul> <li>2025-11-02: Erstver\u00f6ffentlichung der konsolidierten Review-Seite</li> </ul>"},{"location":"security/threat_model/","title":"Threat Model (light)","text":"<p>Ziel: Risiken sichtbar machen und mit pragmatischen Kontrollen adressieren.</p>"},{"location":"security/threat_model/#assets","title":"Assets","text":"<ul> <li>Datenbankinhalte (Dokumente, Inhalte, Vektoren, Zeitreihen)</li> <li>Schl\u00fcsselmaterial (LEK/KEK/DEK)</li> <li>Audit\u2011Trails (Changefeed)</li> </ul>"},{"location":"security/threat_model/#akteure","title":"Akteure","text":"<ul> <li>Admin/Operator (berechtigt)</li> <li>Anwendung/Service (technisch)</li> <li>Angreifer extern/intern (unberechtigt/teilberechtigt)</li> </ul>"},{"location":"security/threat_model/#vertrauensgrenzen","title":"Vertrauensgrenzen","text":"<ul> <li>Client \u2194 Reverse\u2011Proxy \u2194 Themis\u2011Server \u2194 Storage (RocksDB)</li> <li>Externe Schl\u00fcsselverwaltung (Vault o. \u00e4.)</li> </ul>"},{"location":"security/threat_model/#hauptrisiken-auszug","title":"Hauptrisiken (Auszug)","text":"<ul> <li>Unautorisierte Schl\u00fcsselrotation/Schl\u00fcsselabgriff</li> <li>Datenexfiltration \u00fcber Admin\u2011APIs</li> <li>PII\u2011Leakage in Logs/Exports</li> <li>Manipulation Audit\u2011Trail</li> </ul>"},{"location":"security/threat_model/#gegenmanahmen","title":"Gegenma\u00dfnahmen","text":"<ul> <li>RBAC/Netzwerk\u2011Kontrollen vor Admin\u2011APIs (/keys/rotate, /changefeed/retention)</li> <li>TLS\u2011Terminations\u2011Proxy, mTLS optional</li> <li>Secrets\u2011Management (kein Klartext im Repo/Config)</li> <li>Minimierte Logs; Pseudonymisierung sensibler Werte</li> <li>Regelm\u00e4\u00dfige Rotation, Least\u2011Privilege, Vier\u2011Augen\u2011Prinzip bei kritischen Aktionen</li> <li>Backup/Restore mit Integrit\u00e4tspr\u00fcfungen</li> </ul>"},{"location":"security/threat_model/#beobachtbarkeit","title":"Beobachtbarkeit","text":"<ul> <li>Health/Metrics Endpunkte \u00fcberwachen (/health, /metrics)</li> <li>Alarme f\u00fcr Schl\u00fcsselablauf, Retention\u2011Fehler, Anomalien im Changefeed</li> </ul> <p>Weiterlesen: - security/key_management.md, security/audit_and_retention.md - encryption_strategy.md, security_hardening_guide.md, security_audit_checklist.md</p>"},{"location":"storage/geo_relational_schema/","title":"Relationales Schema f\u00fcr Geo-Daten (Post-Go-Live)","text":"<p>Dieses Dokument definiert ein abfragefreundliches relationales Schema f\u00fcr Punkt-, Linien- und Polygon-Daten inklusive Indexierung und Beispielabfragen. Es dient als Zielbild f\u00fcr die Ablage nach dem Ingestion-Prozess.</p>"},{"location":"storage/geo_relational_schema/#ziele","title":"Ziele","text":"<ul> <li>Saubere Trennung von Geometrietypen (Point/LineString/Polygon)</li> <li>Schnelle r\u00e4umliche Abfragen (R-Tree/GiST) und begriffliche Filter (B-Tree/FTS/Trigram)</li> <li>Kompatibel mit EPSG:4326 (lon/lat); Bounding-Box pro Feature</li> <li>Unterst\u00fctzt Suchszenarien wie: \"LSG\", \"Flie\u00dfgew\u00e4sser\", nahe (lon, lat)</li> </ul>"},{"location":"storage/geo_relational_schema/#tabellenentwurf-neutral","title":"Tabellenentwurf (neutral)","text":""},{"location":"storage/geo_relational_schema/#features","title":"features","text":"<ul> <li><code>feature_id</code> (PK, UUID/ULID)</li> <li><code>source_id</code> (TEXT)</li> <li><code>source_pk</code> (TEXT)</li> <li><code>class</code> (TEXT) \u2014 z. B. \"LSG\", \"Flie\u00dfgew\u00e4sser\"</li> <li><code>name</code> (TEXT)</li> <li><code>bbox_min_lon</code> (DOUBLE)</li> <li><code>bbox_min_lat</code> (DOUBLE)</li> <li><code>bbox_max_lon</code> (DOUBLE)</li> <li><code>bbox_max_lat</code> (DOUBLE)</li> <li><code>tags</code> (JSON)</li> <li><code>created_at</code> (TIMESTAMP)</li> </ul>"},{"location":"storage/geo_relational_schema/#points","title":"points","text":"<ul> <li><code>feature_id</code> (FK \u2192 features)</li> <li><code>lon</code> (DOUBLE)</li> <li><code>lat</code> (DOUBLE)</li> </ul>"},{"location":"storage/geo_relational_schema/#lines","title":"lines","text":"<ul> <li><code>feature_id</code> (FK \u2192 features)</li> <li><code>geom_wkt</code> (TEXT) \u2014 WKT LineString; optional: normalisierte St\u00fctzpunkte in separater Tabelle</li> </ul>"},{"location":"storage/geo_relational_schema/#polygons","title":"polygons","text":"<ul> <li><code>feature_id</code> (FK \u2192 features)</li> <li><code>geom_wkt</code> (TEXT) \u2014 WKT Polygon (Au\u00dfenring + Innenringe)</li> </ul>"},{"location":"storage/geo_relational_schema/#terms-begriffe-fur-volltextfacetten","title":"terms (Begriffe f\u00fcr Volltext/Facetten)","text":"<ul> <li><code>feature_id</code> (FK \u2192 features)</li> <li><code>term</code> (TEXT)</li> <li><code>lang</code> (TEXT, optional)</li> </ul>"},{"location":"storage/geo_relational_schema/#synonyms-synonym-alias-lexikon","title":"synonyms (Synonym-/Alias-Lexikon)","text":"<ul> <li><code>term</code> (TEXT)</li> <li><code>canonical</code> (TEXT)</li> <li><code>lang</code> (TEXT)</li> </ul> <p>Hinweis: In PostGIS-Umgebungen k\u00f6nnen <code>geom_wkt</code>-Spalten als <code>geometry</code>-Typ modelliert werden (GiST-Index). In einfacheren Setups bleiben WKT + BBox; r\u00e4umliche Filter laufen \u00fcber BBox-First-Filter + optionale Software-Pr\u00e4zisierung.</p>"},{"location":"storage/geo_relational_schema/#beispiel-ddl-postgresqlpostgis-optional","title":"Beispiel-DDL (PostgreSQL/PostGIS optional)","text":"<pre><code>-- Basis (ohne PostGIS)\nCREATE TABLE features (\n  feature_id TEXT PRIMARY KEY,\n  source_id TEXT NOT NULL,\n  source_pk TEXT NOT NULL,\n  class TEXT,\n  name TEXT,\n  bbox_min_lon DOUBLE PRECISION,\n  bbox_min_lat DOUBLE PRECISION,\n  bbox_max_lon DOUBLE PRECISION,\n  bbox_max_lat DOUBLE PRECISION,\n  tags JSONB,\n  created_at TIMESTAMP DEFAULT now()\n);\nCREATE INDEX ix_features_class ON features(class);\nCREATE INDEX ix_features_name ON features(name);\nCREATE INDEX ix_features_bbox ON features(bbox_min_lon, bbox_min_lat, bbox_max_lon, bbox_max_lat);\n\nCREATE TABLE points (\n  feature_id TEXT REFERENCES features(feature_id) ON DELETE CASCADE,\n  lon DOUBLE PRECISION NOT NULL,\n  lat DOUBLE PRECISION NOT NULL\n);\nCREATE INDEX ix_points_lonlat ON points(lon, lat);\n\nCREATE TABLE lines (\n  feature_id TEXT REFERENCES features(feature_id) ON DELETE CASCADE,\n  geom_wkt TEXT NOT NULL\n);\n\nCREATE TABLE polygons (\n  feature_id TEXT REFERENCES features(feature_id) ON DELETE CASCADE,\n  geom_wkt TEXT NOT NULL\n);\n\nCREATE TABLE terms (\n  feature_id TEXT REFERENCES features(feature_id) ON DELETE CASCADE,\n  term TEXT NOT NULL,\n  lang TEXT\n);\nCREATE INDEX ix_terms_term ON terms(term);\n\nCREATE TABLE synonyms (\n  term TEXT,\n  canonical TEXT,\n  lang TEXT\n);\nCREATE INDEX ix_synonyms_term ON synonyms(term);\n\n-- Optional: FTS/Trigram (PostgreSQL-abh\u00e4ngig)\n-- CREATE EXTENSION pg_trgm;\n-- CREATE INDEX ix_features_name_trgm ON features USING gin (name gin_trgm_ops);\n</code></pre> <pre><code>-- Variante mit PostGIS\n-- CREATE EXTENSION postgis;\nCREATE TABLE features (\n  feature_id TEXT PRIMARY KEY,\n  source_id TEXT NOT NULL,\n  source_pk TEXT NOT NULL,\n  class TEXT,\n  name TEXT,\n  bbox_min_lon DOUBLE PRECISION,\n  bbox_min_lat DOUBLE PRECISION,\n  bbox_max_lon DOUBLE PRECISION,\n  bbox_max_lat DOUBLE PRECISION,\n  tags JSONB,\n  created_at TIMESTAMP DEFAULT now()\n);\n\nCREATE TABLE lines (\n  feature_id TEXT REFERENCES features(feature_id) ON DELETE CASCADE,\n  geom geometry(LineString, 4326) NOT NULL\n);\nCREATE INDEX ix_lines_geom_gist ON lines USING gist (geom);\n\nCREATE TABLE polygons (\n  feature_id TEXT REFERENCES features(feature_id) ON DELETE CASCADE,\n  geom geometry(Polygon, 4326) NOT NULL\n);\nCREATE INDEX ix_polygons_geom_gist ON polygons USING gist (geom);\n\nCREATE TABLE points (\n  feature_id TEXT REFERENCES features(feature_id) ON DELETE CASCADE,\n  geom geometry(Point, 4326) NOT NULL\n);\nCREATE INDEX ix_points_geom_gist ON points USING gist (geom);\n</code></pre>"},{"location":"storage/geo_relational_schema/#beispiel-abfragen","title":"Beispiel-Abfragen","text":""},{"location":"storage/geo_relational_schema/#1-lsg-in-der-nahe-eines-punkts-lon45-lat16","title":"1) \"LSG\" in der N\u00e4he eines Punkts (lon=45, lat=16)","text":"<ul> <li>Neutral (BBox-First, grob):</li> </ul> <pre><code>SELECT f.*\nFROM features f\nWHERE f.class = 'LSG'\n  AND 45 BETWEEN f.bbox_min_lon AND f.bbox_max_lon\n  AND 16 BETWEEN f.bbox_min_lat AND f.bbox_max_lat;\n</code></pre> <ul> <li>PostGIS (pr\u00e4zise):</li> </ul> <pre><code>SELECT f.*\nFROM features f\nJOIN polygons p ON p.feature_id = f.feature_id\nWHERE f.class = 'LSG'\n  AND ST_Contains(p.geom, ST_SetSRID(ST_MakePoint(45, 16), 4326));\n</code></pre>"},{"location":"storage/geo_relational_schema/#2-fliegewasser-nahe-punkt-linestring-distanz","title":"2) \"Flie\u00dfgew\u00e4sser\" nahe Punkt (LineString Distanz)","text":"<pre><code>SELECT f.*\nFROM features f\nJOIN lines l ON l.feature_id = f.feature_id\nWHERE f.class = 'Flie\u00dfgew\u00e4sser'\n  AND ST_DWithin(l.geom, ST_SetSRID(ST_MakePoint(45,16), 4326), 1000); -- 1000m\n</code></pre>"},{"location":"storage/geo_relational_schema/#3-begriffssuche-mit-synonymen","title":"3) Begriffssuche mit Synonymen","text":"<pre><code>-- Synonymaufl\u00f6sung (einfach)\nSELECT f.*\nFROM features f\nJOIN terms t ON t.feature_id = f.feature_id\nLEFT JOIN synonyms s ON s.term = t.term\nWHERE (t.term = 'LSG' OR s.canonical = 'LSG');\n</code></pre>"},{"location":"storage/geo_relational_schema/#etl-mapping-aus-ingestion","title":"ETL-Mapping (aus Ingestion)","text":"<ul> <li><code>class</code>, <code>name</code>, <code>tags</code> aus <code>mappings</code> \u00fcbernehmen</li> <li><code>bbox_*</code> aus normalisierter Geometrie berechnen</li> <li>Punkt-/Linie-/Polygon nach Typ in jeweilige Tabelle schreiben (1:n m\u00f6glich)</li> <li>Begriffe (terms) bef\u00fcllen: <code>name</code>, <code>class</code>, extrahierte Schlagworte</li> <li>Synonyme als Lookup (z. B. aus <code>geo_classes_v1</code>)</li> </ul>"},{"location":"storage/geo_relational_schema/#indexierung-performance","title":"Indexierung &amp; Performance","text":"<ul> <li>BBox-Index beschleunigt Grobfilterung vor genauer Geometriepr\u00fcfung</li> <li>B-Tree auf <code>class</code>, <code>name</code>; optional FTS/Trigram f\u00fcr unscharfe Suchbegriffe</li> <li>GiST/SpGist f\u00fcr Geometriespalten (PostGIS)</li> </ul>"},{"location":"storage/geo_relational_schema/#governance-qualitat","title":"Governance &amp; Qualit\u00e4t","text":"<ul> <li><code>source_id</code> + <code>source_pk</code> f\u00fcr Idempotenz/Lineage</li> <li><code>feature_id</code> als stabile interne ID (UUID/ULID)</li> <li>Validierung: Geometrie-Validit\u00e4t, CRS=EPSG:4326, BBox vorhanden</li> </ul>"},{"location":"storage/geo_relational_schema/#offene-punkte","title":"Offene Punkte","text":"<ul> <li>Optional: MultiGeometrien (MultiPoint/MultiLineString/MultiPolygon)</li> <li>Optional: Generalisierung (Levels of Detail) f\u00fcr schnelle Kartenansichten</li> <li>Optional: Historisierung/Versionierung (Valid-From/To)</li> </ul>"},{"location":"storage/rocksdb_layout/","title":"RocksDB Storage \u2013 Layout &amp; Betrieb","text":"<p>Dieser Leitfaden beschreibt das physische Storage-Verhalten der ThemisDB-Engine auf Basis von RocksDB: Schl\u00fcsselpr\u00e4fixe, WAL, Snapshots und Compaction.</p>"},{"location":"storage/rocksdb_layout/#schlusselraume-prafixe","title":"Schl\u00fcsselr\u00e4ume &amp; Pr\u00e4fixe","text":"<p>Themis nutzt ein Pr\u00e4fix-Schema zur logischen Trennung von Datenbereichen:</p> <ul> <li>Entities (Prim\u00e4rdaten): <code>entity:&lt;table&gt;:&lt;pk&gt;</code> \u2192 Blob (BaseEntity-Serialisierung)</li> <li>Secondary Index: <code>idx:&lt;table&gt;:&lt;column&gt;:&lt;value&gt;:&lt;pk&gt;</code></li> <li>Range Index: <code>ridx:&lt;table&gt;:&lt;column&gt;:&lt;value&gt;:&lt;pk&gt;</code></li> <li>Sparse/TTL/Fulltext: <code>sidx:</code>/<code>ttlidx:</code>/<code>ftidx:</code> entsprechend der Funktion</li> <li>Graph Adjazenz: <code>graph:out:&lt;from_pk&gt;:&lt;edge_id&gt;</code> \u2192 <code>&lt;to_pk&gt;</code>, <code>graph:in:&lt;to_pk&gt;:&lt;edge_id&gt;</code> \u2192 <code>&lt;from_pk&gt;</code></li> <li>Vector Index (Metadaten/Mapping): <code>vector:&lt;table&gt;:&lt;pk&gt;</code> \u2192 Vektorinfo (Embedding out-of-store in Index-Struktur)</li> <li>Changefeed (Audit): <code>changefeed:&lt;sequence&gt;</code> \u2192 Event JSON</li> <li>Time-Series (TSStore): <code>ts:&lt;metric&gt;:&lt;timestamp&gt;:&lt;tags&gt;</code> \u2192 Wert(e)</li> </ul> <p>Siehe auch: <code>docs/indexes.md</code>, <code>docs/temporal_time_range_queries.md</code>, <code>docs/change_data_capture.md</code>, <code>docs/time_series.md</code>.</p>"},{"location":"storage/rocksdb_layout/#column-families-cf","title":"Column Families (CF)","text":"<ul> <li>Standardbetrieb: Default Column Family (CF)</li> <li>Optional (f\u00fcr gro\u00dfe Workloads): Trennung in CFs (z. B. <code>cf_entities</code>, <code>cf_indexes</code>, <code>cf_graph</code>, <code>cf_changefeed</code>, <code>cf_ts</code>) kann LSM-Compactions separieren.</li> <li>Hinweis: Aktuell verwendet Themis standardm\u00e4\u00dfig die Default CF; CF-Trennung ist als Betriebsoptimierung m\u00f6glich und sollte konsistent in Engine-Config &amp; Backups ber\u00fccksichtigt werden.</li> </ul>"},{"location":"storage/rocksdb_layout/#write-ahead-log-wal","title":"Write-Ahead Log (WAL)","text":"<ul> <li>WAL stellt Durability sicher und dient f\u00fcr Recovery nach Abst\u00fcrzen.</li> <li>Empfohlen:</li> <li><code>wal_bytes_per_sync</code> und <code>bytes_per_sync</code> passend zur Hardware</li> <li><code>max_total_wal_size</code> dimensionieren (Spitzen abfangen, aber Platte nicht vollschreiben)</li> <li>Sync-Strategie nach Latenzanforderungen (<code>disableWAL=false</code>, fsync je nach Durability-Ziel)</li> </ul>"},{"location":"storage/rocksdb_layout/#snapshots-mvcc","title":"Snapshots &amp; MVCC","text":"<ul> <li>Snapshots fixieren ein Sichtfenster f\u00fcr Reads (Snapshot-Isolation)</li> <li>Transaktionen verwenden Snapshots, um Repeatable Reads zu erm\u00f6glichen</li> <li>Long-running Snapshots erh\u00f6hen Read Amplification: \u00dcberwachung und Begrenzung empfehlenswert</li> </ul>"},{"location":"storage/rocksdb_layout/#compaction-performance","title":"Compaction &amp; Performance","text":"<ul> <li>Trennung hei\u00dfer/cold Daten (optional via CF) kann Write Amplification reduzieren</li> <li>Kompressions-Strategie (z. B. LZ4 f\u00fcr L0/L1, ZSTD f\u00fcr tiefere Ebenen) je nach Profil</li> <li>Bloom Filter f\u00fcr Punktabfragen (Secondary Index) aktivieren</li> <li>Prefix-Extractor gem\u00e4\u00df Key-Schema (z. B. bis zum <code>:value:</code>-Teil bei <code>idx:</code>) beschleunigt Prefix-Scans</li> </ul>"},{"location":"storage/rocksdb_layout/#backups-restore","title":"Backups &amp; Restore","text":"<ul> <li>RocksDB Backups (SST + MANIFEST + OPTIONS + ggf. WAL) regelm\u00e4\u00dfig erstellen</li> <li>Konsistenz \u00fcber alle CFs sicherstellen (falls eingesetzt)</li> <li>Vor Restore: Version/Options-Kompatibilit\u00e4t pr\u00fcfen</li> </ul>"},{"location":"storage/rocksdb_layout/#monitoring","title":"Monitoring","text":"<ul> <li>Wichtige Kennzahlen: L0 File Count, Compaction Pending, Stall Time, WAL Gr\u00f6\u00dfe, Read-/Write-Amp</li> <li>Prometheus-Export aus Themis (<code>/metrics</code>) erg\u00e4nzen um Storage-Kennzahlen (Roadmap)</li> </ul>"},{"location":"storage/rocksdb_layout/#troubleshooting-kurz","title":"Troubleshooting (Kurz)","text":"<ul> <li>Hohe Latenzen bei Scans: Prefix-Extractor/Bloom pr\u00fcfen; CF-Trennung f\u00fcr Indizes erw\u00e4gen</li> <li>Speicherverbrauch stark: Kompression/Block-Cache-Tuning; Retention (Changefeed/TS) aktivieren</li> <li>Lange Snapshots: Transaktionslaufzeiten begrenzen; <code>cleanupOldTransactions</code> nutzen</li> </ul> <p>Weiterlesen: - <code>docs/mvcc_design.md</code> - <code>docs/transactions.md</code> - RocksDB Tuning Guides (Block Cache, MemTables, Compaction)</p>"}]}