# Hardware Acceleration Support - ThemisDB

**Version:** 1.0  
**Status:** Implementation Phase  
**Last Updated:** 20. November 2025

---

## Ãœbersicht

ThemisDB unterstÃ¼tzt optionale Hardware-Beschleunigung fÃ¼r kritische Operationen:
- **Vector Operations** - KNN-Suche, Distanzberechnungen
- **Graph Operations** - BFS, Shortest Path, Traversals
- **Geo Operations** - RÃ¤umliche Distanzen, Point-in-Polygon Tests

### UnterstÃ¼tzte Backends

| Backend | Typ | Plattform | Status | PrioritÃ¤t |
|---------|-----|-----------|--------|-----------|
| **CPU** | Fallback | Alle | âœ… Implementiert | Default |
| **CUDA** | GPU | NVIDIA | ğŸš§ Stub | P0 |
| **HIP** | GPU | AMD | ğŸš§ Geplant | P1 |
| **ZLUDA** | GPU | AMD (CUDA-Compat) | ğŸš§ Geplant | P1 |
| **Vulkan** | Graphics | Cross-Platform | ğŸš§ Stub | P1 |
| **DirectX** | Graphics | Windows | ğŸš§ Stub | P2 |
| **Metal** | Graphics | macOS/iOS | ğŸš§ Geplant | P2 |
| **ROCm** | Compute | AMD | ğŸš§ Geplant | P2 |
| **OneAPI** | Compute | Intel | ğŸš§ Geplant | P3 |
| **OpenCL** | Compute | Cross-Platform | ğŸš§ Geplant | P3 |
| **OpenGL** | Graphics | Legacy | ğŸš§ Stub | P4 |
| **WebGPU** | Browser | Web | ğŸš§ Geplant | P4 |

---

## Architektur

### Backend-Abstraktion

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       ThemisDB Application Layer        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Vector / Graph / Geo Managers      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         Backend Registry (AUTO)         â”‚
â”‚     (Automatische Backend-Auswahl)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   CUDA   â”‚  Vulkan  â”‚ DirectX  â”‚  CPU   â”‚
â”‚ (NVIDIA) â”‚(Cross-Pl)â”‚(Windows) â”‚(Always)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Komponenten

1. **Compute Backend Interface** (`include/acceleration/compute_backend.h`)
   - Basis-Schnittstellen: `IComputeBackend`, `IVectorBackend`, `IGraphBackend`, `IGeoBackend`
   - Backend-Registry fÃ¼r automatische Auswahl

2. **CPU Fallback** (`include/acceleration/cpu_backend.h`)
   - Immer verfÃ¼gbar
   - Optimiert mit SIMD-Instruktionen (AVX2)
   - Single-threaded oder TBB-parallelisiert

3. **GPU/Graphics Backends** (Optional, Build-Time)
   - CUDA: `include/acceleration/cuda_backend.h`
   - DirectX/Vulkan/OpenGL: `include/acceleration/graphics_backends.h`

---

## Build-Konfiguration

### CMake-Optionen

```cmake
# Generelle GPU-UnterstÃ¼tzung
-DTHEMIS_ENABLE_GPU=ON

# Spezifische Backends (optional)
-DTHEMIS_ENABLE_CUDA=ON          # NVIDIA CUDA
-DTHEMIS_ENABLE_HIP=ON           # AMD HIP
-DTHEMIS_ENABLE_ZLUDA=ON         # AMD ZLUDA (CUDA auf AMD)
-DTHEMIS_ENABLE_ROCM=ON          # AMD ROCm
-DTHEMIS_ENABLE_DIRECTX=ON       # DirectX 12 Compute (Windows)
-DTHEMIS_ENABLE_VULKAN=ON        # Vulkan Compute
-DTHEMIS_ENABLE_OPENGL=ON        # OpenGL Compute Shaders
-DTHEMIS_ENABLE_METAL=ON         # Apple Metal
-DTHEMIS_ENABLE_ONEAPI=ON        # Intel OneAPI/SYCL
-DTHEMIS_ENABLE_OPENCL=ON        # OpenCL
-DTHEMIS_ENABLE_WEBGPU=ON        # WebGPU (experimental)
```

### Build-Beispiele

**Nur CPU (Default):**
```bash
cmake -S . -B build
cmake --build build
```

**Mit CUDA:**
```bash
cmake -S . -B build -DTHEMIS_ENABLE_CUDA=ON
cmake --build build
```

**Multi-Backend (Vulkan + DirectX):**
```bash
cmake -S . -B build \
  -DTHEMIS_ENABLE_VULKAN=ON \
  -DTHEMIS_ENABLE_DIRECTX=ON
cmake --build build
```

**Auto-Detect (alle verfÃ¼gbaren Backends):**
```bash
cmake -S . -B build \
  -DTHEMIS_ENABLE_GPU=ON \
  -DTHEMIS_ENABLE_CUDA=ON \
  -DTHEMIS_ENABLE_VULKAN=ON \
  -DTHEMIS_ENABLE_DIRECTX=ON
cmake --build build
```

---

## Verwendung

### Automatische Backend-Auswahl

```cpp
#include "acceleration/compute_backend.h"
#include "acceleration/cpu_backend.h"

using namespace themis::acceleration;

// Backend-Registry initialisieren
auto& registry = BackendRegistry::instance();
registry.autoDetect();

// Bestes verfÃ¼gbares Vector-Backend holen
auto* vectorBackend = registry.getBestVectorBackend();

if (vectorBackend) {
    std::cout << "Using backend: " << vectorBackend->name() << std::endl;
    
    // KNN-Suche durchfÃ¼hren
    std::vector<float> query = {0.1f, 0.2f, 0.3f};
    auto results = vectorBackend->batchKnnSearch(
        query.data(), 1, 3,
        vectors.data(), numVectors,
        10, true  // k=10, useL2=true
    );
}
```

### Manuelle Backend-Auswahl

```cpp
// Spezifisches Backend wÃ¤hlen
auto* cudaBackend = registry.getBackend(BackendType::CUDA);

if (cudaBackend && cudaBackend->isAvailable()) {
    cudaBackend->initialize();
    
    // Backend-Capabilities prÃ¼fen
    auto caps = cudaBackend->getCapabilities();
    std::cout << "Device: " << caps.deviceName << std::endl;
    std::cout << "VRAM: " << caps.maxMemoryBytes / (1024*1024*1024) << " GB" << std::endl;
    
    // Operationen durchfÃ¼hren...
    
    cudaBackend->shutdown();
}
```

### Graceful Degradation

```cpp
// Versuche GPU, falle zurÃ¼ck auf CPU
auto* backend = registry.getBestVectorBackend();

if (!backend || backend->type() == BackendType::CPU) {
    std::cout << "GPU nicht verfÃ¼gbar, nutze CPU-Fallback" << std::endl;
}

// Backend ist immer vorhanden (mindestens CPU)
auto results = backend->batchKnnSearch(...);
```

---

## Performance-Erwartungen

### Vector Operations (1M Vektoren, Dimension=128)

| Backend | Batch Size | Throughput | Latency (p50) | Speedup vs CPU |
|---------|------------|------------|---------------|----------------|
| CPU (AVX2) | 100 | 1,800 q/s | 0.55 ms | 1x (Baseline) |
| CUDA (T4) | 1,000 | 25,000 q/s | 0.04 ms | 14x |
| CUDA (A100) | 5,000 | 100,000 q/s | 0.05 ms | 55x |
| Vulkan (RTX 4090) | 2,000 | 40,000 q/s | 0.05 ms | 22x |
| DirectX (RTX 4090) | 2,000 | 35,000 q/s | 0.06 ms | 19x |

### Geo Operations (Spatial Distance)

| Backend | Operations/sec | Speedup |
|---------|---------------|---------|
| CPU | 5,000 | 1x |
| CUDA | 50,000+ | 10x |
| Vulkan | 35,000+ | 7x |

### Graph Operations (BFS, 100K Vertices)

| Backend | Traversals/sec | Speedup |
|---------|----------------|---------|
| CPU | 3,200 | 1x |
| CUDA | 25,000+ | 8x |
| Vulkan | 18,000+ | 6x |

---

## Backend-Spezifikationen

### CUDA (NVIDIA)

**Hardware-Anforderungen:**
- GPU: Compute Capability 7.0+ (Volta, Turing, Ampere, Hopper)
- VRAM: Mindestens 8 GB (empfohlen 16 GB+)
- CUDA Toolkit: 11.0+
- Driver: 450.80.02+

**Features:**
- âœ… Faiss GPU Integration fÃ¼r Vector Search
- âœ… Custom CUDA Kernels fÃ¼r Graph/Geo
- âœ… Async Compute Streams
- âœ… VRAM Management mit Fallback

**Implementierungsstatus:** ğŸš§ Stub (P0 - Q2 2026)

---

### Vulkan (Cross-Platform)

**Hardware-Anforderungen:**
- Vulkan 1.2+ fÃ¤hige GPU
- Compute Queue Support
- Driver mit Vulkan SDK

**Features:**
- âœ… Cross-Platform (Windows, Linux, Android)
- âœ… Compute Pipelines fÃ¼r Batch Operations
- âœ… Memory Transfer Optimization
- âœ… Async Queue Execution

**Vorteile:**
- Funktioniert auf NVIDIA, AMD, Intel GPUs
- Moderne API mit expliziter Kontrolle
- Gute Performance (70-90% von CUDA)

**Implementierungsstatus:** ğŸš§ Stub (P1 - Q2 2026)

---

### DirectX 12 (Windows)

**Hardware-Anforderungen:**
- Windows 10 (1809+) oder Windows 11
- DirectX 12 fÃ¤hige GPU
- WDDM 2.5+ Driver

**Features:**
- âœ… DirectX 12 Compute Shaders
- âœ… DirectML fÃ¼r ML Workloads
- âœ… Windows-native Integration
- âš ï¸ Nur Windows

**Vorteile:**
- Native Windows-Integration
- DirectML fÃ¼r AI/ML Operations
- Breite Hardware-UnterstÃ¼tzung (NVIDIA, AMD, Intel)

**Implementierungsstatus:** ğŸš§ Stub (P2 - Q2/Q3 2026)

---

### HIP (AMD)

**Hardware-Anforderungen:**
- AMD GPU (GCN 4.0+)
- ROCm Platform
- HIP Runtime

**Features:**
- âœ… AMD-native Compute
- âœ… CUDA-Ã¤hnliche API
- âœ… Portierbar von CUDA Code
- âœ… ROCm Integration

**Vorteile:**
- Best Performance auf AMD Hardware
- CUDA-Ã¤hnliche Entwicklererfahrung
- Open Source Stack

**Implementierungsstatus:** ğŸš§ Geplant (P1 - Q3 2026)

---

### ZLUDA (AMD CUDA Compatibility)

**Beschreibung:**
- CUDA-KompatibilitÃ¤tsschicht fÃ¼r AMD GPUs
- ErmÃ¶glicht AusfÃ¼hrung von CUDA Code auf AMD Hardware
- Transparent fÃ¼r CUDA-basierten Code

**Features:**
- âœ… CUDA API Compatibility
- âœ… Funktioniert mit Faiss GPU
- âš ï¸ Performance: 70-85% von nativer AMD HIP

**Use Case:**
- Schnelle AMD GPU Support ohne Code-Ã„nderung
- Fallback wenn HIP nicht verfÃ¼gbar
- Bridge-LÃ¶sung fÃ¼r CUDA-basierte Libraries

**Implementierungsstatus:** ğŸš§ Geplant (P1 - Q3 2026)

---

## Roadmap

### Phase 1: Core Infrastructure (Q1 2026) âœ…
- [x] Backend-Abstraktionsschicht
- [x] CPU Fallback Implementation
- [x] Backend Registry
- [x] CMake Integration
- [x] Stub Implementations

### Phase 2: CUDA Implementation (Q2 2026)
- [ ] CUDA Toolkit Integration
- [ ] Faiss GPU Vector Backend
- [ ] Custom CUDA Kernels (Graph/Geo)
- [ ] Performance Benchmarks
- [ ] Documentation

### Phase 3: Vulkan Implementation (Q2/Q3 2026)
- [ ] Vulkan SDK Integration
- [ ] Compute Pipeline Setup
- [ ] Vector/Graph/Geo Kernels
- [ ] Cross-Platform Testing

### Phase 4: Additional Backends (Q3/Q4 2026)
- [ ] DirectX 12 (Windows)
- [ ] HIP (AMD native)
- [ ] ZLUDA (AMD CUDA compat)
- [ ] Metal (Apple)
- [ ] OneAPI (Intel)

---

## Testing

### Unit Tests

```bash
# Test Backend Registry
./build/themis_tests --gtest_filter=AccelerationTest.BackendRegistry

# Test CPU Backend
./build/themis_tests --gtest_filter=AccelerationTest.CPUBackend

# Test CUDA Backend (wenn verfÃ¼gbar)
./build/themis_tests --gtest_filter=AccelerationTest.CUDABackend
```

### Benchmarks

```bash
# Vector Search Benchmark
./build/bench_vector_accel --backend=auto

# Geo Operations Benchmark
./build/bench_geo_accel --backend=cuda

# Graph Traversal Benchmark
./build/bench_graph_accel --backend=vulkan
```

---

## Troubleshooting

### Backend nicht verfÃ¼gbar

**Problem:** Backend wird nicht erkannt
```
Warning: CUDA backend not available, falling back to CPU
```

**LÃ¶sung:**
1. PrÃ¼fe ob Backend beim Build aktiviert wurde (`-DTHEMIS_ENABLE_CUDA=ON`)
2. PrÃ¼fe Driver/Runtime Installation
3. Verifiziere Hardware-KompatibilitÃ¤t

### VRAM Exhausted

**Problem:** GPU-Speicher voll
```
Error: CUDA out of memory
```

**LÃ¶sung:**
1. Reduziere Batch-Size
2. Aktiviere automatischen CPU-Fallback
3. Nutze Chunked Processing

### Performance nicht wie erwartet

**Problem:** GPU langsamer als CPU

**MÃ¶gliche Ursachen:**
- Batch-Size zu klein (Overhead dominiert)
- Memory Transfer Bottleneck
- Nicht optimierte Kernels

**LÃ¶sung:**
- ErhÃ¶he Batch-Size (1000+ Queries)
- Pre-load Daten in VRAM
- Profile mit `nvprof` / `renderdoc`

---

## WeiterfÃ¼hrende Dokumentation

- **GPU Acceleration Plan:** [`docs/performance/GPU_ACCELERATION_PLAN.md`](GPU_ACCELERATION_PLAN.md)
- **CUDA Setup Guide:** `docs/performance/cuda_setup.md` (coming soon)
- **Vulkan Integration:** `docs/performance/vulkan_integration.md` (coming soon)
- **Performance Tuning:** `docs/performance/gpu_tuning.md` (coming soon)

---

**Kontakt:**
- Issues: https://github.com/makr-code/ThemisDB/issues
- Discussions: https://github.com/makr-code/ThemisDB/discussions

**Version:** 1.0  
**Letzte Aktualisierung:** 20. November 2025
