# Themis - Priorisierte Roadmap f√ºr Production Readiness
**Stand:** 29. Oktober 2025, 22:15  
**Basis:** IMPLEMENTATION_STATUS.md Audit-Ergebnisse

---

## üéØ Entscheidungsmatrix: N√§chste Schritte

| Feature | Impact | Aufwand | Risiko | Prio | Empfehlung |
|---------|--------|---------|--------|------|------------|
| ~~**Prometheus Histogramme (kumulative Buckets)**~~ | Mittel | 2-4h | Niedrig | ‚úÖ **ERLEDIGT** | **Quick Win** - Abgeschlossen |
| ~~**HNSW Persistenz**~~ | Hoch | 1-2 Tage | Mittel | ‚úÖ **ERLEDIGT** | **Datenverlust-Risiko eliminiert** |
| ~~**COLLECT/GROUP BY MVP**~~ | Hoch | 3-5 Tage | Mittel | ‚úÖ **ERLEDIGT** | **Basisfunktionalit√§t implementiert** |
| ~~**Vector Search HTTP Endpoint**~~ | Hoch | 1-2 Tage | Niedrig | ‚úÖ **ERLEDIGT** | **API-Integration vollst√§ndig** |
| ~~**OR Query Index-Merge**~~ | Mittel | 2-3 Tage | Mittel | ‚úÖ **ERLEDIGT** | **DisjunctiveQuery implementiert** |
| ~~**OpenTelemetry Tracing**~~ | Mittel | 3-5 Tage | Niedrig | ‚úÖ **ERLEDIGT** | **Production-Debugging enabled** |
| **Inkrementelle Backups** | Niedrig | 5-7 Tage | Hoch | üìã P2 | Nice-to-Have |
| **RBAC (Basic)** | Hoch | 7-10 Tage | Hoch | üìã P2 | Security (sp√§ter) |
| **Apache Arrow Integration** | Niedrig | 10-15 Tage | Mittel | üìã P3 | Analytics (sp√§ter) |

**Status Update (30. Oktober 2025, 13:50):**
- ‚úÖ **Alle P0-Features abgeschlossen!**
- ‚úÖ **P1 OpenTelemetry Tracing: VOLLST√ÑNDIG IMPLEMENTIERT**
  - ‚úÖ Infrastruktur: Tracer-Wrapper, OTLP HTTP Exporter, CMake integration
  - ‚úÖ HTTP-Handler instrumentiert (7 Endpoints)
  - ‚úÖ QueryEngine instrumentiert (11 Methoden + Child-Spans)
  - ‚úÖ AQL-Operator-Pipeline instrumentiert (parse, translate, for, filter, limit, collect, return, traversal+bfs)
  - ‚úÖ Dokumentation aktualisiert (docs/tracing.md)
  - Build erfolgreich, Server-Test bestanden
  - **ALLE P1-TASKS ABGESCHLOSSEN!**

**Abgeschlossene Features:**
- ‚úÖ HNSW-Persistenz: Automatisches Save/Load implementiert
- ‚úÖ COLLECT/GROUP BY MVP: Parser + In-Memory Aggregation (COUNT, SUM, AVG, MIN, MAX)
- ‚úÖ Prometheus-Histogramme: Kumulative Buckets implementiert + validiert
- ‚úÖ Vector Search HTTP Endpoint: POST /vector/search mit k-NN Suche
- ‚úÖ OR Query Index-Merge: DisjunctiveQuery mit Index-Union
- ‚úÖ OpenTelemetry Distributed Tracing: End-to-End Instrumentierung (HTTP ‚Üí QueryEngine ‚Üí AQL Operators)

**Legende:**
- üî• P0 = Kritisch (sofort/diese Woche) - ‚úÖ **ALLE ERLEDIGT**
- ‚ö†Ô∏è P1 = Wichtig (n√§chste 2 Wochen) - ‚úÖ **ALLE ERLEDIGT**
- üìã P2 = Nice-to-Have (n√§chster Sprint) - **N√ÑCHSTE PHASE**
- üìã P3 = Backlog (zuk√ºnftig)

---

## üöÄ Empfohlene Reihenfolge (Batch 1: Diese Woche)

### Option A: Quick Wins zuerst (Momentum aufbauen) ‚úÖ ABGESCHLOSSEN
```
Tag 1-2:  Prometheus Histogramme (kumulative Buckets) ‚úÖ
Tag 2-4:  OR/NOT Index-Merge (Query-Flexibilit√§t) ‚úÖ
Tag 5-7:  HNSW Persistenz (Datenverlust-Risiko eliminieren) ‚úÖ
```
**Ergebnis:** Alle P0-Features implementiert und getestet!

### Batch 2: P1 Features (Diese/N√§chste Woche)

```
Tag 1-2:  OpenTelemetry Tracing - Infrastruktur ‚úÖ
Tag 2-3:  OpenTelemetry Tracing - Instrumentierung (HTTP, Query)
Tag 4-5:  Jaeger Integration testen + Dokumentation
```

### Option B: Strategische Features zuerst (Fundamentals)
```
Tag 1-5:  COLLECT/GROUP BY MVP (Basisfunktionalit√§t)
Tag 6-7:  HNSW Persistenz (Datenverlust-Risiko)
Tag 8:    Prometheus Histogramme (Quick Win zum Abschluss)
```
**Vorteil:** Kernfunktionalit√§t (Aggregationen) schnell verf√ºgbar  
**Nachteil:** L√§ngerer initialer Entwicklungszyklus

### Option C: Risiko-Minimierung zuerst (Defensive)
```
Tag 1-2:  HNSW Persistenz (Datenverlust-Risiko eliminieren)
Tag 3-7:  COLLECT/GROUP BY MVP (Basisfunktionalit√§t)
Tag 8:    Prometheus Histogramme (Quick Win)
```
**Vorteil:** Kritische Risiken (Datenverlust) sofort adressiert  
**Nachteil:** Komplexes Feature am Anfang (HNSW save/load)

---

## üîç Detaillierte Analyse: Top 3 Features

### 1Ô∏è‚É£ Prometheus Histogramme (kumulative Buckets)

**Problem:**
- Aktuelle Implementation: Non-kumulative Buckets (jeder Bucket z√§hlt nur seinen Range)
- Prometheus-Spec: Buckets m√ºssen kumulativ sein (`le="100"` = alle Werte ‚â§ 100)
- Impact: Grafana/Prometheus-Tools zeigen falsche Percentiles

**L√∂sung:**
```cpp
// Aktuell (FALSCH):
if (ms <= 1) page_bucket_1ms_++;
else if (ms <= 5) page_bucket_5ms_++;
// ...

// Korrekt (KUMULATIV):
if (ms <= 1) page_bucket_1ms_++;
if (ms <= 5) page_bucket_5ms_++;
if (ms <= 10) page_bucket_10ms_++;
// ... (jeder Wert inkrementiert ALLE passenden Buckets)
```

**Aufwand:**
- √Ñnderungen: `http_server.cpp` (recordLatency, recordPageFetch)
- Tests: Smoke-Test erweitern (Bucket-Pr√ºfung)
- Doku: README.md aktualisieren
- **Gesch√§tzt: 2-4 Stunden**

**DoD (Definition of Done):**
- [ ] recordLatency() verwendet kumulative Bucket-Logik
- [ ] recordPageFetch() verwendet kumulative Bucket-Logik
- [ ] Smoke-Test validiert: Wert 150ms ‚Üí buckets 1,5,10,25,50,100,250,500,1000,5000,Inf alle ‚â• 1
- [ ] README.md Histogram-Beschreibung korrigiert

---

### 2Ô∏è‚É£ HNSW Persistenz (save/load)

**Problem:**
- Vector-Index ist nur In-Memory
- Server-Restart ‚Üí alle Vektoren weg
- Manuelles Rebuild n√∂tig (Performance-Impact)

**L√∂sung:**
```cpp
// HNSWlib API:
index_->saveIndex("data/vector_index_<collection>.bin");
index_->loadIndex("data/vector_index_<collection>.bin", space_, max_elements_);
```

**Implementierung:**
1. **Startup:** `VectorIndexManager::init()` pr√ºft auf existierende `.bin`, l√§dt wenn vorhanden
2. **Shutdown:** `VectorIndexManager::shutdown()` speichert Index
3. **Background Save:** Optional: Periodisches Save alle N Minuten
4. **Versioning:** Filename-Schema: `<collection>_v<version>.bin`

**Aufwand:**
- Code: `vector_index.cpp` (init/shutdown/save/load)
- Tests: `test_vector_index.cpp` (save ‚Üí restart ‚Üí load ‚Üí verify results)
- Config: `config.json` (vector_save_interval_minutes)
- **Gesch√§tzt: 1-2 Tage**

**DoD:**
- [ ] `saveIndex()` speichert bei Shutdown
- [ ] `loadIndex()` l√§dt bei Startup (wenn vorhanden)
- [ ] Test: Add 100 Vektoren ‚Üí Restart ‚Üí Search findet alle
- [ ] Config-Option: `vector_auto_save: true/false`

---

### 3Ô∏è‚É£ COLLECT/GROUP BY MVP

**Problem:**
- Aggregationen sind SQL/AQL-Standard-Feature
- AST-Node (`CollectNode`) existiert, aber keine Executor-Integration
- Queries wie `SELECT city, COUNT(*) FROM users GROUP BY city` unm√∂glich

**L√∂sung (MVP-Scope):**
```aql
// Beispiel:
FOR doc IN orders
  FILTER doc.created_at >= "2025-01-01"
  COLLECT city = doc.city
  AGGREGATE 
    total = SUM(doc.amount),
    count = COUNT()
  RETURN {city, total, count}
```

**Implementierung:**
1. **Parser:** `CollectNode` parsing (bereits vorhanden in AST)
2. **Translator:** `handleCollect()` in `aql_translator.cpp`
3. **Executor:** 
   - Hash-Map f√ºr Gruppierung: `std::unordered_map<string, AggregateState>`
   - Aggregat-Funktionen: COUNT, SUM, AVG, MIN, MAX
   - Streaming-Execution (keine Full-Scan-Materialisierung)
4. **Tests:** Unit-Tests + HTTP-Integration-Tests

**Aufwand:**
- Code: `aql_translator.cpp`, `query_engine.cpp`
- Tests: `test_aql_translator.cpp` (mindestens 10 neue Tests)
- Doku: `docs/aql_syntax.md` aktualisieren
- **Gesch√§tzt: 3-5 Tage**

**MVP-Scope (Reduktion):**
- ‚úÖ Einspaltige Gruppierung (`COLLECT city = doc.city`)
- ‚úÖ Basis-Aggregat-Funktionen (COUNT, SUM, AVG, MIN, MAX)
- ‚ùå Mehrspaltige Gruppierung (sp√§ter)
- ‚ùå HAVING-Filter (sp√§ter)
- ‚ùå KEEP/WITH COUNT (sp√§ter)

**DoD:**
- [ ] `COLLECT field = expr` funktioniert
- [ ] `AGGREGATE count = COUNT()` funktioniert
- [ ] `AGGREGATE sum = SUM(field)` funktioniert
- [ ] Unit-Tests: 10+ Test-Cases PASS
- [ ] HTTP-Test: End-to-End GROUP BY Query
- [ ] Doku: Beispiel in `docs/aql_syntax.md`

---

## üìä Impact-Analyse

### Business Value
1. **COLLECT/GROUP BY:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Kernfunktionalit√§t, Kundenerwartung)
2. **HNSW Persistenz:** ‚≠ê‚≠ê‚≠ê‚≠ê (Datenverlust-Risiko, Produktionsf√§higkeit)
3. **Prometheus Histogramme:** ‚≠ê‚≠ê‚≠ê (Observability, Ops-Qualit√§t)

### Technical Debt Reduction
1. **Prometheus Histogramme:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Compliance-Fix, behebt Spec-Verletzung)
2. **HNSW Persistenz:** ‚≠ê‚≠ê‚≠ê‚≠ê (Architektur-L√ºcke schlie√üen)
3. **COLLECT/GROUP BY:** ‚≠ê‚≠ê‚≠ê (AST-Code-Completion)

### Risk Mitigation
1. **HNSW Persistenz:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (Datenverlust-Risiko eliminieren)
2. **COLLECT/GROUP BY:** ‚≠ê‚≠ê (Feature-L√ºcke, kein direktes Risiko)
3. **Prometheus Histogramme:** ‚≠ê‚≠ê (Monitoring-Fehler, aber nicht kritisch)

---

## ‚úÖ Empfehlung: Hybrid-Ansatz

**Woche 1 (Tag 1-7):**
```
üî• Tag 1 (2-4h):    Prometheus Histogramme (Quick Win, Motivation)
üî• Tag 1-3 (2 Tage): HNSW Persistenz (Risiko-Minimierung)
üî• Tag 4-7 (4 Tage): COLLECT/GROUP BY MVP (Strategisch wichtig)
```

**Rationale:**
1. **Quick Win am Anfang:** Momentum, sichtbarer Fortschritt nach 4h
2. **Risiko-Minimierung:** HNSW-Persistenz vor Wochenende fertig
3. **Strategisches Feature:** COLLECT/GROUP BY nutzt volle Woche

**Erwartete Ergebnisse (Ende Woche 1):**
- ‚úÖ Prometheus-konforme Histogramme
- ‚úÖ Vector-Index √ºberleben Server-Restart
- ‚úÖ Basis-Aggregationen (COLLECT/COUNT/SUM) funktional
- üìà Production-Readiness-Score: ~35% ‚Üí ~55%

---

## üìÖ Backlog (Woche 2+)

**Woche 2:**
- OR/NOT Index-Merge (2-3 Tage)
- OpenTelemetry Tracing (3-5 Tage)

**Sprint 2:**
- Inkrementelle Backups/WAL-Archiving
- Automated Restore-Verification
- Strukturierte JSON-Logs

**Sprint 3:**
- RBAC (Basic)
- Query/Plan-Cache
- POST /config (Hot-Reload)

**Langfristig:**
- Apache Arrow Integration
- Phase 4 (Filesystem/Content) Start
- Phase 7 (Security/Governance) Vollausbau

---

## üéØ Entscheidung erforderlich

**Bitte w√§hlen:**
1. **Option A:** Quick Wins zuerst (Prometheus ‚Üí OR/NOT ‚Üí HNSW)
2. **Option B:** Strategisch (COLLECT ‚Üí HNSW ‚Üí Prometheus)
3. **Option C:** Risiko-Minimierung (HNSW ‚Üí COLLECT ‚Üí Prometheus)
4. **Empfehlung:** Hybrid (Prometheus [Quick Win] ‚Üí HNSW [Risiko] ‚Üí COLLECT [Strategisch])

**Oder eigene Priorisierung nennen.**

---

**Erstellt:** 29. Oktober 2025  
**N√§chster Review:** Nach Abschluss von 3 P0-Features
