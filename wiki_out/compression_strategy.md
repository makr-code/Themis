# Komprimierungsstrategie f√ºr ThemisDB

## Executive Summary

**Aktueller Stand:**
- ‚úÖ RocksDB Block-Kompression: LZ4 (Level 0-5) + ZSTD (Level 6+) **IMPLEMENTIERT**
- ‚úÖ Gorilla Time-Series Codec: **IMPLEMENTIERT** (Roundtrip-Fix f√ºr Windows/MSVC)
- üü° Vector-Quantisierung (SQ8): **IMPLEMENTIERT (auto ab 1M)**
- ‚úÖ Gorilla-Integration in TSStore: **IMPLEMENTIERT**
- ‚úÖ Content-Blob-Kompression (ZSTD): **IMPLEMENTIERT**

**Komprimierungs-Potenziale mit Geschwindigkeitseinbu√üen:**

| Datentyp | Aktuell | Vorschlag | Ratio | CPU-Overhead | Speed-Impact | Priorit√§t |
|----------|---------|-----------|-------|--------------|--------------|-----------|
| **Time-Series** | Keine | Gorilla | 10-20x | +15% | -5% read/write | üî¥ **HOCH** |
| **Vektoren (Embeddings)** | Keine | Scalar Quantization (int8) | 4x | +20% | -10% search | üü° **MITTEL** |
| **Vektoren (Embeddings)** | Keine | Product Quantization (PQ) | 8-32x | +50% | -25% search | üü¢ **NIEDRIG** (nur >100M Vektoren) |
| **Content-Blobs (Dokumente)** | RocksDB LZ4/ZSTD | Separates ZSTD (Level 19) | 1.5-2x | +30% | -15% upload | üü° **MITTEL** |
| **JSON Metadata** | RocksDB LZ4 | RocksDB LZ4 (optimal) | ‚Äî | ‚Äî | ‚Äî | ‚úÖ **OPTIMAL** |
| **Graph-Kanten** | RocksDB LZ4 | RocksDB LZ4 (optimal) | ‚Äî | ‚Äî | ‚Äî | ‚úÖ **OPTIMAL** |

---

## 1. Time-Series: Gorilla Compression ‚ö° HOHE PRIORIT√ÑT

### Status Quo
- **Gorilla Codec**: Vollst√§ndig implementiert (`include/timeseries/gorilla.h`, Roundtrip-Tests bestehen)
- **TSStore**: Gorilla-Integration aktiv (Chunk-basiert, dual-scan raw+compressed)

### Benchmark-Daten (Industrie)
- **Ratio**: 10-20x f√ºr typische Metriken (CPU, Memory, Temperatur)
- **CPU-Overhead**: +10-15% Encode, +5% Decode
- **Latenz**: +2ms/10k Punkte (encode), +1ms/10k Punkte (decode)

### Implementierungsvorschlag
```cpp
// In TSStore::put()
if (config.compression == "gorilla") {
    std::vector<uint8_t> compressed = GorillaCodec::encode(timestamps, values);
    db_.put(key, compressed); // Statt raw float64-Array
}

// In TSStore::query()
if (header.compression == "gorilla") {
    auto [ts, vals] = GorillaCodec::decode(blob);
    return vals;
}
```

### Konfiguration
```json
{
  "timeseries": {
    "compression": "gorilla",        // "none", "gorilla", "zstd"
    "chunk_size_hours": 24           // 24h-Chunks optimal f√ºr Gorilla
  }
}
```

### Trade-offs
- ‚úÖ **Speicherersparnis**: 10-20x (100GB ‚Üí 5-10GB)
- ‚úÖ **I/O-Reduktion**: Weniger Disk-IOPS ‚Üí schnellere Aggregationen
- ‚ö†Ô∏è **CPU-Kosten**: +15% bei Ingestion, +5% bei Queries
- ‚ö†Ô∏è **Latenz**: +1-2ms/Query (akzeptabel f√ºr Time-Series-Workloads)

**Empfehlung:** ‚úÖ **IMPLEMENTIEREN** ‚Äî Time-Series-Workloads sind I/O-bound, nicht CPU-bound. Gorilla zahlt sich aus!

---

## 2. Vektoren: Quantisierung (Embeddings)

### Status Quo
- **Storage**: Float32-Vektoren in BaseEntity; ab Schwellwert auto-quantisiert (SQ8) beim Persistieren
- **Compression**: SQ8 mit per-Vektor-Scale auf Disk; In-Memory-Cache bleibt float32 f√ºr Suche
- **HNSWlib**: Unver√§ndert; Vektoren werden beim Laden dequantisiert

### Best-Practice: Scalar Quantization (int8)

**Was ist das?**
- Konvertiere `float32 ‚Üí int8` via Min-Max-Skalierung oder Learned Quantization
- Ratio: **4x Speicherersparnis** (32 Bit ‚Üí 8 Bit)
- Genauigkeit: 95-98% Recall@10 (je nach Datenverteilung)

**FAISS-Benchmark** (768-dim Embeddings, 1M Vektoren):
```
Index Type          Memory (GB)    Search (ms/query)    Recall@10
------------------------------------------------------------------
Flat (float32)           3.0             45                100%
SQ8 (int8)               0.75            38                 97%
PQ16 (16 Codes)          0.1             12                 92%
```

**HNSWlib-Integration:**
- HNSWlib unterst√ºtzt **KEINE native Quantisierung**
- Manuelle Implementierung n√∂tig:
  1. Quantisiere Vektoren vor `addPoint()`
  2. Speichere Quantisierungsparameter (min/max, codebook)
  3. Quantisiere Queryvektoren vor `searchKnn()`

**CPU-Overhead:**
- Encode: +20% (quantize on insert)
- Decode: +10% (dequantize on search)
- Search: -10% schneller (weniger Speicher ‚Üí bessere Cache-Nutzung)

**Implementierungs-Aufwand:** üî¥ **HOCH** (~3-5 Tage, komplexe API-√Ñnderungen)

### Best-Practice: Product Quantization (PQ)

**Was ist das?**
- Teile Vektor in Subvektoren (z.B. 768-dim ‚Üí 16x48-dim)
- Clustere jeden Subvektor (k-means mit 256 Clustern)
- Speichere nur Cluster-IDs (16 Bytes statt 3072 Bytes)
- Ratio: **8-32x Speicherersparnis**

**Wann sinnvoll?**
- ‚ùå **NICHT f√ºr Themis**: PQ lohnt sich erst ab **>10M Vektoren**
- ‚úÖ **Nur f√ºr Hyperscaler**: Google, Meta, Pinecone nutzen PQ
- ‚ö†Ô∏è **Recall-Verlust**: 85-95% Recall@10 (schlechter als SQ8)

**Empfehlung:** üö´ **SKIP** ‚Äî Zu komplex f√ºr Themis, nur f√ºr >10M Vektoren relevant

### Vector Compression: Empfehlung

| Vektoranzahl | Empfehlung | Ratio | Recall | Aufwand |
|--------------|------------|-------|--------|---------|
| < 100k | **Keine Quantisierung** | 1x | 100% | ‚Äî |
| 100k - 1M | **Scalar Quantization (int8)** | 4x | 97% | üü° Mittel |
| > 1M | **Product Quantization (PQ)** | 8-32x | 92% | üî¥ Hoch |

**Aktuelle Themis-Empfehlung:** 
- ‚úÖ Default: **Auto-SQ8 ab 1M Vektoren** (konfigurierbar via `config:vector` ‚Üí `{ "quantization": "auto|none|sq8", "auto_threshold": 1000000 }`)
- ‚úÖ F√ºr <1M: **Float32** (kein Qualit√§tsverlust, minimaler CPU-Overhead)

---

## 3. Content-Blobs: Dedizierte Kompression

### Status Quo
- **Storage**: RocksDB BlobDB mit `blob_size_threshold = 4096` (>4KB ‚Üí Blob-Datei)
- **Compression**: RocksDB Block-Kompression (LZ4/ZSTD) auf gesamten LSM-Tree
- **Problem**: BlobDB-Dateien werden NICHT komprimiert (RocksDB Bug/Limitation)

### Implementiert: Explizite ZSTD-Kompression vor BlobDB

```cpp
// In ContentManager::importContent()
if (blob.size() > 4096 && config.compress_blobs) {
    std::vector<uint8_t> compressed = zstd_compress(blob, level=19); // Max-Ratio
    std::string bkey = "content_blob:" + meta.id;
    storage_->put(bkey, compressed);
    meta.compressed = true;
    meta.compression_type = "zstd";
}
```

### Trade-offs
| Dokumenttyp | Ratio (ZSTD Level 19) | Encode (MB/s) | Decode (MB/s) | CPU-Overhead |
|-------------|-----------------------|---------------|---------------|--------------|
| **PDF** | 3-5x | 20 | 150 | +30% write |
| **DOCX** | 1.2x (schon ZIP) | 50 | 200 | +10% write |
| **TXT** | 4-8x | 30 | 180 | +25% write |
| **JSON** | 5-10x | 25 | 160 | +30% write |
| **Images (JPEG/PNG)** | 1.0x (schon komprimiert) | ‚Äî | ‚Äî | ‚Äî |

**Wann komprimieren?**
```cpp
bool should_compress_blob(const std::string& mime_type, size_t size) {
    // Skip f√ºr bereits komprimierte Formate
    if (mime_type.find("image/") == 0) return false; // JPEG, PNG, WebP
    if (mime_type.find("video/") == 0) return false; // MP4, WebM
    if (mime_type == "application/zip") return false;
    if (mime_type == "application/gzip") return false;
    
    // Komprimiere Text/JSON/XML/PDF
    if (size > 4096) return true; // Nur >4KB
    return false;
}
```

### Benchmark-Szenario
**10.000 PDF-Dokumente √† 500KB (5GB total):**
```
Storage Method          Disk Size    Write (MB/s)    Read (MB/s)
-----------------------------------------------------------------
RocksDB LZ4 (Block)          3.5 GB         120            250
RocksDB ZSTD (Block)         2.8 GB         100            220
ZSTD Level 19 (Blob)         1.5 GB          50            180
```

**Status / Empfehlung:** 
- ‚úÖ **IMPLEMENTIERT** (ContentManager komprimiert ZSTD wenn `config:content.compress_blobs=true` und `size>4KB`, MIME-Filter m√∂glich)
- ‚öôÔ∏è **Config-Keys in DB**: `config:content` ‚Üí `{ "compress_blobs": true, "compression_level": 19, "skip_compressed_mimes": ["image/", "video/", "application/zip", "application/gzip"] }`
- ‚ö†Ô∏è **Skip f√ºr Images/Videos** (schon komprimiert)

---

## 4. JSON Metadata: Optimal (keine √Ñnderung n√∂tig)

### Status Quo
- **ContentMeta, ChunkMeta, BaseEntity**: Gespeichert als JSON-Strings in RocksDB
- **Compression**: RocksDB Block-Kompression (LZ4) ‚Üí **optimal f√ºr JSON**

### Benchmark
**10.000 ContentMeta-Objekte √† 2KB (20MB total):**
```
Compression         Disk Size    Ratio    CPU-Overhead
-------------------------------------------------------
None                  20 MB       1.0x         ‚Äî
LZ4                    8 MB       2.5x        +5%
ZSTD                   6 MB       3.3x       +15%
```

**Empfehlung:** ‚úÖ **KEINE √ÑNDERUNG** ‚Äî RocksDB LZ4 ist optimal f√ºr JSON-Metadaten

---

## 5. Graph-Kanten: Optimal (keine √Ñnderung n√∂tig)

### Status Quo
- **Graph-Edges**: BaseEntity mit `from`, `to`, `label`, `weight`, `properties`
- **Storage**: RocksDB mit Key-Prefix `graph:edge:`
- **Compression**: RocksDB LZ4 (Block-Kompression)

### Benchmark
**100.000 Kanten √† 500 Bytes (50MB total):**
```
Compression         Disk Size    Ratio    CPU-Overhead
-------------------------------------------------------
None                  50 MB       1.0x         ‚Äî
LZ4                   22 MB       2.3x        +5%
ZSTD                  18 MB       2.8x       +12%
```

**Empfehlung:** ‚úÖ **KEINE √ÑNDERUNG** ‚Äî RocksDB LZ4 ist optimal f√ºr Graph-Daten

---

## Implementierungsplan (Priorisiert)

### Phase 1: Time-Series Gorilla (HIGH PRIORITY) üî¥ ‚úÖ DONE
**Aufwand:** ~1-2 Tage  
**Impact:** 10-20x Speicherersparnis, +15% CPU  
**Tasks:**
1. ‚úÖ Gorilla Codec implementiert + getestet
2. ‚úÖ TSStore Integration (Config, Header, Encode/Decode)
3. ‚ùå HTTP-Endpoint `/timeseries/compression/config` (GET/PUT) ‚Äî optional
4. ‚úÖ Benchmarks (compression_ratio, encode_time, decode_time)

**Status:** Integration abgeschlossen; l√§uft defaultm√§√üig (Gorilla-Chunk-basiert) in `TSStore`.

### Phase 2: Content-Blob ZSTD (MEDIUM PRIORITY) üü° ‚úÖ DONE
**Aufwand:** ~1 Tag  
**Impact:** 1.5-2x Speicherersparnis f√ºr Text-Dokumente, +30% CPU  
**Tasks:**
1. ‚úÖ ZSTD-Wrapper (`utils/zstd_codec.h` / `.cpp`)
2. ‚úÖ ContentManager-Integration (Pre-compress vor Speicherung)
3. ‚úÖ MIME-Type-Filter (skip Images/Videos)
4. ‚úÖ Config-Option `config:content.compress_blobs`, `compression_level`, `skip_compressed_mimes`
5. ‚úÖ Tests (roundtrip, verschiedene Dokumenttypen) ‚Äî Manuelle Pr√ºfung

**Status:** ZSTD-Kompression integriert in `ContentManager::importContent()`; Transparente Dekompression in `getContentBlob()`.

### Phase 3: Vector Scalar Quantization (LOW PRIORITY) üü¢ ‚úÖ DONE
**Aufwand:** ~3-5 Tage  
**Impact:** ~4x Speicherersparnis (Disk), -3% Search-Qualit√§t (estimated)  
**Condition:** Automatisch aktiviert ab 1M Vektoren; konfigurierbar via DB-Key `config:vector`  
**Tasks:**
1. ‚úÖ Quantizer-Logik (Per-Vektor Symmetric Quant int8)
2. ‚úÖ VectorIndexManager-Integration (quantize on persist)
3. ‚úÖ Dequantisierung in `rebuildFromStorage` und `bruteForceSearch_` f√ºr on-demand loads
4. ‚ùå Benchmarks (recall@k, speed, memory) ‚Äî Future work

**Status:** SQ8 implementiert in `VectorIndexManager::addEntity`-Varianten; Disk-Storage nutzt `embedding_q` (bytes) + `embedding_scale` (double) statt `embedding` (vec<float>). In-Memory-Cache bleibt float32.

---

## Konfigurationsbeispiel (vollst√§ndig)

```json
{
  "storage": {
    "db_path": "./data/themis",
    "compression_default": "lz4",     // ‚úÖ OPTIMAL f√ºr JSON/Graph
    "compression_bottommost": "zstd", // ‚úÖ OPTIMAL f√ºr alte Daten
    "blob_size_threshold": 4096       // ‚úÖ >4KB ‚Üí BlobDB
  },
  "timeseries": {
    "compression": "gorilla",          // üî¥ TODO: IMPLEMENTIEREN
    "chunk_size_hours": 24
  },
  "content": {
    "compress_blobs": true,            // ‚úÖ IMPLEMENTIERT (via config:content in DB)
    "compression_level": 19,           // ZSTD Level
    "skip_compressed_mimes": [
      "image/", "video/", "application/zip", "application/gzip"
    ]
  },
  "vector": {
    "quantization": "auto",            // ‚úÖ IMPLEMENTIERT: "none", "sq8", "auto" (via config:vector in DB)
    "auto_threshold": 1000000,         // auto SQ8 ab 1M Vektoren
    "dimension": 768
  }
}
```

---

## Best-Practice-Check: Vector Compression ‚úÖ

### Industrie-Standards
| System | Vector Count | Quantization | Warum? |
|--------|--------------|--------------|--------|
| **Pinecone** | >100M | PQ + HNSW | Speicher-Kosten dominant |
| **Weaviate** | <10M | Float32 | Qualit√§t > Speicher |
| **Milvus** | >1M | SQ8/PQ (optional) | Hybrid-Ansatz |
| **Qdrant** | <1M | Float32 (default) | Performance > Speicher |

**Themis Position:** <1M Vektoren ‚Üí Float32 ist **Best-Practice** ‚úÖ

### Wann Quantisierung?
```
IF vector_count > 1M AND memory_cost > compute_cost:
    USE scalar_quantization (SQ8)
ELIF vector_count > 10M AND recall_tolerance < 95%:
    USE product_quantization (PQ)
ELSE:
    USE float32 (OPTIMAL)
```

**Themis:** Aktuell <1M Vektoren ‚Üí **Keine Quantisierung n√∂tig** ‚úÖ

---

## Zusammenfassung

| Feature | Status | Priorit√§t | Aufwand | Ratio | CPU-Overhead |
|---------|--------|-----------|---------|-------|--------------|
| **RocksDB LZ4/ZSTD** | ‚úÖ Implementiert | ‚Äî | ‚Äî | 2.4x | +5% |
| **Gorilla Time-Series** | ‚úÖ Implementiert | üî¥ HOCH | ‚Äî | 10-20x | +15% |
| **Content-Blob ZSTD** | ‚úÖ Implementiert | üü° MITTEL | ‚Äî | 1.5-2x | +30% |
| **Vector SQ8** | ‚úÖ Implementiert (auto ‚â•1M) | üü¢ NIEDRIG | ‚Äî | ~4x (Disk) | +20% |
| **Vector PQ** | üö´ Skip | ‚Äî | ‚Äî | 8-32x | +50% |

**Empfohlene Reihenfolge:**
1. ‚úÖ **Gorilla f√ºr Time-Series** (DONE ‚Äì gr√∂√üter Impact, niedrige Komplexit√§t)
2. ‚úÖ **Content-Blob ZSTD** (DONE ‚Äì mittlerer Impact, niedrige Komplexit√§t)
3. ‚úÖ **Vector SQ8** (DONE ‚Äì auto ab 1M, hohe Komplexit√§t nun implementiert)

**N√§chste Schritte:**
- Recall/Speed-Benchmarks f√ºr SQ8 nachmessen
- Optional: HTTP-Endpoint `/ts/config` f√ºr Gorilla-Optionen
- Migration Tool f√ºr bestehende Float32-Vektoren ‚Üí SQ8
